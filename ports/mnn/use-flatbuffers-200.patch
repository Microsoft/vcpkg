diff --git a/schema/current/BasicOptimizer_generated.h b/schema/current/BasicOptimizer_generated.h
index 6bb12f7e..71dfc330 100644
--- a/schema/current/BasicOptimizer_generated.h
+++ b/schema/current/BasicOptimizer_generated.h
@@ -4,23 +4,26 @@
 #ifndef FLATBUFFERS_GENERATED_BASICOPTIMIZER_MNN_OPTIMIZER_H_
 #define FLATBUFFERS_GENERATED_BASICOPTIMIZER_MNN_OPTIMIZER_H_
 
+#include "flatbuffers/flatbuffers.h"
 
-#include "CaffeOp_generated.h"
-#include "GpuLibrary_generated.h"
-#include "MNN_generated.h"
 #include "TFQuantizeOp_generated.h"
-#include "Tensor_generated.h"
-#include "TensorflowOp_generated.h"
 #include "Type_generated.h"
 #include "UserDefine_generated.h"
+#include "MNN_generated.h"
+#include "CaffeOp_generated.h"
+#include "GpuLibrary_generated.h"
+#include "TensorflowOp_generated.h"
+#include "Tensor_generated.h"
 
 namespace MNN {
 namespace Optimizer {
 
 struct BackendConfig;
+struct BackendConfigBuilder;
 struct BackendConfigT;
 
 struct Merge;
+struct MergeBuilder;
 struct MergeT;
 
 inline const flatbuffers::TypeTable *BackendConfigTypeTable();
@@ -29,22 +32,16 @@ inline const flatbuffers::TypeTable *MergeTypeTable();
 
 struct BackendConfigT : public flatbuffers::NativeTable {
   typedef BackendConfig TableType;
-  int32_t memroy;
-  MNN::ForwardType type;
-  int32_t precision;
-  int32_t power;
-  int32_t numberThread;
-  BackendConfigT()
-      : memroy(0),
-        type(MNN::ForwardType_CPU),
-        precision(0),
-        power(0),
-        numberThread(1) {
-  }
+  int32_t memroy = 0;
+  MNN::ForwardType type = MNN::ForwardType_CPU;
+  int32_t precision = 0;
+  int32_t power = 0;
+  int32_t numberThread = 1;
 };
 
 struct BackendConfig FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
   typedef BackendConfigT NativeTableType;
+  typedef BackendConfigBuilder Builder;
   static const flatbuffers::TypeTable *MiniReflectTypeTable() {
     return BackendConfigTypeTable();
   }
@@ -85,6 +82,7 @@ struct BackendConfig FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
 };
 
 struct BackendConfigBuilder {
+  typedef BackendConfig Table;
   flatbuffers::FlatBufferBuilder &fbb_;
   flatbuffers::uoffset_t start_;
   void add_memroy(int32_t memroy) {
@@ -106,7 +104,6 @@ struct BackendConfigBuilder {
         : fbb_(_fbb) {
     start_ = fbb_.StartTable();
   }
-  BackendConfigBuilder &operator=(const BackendConfigBuilder &);
   flatbuffers::Offset<BackendConfig> Finish() {
     const auto end = fbb_.EndTable(start_);
     auto o = flatbuffers::Offset<BackendConfig>(end);
@@ -134,18 +131,16 @@ flatbuffers::Offset<BackendConfig> CreateBackendConfig(flatbuffers::FlatBufferBu
 
 struct MergeT : public flatbuffers::NativeTable {
   typedef Merge TableType;
-  std::vector<int32_t> outputIndexes;
-  std::vector<int32_t> inputIndexes;
-  int32_t tensorNumber;
-  std::unique_ptr<BackendConfigT> backend;
-  std::vector<std::unique_ptr<MNN::OpT>> oplists;
-  MergeT()
-      : tensorNumber(0) {
-  }
+  std::vector<int32_t> outputIndexes{};
+  std::vector<int32_t> inputIndexes{};
+  int32_t tensorNumber = 0;
+  std::unique_ptr<MNN::Optimizer::BackendConfigT> backend{};
+  std::vector<std::unique_ptr<MNN::OpT>> oplists{};
 };
 
 struct Merge FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
   typedef MergeT NativeTableType;
+  typedef MergeBuilder Builder;
   static const flatbuffers::TypeTable *MiniReflectTypeTable() {
     return MergeTypeTable();
   }
@@ -165,8 +160,8 @@ struct Merge FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
   int32_t tensorNumber() const {
     return GetField<int32_t>(VT_TENSORNUMBER, 0);
   }
-  const BackendConfig *backend() const {
-    return GetPointer<const BackendConfig *>(VT_BACKEND);
+  const MNN::Optimizer::BackendConfig *backend() const {
+    return GetPointer<const MNN::Optimizer::BackendConfig *>(VT_BACKEND);
   }
   const flatbuffers::Vector<flatbuffers::Offset<MNN::Op>> *oplists() const {
     return GetPointer<const flatbuffers::Vector<flatbuffers::Offset<MNN::Op>> *>(VT_OPLISTS);
@@ -191,6 +186,7 @@ struct Merge FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
 };
 
 struct MergeBuilder {
+  typedef Merge Table;
   flatbuffers::FlatBufferBuilder &fbb_;
   flatbuffers::uoffset_t start_;
   void add_outputIndexes(flatbuffers::Offset<flatbuffers::Vector<int32_t>> outputIndexes) {
@@ -202,7 +198,7 @@ struct MergeBuilder {
   void add_tensorNumber(int32_t tensorNumber) {
     fbb_.AddElement<int32_t>(Merge::VT_TENSORNUMBER, tensorNumber, 0);
   }
-  void add_backend(flatbuffers::Offset<BackendConfig> backend) {
+  void add_backend(flatbuffers::Offset<MNN::Optimizer::BackendConfig> backend) {
     fbb_.AddOffset(Merge::VT_BACKEND, backend);
   }
   void add_oplists(flatbuffers::Offset<flatbuffers::Vector<flatbuffers::Offset<MNN::Op>>> oplists) {
@@ -212,7 +208,6 @@ struct MergeBuilder {
         : fbb_(_fbb) {
     start_ = fbb_.StartTable();
   }
-  MergeBuilder &operator=(const MergeBuilder &);
   flatbuffers::Offset<Merge> Finish() {
     const auto end = fbb_.EndTable(start_);
     auto o = flatbuffers::Offset<Merge>(end);
@@ -225,7 +220,7 @@ inline flatbuffers::Offset<Merge> CreateMerge(
     flatbuffers::Offset<flatbuffers::Vector<int32_t>> outputIndexes = 0,
     flatbuffers::Offset<flatbuffers::Vector<int32_t>> inputIndexes = 0,
     int32_t tensorNumber = 0,
-    flatbuffers::Offset<BackendConfig> backend = 0,
+    flatbuffers::Offset<MNN::Optimizer::BackendConfig> backend = 0,
     flatbuffers::Offset<flatbuffers::Vector<flatbuffers::Offset<MNN::Op>>> oplists = 0) {
   MergeBuilder builder_(_fbb);
   builder_.add_oplists(oplists);
@@ -241,7 +236,7 @@ inline flatbuffers::Offset<Merge> CreateMergeDirect(
     const std::vector<int32_t> *outputIndexes = nullptr,
     const std::vector<int32_t> *inputIndexes = nullptr,
     int32_t tensorNumber = 0,
-    flatbuffers::Offset<BackendConfig> backend = 0,
+    flatbuffers::Offset<MNN::Optimizer::BackendConfig> backend = 0,
     const std::vector<flatbuffers::Offset<MNN::Op>> *oplists = nullptr) {
   auto outputIndexes__ = outputIndexes ? _fbb.CreateVector<int32_t>(*outputIndexes) : 0;
   auto inputIndexes__ = inputIndexes ? _fbb.CreateVector<int32_t>(*inputIndexes) : 0;
@@ -258,19 +253,19 @@ inline flatbuffers::Offset<Merge> CreateMergeDirect(
 flatbuffers::Offset<Merge> CreateMerge(flatbuffers::FlatBufferBuilder &_fbb, const MergeT *_o, const flatbuffers::rehasher_function_t *_rehasher = nullptr);
 
 inline BackendConfigT *BackendConfig::UnPack(const flatbuffers::resolver_function_t *_resolver) const {
-  auto _o = new BackendConfigT();
-  UnPackTo(_o, _resolver);
-  return _o;
+  auto _o = std::unique_ptr<BackendConfigT>(new BackendConfigT());
+  UnPackTo(_o.get(), _resolver);
+  return _o.release();
 }
 
 inline void BackendConfig::UnPackTo(BackendConfigT *_o, const flatbuffers::resolver_function_t *_resolver) const {
   (void)_o;
   (void)_resolver;
-  { auto _e = memroy(); _o->memroy = _e; };
-  { auto _e = type(); _o->type = _e; };
-  { auto _e = precision(); _o->precision = _e; };
-  { auto _e = power(); _o->power = _e; };
-  { auto _e = numberThread(); _o->numberThread = _e; };
+  { auto _e = memroy(); _o->memroy = _e; }
+  { auto _e = type(); _o->type = _e; }
+  { auto _e = precision(); _o->precision = _e; }
+  { auto _e = power(); _o->power = _e; }
+  { auto _e = numberThread(); _o->numberThread = _e; }
 }
 
 inline flatbuffers::Offset<BackendConfig> BackendConfig::Pack(flatbuffers::FlatBufferBuilder &_fbb, const BackendConfigT* _o, const flatbuffers::rehasher_function_t *_rehasher) {
@@ -296,19 +291,19 @@ inline flatbuffers::Offset<BackendConfig> CreateBackendConfig(flatbuffers::FlatB
 }
 
 inline MergeT *Merge::UnPack(const flatbuffers::resolver_function_t *_resolver) const {
-  auto _o = new MergeT();
-  UnPackTo(_o, _resolver);
-  return _o;
+  auto _o = std::unique_ptr<MergeT>(new MergeT());
+  UnPackTo(_o.get(), _resolver);
+  return _o.release();
 }
 
 inline void Merge::UnPackTo(MergeT *_o, const flatbuffers::resolver_function_t *_resolver) const {
   (void)_o;
   (void)_resolver;
-  { auto _e = outputIndexes(); if (_e) { _o->outputIndexes.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->outputIndexes[_i] = _e->Get(_i); } } };
-  { auto _e = inputIndexes(); if (_e) { _o->inputIndexes.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->inputIndexes[_i] = _e->Get(_i); } } };
-  { auto _e = tensorNumber(); _o->tensorNumber = _e; };
-  { auto _e = backend(); if (_e) _o->backend = std::unique_ptr<BackendConfigT>(_e->UnPack(_resolver)); };
-  { auto _e = oplists(); if (_e) { _o->oplists.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->oplists[_i] = std::unique_ptr<MNN::OpT>(_e->Get(_i)->UnPack(_resolver)); } } };
+  { auto _e = outputIndexes(); if (_e) { _o->outputIndexes.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->outputIndexes[_i] = _e->Get(_i); } } }
+  { auto _e = inputIndexes(); if (_e) { _o->inputIndexes.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->inputIndexes[_i] = _e->Get(_i); } } }
+  { auto _e = tensorNumber(); _o->tensorNumber = _e; }
+  { auto _e = backend(); if (_e) _o->backend = std::unique_ptr<MNN::Optimizer::BackendConfigT>(_e->UnPack(_resolver)); }
+  { auto _e = oplists(); if (_e) { _o->oplists.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->oplists[_i] = std::unique_ptr<MNN::OpT>(_e->Get(_i)->UnPack(_resolver)); } } }
 }
 
 inline flatbuffers::Offset<Merge> Merge::Pack(flatbuffers::FlatBufferBuilder &_fbb, const MergeT* _o, const flatbuffers::rehasher_function_t *_rehasher) {
@@ -352,7 +347,7 @@ inline const flatbuffers::TypeTable *BackendConfigTypeTable() {
     "numberThread"
   };
   static const flatbuffers::TypeTable tt = {
-    flatbuffers::ST_TABLE, 5, type_codes, type_refs, nullptr, names
+    flatbuffers::ST_TABLE, 5, type_codes, type_refs, nullptr, nullptr, names
   };
   return &tt;
 }
@@ -366,7 +361,7 @@ inline const flatbuffers::TypeTable *MergeTypeTable() {
     { flatbuffers::ET_SEQUENCE, 1, 1 }
   };
   static const flatbuffers::TypeFunction type_refs[] = {
-    BackendConfigTypeTable,
+    MNN::Optimizer::BackendConfigTypeTable,
     MNN::OpTypeTable
   };
   static const char * const names[] = {
@@ -377,7 +372,7 @@ inline const flatbuffers::TypeTable *MergeTypeTable() {
     "oplists"
   };
   static const flatbuffers::TypeTable tt = {
-    flatbuffers::ST_TABLE, 5, type_codes, type_refs, nullptr, names
+    flatbuffers::ST_TABLE, 5, type_codes, type_refs, nullptr, nullptr, names
   };
   return &tt;
 }
diff --git a/schema/current/CaffeOp_generated.h b/schema/current/CaffeOp_generated.h
index 12bc81f2..2f9b63bf 100644
--- a/schema/current/CaffeOp_generated.h
+++ b/schema/current/CaffeOp_generated.h
@@ -4,109 +4,143 @@
 #ifndef FLATBUFFERS_GENERATED_CAFFEOP_MNN_H_
 #define FLATBUFFERS_GENERATED_CAFFEOP_MNN_H_
 
+#include "flatbuffers/flatbuffers.h"
 
-#include "Tensor_generated.h"
 #include "Type_generated.h"
+#include "Tensor_generated.h"
 
 namespace MNN {
 
 struct Convolution2DCommon;
+struct Convolution2DCommonBuilder;
 struct Convolution2DCommonT;
 
 struct Convolution3DCommon;
+struct Convolution3DCommonBuilder;
 struct Convolution3DCommonT;
 
 struct IDSTQuan;
+struct IDSTQuanBuilder;
 struct IDSTQuanT;
 
 struct QuantizedFloatParam;
+struct QuantizedFloatParamBuilder;
 struct QuantizedFloatParamT;
 
 struct Convolution2D;
+struct Convolution2DBuilder;
 struct Convolution2DT;
 
 struct Convolution3D;
+struct Convolution3DBuilder;
 struct Convolution3DT;
 
 struct InnerProduct;
+struct InnerProductBuilder;
 struct InnerProductT;
 
 struct Pool;
+struct PoolBuilder;
 struct PoolT;
 
 struct Pool3D;
+struct Pool3DBuilder;
 struct Pool3DT;
 
 struct Relu;
+struct ReluBuilder;
 struct ReluT;
 
 struct Relu6;
+struct Relu6Builder;
 struct Relu6T;
 
 struct PRelu;
+struct PReluBuilder;
 struct PReluT;
 
 struct ELU;
+struct ELUBuilder;
 struct ELUT;
 
 struct LRN;
+struct LRNBuilder;
 struct LRNT;
 
 struct ArgMax;
+struct ArgMaxBuilder;
 struct ArgMaxT;
 
 struct Axis;
+struct AxisBuilder;
 struct AxisT;
 
 struct Input;
+struct InputBuilder;
 struct InputT;
 
 struct LSTM;
+struct LSTMBuilder;
 struct LSTMT;
 
 struct Slice;
+struct SliceBuilder;
 struct SliceT;
 
 struct BatchNorm;
+struct BatchNormBuilder;
 struct BatchNormT;
 
 struct Scale;
+struct ScaleBuilder;
 struct ScaleT;
 
 struct Eltwise;
+struct EltwiseBuilder;
 struct EltwiseT;
 
 struct Flatten;
+struct FlattenBuilder;
 struct FlattenT;
 
 struct Permute;
+struct PermuteBuilder;
 struct PermuteT;
 
 struct Reshape;
+struct ReshapeBuilder;
 struct ReshapeT;
 
 struct DetectionOutput;
+struct DetectionOutputBuilder;
 struct DetectionOutputT;
 
 struct RoiPooling;
+struct RoiPoolingBuilder;
 struct RoiPoolingT;
 
 struct Proposal;
+struct ProposalBuilder;
 struct ProposalT;
 
 struct Interp;
+struct InterpBuilder;
 struct InterpT;
 
 struct Resize;
+struct ResizeBuilder;
 struct ResizeT;
 
 struct PriorBox;
+struct PriorBoxBuilder;
 struct PriorBoxT;
 
 struct Normalize;
+struct NormalizeBuilder;
 struct NormalizeT;
 
 struct EltwiseInt8;
+struct EltwiseInt8Builder;
 struct EltwiseInt8T;
 
 inline const flatbuffers::TypeTable *Convolution2DCommonTypeTable();
@@ -175,7 +209,7 @@ inline const flatbuffers::TypeTable *NormalizeTypeTable();
 
 inline const flatbuffers::TypeTable *EltwiseInt8TypeTable();
 
-enum PadMode {
+enum PadMode : int8_t {
   PadMode_CAFFE = 0,
   PadMode_VALID = 1,
   PadMode_SAME = 2,
@@ -193,7 +227,7 @@ inline const PadMode (&EnumValuesPadMode())[3] {
 }
 
 inline const char * const *EnumNamesPadMode() {
-  static const char * const names[] = {
+  static const char * const names[4] = {
     "CAFFE",
     "VALID",
     "SAME",
@@ -203,12 +237,12 @@ inline const char * const *EnumNamesPadMode() {
 }
 
 inline const char *EnumNamePadMode(PadMode e) {
-  if (e < PadMode_CAFFE || e > PadMode_SAME) return "";
-  const size_t index = static_cast<int>(e);
+  if (flatbuffers::IsOutRange(e, PadMode_CAFFE, PadMode_SAME)) return "";
+  const size_t index = static_cast<size_t>(e);
   return EnumNamesPadMode()[index];
 }
 
-enum QuantizeAlgo {
+enum QuantizeAlgo : int8_t {
   QuantizeAlgo_DEFAULT = 0,
   QuantizeAlgo_OVERFLOW_AWARE = 1,
   QuantizeAlgo_MIN = QuantizeAlgo_DEFAULT,
@@ -224,7 +258,7 @@ inline const QuantizeAlgo (&EnumValuesQuantizeAlgo())[2] {
 }
 
 inline const char * const *EnumNamesQuantizeAlgo() {
-  static const char * const names[] = {
+  static const char * const names[3] = {
     "DEFAULT",
     "OVERFLOW_AWARE",
     nullptr
@@ -233,12 +267,12 @@ inline const char * const *EnumNamesQuantizeAlgo() {
 }
 
 inline const char *EnumNameQuantizeAlgo(QuantizeAlgo e) {
-  if (e < QuantizeAlgo_DEFAULT || e > QuantizeAlgo_OVERFLOW_AWARE) return "";
-  const size_t index = static_cast<int>(e);
+  if (flatbuffers::IsOutRange(e, QuantizeAlgo_DEFAULT, QuantizeAlgo_OVERFLOW_AWARE)) return "";
+  const size_t index = static_cast<size_t>(e);
   return EnumNamesQuantizeAlgo()[index];
 }
 
-enum PoolType {
+enum PoolType : int8_t {
   PoolType_MAXPOOL = 0,
   PoolType_AVEPOOL = 1,
   PoolType_MIN = PoolType_MAXPOOL,
@@ -254,7 +288,7 @@ inline const PoolType (&EnumValuesPoolType())[2] {
 }
 
 inline const char * const *EnumNamesPoolType() {
-  static const char * const names[] = {
+  static const char * const names[3] = {
     "MAXPOOL",
     "AVEPOOL",
     nullptr
@@ -263,12 +297,12 @@ inline const char * const *EnumNamesPoolType() {
 }
 
 inline const char *EnumNamePoolType(PoolType e) {
-  if (e < PoolType_MAXPOOL || e > PoolType_AVEPOOL) return "";
-  const size_t index = static_cast<int>(e);
+  if (flatbuffers::IsOutRange(e, PoolType_MAXPOOL, PoolType_AVEPOOL)) return "";
+  const size_t index = static_cast<size_t>(e);
   return EnumNamesPoolType()[index];
 }
 
-enum PoolPadType {
+enum PoolPadType : int8_t {
   PoolPadType_CAFFE = 0,
   PoolPadType_VALID = 1,
   PoolPadType_SAME = 2,
@@ -286,7 +320,7 @@ inline const PoolPadType (&EnumValuesPoolPadType())[3] {
 }
 
 inline const char * const *EnumNamesPoolPadType() {
-  static const char * const names[] = {
+  static const char * const names[4] = {
     "CAFFE",
     "VALID",
     "SAME",
@@ -296,12 +330,12 @@ inline const char * const *EnumNamesPoolPadType() {
 }
 
 inline const char *EnumNamePoolPadType(PoolPadType e) {
-  if (e < PoolPadType_CAFFE || e > PoolPadType_SAME) return "";
-  const size_t index = static_cast<int>(e);
+  if (flatbuffers::IsOutRange(e, PoolPadType_CAFFE, PoolPadType_SAME)) return "";
+  const size_t index = static_cast<size_t>(e);
   return EnumNamesPoolPadType()[index];
 }
 
-enum AvgPoolCountType {
+enum AvgPoolCountType : int8_t {
   AvgPoolCountType_DEFAULT = 0,
   AvgPoolCountType_INCLUDE_PADDING = 1,
   AvgPoolCountType_EXCLUDE_PADDING = 2,
@@ -319,7 +353,7 @@ inline const AvgPoolCountType (&EnumValuesAvgPoolCountType())[3] {
 }
 
 inline const char * const *EnumNamesAvgPoolCountType() {
-  static const char * const names[] = {
+  static const char * const names[4] = {
     "DEFAULT",
     "INCLUDE_PADDING",
     "EXCLUDE_PADDING",
@@ -329,12 +363,12 @@ inline const char * const *EnumNamesAvgPoolCountType() {
 }
 
 inline const char *EnumNameAvgPoolCountType(AvgPoolCountType e) {
-  if (e < AvgPoolCountType_DEFAULT || e > AvgPoolCountType_EXCLUDE_PADDING) return "";
-  const size_t index = static_cast<int>(e);
+  if (flatbuffers::IsOutRange(e, AvgPoolCountType_DEFAULT, AvgPoolCountType_EXCLUDE_PADDING)) return "";
+  const size_t index = static_cast<size_t>(e);
   return EnumNamesAvgPoolCountType()[index];
 }
 
-enum EltwiseType {
+enum EltwiseType : int8_t {
   EltwiseType_PROD = 0,
   EltwiseType_SUM = 1,
   EltwiseType_MAXIMUM = 2,
@@ -354,7 +388,7 @@ inline const EltwiseType (&EnumValuesEltwiseType())[4] {
 }
 
 inline const char * const *EnumNamesEltwiseType() {
-  static const char * const names[] = {
+  static const char * const names[5] = {
     "PROD",
     "SUM",
     "MAXIMUM",
@@ -365,12 +399,12 @@ inline const char * const *EnumNamesEltwiseType() {
 }
 
 inline const char *EnumNameEltwiseType(EltwiseType e) {
-  if (e < EltwiseType_PROD || e > EltwiseType_SUB) return "";
-  const size_t index = static_cast<int>(e);
+  if (flatbuffers::IsOutRange(e, EltwiseType_PROD, EltwiseType_SUB)) return "";
+  const size_t index = static_cast<size_t>(e);
   return EnumNamesEltwiseType()[index];
 }
 
-enum CoordinateTransformationMode {
+enum CoordinateTransformationMode : int8_t {
   CoordinateTransformationMode_NotSet = 0,
   CoordinateTransformationMode_AlignCorners = 1,
   CoordinateTransformationMode_HalfPixels = 2,
@@ -396,7 +430,7 @@ inline const CoordinateTransformationMode (&EnumValuesCoordinateTransformationMo
 }
 
 inline const char * const *EnumNamesCoordinateTransformationMode() {
-  static const char * const names[] = {
+  static const char * const names[8] = {
     "NotSet",
     "AlignCorners",
     "HalfPixels",
@@ -410,49 +444,34 @@ inline const char * const *EnumNamesCoordinateTransformationMode() {
 }
 
 inline const char *EnumNameCoordinateTransformationMode(CoordinateTransformationMode e) {
-  if (e < CoordinateTransformationMode_NotSet || e > CoordinateTransformationMode_TensorflowCropAndResize) return "";
-  const size_t index = static_cast<int>(e);
+  if (flatbuffers::IsOutRange(e, CoordinateTransformationMode_NotSet, CoordinateTransformationMode_TensorflowCropAndResize)) return "";
+  const size_t index = static_cast<size_t>(e);
   return EnumNamesCoordinateTransformationMode()[index];
 }
 
 struct Convolution2DCommonT : public flatbuffers::NativeTable {
   typedef Convolution2DCommon TableType;
-  int32_t padX;
-  int32_t padY;
-  int32_t kernelX;
-  int32_t kernelY;
-  int32_t strideX;
-  int32_t strideY;
-  int32_t dilateX;
-  int32_t dilateY;
-  PadMode padMode;
-  int32_t group;
-  int32_t outputCount;
-  int32_t inputCount;
-  bool relu;
-  bool relu6;
-  std::vector<int32_t> pads;
-  std::vector<int32_t> outPads;
-  Convolution2DCommonT()
-      : padX(0),
-        padY(0),
-        kernelX(1),
-        kernelY(1),
-        strideX(1),
-        strideY(1),
-        dilateX(1),
-        dilateY(1),
-        padMode(PadMode_CAFFE),
-        group(1),
-        outputCount(0),
-        inputCount(0),
-        relu(false),
-        relu6(false) {
-  }
+  int32_t padX = 0;
+  int32_t padY = 0;
+  int32_t kernelX = 1;
+  int32_t kernelY = 1;
+  int32_t strideX = 1;
+  int32_t strideY = 1;
+  int32_t dilateX = 1;
+  int32_t dilateY = 1;
+  MNN::PadMode padMode = MNN::PadMode_CAFFE;
+  int32_t group = 1;
+  int32_t outputCount = 0;
+  int32_t inputCount = 0;
+  bool relu = false;
+  bool relu6 = false;
+  std::vector<int32_t> pads{};
+  std::vector<int32_t> outPads{};
 };
 
 struct Convolution2DCommon FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
   typedef Convolution2DCommonT NativeTableType;
+  typedef Convolution2DCommonBuilder Builder;
   static const flatbuffers::TypeTable *MiniReflectTypeTable() {
     return Convolution2DCommonTypeTable();
   }
@@ -498,8 +517,8 @@ struct Convolution2DCommon FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table
   int32_t dilateY() const {
     return GetField<int32_t>(VT_DILATEY, 1);
   }
-  PadMode padMode() const {
-    return static_cast<PadMode>(GetField<int8_t>(VT_PADMODE, 0));
+  MNN::PadMode padMode() const {
+    return static_cast<MNN::PadMode>(GetField<int8_t>(VT_PADMODE, 0));
   }
   int32_t group() const {
     return GetField<int32_t>(VT_GROUP, 1);
@@ -550,6 +569,7 @@ struct Convolution2DCommon FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table
 };
 
 struct Convolution2DCommonBuilder {
+  typedef Convolution2DCommon Table;
   flatbuffers::FlatBufferBuilder &fbb_;
   flatbuffers::uoffset_t start_;
   void add_padX(int32_t padX) {
@@ -576,7 +596,7 @@ struct Convolution2DCommonBuilder {
   void add_dilateY(int32_t dilateY) {
     fbb_.AddElement<int32_t>(Convolution2DCommon::VT_DILATEY, dilateY, 1);
   }
-  void add_padMode(PadMode padMode) {
+  void add_padMode(MNN::PadMode padMode) {
     fbb_.AddElement<int8_t>(Convolution2DCommon::VT_PADMODE, static_cast<int8_t>(padMode), 0);
   }
   void add_group(int32_t group) {
@@ -604,7 +624,6 @@ struct Convolution2DCommonBuilder {
         : fbb_(_fbb) {
     start_ = fbb_.StartTable();
   }
-  Convolution2DCommonBuilder &operator=(const Convolution2DCommonBuilder &);
   flatbuffers::Offset<Convolution2DCommon> Finish() {
     const auto end = fbb_.EndTable(start_);
     auto o = flatbuffers::Offset<Convolution2DCommon>(end);
@@ -622,7 +641,7 @@ inline flatbuffers::Offset<Convolution2DCommon> CreateConvolution2DCommon(
     int32_t strideY = 1,
     int32_t dilateX = 1,
     int32_t dilateY = 1,
-    PadMode padMode = PadMode_CAFFE,
+    MNN::PadMode padMode = MNN::PadMode_CAFFE,
     int32_t group = 1,
     int32_t outputCount = 0,
     int32_t inputCount = 0,
@@ -660,7 +679,7 @@ inline flatbuffers::Offset<Convolution2DCommon> CreateConvolution2DCommonDirect(
     int32_t strideY = 1,
     int32_t dilateX = 1,
     int32_t dilateY = 1,
-    PadMode padMode = PadMode_CAFFE,
+    MNN::PadMode padMode = MNN::PadMode_CAFFE,
     int32_t group = 1,
     int32_t outputCount = 0,
     int32_t inputCount = 0,
@@ -694,26 +713,20 @@ flatbuffers::Offset<Convolution2DCommon> CreateConvolution2DCommon(flatbuffers::
 
 struct Convolution3DCommonT : public flatbuffers::NativeTable {
   typedef Convolution3DCommon TableType;
-  std::vector<int32_t> dilates;
-  std::vector<int32_t> strides;
-  std::vector<int32_t> kernels;
-  std::vector<int32_t> pads;
-  PadMode padMode;
-  int32_t inputCount;
-  int32_t outputCount;
-  bool relu;
-  bool relu6;
-  Convolution3DCommonT()
-      : padMode(PadMode_CAFFE),
-        inputCount(0),
-        outputCount(0),
-        relu(false),
-        relu6(false) {
-  }
+  std::vector<int32_t> dilates{};
+  std::vector<int32_t> strides{};
+  std::vector<int32_t> kernels{};
+  std::vector<int32_t> pads{};
+  MNN::PadMode padMode = MNN::PadMode_CAFFE;
+  int32_t inputCount = 0;
+  int32_t outputCount = 0;
+  bool relu = false;
+  bool relu6 = false;
 };
 
 struct Convolution3DCommon FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
   typedef Convolution3DCommonT NativeTableType;
+  typedef Convolution3DCommonBuilder Builder;
   static const flatbuffers::TypeTable *MiniReflectTypeTable() {
     return Convolution3DCommonTypeTable();
   }
@@ -740,8 +753,8 @@ struct Convolution3DCommon FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table
   const flatbuffers::Vector<int32_t> *pads() const {
     return GetPointer<const flatbuffers::Vector<int32_t> *>(VT_PADS);
   }
-  PadMode padMode() const {
-    return static_cast<PadMode>(GetField<int8_t>(VT_PADMODE, 0));
+  MNN::PadMode padMode() const {
+    return static_cast<MNN::PadMode>(GetField<int8_t>(VT_PADMODE, 0));
   }
   int32_t inputCount() const {
     return GetField<int32_t>(VT_INPUTCOUNT, 0);
@@ -778,6 +791,7 @@ struct Convolution3DCommon FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table
 };
 
 struct Convolution3DCommonBuilder {
+  typedef Convolution3DCommon Table;
   flatbuffers::FlatBufferBuilder &fbb_;
   flatbuffers::uoffset_t start_;
   void add_dilates(flatbuffers::Offset<flatbuffers::Vector<int32_t>> dilates) {
@@ -792,7 +806,7 @@ struct Convolution3DCommonBuilder {
   void add_pads(flatbuffers::Offset<flatbuffers::Vector<int32_t>> pads) {
     fbb_.AddOffset(Convolution3DCommon::VT_PADS, pads);
   }
-  void add_padMode(PadMode padMode) {
+  void add_padMode(MNN::PadMode padMode) {
     fbb_.AddElement<int8_t>(Convolution3DCommon::VT_PADMODE, static_cast<int8_t>(padMode), 0);
   }
   void add_inputCount(int32_t inputCount) {
@@ -811,7 +825,6 @@ struct Convolution3DCommonBuilder {
         : fbb_(_fbb) {
     start_ = fbb_.StartTable();
   }
-  Convolution3DCommonBuilder &operator=(const Convolution3DCommonBuilder &);
   flatbuffers::Offset<Convolution3DCommon> Finish() {
     const auto end = fbb_.EndTable(start_);
     auto o = flatbuffers::Offset<Convolution3DCommon>(end);
@@ -825,7 +838,7 @@ inline flatbuffers::Offset<Convolution3DCommon> CreateConvolution3DCommon(
     flatbuffers::Offset<flatbuffers::Vector<int32_t>> strides = 0,
     flatbuffers::Offset<flatbuffers::Vector<int32_t>> kernels = 0,
     flatbuffers::Offset<flatbuffers::Vector<int32_t>> pads = 0,
-    PadMode padMode = PadMode_CAFFE,
+    MNN::PadMode padMode = MNN::PadMode_CAFFE,
     int32_t inputCount = 0,
     int32_t outputCount = 0,
     bool relu = false,
@@ -849,7 +862,7 @@ inline flatbuffers::Offset<Convolution3DCommon> CreateConvolution3DCommonDirect(
     const std::vector<int32_t> *strides = nullptr,
     const std::vector<int32_t> *kernels = nullptr,
     const std::vector<int32_t> *pads = nullptr,
-    PadMode padMode = PadMode_CAFFE,
+    MNN::PadMode padMode = MNN::PadMode_CAFFE,
     int32_t inputCount = 0,
     int32_t outputCount = 0,
     bool relu = false,
@@ -875,32 +888,22 @@ flatbuffers::Offset<Convolution3DCommon> CreateConvolution3DCommon(flatbuffers::
 
 struct IDSTQuanT : public flatbuffers::NativeTable {
   typedef IDSTQuan TableType;
-  std::vector<int8_t> buffer;
-  std::vector<float> alpha;
-  int32_t type;
-  bool useInt32;
-  float quantScale;
-  float scaleIn;
-  float scaleOut;
-  int32_t aMax;
-  int32_t aMin;
-  int32_t readType;
-  bool has_scaleInt;
-  IDSTQuanT()
-      : type(0),
-        useInt32(false),
-        quantScale(0.0f),
-        scaleIn(0.0f),
-        scaleOut(0.0f),
-        aMax(0),
-        aMin(0),
-        readType(0),
-        has_scaleInt(false) {
-  }
+  std::vector<int8_t> buffer{};
+  std::vector<float> alpha{};
+  int32_t type = 0;
+  bool useInt32 = false;
+  float quantScale = 0.0f;
+  float scaleIn = 0.0f;
+  float scaleOut = 0.0f;
+  int32_t aMax = 0;
+  int32_t aMin = 0;
+  int32_t readType = 0;
+  bool has_scaleInt = false;
 };
 
 struct IDSTQuan FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
   typedef IDSTQuanT NativeTableType;
+  typedef IDSTQuanBuilder Builder;
   static const flatbuffers::TypeTable *MiniReflectTypeTable() {
     return IDSTQuanTypeTable();
   }
@@ -973,6 +976,7 @@ struct IDSTQuan FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
 };
 
 struct IDSTQuanBuilder {
+  typedef IDSTQuan Table;
   flatbuffers::FlatBufferBuilder &fbb_;
   flatbuffers::uoffset_t start_;
   void add_buffer(flatbuffers::Offset<flatbuffers::Vector<int8_t>> buffer) {
@@ -1012,7 +1016,6 @@ struct IDSTQuanBuilder {
         : fbb_(_fbb) {
     start_ = fbb_.StartTable();
   }
-  IDSTQuanBuilder &operator=(const IDSTQuanBuilder &);
   flatbuffers::Offset<IDSTQuan> Finish() {
     const auto end = fbb_.EndTable(start_);
     auto o = flatbuffers::Offset<IDSTQuan>(end);
@@ -1082,20 +1085,17 @@ flatbuffers::Offset<IDSTQuan> CreateIDSTQuan(flatbuffers::FlatBufferBuilder &_fb
 
 struct QuantizedFloatParamT : public flatbuffers::NativeTable {
   typedef QuantizedFloatParam TableType;
-  std::vector<int8_t> weight;
-  std::vector<int32_t> bias;
-  std::vector<float> scale;
-  std::vector<float> tensorScale;
-  QuantizeAlgo method;
-  int32_t nbits;
-  QuantizedFloatParamT()
-      : method(QuantizeAlgo_DEFAULT),
-        nbits(8) {
-  }
+  std::vector<int8_t> weight{};
+  std::vector<int32_t> bias{};
+  std::vector<float> scale{};
+  std::vector<float> tensorScale{};
+  MNN::QuantizeAlgo method = MNN::QuantizeAlgo_DEFAULT;
+  int32_t nbits = 8;
 };
 
 struct QuantizedFloatParam FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
   typedef QuantizedFloatParamT NativeTableType;
+  typedef QuantizedFloatParamBuilder Builder;
   static const flatbuffers::TypeTable *MiniReflectTypeTable() {
     return QuantizedFloatParamTypeTable();
   }
@@ -1119,8 +1119,8 @@ struct QuantizedFloatParam FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table
   const flatbuffers::Vector<float> *tensorScale() const {
     return GetPointer<const flatbuffers::Vector<float> *>(VT_TENSORSCALE);
   }
-  QuantizeAlgo method() const {
-    return static_cast<QuantizeAlgo>(GetField<int8_t>(VT_METHOD, 0));
+  MNN::QuantizeAlgo method() const {
+    return static_cast<MNN::QuantizeAlgo>(GetField<int8_t>(VT_METHOD, 0));
   }
   int32_t nbits() const {
     return GetField<int32_t>(VT_NBITS, 8);
@@ -1145,6 +1145,7 @@ struct QuantizedFloatParam FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table
 };
 
 struct QuantizedFloatParamBuilder {
+  typedef QuantizedFloatParam Table;
   flatbuffers::FlatBufferBuilder &fbb_;
   flatbuffers::uoffset_t start_;
   void add_weight(flatbuffers::Offset<flatbuffers::Vector<int8_t>> weight) {
@@ -1159,7 +1160,7 @@ struct QuantizedFloatParamBuilder {
   void add_tensorScale(flatbuffers::Offset<flatbuffers::Vector<float>> tensorScale) {
     fbb_.AddOffset(QuantizedFloatParam::VT_TENSORSCALE, tensorScale);
   }
-  void add_method(QuantizeAlgo method) {
+  void add_method(MNN::QuantizeAlgo method) {
     fbb_.AddElement<int8_t>(QuantizedFloatParam::VT_METHOD, static_cast<int8_t>(method), 0);
   }
   void add_nbits(int32_t nbits) {
@@ -1169,7 +1170,6 @@ struct QuantizedFloatParamBuilder {
         : fbb_(_fbb) {
     start_ = fbb_.StartTable();
   }
-  QuantizedFloatParamBuilder &operator=(const QuantizedFloatParamBuilder &);
   flatbuffers::Offset<QuantizedFloatParam> Finish() {
     const auto end = fbb_.EndTable(start_);
     auto o = flatbuffers::Offset<QuantizedFloatParam>(end);
@@ -1183,7 +1183,7 @@ inline flatbuffers::Offset<QuantizedFloatParam> CreateQuantizedFloatParam(
     flatbuffers::Offset<flatbuffers::Vector<int32_t>> bias = 0,
     flatbuffers::Offset<flatbuffers::Vector<float>> scale = 0,
     flatbuffers::Offset<flatbuffers::Vector<float>> tensorScale = 0,
-    QuantizeAlgo method = QuantizeAlgo_DEFAULT,
+    MNN::QuantizeAlgo method = MNN::QuantizeAlgo_DEFAULT,
     int32_t nbits = 8) {
   QuantizedFloatParamBuilder builder_(_fbb);
   builder_.add_nbits(nbits);
@@ -1201,7 +1201,7 @@ inline flatbuffers::Offset<QuantizedFloatParam> CreateQuantizedFloatParamDirect(
     const std::vector<int32_t> *bias = nullptr,
     const std::vector<float> *scale = nullptr,
     const std::vector<float> *tensorScale = nullptr,
-    QuantizeAlgo method = QuantizeAlgo_DEFAULT,
+    MNN::QuantizeAlgo method = MNN::QuantizeAlgo_DEFAULT,
     int32_t nbits = 8) {
   auto weight__ = weight ? _fbb.CreateVector<int8_t>(*weight) : 0;
   auto bias__ = bias ? _fbb.CreateVector<int32_t>(*bias) : 0;
@@ -1221,17 +1221,16 @@ flatbuffers::Offset<QuantizedFloatParam> CreateQuantizedFloatParam(flatbuffers::
 
 struct Convolution2DT : public flatbuffers::NativeTable {
   typedef Convolution2D TableType;
-  std::unique_ptr<Convolution2DCommonT> common;
-  std::vector<float> weight;
-  std::vector<float> bias;
-  std::unique_ptr<IDSTQuanT> quanParameter;
-  std::unique_ptr<QuantizedFloatParamT> symmetricQuan;
-  Convolution2DT() {
-  }
+  std::unique_ptr<MNN::Convolution2DCommonT> common{};
+  std::vector<float> weight{};
+  std::vector<float> bias{};
+  std::unique_ptr<MNN::IDSTQuanT> quanParameter{};
+  std::unique_ptr<MNN::QuantizedFloatParamT> symmetricQuan{};
 };
 
 struct Convolution2D FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
   typedef Convolution2DT NativeTableType;
+  typedef Convolution2DBuilder Builder;
   static const flatbuffers::TypeTable *MiniReflectTypeTable() {
     return Convolution2DTypeTable();
   }
@@ -1242,8 +1241,8 @@ struct Convolution2D FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
     VT_QUANPARAMETER = 10,
     VT_SYMMETRICQUAN = 12
   };
-  const Convolution2DCommon *common() const {
-    return GetPointer<const Convolution2DCommon *>(VT_COMMON);
+  const MNN::Convolution2DCommon *common() const {
+    return GetPointer<const MNN::Convolution2DCommon *>(VT_COMMON);
   }
   const flatbuffers::Vector<float> *weight() const {
     return GetPointer<const flatbuffers::Vector<float> *>(VT_WEIGHT);
@@ -1251,11 +1250,11 @@ struct Convolution2D FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
   const flatbuffers::Vector<float> *bias() const {
     return GetPointer<const flatbuffers::Vector<float> *>(VT_BIAS);
   }
-  const IDSTQuan *quanParameter() const {
-    return GetPointer<const IDSTQuan *>(VT_QUANPARAMETER);
+  const MNN::IDSTQuan *quanParameter() const {
+    return GetPointer<const MNN::IDSTQuan *>(VT_QUANPARAMETER);
   }
-  const QuantizedFloatParam *symmetricQuan() const {
-    return GetPointer<const QuantizedFloatParam *>(VT_SYMMETRICQUAN);
+  const MNN::QuantizedFloatParam *symmetricQuan() const {
+    return GetPointer<const MNN::QuantizedFloatParam *>(VT_SYMMETRICQUAN);
   }
   bool Verify(flatbuffers::Verifier &verifier) const {
     return VerifyTableStart(verifier) &&
@@ -1277,9 +1276,10 @@ struct Convolution2D FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
 };
 
 struct Convolution2DBuilder {
+  typedef Convolution2D Table;
   flatbuffers::FlatBufferBuilder &fbb_;
   flatbuffers::uoffset_t start_;
-  void add_common(flatbuffers::Offset<Convolution2DCommon> common) {
+  void add_common(flatbuffers::Offset<MNN::Convolution2DCommon> common) {
     fbb_.AddOffset(Convolution2D::VT_COMMON, common);
   }
   void add_weight(flatbuffers::Offset<flatbuffers::Vector<float>> weight) {
@@ -1288,17 +1288,16 @@ struct Convolution2DBuilder {
   void add_bias(flatbuffers::Offset<flatbuffers::Vector<float>> bias) {
     fbb_.AddOffset(Convolution2D::VT_BIAS, bias);
   }
-  void add_quanParameter(flatbuffers::Offset<IDSTQuan> quanParameter) {
+  void add_quanParameter(flatbuffers::Offset<MNN::IDSTQuan> quanParameter) {
     fbb_.AddOffset(Convolution2D::VT_QUANPARAMETER, quanParameter);
   }
-  void add_symmetricQuan(flatbuffers::Offset<QuantizedFloatParam> symmetricQuan) {
+  void add_symmetricQuan(flatbuffers::Offset<MNN::QuantizedFloatParam> symmetricQuan) {
     fbb_.AddOffset(Convolution2D::VT_SYMMETRICQUAN, symmetricQuan);
   }
   explicit Convolution2DBuilder(flatbuffers::FlatBufferBuilder &_fbb)
         : fbb_(_fbb) {
     start_ = fbb_.StartTable();
   }
-  Convolution2DBuilder &operator=(const Convolution2DBuilder &);
   flatbuffers::Offset<Convolution2D> Finish() {
     const auto end = fbb_.EndTable(start_);
     auto o = flatbuffers::Offset<Convolution2D>(end);
@@ -1308,11 +1307,11 @@ struct Convolution2DBuilder {
 
 inline flatbuffers::Offset<Convolution2D> CreateConvolution2D(
     flatbuffers::FlatBufferBuilder &_fbb,
-    flatbuffers::Offset<Convolution2DCommon> common = 0,
+    flatbuffers::Offset<MNN::Convolution2DCommon> common = 0,
     flatbuffers::Offset<flatbuffers::Vector<float>> weight = 0,
     flatbuffers::Offset<flatbuffers::Vector<float>> bias = 0,
-    flatbuffers::Offset<IDSTQuan> quanParameter = 0,
-    flatbuffers::Offset<QuantizedFloatParam> symmetricQuan = 0) {
+    flatbuffers::Offset<MNN::IDSTQuan> quanParameter = 0,
+    flatbuffers::Offset<MNN::QuantizedFloatParam> symmetricQuan = 0) {
   Convolution2DBuilder builder_(_fbb);
   builder_.add_symmetricQuan(symmetricQuan);
   builder_.add_quanParameter(quanParameter);
@@ -1324,11 +1323,11 @@ inline flatbuffers::Offset<Convolution2D> CreateConvolution2D(
 
 inline flatbuffers::Offset<Convolution2D> CreateConvolution2DDirect(
     flatbuffers::FlatBufferBuilder &_fbb,
-    flatbuffers::Offset<Convolution2DCommon> common = 0,
+    flatbuffers::Offset<MNN::Convolution2DCommon> common = 0,
     const std::vector<float> *weight = nullptr,
     const std::vector<float> *bias = nullptr,
-    flatbuffers::Offset<IDSTQuan> quanParameter = 0,
-    flatbuffers::Offset<QuantizedFloatParam> symmetricQuan = 0) {
+    flatbuffers::Offset<MNN::IDSTQuan> quanParameter = 0,
+    flatbuffers::Offset<MNN::QuantizedFloatParam> symmetricQuan = 0) {
   auto weight__ = weight ? _fbb.CreateVector<float>(*weight) : 0;
   auto bias__ = bias ? _fbb.CreateVector<float>(*bias) : 0;
   return MNN::CreateConvolution2D(
@@ -1344,15 +1343,14 @@ flatbuffers::Offset<Convolution2D> CreateConvolution2D(flatbuffers::FlatBufferBu
 
 struct Convolution3DT : public flatbuffers::NativeTable {
   typedef Convolution3D TableType;
-  std::unique_ptr<Convolution3DCommonT> common;
-  std::vector<float> weight;
-  std::vector<float> bias;
-  Convolution3DT() {
-  }
+  std::unique_ptr<MNN::Convolution3DCommonT> common{};
+  std::vector<float> weight{};
+  std::vector<float> bias{};
 };
 
 struct Convolution3D FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
   typedef Convolution3DT NativeTableType;
+  typedef Convolution3DBuilder Builder;
   static const flatbuffers::TypeTable *MiniReflectTypeTable() {
     return Convolution3DTypeTable();
   }
@@ -1361,8 +1359,8 @@ struct Convolution3D FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
     VT_WEIGHT = 6,
     VT_BIAS = 8
   };
-  const Convolution3DCommon *common() const {
-    return GetPointer<const Convolution3DCommon *>(VT_COMMON);
+  const MNN::Convolution3DCommon *common() const {
+    return GetPointer<const MNN::Convolution3DCommon *>(VT_COMMON);
   }
   const flatbuffers::Vector<float> *weight() const {
     return GetPointer<const flatbuffers::Vector<float> *>(VT_WEIGHT);
@@ -1386,9 +1384,10 @@ struct Convolution3D FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
 };
 
 struct Convolution3DBuilder {
+  typedef Convolution3D Table;
   flatbuffers::FlatBufferBuilder &fbb_;
   flatbuffers::uoffset_t start_;
-  void add_common(flatbuffers::Offset<Convolution3DCommon> common) {
+  void add_common(flatbuffers::Offset<MNN::Convolution3DCommon> common) {
     fbb_.AddOffset(Convolution3D::VT_COMMON, common);
   }
   void add_weight(flatbuffers::Offset<flatbuffers::Vector<float>> weight) {
@@ -1401,7 +1400,6 @@ struct Convolution3DBuilder {
         : fbb_(_fbb) {
     start_ = fbb_.StartTable();
   }
-  Convolution3DBuilder &operator=(const Convolution3DBuilder &);
   flatbuffers::Offset<Convolution3D> Finish() {
     const auto end = fbb_.EndTable(start_);
     auto o = flatbuffers::Offset<Convolution3D>(end);
@@ -1411,7 +1409,7 @@ struct Convolution3DBuilder {
 
 inline flatbuffers::Offset<Convolution3D> CreateConvolution3D(
     flatbuffers::FlatBufferBuilder &_fbb,
-    flatbuffers::Offset<Convolution3DCommon> common = 0,
+    flatbuffers::Offset<MNN::Convolution3DCommon> common = 0,
     flatbuffers::Offset<flatbuffers::Vector<float>> weight = 0,
     flatbuffers::Offset<flatbuffers::Vector<float>> bias = 0) {
   Convolution3DBuilder builder_(_fbb);
@@ -1423,7 +1421,7 @@ inline flatbuffers::Offset<Convolution3D> CreateConvolution3D(
 
 inline flatbuffers::Offset<Convolution3D> CreateConvolution3DDirect(
     flatbuffers::FlatBufferBuilder &_fbb,
-    flatbuffers::Offset<Convolution3DCommon> common = 0,
+    flatbuffers::Offset<MNN::Convolution3DCommon> common = 0,
     const std::vector<float> *weight = nullptr,
     const std::vector<float> *bias = nullptr) {
   auto weight__ = weight ? _fbb.CreateVector<float>(*weight) : 0;
@@ -1439,25 +1437,19 @@ flatbuffers::Offset<Convolution3D> CreateConvolution3D(flatbuffers::FlatBufferBu
 
 struct InnerProductT : public flatbuffers::NativeTable {
   typedef InnerProduct TableType;
-  int32_t outputCount;
-  int32_t biasTerm;
-  int32_t weightSize;
-  std::vector<float> weight;
-  std::vector<float> bias;
-  int32_t axis;
-  bool transpose;
-  std::unique_ptr<IDSTQuanT> quanParameter;
-  InnerProductT()
-      : outputCount(0),
-        biasTerm(0),
-        weightSize(0),
-        axis(0),
-        transpose(false) {
-  }
+  int32_t outputCount = 0;
+  int32_t biasTerm = 0;
+  int32_t weightSize = 0;
+  std::vector<float> weight{};
+  std::vector<float> bias{};
+  int32_t axis = 0;
+  bool transpose = false;
+  std::unique_ptr<MNN::IDSTQuanT> quanParameter{};
 };
 
 struct InnerProduct FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
   typedef InnerProductT NativeTableType;
+  typedef InnerProductBuilder Builder;
   static const flatbuffers::TypeTable *MiniReflectTypeTable() {
     return InnerProductTypeTable();
   }
@@ -1492,8 +1484,8 @@ struct InnerProduct FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
   bool transpose() const {
     return GetField<uint8_t>(VT_TRANSPOSE, 0) != 0;
   }
-  const IDSTQuan *quanParameter() const {
-    return GetPointer<const IDSTQuan *>(VT_QUANPARAMETER);
+  const MNN::IDSTQuan *quanParameter() const {
+    return GetPointer<const MNN::IDSTQuan *>(VT_QUANPARAMETER);
   }
   bool Verify(flatbuffers::Verifier &verifier) const {
     return VerifyTableStart(verifier) &&
@@ -1516,6 +1508,7 @@ struct InnerProduct FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
 };
 
 struct InnerProductBuilder {
+  typedef InnerProduct Table;
   flatbuffers::FlatBufferBuilder &fbb_;
   flatbuffers::uoffset_t start_;
   void add_outputCount(int32_t outputCount) {
@@ -1539,14 +1532,13 @@ struct InnerProductBuilder {
   void add_transpose(bool transpose) {
     fbb_.AddElement<uint8_t>(InnerProduct::VT_TRANSPOSE, static_cast<uint8_t>(transpose), 0);
   }
-  void add_quanParameter(flatbuffers::Offset<IDSTQuan> quanParameter) {
+  void add_quanParameter(flatbuffers::Offset<MNN::IDSTQuan> quanParameter) {
     fbb_.AddOffset(InnerProduct::VT_QUANPARAMETER, quanParameter);
   }
   explicit InnerProductBuilder(flatbuffers::FlatBufferBuilder &_fbb)
         : fbb_(_fbb) {
     start_ = fbb_.StartTable();
   }
-  InnerProductBuilder &operator=(const InnerProductBuilder &);
   flatbuffers::Offset<InnerProduct> Finish() {
     const auto end = fbb_.EndTable(start_);
     auto o = flatbuffers::Offset<InnerProduct>(end);
@@ -1563,7 +1555,7 @@ inline flatbuffers::Offset<InnerProduct> CreateInnerProduct(
     flatbuffers::Offset<flatbuffers::Vector<float>> bias = 0,
     int32_t axis = 0,
     bool transpose = false,
-    flatbuffers::Offset<IDSTQuan> quanParameter = 0) {
+    flatbuffers::Offset<MNN::IDSTQuan> quanParameter = 0) {
   InnerProductBuilder builder_(_fbb);
   builder_.add_quanParameter(quanParameter);
   builder_.add_axis(axis);
@@ -1585,7 +1577,7 @@ inline flatbuffers::Offset<InnerProduct> CreateInnerProductDirect(
     const std::vector<float> *bias = nullptr,
     int32_t axis = 0,
     bool transpose = false,
-    flatbuffers::Offset<IDSTQuan> quanParameter = 0) {
+    flatbuffers::Offset<MNN::IDSTQuan> quanParameter = 0) {
   auto weight__ = weight ? _fbb.CreateVector<float>(*weight) : 0;
   auto bias__ = bias ? _fbb.CreateVector<float>(*bias) : 0;
   return MNN::CreateInnerProduct(
@@ -1604,37 +1596,24 @@ flatbuffers::Offset<InnerProduct> CreateInnerProduct(flatbuffers::FlatBufferBuil
 
 struct PoolT : public flatbuffers::NativeTable {
   typedef Pool TableType;
-  int32_t padX;
-  int32_t padY;
-  bool isGlobal;
-  int32_t kernelX;
-  int32_t kernelY;
-  int32_t strideX;
-  int32_t strideY;
-  PoolType type;
-  PoolPadType padType;
-  DataType dataType;
-  bool ceilModel;
-  std::vector<int32_t> pads;
-  AvgPoolCountType countType;
-  PoolT()
-      : padX(0),
-        padY(0),
-        isGlobal(false),
-        kernelX(0),
-        kernelY(0),
-        strideX(0),
-        strideY(0),
-        type(PoolType_MAXPOOL),
-        padType(PoolPadType_CAFFE),
-        dataType(DataType_DT_FLOAT),
-        ceilModel(true),
-        countType(AvgPoolCountType_DEFAULT) {
-  }
+  int32_t padX = 0;
+  int32_t padY = 0;
+  bool isGlobal = false;
+  int32_t kernelX = 0;
+  int32_t kernelY = 0;
+  int32_t strideX = 0;
+  int32_t strideY = 0;
+  MNN::PoolType type = MNN::PoolType_MAXPOOL;
+  MNN::PoolPadType padType = MNN::PoolPadType_CAFFE;
+  MNN::DataType dataType = MNN::DataType_DT_FLOAT;
+  bool ceilModel = true;
+  std::vector<int32_t> pads{};
+  MNN::AvgPoolCountType countType = MNN::AvgPoolCountType_DEFAULT;
 };
 
 struct Pool FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
   typedef PoolT NativeTableType;
+  typedef PoolBuilder Builder;
   static const flatbuffers::TypeTable *MiniReflectTypeTable() {
     return PoolTypeTable();
   }
@@ -1674,14 +1653,14 @@ struct Pool FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
   int32_t strideY() const {
     return GetField<int32_t>(VT_STRIDEY, 0);
   }
-  PoolType type() const {
-    return static_cast<PoolType>(GetField<int8_t>(VT_TYPE, 0));
+  MNN::PoolType type() const {
+    return static_cast<MNN::PoolType>(GetField<int8_t>(VT_TYPE, 0));
   }
-  PoolPadType padType() const {
-    return static_cast<PoolPadType>(GetField<int8_t>(VT_PADTYPE, 0));
+  MNN::PoolPadType padType() const {
+    return static_cast<MNN::PoolPadType>(GetField<int8_t>(VT_PADTYPE, 0));
   }
-  DataType dataType() const {
-    return static_cast<DataType>(GetField<int32_t>(VT_DATATYPE, 1));
+  MNN::DataType dataType() const {
+    return static_cast<MNN::DataType>(GetField<int32_t>(VT_DATATYPE, 1));
   }
   bool ceilModel() const {
     return GetField<uint8_t>(VT_CEILMODEL, 1) != 0;
@@ -1689,8 +1668,8 @@ struct Pool FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
   const flatbuffers::Vector<int32_t> *pads() const {
     return GetPointer<const flatbuffers::Vector<int32_t> *>(VT_PADS);
   }
-  AvgPoolCountType countType() const {
-    return static_cast<AvgPoolCountType>(GetField<int8_t>(VT_COUNTTYPE, 0));
+  MNN::AvgPoolCountType countType() const {
+    return static_cast<MNN::AvgPoolCountType>(GetField<int8_t>(VT_COUNTTYPE, 0));
   }
   bool Verify(flatbuffers::Verifier &verifier) const {
     return VerifyTableStart(verifier) &&
@@ -1716,6 +1695,7 @@ struct Pool FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
 };
 
 struct PoolBuilder {
+  typedef Pool Table;
   flatbuffers::FlatBufferBuilder &fbb_;
   flatbuffers::uoffset_t start_;
   void add_padX(int32_t padX) {
@@ -1739,13 +1719,13 @@ struct PoolBuilder {
   void add_strideY(int32_t strideY) {
     fbb_.AddElement<int32_t>(Pool::VT_STRIDEY, strideY, 0);
   }
-  void add_type(PoolType type) {
+  void add_type(MNN::PoolType type) {
     fbb_.AddElement<int8_t>(Pool::VT_TYPE, static_cast<int8_t>(type), 0);
   }
-  void add_padType(PoolPadType padType) {
+  void add_padType(MNN::PoolPadType padType) {
     fbb_.AddElement<int8_t>(Pool::VT_PADTYPE, static_cast<int8_t>(padType), 0);
   }
-  void add_dataType(DataType dataType) {
+  void add_dataType(MNN::DataType dataType) {
     fbb_.AddElement<int32_t>(Pool::VT_DATATYPE, static_cast<int32_t>(dataType), 1);
   }
   void add_ceilModel(bool ceilModel) {
@@ -1754,14 +1734,13 @@ struct PoolBuilder {
   void add_pads(flatbuffers::Offset<flatbuffers::Vector<int32_t>> pads) {
     fbb_.AddOffset(Pool::VT_PADS, pads);
   }
-  void add_countType(AvgPoolCountType countType) {
+  void add_countType(MNN::AvgPoolCountType countType) {
     fbb_.AddElement<int8_t>(Pool::VT_COUNTTYPE, static_cast<int8_t>(countType), 0);
   }
   explicit PoolBuilder(flatbuffers::FlatBufferBuilder &_fbb)
         : fbb_(_fbb) {
     start_ = fbb_.StartTable();
   }
-  PoolBuilder &operator=(const PoolBuilder &);
   flatbuffers::Offset<Pool> Finish() {
     const auto end = fbb_.EndTable(start_);
     auto o = flatbuffers::Offset<Pool>(end);
@@ -1778,12 +1757,12 @@ inline flatbuffers::Offset<Pool> CreatePool(
     int32_t kernelY = 0,
     int32_t strideX = 0,
     int32_t strideY = 0,
-    PoolType type = PoolType_MAXPOOL,
-    PoolPadType padType = PoolPadType_CAFFE,
-    DataType dataType = DataType_DT_FLOAT,
+    MNN::PoolType type = MNN::PoolType_MAXPOOL,
+    MNN::PoolPadType padType = MNN::PoolPadType_CAFFE,
+    MNN::DataType dataType = MNN::DataType_DT_FLOAT,
     bool ceilModel = true,
     flatbuffers::Offset<flatbuffers::Vector<int32_t>> pads = 0,
-    AvgPoolCountType countType = AvgPoolCountType_DEFAULT) {
+    MNN::AvgPoolCountType countType = MNN::AvgPoolCountType_DEFAULT) {
   PoolBuilder builder_(_fbb);
   builder_.add_pads(pads);
   builder_.add_dataType(dataType);
@@ -1810,12 +1789,12 @@ inline flatbuffers::Offset<Pool> CreatePoolDirect(
     int32_t kernelY = 0,
     int32_t strideX = 0,
     int32_t strideY = 0,
-    PoolType type = PoolType_MAXPOOL,
-    PoolPadType padType = PoolPadType_CAFFE,
-    DataType dataType = DataType_DT_FLOAT,
+    MNN::PoolType type = MNN::PoolType_MAXPOOL,
+    MNN::PoolPadType padType = MNN::PoolPadType_CAFFE,
+    MNN::DataType dataType = MNN::DataType_DT_FLOAT,
     bool ceilModel = true,
     const std::vector<int32_t> *pads = nullptr,
-    AvgPoolCountType countType = AvgPoolCountType_DEFAULT) {
+    MNN::AvgPoolCountType countType = MNN::AvgPoolCountType_DEFAULT) {
   auto pads__ = pads ? _fbb.CreateVector<int32_t>(*pads) : 0;
   return MNN::CreatePool(
       _fbb,
@@ -1838,19 +1817,16 @@ flatbuffers::Offset<Pool> CreatePool(flatbuffers::FlatBufferBuilder &_fbb, const
 
 struct Pool3DT : public flatbuffers::NativeTable {
   typedef Pool3D TableType;
-  std::vector<int32_t> strides;
-  std::vector<int32_t> kernels;
-  std::vector<int32_t> pads;
-  PoolType type;
-  PoolPadType padType;
-  Pool3DT()
-      : type(PoolType_MAXPOOL),
-        padType(PoolPadType_CAFFE) {
-  }
+  std::vector<int32_t> strides{};
+  std::vector<int32_t> kernels{};
+  std::vector<int32_t> pads{};
+  MNN::PoolType type = MNN::PoolType_MAXPOOL;
+  MNN::PoolPadType padType = MNN::PoolPadType_CAFFE;
 };
 
 struct Pool3D FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
   typedef Pool3DT NativeTableType;
+  typedef Pool3DBuilder Builder;
   static const flatbuffers::TypeTable *MiniReflectTypeTable() {
     return Pool3DTypeTable();
   }
@@ -1870,11 +1846,11 @@ struct Pool3D FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
   const flatbuffers::Vector<int32_t> *pads() const {
     return GetPointer<const flatbuffers::Vector<int32_t> *>(VT_PADS);
   }
-  PoolType type() const {
-    return static_cast<PoolType>(GetField<int8_t>(VT_TYPE, 0));
+  MNN::PoolType type() const {
+    return static_cast<MNN::PoolType>(GetField<int8_t>(VT_TYPE, 0));
   }
-  PoolPadType padType() const {
-    return static_cast<PoolPadType>(GetField<int8_t>(VT_PADTYPE, 0));
+  MNN::PoolPadType padType() const {
+    return static_cast<MNN::PoolPadType>(GetField<int8_t>(VT_PADTYPE, 0));
   }
   bool Verify(flatbuffers::Verifier &verifier) const {
     return VerifyTableStart(verifier) &&
@@ -1894,6 +1870,7 @@ struct Pool3D FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
 };
 
 struct Pool3DBuilder {
+  typedef Pool3D Table;
   flatbuffers::FlatBufferBuilder &fbb_;
   flatbuffers::uoffset_t start_;
   void add_strides(flatbuffers::Offset<flatbuffers::Vector<int32_t>> strides) {
@@ -1905,17 +1882,16 @@ struct Pool3DBuilder {
   void add_pads(flatbuffers::Offset<flatbuffers::Vector<int32_t>> pads) {
     fbb_.AddOffset(Pool3D::VT_PADS, pads);
   }
-  void add_type(PoolType type) {
+  void add_type(MNN::PoolType type) {
     fbb_.AddElement<int8_t>(Pool3D::VT_TYPE, static_cast<int8_t>(type), 0);
   }
-  void add_padType(PoolPadType padType) {
+  void add_padType(MNN::PoolPadType padType) {
     fbb_.AddElement<int8_t>(Pool3D::VT_PADTYPE, static_cast<int8_t>(padType), 0);
   }
   explicit Pool3DBuilder(flatbuffers::FlatBufferBuilder &_fbb)
         : fbb_(_fbb) {
     start_ = fbb_.StartTable();
   }
-  Pool3DBuilder &operator=(const Pool3DBuilder &);
   flatbuffers::Offset<Pool3D> Finish() {
     const auto end = fbb_.EndTable(start_);
     auto o = flatbuffers::Offset<Pool3D>(end);
@@ -1928,8 +1904,8 @@ inline flatbuffers::Offset<Pool3D> CreatePool3D(
     flatbuffers::Offset<flatbuffers::Vector<int32_t>> strides = 0,
     flatbuffers::Offset<flatbuffers::Vector<int32_t>> kernels = 0,
     flatbuffers::Offset<flatbuffers::Vector<int32_t>> pads = 0,
-    PoolType type = PoolType_MAXPOOL,
-    PoolPadType padType = PoolPadType_CAFFE) {
+    MNN::PoolType type = MNN::PoolType_MAXPOOL,
+    MNN::PoolPadType padType = MNN::PoolPadType_CAFFE) {
   Pool3DBuilder builder_(_fbb);
   builder_.add_pads(pads);
   builder_.add_kernels(kernels);
@@ -1944,8 +1920,8 @@ inline flatbuffers::Offset<Pool3D> CreatePool3DDirect(
     const std::vector<int32_t> *strides = nullptr,
     const std::vector<int32_t> *kernels = nullptr,
     const std::vector<int32_t> *pads = nullptr,
-    PoolType type = PoolType_MAXPOOL,
-    PoolPadType padType = PoolPadType_CAFFE) {
+    MNN::PoolType type = MNN::PoolType_MAXPOOL,
+    MNN::PoolPadType padType = MNN::PoolPadType_CAFFE) {
   auto strides__ = strides ? _fbb.CreateVector<int32_t>(*strides) : 0;
   auto kernels__ = kernels ? _fbb.CreateVector<int32_t>(*kernels) : 0;
   auto pads__ = pads ? _fbb.CreateVector<int32_t>(*pads) : 0;
@@ -1962,14 +1938,12 @@ flatbuffers::Offset<Pool3D> CreatePool3D(flatbuffers::FlatBufferBuilder &_fbb, c
 
 struct ReluT : public flatbuffers::NativeTable {
   typedef Relu TableType;
-  float slope;
-  ReluT()
-      : slope(0.0f) {
-  }
+  float slope = 0.0f;
 };
 
 struct Relu FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
   typedef ReluT NativeTableType;
+  typedef ReluBuilder Builder;
   static const flatbuffers::TypeTable *MiniReflectTypeTable() {
     return ReluTypeTable();
   }
@@ -1990,6 +1964,7 @@ struct Relu FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
 };
 
 struct ReluBuilder {
+  typedef Relu Table;
   flatbuffers::FlatBufferBuilder &fbb_;
   flatbuffers::uoffset_t start_;
   void add_slope(float slope) {
@@ -1999,7 +1974,6 @@ struct ReluBuilder {
         : fbb_(_fbb) {
     start_ = fbb_.StartTable();
   }
-  ReluBuilder &operator=(const ReluBuilder &);
   flatbuffers::Offset<Relu> Finish() {
     const auto end = fbb_.EndTable(start_);
     auto o = flatbuffers::Offset<Relu>(end);
@@ -2019,16 +1993,13 @@ flatbuffers::Offset<Relu> CreateRelu(flatbuffers::FlatBufferBuilder &_fbb, const
 
 struct Relu6T : public flatbuffers::NativeTable {
   typedef Relu6 TableType;
-  float minValue;
-  float maxValue;
-  Relu6T()
-      : minValue(0.0f),
-        maxValue(6.0f) {
-  }
+  float minValue = 0.0f;
+  float maxValue = 6.0f;
 };
 
 struct Relu6 FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
   typedef Relu6T NativeTableType;
+  typedef Relu6Builder Builder;
   static const flatbuffers::TypeTable *MiniReflectTypeTable() {
     return Relu6TypeTable();
   }
@@ -2054,6 +2025,7 @@ struct Relu6 FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
 };
 
 struct Relu6Builder {
+  typedef Relu6 Table;
   flatbuffers::FlatBufferBuilder &fbb_;
   flatbuffers::uoffset_t start_;
   void add_minValue(float minValue) {
@@ -2066,7 +2038,6 @@ struct Relu6Builder {
         : fbb_(_fbb) {
     start_ = fbb_.StartTable();
   }
-  Relu6Builder &operator=(const Relu6Builder &);
   flatbuffers::Offset<Relu6> Finish() {
     const auto end = fbb_.EndTable(start_);
     auto o = flatbuffers::Offset<Relu6>(end);
@@ -2088,15 +2059,13 @@ flatbuffers::Offset<Relu6> CreateRelu6(flatbuffers::FlatBufferBuilder &_fbb, con
 
 struct PReluT : public flatbuffers::NativeTable {
   typedef PRelu TableType;
-  int32_t slopeCount;
-  std::vector<float> slope;
-  PReluT()
-      : slopeCount(0) {
-  }
+  int32_t slopeCount = 0;
+  std::vector<float> slope{};
 };
 
 struct PRelu FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
   typedef PReluT NativeTableType;
+  typedef PReluBuilder Builder;
   static const flatbuffers::TypeTable *MiniReflectTypeTable() {
     return PReluTypeTable();
   }
@@ -2123,6 +2092,7 @@ struct PRelu FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
 };
 
 struct PReluBuilder {
+  typedef PRelu Table;
   flatbuffers::FlatBufferBuilder &fbb_;
   flatbuffers::uoffset_t start_;
   void add_slopeCount(int32_t slopeCount) {
@@ -2135,7 +2105,6 @@ struct PReluBuilder {
         : fbb_(_fbb) {
     start_ = fbb_.StartTable();
   }
-  PReluBuilder &operator=(const PReluBuilder &);
   flatbuffers::Offset<PRelu> Finish() {
     const auto end = fbb_.EndTable(start_);
     auto o = flatbuffers::Offset<PRelu>(end);
@@ -2168,14 +2137,12 @@ flatbuffers::Offset<PRelu> CreatePRelu(flatbuffers::FlatBufferBuilder &_fbb, con
 
 struct ELUT : public flatbuffers::NativeTable {
   typedef ELU TableType;
-  float alpha;
-  ELUT()
-      : alpha(0.0f) {
-  }
+  float alpha = 0.0f;
 };
 
 struct ELU FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
   typedef ELUT NativeTableType;
+  typedef ELUBuilder Builder;
   static const flatbuffers::TypeTable *MiniReflectTypeTable() {
     return ELUTypeTable();
   }
@@ -2196,6 +2163,7 @@ struct ELU FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
 };
 
 struct ELUBuilder {
+  typedef ELU Table;
   flatbuffers::FlatBufferBuilder &fbb_;
   flatbuffers::uoffset_t start_;
   void add_alpha(float alpha) {
@@ -2205,7 +2173,6 @@ struct ELUBuilder {
         : fbb_(_fbb) {
     start_ = fbb_.StartTable();
   }
-  ELUBuilder &operator=(const ELUBuilder &);
   flatbuffers::Offset<ELU> Finish() {
     const auto end = fbb_.EndTable(start_);
     auto o = flatbuffers::Offset<ELU>(end);
@@ -2225,20 +2192,15 @@ flatbuffers::Offset<ELU> CreateELU(flatbuffers::FlatBufferBuilder &_fbb, const E
 
 struct LRNT : public flatbuffers::NativeTable {
   typedef LRN TableType;
-  int32_t regionType;
-  int32_t localSize;
-  float alpha;
-  float beta;
-  LRNT()
-      : regionType(0),
-        localSize(0),
-        alpha(0.0f),
-        beta(0.0f) {
-  }
+  int32_t regionType = 0;
+  int32_t localSize = 0;
+  float alpha = 0.0f;
+  float beta = 0.0f;
 };
 
 struct LRN FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
   typedef LRNT NativeTableType;
+  typedef LRNBuilder Builder;
   static const flatbuffers::TypeTable *MiniReflectTypeTable() {
     return LRNTypeTable();
   }
@@ -2274,6 +2236,7 @@ struct LRN FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
 };
 
 struct LRNBuilder {
+  typedef LRN Table;
   flatbuffers::FlatBufferBuilder &fbb_;
   flatbuffers::uoffset_t start_;
   void add_regionType(int32_t regionType) {
@@ -2292,7 +2255,6 @@ struct LRNBuilder {
         : fbb_(_fbb) {
     start_ = fbb_.StartTable();
   }
-  LRNBuilder &operator=(const LRNBuilder &);
   flatbuffers::Offset<LRN> Finish() {
     const auto end = fbb_.EndTable(start_);
     auto o = flatbuffers::Offset<LRN>(end);
@@ -2318,20 +2280,15 @@ flatbuffers::Offset<LRN> CreateLRN(flatbuffers::FlatBufferBuilder &_fbb, const L
 
 struct ArgMaxT : public flatbuffers::NativeTable {
   typedef ArgMax TableType;
-  int32_t outMaxVal;
-  int32_t topK;
-  int32_t axis;
-  int32_t softmaxThreshold;
-  ArgMaxT()
-      : outMaxVal(0),
-        topK(0),
-        axis(0),
-        softmaxThreshold(0) {
-  }
+  int32_t outMaxVal = 0;
+  int32_t topK = 0;
+  int32_t axis = 0;
+  int32_t softmaxThreshold = 0;
 };
 
 struct ArgMax FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
   typedef ArgMaxT NativeTableType;
+  typedef ArgMaxBuilder Builder;
   static const flatbuffers::TypeTable *MiniReflectTypeTable() {
     return ArgMaxTypeTable();
   }
@@ -2367,6 +2324,7 @@ struct ArgMax FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
 };
 
 struct ArgMaxBuilder {
+  typedef ArgMax Table;
   flatbuffers::FlatBufferBuilder &fbb_;
   flatbuffers::uoffset_t start_;
   void add_outMaxVal(int32_t outMaxVal) {
@@ -2385,7 +2343,6 @@ struct ArgMaxBuilder {
         : fbb_(_fbb) {
     start_ = fbb_.StartTable();
   }
-  ArgMaxBuilder &operator=(const ArgMaxBuilder &);
   flatbuffers::Offset<ArgMax> Finish() {
     const auto end = fbb_.EndTable(start_);
     auto o = flatbuffers::Offset<ArgMax>(end);
@@ -2411,14 +2368,12 @@ flatbuffers::Offset<ArgMax> CreateArgMax(flatbuffers::FlatBufferBuilder &_fbb, c
 
 struct AxisT : public flatbuffers::NativeTable {
   typedef Axis TableType;
-  int32_t axis;
-  AxisT()
-      : axis(0) {
-  }
+  int32_t axis = 0;
 };
 
 struct Axis FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
   typedef AxisT NativeTableType;
+  typedef AxisBuilder Builder;
   static const flatbuffers::TypeTable *MiniReflectTypeTable() {
     return AxisTypeTable();
   }
@@ -2439,6 +2394,7 @@ struct Axis FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
 };
 
 struct AxisBuilder {
+  typedef Axis Table;
   flatbuffers::FlatBufferBuilder &fbb_;
   flatbuffers::uoffset_t start_;
   void add_axis(int32_t axis) {
@@ -2448,7 +2404,6 @@ struct AxisBuilder {
         : fbb_(_fbb) {
     start_ = fbb_.StartTable();
   }
-  AxisBuilder &operator=(const AxisBuilder &);
   flatbuffers::Offset<Axis> Finish() {
     const auto end = fbb_.EndTable(start_);
     auto o = flatbuffers::Offset<Axis>(end);
@@ -2468,17 +2423,14 @@ flatbuffers::Offset<Axis> CreateAxis(flatbuffers::FlatBufferBuilder &_fbb, const
 
 struct InputT : public flatbuffers::NativeTable {
   typedef Input TableType;
-  std::vector<int32_t> dims;
-  DataType dtype;
-  MNN_DATA_FORMAT dformat;
-  InputT()
-      : dtype(DataType_DT_FLOAT),
-        dformat(MNN_DATA_FORMAT_NC4HW4) {
-  }
+  std::vector<int32_t> dims{};
+  MNN::DataType dtype = MNN::DataType_DT_FLOAT;
+  MNN::MNN_DATA_FORMAT dformat = MNN::MNN_DATA_FORMAT_NC4HW4;
 };
 
 struct Input FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
   typedef InputT NativeTableType;
+  typedef InputBuilder Builder;
   static const flatbuffers::TypeTable *MiniReflectTypeTable() {
     return InputTypeTable();
   }
@@ -2490,11 +2442,11 @@ struct Input FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
   const flatbuffers::Vector<int32_t> *dims() const {
     return GetPointer<const flatbuffers::Vector<int32_t> *>(VT_DIMS);
   }
-  DataType dtype() const {
-    return static_cast<DataType>(GetField<int32_t>(VT_DTYPE, 1));
+  MNN::DataType dtype() const {
+    return static_cast<MNN::DataType>(GetField<int32_t>(VT_DTYPE, 1));
   }
-  MNN_DATA_FORMAT dformat() const {
-    return static_cast<MNN_DATA_FORMAT>(GetField<int8_t>(VT_DFORMAT, 2));
+  MNN::MNN_DATA_FORMAT dformat() const {
+    return static_cast<MNN::MNN_DATA_FORMAT>(GetField<int8_t>(VT_DFORMAT, 2));
   }
   bool Verify(flatbuffers::Verifier &verifier) const {
     return VerifyTableStart(verifier) &&
@@ -2510,22 +2462,22 @@ struct Input FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
 };
 
 struct InputBuilder {
+  typedef Input Table;
   flatbuffers::FlatBufferBuilder &fbb_;
   flatbuffers::uoffset_t start_;
   void add_dims(flatbuffers::Offset<flatbuffers::Vector<int32_t>> dims) {
     fbb_.AddOffset(Input::VT_DIMS, dims);
   }
-  void add_dtype(DataType dtype) {
+  void add_dtype(MNN::DataType dtype) {
     fbb_.AddElement<int32_t>(Input::VT_DTYPE, static_cast<int32_t>(dtype), 1);
   }
-  void add_dformat(MNN_DATA_FORMAT dformat) {
+  void add_dformat(MNN::MNN_DATA_FORMAT dformat) {
     fbb_.AddElement<int8_t>(Input::VT_DFORMAT, static_cast<int8_t>(dformat), 2);
   }
   explicit InputBuilder(flatbuffers::FlatBufferBuilder &_fbb)
         : fbb_(_fbb) {
     start_ = fbb_.StartTable();
   }
-  InputBuilder &operator=(const InputBuilder &);
   flatbuffers::Offset<Input> Finish() {
     const auto end = fbb_.EndTable(start_);
     auto o = flatbuffers::Offset<Input>(end);
@@ -2536,8 +2488,8 @@ struct InputBuilder {
 inline flatbuffers::Offset<Input> CreateInput(
     flatbuffers::FlatBufferBuilder &_fbb,
     flatbuffers::Offset<flatbuffers::Vector<int32_t>> dims = 0,
-    DataType dtype = DataType_DT_FLOAT,
-    MNN_DATA_FORMAT dformat = MNN_DATA_FORMAT_NC4HW4) {
+    MNN::DataType dtype = MNN::DataType_DT_FLOAT,
+    MNN::MNN_DATA_FORMAT dformat = MNN::MNN_DATA_FORMAT_NC4HW4) {
   InputBuilder builder_(_fbb);
   builder_.add_dtype(dtype);
   builder_.add_dims(dims);
@@ -2548,8 +2500,8 @@ inline flatbuffers::Offset<Input> CreateInput(
 inline flatbuffers::Offset<Input> CreateInputDirect(
     flatbuffers::FlatBufferBuilder &_fbb,
     const std::vector<int32_t> *dims = nullptr,
-    DataType dtype = DataType_DT_FLOAT,
-    MNN_DATA_FORMAT dformat = MNN_DATA_FORMAT_NC4HW4) {
+    MNN::DataType dtype = MNN::DataType_DT_FLOAT,
+    MNN::MNN_DATA_FORMAT dformat = MNN::MNN_DATA_FORMAT_NC4HW4) {
   auto dims__ = dims ? _fbb.CreateVector<int32_t>(*dims) : 0;
   return MNN::CreateInput(
       _fbb,
@@ -2562,25 +2514,20 @@ flatbuffers::Offset<Input> CreateInput(flatbuffers::FlatBufferBuilder &_fbb, con
 
 struct LSTMT : public flatbuffers::NativeTable {
   typedef LSTM TableType;
-  int32_t outputCount;
-  int32_t weightSize;
-  float clippingThreshold;
-  std::unique_ptr<BlobT> weightI;
-  std::unique_ptr<BlobT> weightH;
-  std::unique_ptr<BlobT> bias;
-  std::unique_ptr<BlobT> weightIQ;
-  std::unique_ptr<BlobT> weightIA;
-  float quantScale;
-  LSTMT()
-      : outputCount(0),
-        weightSize(0),
-        clippingThreshold(0.0f),
-        quantScale(0.0f) {
-  }
+  int32_t outputCount = 0;
+  int32_t weightSize = 0;
+  float clippingThreshold = 0.0f;
+  std::unique_ptr<MNN::BlobT> weightI{};
+  std::unique_ptr<MNN::BlobT> weightH{};
+  std::unique_ptr<MNN::BlobT> bias{};
+  std::unique_ptr<MNN::BlobT> weightIQ{};
+  std::unique_ptr<MNN::BlobT> weightIA{};
+  float quantScale = 0.0f;
 };
 
 struct LSTM FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
   typedef LSTMT NativeTableType;
+  typedef LSTMBuilder Builder;
   static const flatbuffers::TypeTable *MiniReflectTypeTable() {
     return LSTMTypeTable();
   }
@@ -2604,20 +2551,20 @@ struct LSTM FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
   float clippingThreshold() const {
     return GetField<float>(VT_CLIPPINGTHRESHOLD, 0.0f);
   }
-  const Blob *weightI() const {
-    return GetPointer<const Blob *>(VT_WEIGHTI);
+  const MNN::Blob *weightI() const {
+    return GetPointer<const MNN::Blob *>(VT_WEIGHTI);
   }
-  const Blob *weightH() const {
-    return GetPointer<const Blob *>(VT_WEIGHTH);
+  const MNN::Blob *weightH() const {
+    return GetPointer<const MNN::Blob *>(VT_WEIGHTH);
   }
-  const Blob *bias() const {
-    return GetPointer<const Blob *>(VT_BIAS);
+  const MNN::Blob *bias() const {
+    return GetPointer<const MNN::Blob *>(VT_BIAS);
   }
-  const Blob *weightIQ() const {
-    return GetPointer<const Blob *>(VT_WEIGHTIQ);
+  const MNN::Blob *weightIQ() const {
+    return GetPointer<const MNN::Blob *>(VT_WEIGHTIQ);
   }
-  const Blob *weightIA() const {
-    return GetPointer<const Blob *>(VT_WEIGHTIA);
+  const MNN::Blob *weightIA() const {
+    return GetPointer<const MNN::Blob *>(VT_WEIGHTIA);
   }
   float quantScale() const {
     return GetField<float>(VT_QUANTSCALE, 0.0f);
@@ -2646,6 +2593,7 @@ struct LSTM FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
 };
 
 struct LSTMBuilder {
+  typedef LSTM Table;
   flatbuffers::FlatBufferBuilder &fbb_;
   flatbuffers::uoffset_t start_;
   void add_outputCount(int32_t outputCount) {
@@ -2657,19 +2605,19 @@ struct LSTMBuilder {
   void add_clippingThreshold(float clippingThreshold) {
     fbb_.AddElement<float>(LSTM::VT_CLIPPINGTHRESHOLD, clippingThreshold, 0.0f);
   }
-  void add_weightI(flatbuffers::Offset<Blob> weightI) {
+  void add_weightI(flatbuffers::Offset<MNN::Blob> weightI) {
     fbb_.AddOffset(LSTM::VT_WEIGHTI, weightI);
   }
-  void add_weightH(flatbuffers::Offset<Blob> weightH) {
+  void add_weightH(flatbuffers::Offset<MNN::Blob> weightH) {
     fbb_.AddOffset(LSTM::VT_WEIGHTH, weightH);
   }
-  void add_bias(flatbuffers::Offset<Blob> bias) {
+  void add_bias(flatbuffers::Offset<MNN::Blob> bias) {
     fbb_.AddOffset(LSTM::VT_BIAS, bias);
   }
-  void add_weightIQ(flatbuffers::Offset<Blob> weightIQ) {
+  void add_weightIQ(flatbuffers::Offset<MNN::Blob> weightIQ) {
     fbb_.AddOffset(LSTM::VT_WEIGHTIQ, weightIQ);
   }
-  void add_weightIA(flatbuffers::Offset<Blob> weightIA) {
+  void add_weightIA(flatbuffers::Offset<MNN::Blob> weightIA) {
     fbb_.AddOffset(LSTM::VT_WEIGHTIA, weightIA);
   }
   void add_quantScale(float quantScale) {
@@ -2679,7 +2627,6 @@ struct LSTMBuilder {
         : fbb_(_fbb) {
     start_ = fbb_.StartTable();
   }
-  LSTMBuilder &operator=(const LSTMBuilder &);
   flatbuffers::Offset<LSTM> Finish() {
     const auto end = fbb_.EndTable(start_);
     auto o = flatbuffers::Offset<LSTM>(end);
@@ -2692,11 +2639,11 @@ inline flatbuffers::Offset<LSTM> CreateLSTM(
     int32_t outputCount = 0,
     int32_t weightSize = 0,
     float clippingThreshold = 0.0f,
-    flatbuffers::Offset<Blob> weightI = 0,
-    flatbuffers::Offset<Blob> weightH = 0,
-    flatbuffers::Offset<Blob> bias = 0,
-    flatbuffers::Offset<Blob> weightIQ = 0,
-    flatbuffers::Offset<Blob> weightIA = 0,
+    flatbuffers::Offset<MNN::Blob> weightI = 0,
+    flatbuffers::Offset<MNN::Blob> weightH = 0,
+    flatbuffers::Offset<MNN::Blob> bias = 0,
+    flatbuffers::Offset<MNN::Blob> weightIQ = 0,
+    flatbuffers::Offset<MNN::Blob> weightIA = 0,
     float quantScale = 0.0f) {
   LSTMBuilder builder_(_fbb);
   builder_.add_quantScale(quantScale);
@@ -2715,17 +2662,14 @@ flatbuffers::Offset<LSTM> CreateLSTM(flatbuffers::FlatBufferBuilder &_fbb, const
 
 struct SliceT : public flatbuffers::NativeTable {
   typedef Slice TableType;
-  int32_t axis;
-  std::vector<int32_t> slicePoints;
-  NetSource sourceType;
-  SliceT()
-      : axis(0),
-        sourceType(NetSource_CAFFE) {
-  }
+  int32_t axis = 0;
+  std::vector<int32_t> slicePoints{};
+  MNN::NetSource sourceType = MNN::NetSource_CAFFE;
 };
 
 struct Slice FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
   typedef SliceT NativeTableType;
+  typedef SliceBuilder Builder;
   static const flatbuffers::TypeTable *MiniReflectTypeTable() {
     return SliceTypeTable();
   }
@@ -2740,8 +2684,8 @@ struct Slice FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
   const flatbuffers::Vector<int32_t> *slicePoints() const {
     return GetPointer<const flatbuffers::Vector<int32_t> *>(VT_SLICEPOINTS);
   }
-  NetSource sourceType() const {
-    return static_cast<NetSource>(GetField<int8_t>(VT_SOURCETYPE, 0));
+  MNN::NetSource sourceType() const {
+    return static_cast<MNN::NetSource>(GetField<int8_t>(VT_SOURCETYPE, 0));
   }
   bool Verify(flatbuffers::Verifier &verifier) const {
     return VerifyTableStart(verifier) &&
@@ -2757,6 +2701,7 @@ struct Slice FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
 };
 
 struct SliceBuilder {
+  typedef Slice Table;
   flatbuffers::FlatBufferBuilder &fbb_;
   flatbuffers::uoffset_t start_;
   void add_axis(int32_t axis) {
@@ -2765,14 +2710,13 @@ struct SliceBuilder {
   void add_slicePoints(flatbuffers::Offset<flatbuffers::Vector<int32_t>> slicePoints) {
     fbb_.AddOffset(Slice::VT_SLICEPOINTS, slicePoints);
   }
-  void add_sourceType(NetSource sourceType) {
+  void add_sourceType(MNN::NetSource sourceType) {
     fbb_.AddElement<int8_t>(Slice::VT_SOURCETYPE, static_cast<int8_t>(sourceType), 0);
   }
   explicit SliceBuilder(flatbuffers::FlatBufferBuilder &_fbb)
         : fbb_(_fbb) {
     start_ = fbb_.StartTable();
   }
-  SliceBuilder &operator=(const SliceBuilder &);
   flatbuffers::Offset<Slice> Finish() {
     const auto end = fbb_.EndTable(start_);
     auto o = flatbuffers::Offset<Slice>(end);
@@ -2784,7 +2728,7 @@ inline flatbuffers::Offset<Slice> CreateSlice(
     flatbuffers::FlatBufferBuilder &_fbb,
     int32_t axis = 0,
     flatbuffers::Offset<flatbuffers::Vector<int32_t>> slicePoints = 0,
-    NetSource sourceType = NetSource_CAFFE) {
+    MNN::NetSource sourceType = MNN::NetSource_CAFFE) {
   SliceBuilder builder_(_fbb);
   builder_.add_slicePoints(slicePoints);
   builder_.add_axis(axis);
@@ -2796,7 +2740,7 @@ inline flatbuffers::Offset<Slice> CreateSliceDirect(
     flatbuffers::FlatBufferBuilder &_fbb,
     int32_t axis = 0,
     const std::vector<int32_t> *slicePoints = nullptr,
-    NetSource sourceType = NetSource_CAFFE) {
+    MNN::NetSource sourceType = MNN::NetSource_CAFFE) {
   auto slicePoints__ = slicePoints ? _fbb.CreateVector<int32_t>(*slicePoints) : 0;
   return MNN::CreateSlice(
       _fbb,
@@ -2809,22 +2753,19 @@ flatbuffers::Offset<Slice> CreateSlice(flatbuffers::FlatBufferBuilder &_fbb, con
 
 struct BatchNormT : public flatbuffers::NativeTable {
   typedef BatchNorm TableType;
-  int32_t channels;
-  std::vector<float> slopeData;
-  std::vector<float> meanData;
-  std::vector<float> varData;
-  std::vector<float> biasData;
-  std::vector<float> Adata;
-  std::vector<float> Bdata;
-  float epsilon;
-  BatchNormT()
-      : channels(0),
-        epsilon(0.001f) {
-  }
+  int32_t channels = 0;
+  std::vector<float> slopeData{};
+  std::vector<float> meanData{};
+  std::vector<float> varData{};
+  std::vector<float> biasData{};
+  std::vector<float> Adata{};
+  std::vector<float> Bdata{};
+  float epsilon = 0.001f;
 };
 
 struct BatchNorm FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
   typedef BatchNormT NativeTableType;
+  typedef BatchNormBuilder Builder;
   static const flatbuffers::TypeTable *MiniReflectTypeTable() {
     return BatchNormTypeTable();
   }
@@ -2886,6 +2827,7 @@ struct BatchNorm FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
 };
 
 struct BatchNormBuilder {
+  typedef BatchNorm Table;
   flatbuffers::FlatBufferBuilder &fbb_;
   flatbuffers::uoffset_t start_;
   void add_channels(int32_t channels) {
@@ -2916,7 +2858,6 @@ struct BatchNormBuilder {
         : fbb_(_fbb) {
     start_ = fbb_.StartTable();
   }
-  BatchNormBuilder &operator=(const BatchNormBuilder &);
   flatbuffers::Offset<BatchNorm> Finish() {
     const auto end = fbb_.EndTable(start_);
     auto o = flatbuffers::Offset<BatchNorm>(end);
@@ -2978,16 +2919,14 @@ flatbuffers::Offset<BatchNorm> CreateBatchNorm(flatbuffers::FlatBufferBuilder &_
 
 struct ScaleT : public flatbuffers::NativeTable {
   typedef Scale TableType;
-  int32_t channels;
-  std::vector<float> scaleData;
-  std::vector<float> biasData;
-  ScaleT()
-      : channels(0) {
-  }
+  int32_t channels = 0;
+  std::vector<float> scaleData{};
+  std::vector<float> biasData{};
 };
 
 struct Scale FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
   typedef ScaleT NativeTableType;
+  typedef ScaleBuilder Builder;
   static const flatbuffers::TypeTable *MiniReflectTypeTable() {
     return ScaleTypeTable();
   }
@@ -3020,6 +2959,7 @@ struct Scale FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
 };
 
 struct ScaleBuilder {
+  typedef Scale Table;
   flatbuffers::FlatBufferBuilder &fbb_;
   flatbuffers::uoffset_t start_;
   void add_channels(int32_t channels) {
@@ -3035,7 +2975,6 @@ struct ScaleBuilder {
         : fbb_(_fbb) {
     start_ = fbb_.StartTable();
   }
-  ScaleBuilder &operator=(const ScaleBuilder &);
   flatbuffers::Offset<Scale> Finish() {
     const auto end = fbb_.EndTable(start_);
     auto o = flatbuffers::Offset<Scale>(end);
@@ -3073,15 +3012,13 @@ flatbuffers::Offset<Scale> CreateScale(flatbuffers::FlatBufferBuilder &_fbb, con
 
 struct EltwiseT : public flatbuffers::NativeTable {
   typedef Eltwise TableType;
-  EltwiseType type;
-  std::vector<float> coeff;
-  EltwiseT()
-      : type(EltwiseType_PROD) {
-  }
+  MNN::EltwiseType type = MNN::EltwiseType_PROD;
+  std::vector<float> coeff{};
 };
 
 struct Eltwise FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
   typedef EltwiseT NativeTableType;
+  typedef EltwiseBuilder Builder;
   static const flatbuffers::TypeTable *MiniReflectTypeTable() {
     return EltwiseTypeTable();
   }
@@ -3089,8 +3026,8 @@ struct Eltwise FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
     VT_TYPE = 4,
     VT_COEFF = 6
   };
-  EltwiseType type() const {
-    return static_cast<EltwiseType>(GetField<int8_t>(VT_TYPE, 0));
+  MNN::EltwiseType type() const {
+    return static_cast<MNN::EltwiseType>(GetField<int8_t>(VT_TYPE, 0));
   }
   const flatbuffers::Vector<float> *coeff() const {
     return GetPointer<const flatbuffers::Vector<float> *>(VT_COEFF);
@@ -3108,9 +3045,10 @@ struct Eltwise FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
 };
 
 struct EltwiseBuilder {
+  typedef Eltwise Table;
   flatbuffers::FlatBufferBuilder &fbb_;
   flatbuffers::uoffset_t start_;
-  void add_type(EltwiseType type) {
+  void add_type(MNN::EltwiseType type) {
     fbb_.AddElement<int8_t>(Eltwise::VT_TYPE, static_cast<int8_t>(type), 0);
   }
   void add_coeff(flatbuffers::Offset<flatbuffers::Vector<float>> coeff) {
@@ -3120,7 +3058,6 @@ struct EltwiseBuilder {
         : fbb_(_fbb) {
     start_ = fbb_.StartTable();
   }
-  EltwiseBuilder &operator=(const EltwiseBuilder &);
   flatbuffers::Offset<Eltwise> Finish() {
     const auto end = fbb_.EndTable(start_);
     auto o = flatbuffers::Offset<Eltwise>(end);
@@ -3130,7 +3067,7 @@ struct EltwiseBuilder {
 
 inline flatbuffers::Offset<Eltwise> CreateEltwise(
     flatbuffers::FlatBufferBuilder &_fbb,
-    EltwiseType type = EltwiseType_PROD,
+    MNN::EltwiseType type = MNN::EltwiseType_PROD,
     flatbuffers::Offset<flatbuffers::Vector<float>> coeff = 0) {
   EltwiseBuilder builder_(_fbb);
   builder_.add_coeff(coeff);
@@ -3140,7 +3077,7 @@ inline flatbuffers::Offset<Eltwise> CreateEltwise(
 
 inline flatbuffers::Offset<Eltwise> CreateEltwiseDirect(
     flatbuffers::FlatBufferBuilder &_fbb,
-    EltwiseType type = EltwiseType_PROD,
+    MNN::EltwiseType type = MNN::EltwiseType_PROD,
     const std::vector<float> *coeff = nullptr) {
   auto coeff__ = coeff ? _fbb.CreateVector<float>(*coeff) : 0;
   return MNN::CreateEltwise(
@@ -3153,16 +3090,13 @@ flatbuffers::Offset<Eltwise> CreateEltwise(flatbuffers::FlatBufferBuilder &_fbb,
 
 struct FlattenT : public flatbuffers::NativeTable {
   typedef Flatten TableType;
-  int32_t axis;
-  int32_t endAxis;
-  FlattenT()
-      : axis(0),
-        endAxis(0) {
-  }
+  int32_t axis = 0;
+  int32_t endAxis = 0;
 };
 
 struct Flatten FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
   typedef FlattenT NativeTableType;
+  typedef FlattenBuilder Builder;
   static const flatbuffers::TypeTable *MiniReflectTypeTable() {
     return FlattenTypeTable();
   }
@@ -3188,6 +3122,7 @@ struct Flatten FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
 };
 
 struct FlattenBuilder {
+  typedef Flatten Table;
   flatbuffers::FlatBufferBuilder &fbb_;
   flatbuffers::uoffset_t start_;
   void add_axis(int32_t axis) {
@@ -3200,7 +3135,6 @@ struct FlattenBuilder {
         : fbb_(_fbb) {
     start_ = fbb_.StartTable();
   }
-  FlattenBuilder &operator=(const FlattenBuilder &);
   flatbuffers::Offset<Flatten> Finish() {
     const auto end = fbb_.EndTable(start_);
     auto o = flatbuffers::Offset<Flatten>(end);
@@ -3222,13 +3156,12 @@ flatbuffers::Offset<Flatten> CreateFlatten(flatbuffers::FlatBufferBuilder &_fbb,
 
 struct PermuteT : public flatbuffers::NativeTable {
   typedef Permute TableType;
-  std::vector<int32_t> dims;
-  PermuteT() {
-  }
+  std::vector<int32_t> dims{};
 };
 
 struct Permute FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
   typedef PermuteT NativeTableType;
+  typedef PermuteBuilder Builder;
   static const flatbuffers::TypeTable *MiniReflectTypeTable() {
     return PermuteTypeTable();
   }
@@ -3250,6 +3183,7 @@ struct Permute FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
 };
 
 struct PermuteBuilder {
+  typedef Permute Table;
   flatbuffers::FlatBufferBuilder &fbb_;
   flatbuffers::uoffset_t start_;
   void add_dims(flatbuffers::Offset<flatbuffers::Vector<int32_t>> dims) {
@@ -3259,7 +3193,6 @@ struct PermuteBuilder {
         : fbb_(_fbb) {
     start_ = fbb_.StartTable();
   }
-  PermuteBuilder &operator=(const PermuteBuilder &);
   flatbuffers::Offset<Permute> Finish() {
     const auto end = fbb_.EndTable(start_);
     auto o = flatbuffers::Offset<Permute>(end);
@@ -3288,15 +3221,13 @@ flatbuffers::Offset<Permute> CreatePermute(flatbuffers::FlatBufferBuilder &_fbb,
 
 struct ReshapeT : public flatbuffers::NativeTable {
   typedef Reshape TableType;
-  std::vector<int32_t> dims;
-  MNN_DATA_FORMAT dimType;
-  ReshapeT()
-      : dimType(MNN_DATA_FORMAT_NCHW) {
-  }
+  std::vector<int32_t> dims{};
+  MNN::MNN_DATA_FORMAT dimType = MNN::MNN_DATA_FORMAT_NCHW;
 };
 
 struct Reshape FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
   typedef ReshapeT NativeTableType;
+  typedef ReshapeBuilder Builder;
   static const flatbuffers::TypeTable *MiniReflectTypeTable() {
     return ReshapeTypeTable();
   }
@@ -3307,8 +3238,8 @@ struct Reshape FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
   const flatbuffers::Vector<int32_t> *dims() const {
     return GetPointer<const flatbuffers::Vector<int32_t> *>(VT_DIMS);
   }
-  MNN_DATA_FORMAT dimType() const {
-    return static_cast<MNN_DATA_FORMAT>(GetField<int8_t>(VT_DIMTYPE, 0));
+  MNN::MNN_DATA_FORMAT dimType() const {
+    return static_cast<MNN::MNN_DATA_FORMAT>(GetField<int8_t>(VT_DIMTYPE, 0));
   }
   bool Verify(flatbuffers::Verifier &verifier) const {
     return VerifyTableStart(verifier) &&
@@ -3323,19 +3254,19 @@ struct Reshape FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
 };
 
 struct ReshapeBuilder {
+  typedef Reshape Table;
   flatbuffers::FlatBufferBuilder &fbb_;
   flatbuffers::uoffset_t start_;
   void add_dims(flatbuffers::Offset<flatbuffers::Vector<int32_t>> dims) {
     fbb_.AddOffset(Reshape::VT_DIMS, dims);
   }
-  void add_dimType(MNN_DATA_FORMAT dimType) {
+  void add_dimType(MNN::MNN_DATA_FORMAT dimType) {
     fbb_.AddElement<int8_t>(Reshape::VT_DIMTYPE, static_cast<int8_t>(dimType), 0);
   }
   explicit ReshapeBuilder(flatbuffers::FlatBufferBuilder &_fbb)
         : fbb_(_fbb) {
     start_ = fbb_.StartTable();
   }
-  ReshapeBuilder &operator=(const ReshapeBuilder &);
   flatbuffers::Offset<Reshape> Finish() {
     const auto end = fbb_.EndTable(start_);
     auto o = flatbuffers::Offset<Reshape>(end);
@@ -3346,7 +3277,7 @@ struct ReshapeBuilder {
 inline flatbuffers::Offset<Reshape> CreateReshape(
     flatbuffers::FlatBufferBuilder &_fbb,
     flatbuffers::Offset<flatbuffers::Vector<int32_t>> dims = 0,
-    MNN_DATA_FORMAT dimType = MNN_DATA_FORMAT_NCHW) {
+    MNN::MNN_DATA_FORMAT dimType = MNN::MNN_DATA_FORMAT_NCHW) {
   ReshapeBuilder builder_(_fbb);
   builder_.add_dims(dims);
   builder_.add_dimType(dimType);
@@ -3356,7 +3287,7 @@ inline flatbuffers::Offset<Reshape> CreateReshape(
 inline flatbuffers::Offset<Reshape> CreateReshapeDirect(
     flatbuffers::FlatBufferBuilder &_fbb,
     const std::vector<int32_t> *dims = nullptr,
-    MNN_DATA_FORMAT dimType = MNN_DATA_FORMAT_NCHW) {
+    MNN::MNN_DATA_FORMAT dimType = MNN::MNN_DATA_FORMAT_NCHW) {
   auto dims__ = dims ? _fbb.CreateVector<int32_t>(*dims) : 0;
   return MNN::CreateReshape(
       _fbb,
@@ -3368,32 +3299,21 @@ flatbuffers::Offset<Reshape> CreateReshape(flatbuffers::FlatBufferBuilder &_fbb,
 
 struct DetectionOutputT : public flatbuffers::NativeTable {
   typedef DetectionOutput TableType;
-  int32_t classCount;
-  float nmsThresholdold;
-  int32_t nmsTopK;
-  int32_t keepTopK;
-  float confidenceThreshold;
-  int32_t shareLocation;
-  int32_t backgroundLable;
-  int32_t varianceEncodedTarget;
-  int32_t codeType;
-  float objectnessScore;
-  DetectionOutputT()
-      : classCount(0),
-        nmsThresholdold(0.0f),
-        nmsTopK(0),
-        keepTopK(0),
-        confidenceThreshold(0.0f),
-        shareLocation(0),
-        backgroundLable(0),
-        varianceEncodedTarget(0),
-        codeType(0),
-        objectnessScore(0.01f) {
-  }
+  int32_t classCount = 0;
+  float nmsThresholdold = 0.0f;
+  int32_t nmsTopK = 0;
+  int32_t keepTopK = 0;
+  float confidenceThreshold = 0.0f;
+  int32_t shareLocation = 0;
+  int32_t backgroundLable = 0;
+  int32_t varianceEncodedTarget = 0;
+  int32_t codeType = 0;
+  float objectnessScore = 0.01f;
 };
 
 struct DetectionOutput FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
   typedef DetectionOutputT NativeTableType;
+  typedef DetectionOutputBuilder Builder;
   static const flatbuffers::TypeTable *MiniReflectTypeTable() {
     return DetectionOutputTypeTable();
   }
@@ -3459,6 +3379,7 @@ struct DetectionOutput FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
 };
 
 struct DetectionOutputBuilder {
+  typedef DetectionOutput Table;
   flatbuffers::FlatBufferBuilder &fbb_;
   flatbuffers::uoffset_t start_;
   void add_classCount(int32_t classCount) {
@@ -3495,7 +3416,6 @@ struct DetectionOutputBuilder {
         : fbb_(_fbb) {
     start_ = fbb_.StartTable();
   }
-  DetectionOutputBuilder &operator=(const DetectionOutputBuilder &);
   flatbuffers::Offset<DetectionOutput> Finish() {
     const auto end = fbb_.EndTable(start_);
     auto o = flatbuffers::Offset<DetectionOutput>(end);
@@ -3533,18 +3453,14 @@ flatbuffers::Offset<DetectionOutput> CreateDetectionOutput(flatbuffers::FlatBuff
 
 struct RoiPoolingT : public flatbuffers::NativeTable {
   typedef RoiPooling TableType;
-  int32_t pooledWidth;
-  int32_t pooledHeight;
-  float spatialScale;
-  RoiPoolingT()
-      : pooledWidth(0),
-        pooledHeight(0),
-        spatialScale(0.0f) {
-  }
+  int32_t pooledWidth = 0;
+  int32_t pooledHeight = 0;
+  float spatialScale = 0.0f;
 };
 
 struct RoiPooling FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
   typedef RoiPoolingT NativeTableType;
+  typedef RoiPoolingBuilder Builder;
   static const flatbuffers::TypeTable *MiniReflectTypeTable() {
     return RoiPoolingTypeTable();
   }
@@ -3575,6 +3491,7 @@ struct RoiPooling FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
 };
 
 struct RoiPoolingBuilder {
+  typedef RoiPooling Table;
   flatbuffers::FlatBufferBuilder &fbb_;
   flatbuffers::uoffset_t start_;
   void add_pooledWidth(int32_t pooledWidth) {
@@ -3590,7 +3507,6 @@ struct RoiPoolingBuilder {
         : fbb_(_fbb) {
     start_ = fbb_.StartTable();
   }
-  RoiPoolingBuilder &operator=(const RoiPoolingBuilder &);
   flatbuffers::Offset<RoiPooling> Finish() {
     const auto end = fbb_.EndTable(start_);
     auto o = flatbuffers::Offset<RoiPooling>(end);
@@ -3614,27 +3530,20 @@ flatbuffers::Offset<RoiPooling> CreateRoiPooling(flatbuffers::FlatBufferBuilder
 
 struct ProposalT : public flatbuffers::NativeTable {
   typedef Proposal TableType;
-  int32_t featStride;
-  int32_t baseSize;
-  int32_t preNmsTopN;
-  int32_t afterNmsTopN;
-  float nmsThreshold;
-  int32_t minSize;
-  std::unique_ptr<BlobT> ratios;
-  std::unique_ptr<BlobT> scales;
-  std::unique_ptr<BlobT> anchors;
-  ProposalT()
-      : featStride(0),
-        baseSize(0),
-        preNmsTopN(0),
-        afterNmsTopN(0),
-        nmsThreshold(0.0f),
-        minSize(0) {
-  }
+  int32_t featStride = 0;
+  int32_t baseSize = 0;
+  int32_t preNmsTopN = 0;
+  int32_t afterNmsTopN = 0;
+  float nmsThreshold = 0.0f;
+  int32_t minSize = 0;
+  std::unique_ptr<MNN::BlobT> ratios{};
+  std::unique_ptr<MNN::BlobT> scales{};
+  std::unique_ptr<MNN::BlobT> anchors{};
 };
 
 struct Proposal FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
   typedef ProposalT NativeTableType;
+  typedef ProposalBuilder Builder;
   static const flatbuffers::TypeTable *MiniReflectTypeTable() {
     return ProposalTypeTable();
   }
@@ -3667,14 +3576,14 @@ struct Proposal FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
   int32_t minSize() const {
     return GetField<int32_t>(VT_MINSIZE, 0);
   }
-  const Blob *ratios() const {
-    return GetPointer<const Blob *>(VT_RATIOS);
+  const MNN::Blob *ratios() const {
+    return GetPointer<const MNN::Blob *>(VT_RATIOS);
   }
-  const Blob *scales() const {
-    return GetPointer<const Blob *>(VT_SCALES);
+  const MNN::Blob *scales() const {
+    return GetPointer<const MNN::Blob *>(VT_SCALES);
   }
-  const Blob *anchors() const {
-    return GetPointer<const Blob *>(VT_ANCHORS);
+  const MNN::Blob *anchors() const {
+    return GetPointer<const MNN::Blob *>(VT_ANCHORS);
   }
   bool Verify(flatbuffers::Verifier &verifier) const {
     return VerifyTableStart(verifier) &&
@@ -3698,6 +3607,7 @@ struct Proposal FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
 };
 
 struct ProposalBuilder {
+  typedef Proposal Table;
   flatbuffers::FlatBufferBuilder &fbb_;
   flatbuffers::uoffset_t start_;
   void add_featStride(int32_t featStride) {
@@ -3718,20 +3628,19 @@ struct ProposalBuilder {
   void add_minSize(int32_t minSize) {
     fbb_.AddElement<int32_t>(Proposal::VT_MINSIZE, minSize, 0);
   }
-  void add_ratios(flatbuffers::Offset<Blob> ratios) {
+  void add_ratios(flatbuffers::Offset<MNN::Blob> ratios) {
     fbb_.AddOffset(Proposal::VT_RATIOS, ratios);
   }
-  void add_scales(flatbuffers::Offset<Blob> scales) {
+  void add_scales(flatbuffers::Offset<MNN::Blob> scales) {
     fbb_.AddOffset(Proposal::VT_SCALES, scales);
   }
-  void add_anchors(flatbuffers::Offset<Blob> anchors) {
+  void add_anchors(flatbuffers::Offset<MNN::Blob> anchors) {
     fbb_.AddOffset(Proposal::VT_ANCHORS, anchors);
   }
   explicit ProposalBuilder(flatbuffers::FlatBufferBuilder &_fbb)
         : fbb_(_fbb) {
     start_ = fbb_.StartTable();
   }
-  ProposalBuilder &operator=(const ProposalBuilder &);
   flatbuffers::Offset<Proposal> Finish() {
     const auto end = fbb_.EndTable(start_);
     auto o = flatbuffers::Offset<Proposal>(end);
@@ -3747,9 +3656,9 @@ inline flatbuffers::Offset<Proposal> CreateProposal(
     int32_t afterNmsTopN = 0,
     float nmsThreshold = 0.0f,
     int32_t minSize = 0,
-    flatbuffers::Offset<Blob> ratios = 0,
-    flatbuffers::Offset<Blob> scales = 0,
-    flatbuffers::Offset<Blob> anchors = 0) {
+    flatbuffers::Offset<MNN::Blob> ratios = 0,
+    flatbuffers::Offset<MNN::Blob> scales = 0,
+    flatbuffers::Offset<MNN::Blob> anchors = 0) {
   ProposalBuilder builder_(_fbb);
   builder_.add_anchors(anchors);
   builder_.add_scales(scales);
@@ -3767,34 +3676,22 @@ flatbuffers::Offset<Proposal> CreateProposal(flatbuffers::FlatBufferBuilder &_fb
 
 struct InterpT : public flatbuffers::NativeTable {
   typedef Interp TableType;
-  float widthScale;
-  float heightScale;
-  int32_t outputWidth;
-  int32_t outputHeight;
-  int32_t resizeType;
-  bool alignCorners;
-  bool halfPixelCenters;
-  float widthOffset;
-  float heightOffset;
-  float cubicCoeffA;
-  CoordinateTransformationMode ctm;
-  InterpT()
-      : widthScale(0.0f),
-        heightScale(0.0f),
-        outputWidth(0),
-        outputHeight(0),
-        resizeType(0),
-        alignCorners(false),
-        halfPixelCenters(false),
-        widthOffset(0.0f),
-        heightOffset(0.0f),
-        cubicCoeffA(-0.75f),
-        ctm(CoordinateTransformationMode_NotSet) {
-  }
+  float widthScale = 0.0f;
+  float heightScale = 0.0f;
+  int32_t outputWidth = 0;
+  int32_t outputHeight = 0;
+  int32_t resizeType = 0;
+  bool alignCorners = false;
+  bool halfPixelCenters = false;
+  float widthOffset = 0.0f;
+  float heightOffset = 0.0f;
+  float cubicCoeffA = -0.75f;
+  MNN::CoordinateTransformationMode ctm = MNN::CoordinateTransformationMode_NotSet;
 };
 
 struct Interp FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
   typedef InterpT NativeTableType;
+  typedef InterpBuilder Builder;
   static const flatbuffers::TypeTable *MiniReflectTypeTable() {
     return InterpTypeTable();
   }
@@ -3841,8 +3738,8 @@ struct Interp FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
   float cubicCoeffA() const {
     return GetField<float>(VT_CUBICCOEFFA, -0.75f);
   }
-  CoordinateTransformationMode ctm() const {
-    return static_cast<CoordinateTransformationMode>(GetField<int8_t>(VT_CTM, 0));
+  MNN::CoordinateTransformationMode ctm() const {
+    return static_cast<MNN::CoordinateTransformationMode>(GetField<int8_t>(VT_CTM, 0));
   }
   bool Verify(flatbuffers::Verifier &verifier) const {
     return VerifyTableStart(verifier) &&
@@ -3865,6 +3762,7 @@ struct Interp FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
 };
 
 struct InterpBuilder {
+  typedef Interp Table;
   flatbuffers::FlatBufferBuilder &fbb_;
   flatbuffers::uoffset_t start_;
   void add_widthScale(float widthScale) {
@@ -3897,14 +3795,13 @@ struct InterpBuilder {
   void add_cubicCoeffA(float cubicCoeffA) {
     fbb_.AddElement<float>(Interp::VT_CUBICCOEFFA, cubicCoeffA, -0.75f);
   }
-  void add_ctm(CoordinateTransformationMode ctm) {
+  void add_ctm(MNN::CoordinateTransformationMode ctm) {
     fbb_.AddElement<int8_t>(Interp::VT_CTM, static_cast<int8_t>(ctm), 0);
   }
   explicit InterpBuilder(flatbuffers::FlatBufferBuilder &_fbb)
         : fbb_(_fbb) {
     start_ = fbb_.StartTable();
   }
-  InterpBuilder &operator=(const InterpBuilder &);
   flatbuffers::Offset<Interp> Finish() {
     const auto end = fbb_.EndTable(start_);
     auto o = flatbuffers::Offset<Interp>(end);
@@ -3924,7 +3821,7 @@ inline flatbuffers::Offset<Interp> CreateInterp(
     float widthOffset = 0.0f,
     float heightOffset = 0.0f,
     float cubicCoeffA = -0.75f,
-    CoordinateTransformationMode ctm = CoordinateTransformationMode_NotSet) {
+    MNN::CoordinateTransformationMode ctm = MNN::CoordinateTransformationMode_NotSet) {
   InterpBuilder builder_(_fbb);
   builder_.add_cubicCoeffA(cubicCoeffA);
   builder_.add_heightOffset(heightOffset);
@@ -3944,16 +3841,13 @@ flatbuffers::Offset<Interp> CreateInterp(flatbuffers::FlatBufferBuilder &_fbb, c
 
 struct ResizeT : public flatbuffers::NativeTable {
   typedef Resize TableType;
-  float xScale;
-  float yScale;
-  ResizeT()
-      : xScale(0.0f),
-        yScale(0.0f) {
-  }
+  float xScale = 0.0f;
+  float yScale = 0.0f;
 };
 
 struct Resize FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
   typedef ResizeT NativeTableType;
+  typedef ResizeBuilder Builder;
   static const flatbuffers::TypeTable *MiniReflectTypeTable() {
     return ResizeTypeTable();
   }
@@ -3979,6 +3873,7 @@ struct Resize FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
 };
 
 struct ResizeBuilder {
+  typedef Resize Table;
   flatbuffers::FlatBufferBuilder &fbb_;
   flatbuffers::uoffset_t start_;
   void add_xScale(float xScale) {
@@ -3991,7 +3886,6 @@ struct ResizeBuilder {
         : fbb_(_fbb) {
     start_ = fbb_.StartTable();
   }
-  ResizeBuilder &operator=(const ResizeBuilder &);
   flatbuffers::Offset<Resize> Finish() {
     const auto end = fbb_.EndTable(start_);
     auto o = flatbuffers::Offset<Resize>(end);
@@ -4013,30 +3907,22 @@ flatbuffers::Offset<Resize> CreateResize(flatbuffers::FlatBufferBuilder &_fbb, c
 
 struct PriorBoxT : public flatbuffers::NativeTable {
   typedef PriorBox TableType;
-  std::vector<float> minSizes;
-  std::vector<float> maxSizes;
-  std::vector<float> aspectRatios;
-  std::vector<float> variances;
-  bool flip;
-  bool clip;
-  int32_t imageWidth;
-  int32_t imageHeight;
-  int32_t stepWidth;
-  int32_t stepHeight;
-  float offset;
-  PriorBoxT()
-      : flip(false),
-        clip(false),
-        imageWidth(0),
-        imageHeight(0),
-        stepWidth(0),
-        stepHeight(0),
-        offset(0.0f) {
-  }
+  std::vector<float> minSizes{};
+  std::vector<float> maxSizes{};
+  std::vector<float> aspectRatios{};
+  std::vector<float> variances{};
+  bool flip = false;
+  bool clip = false;
+  int32_t imageWidth = 0;
+  int32_t imageHeight = 0;
+  int32_t stepWidth = 0;
+  int32_t stepHeight = 0;
+  float offset = 0.0f;
 };
 
 struct PriorBox FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
   typedef PriorBoxT NativeTableType;
+  typedef PriorBoxBuilder Builder;
   static const flatbuffers::TypeTable *MiniReflectTypeTable() {
     return PriorBoxTypeTable();
   }
@@ -4111,6 +3997,7 @@ struct PriorBox FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
 };
 
 struct PriorBoxBuilder {
+  typedef PriorBox Table;
   flatbuffers::FlatBufferBuilder &fbb_;
   flatbuffers::uoffset_t start_;
   void add_minSizes(flatbuffers::Offset<flatbuffers::Vector<float>> minSizes) {
@@ -4150,7 +4037,6 @@ struct PriorBoxBuilder {
         : fbb_(_fbb) {
     start_ = fbb_.StartTable();
   }
-  PriorBoxBuilder &operator=(const PriorBoxBuilder &);
   flatbuffers::Offset<PriorBox> Finish() {
     const auto end = fbb_.EndTable(start_);
     auto o = flatbuffers::Offset<PriorBox>(end);
@@ -4222,19 +4108,15 @@ flatbuffers::Offset<PriorBox> CreatePriorBox(flatbuffers::FlatBufferBuilder &_fb
 
 struct NormalizeT : public flatbuffers::NativeTable {
   typedef Normalize TableType;
-  int32_t acrossSpatial;
-  int32_t channelShared;
-  float eps;
-  std::vector<float> scale;
-  NormalizeT()
-      : acrossSpatial(0),
-        channelShared(0),
-        eps(0.0f) {
-  }
+  int32_t acrossSpatial = 0;
+  int32_t channelShared = 0;
+  float eps = 0.0f;
+  std::vector<float> scale{};
 };
 
 struct Normalize FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
   typedef NormalizeT NativeTableType;
+  typedef NormalizeBuilder Builder;
   static const flatbuffers::TypeTable *MiniReflectTypeTable() {
     return NormalizeTypeTable();
   }
@@ -4271,6 +4153,7 @@ struct Normalize FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
 };
 
 struct NormalizeBuilder {
+  typedef Normalize Table;
   flatbuffers::FlatBufferBuilder &fbb_;
   flatbuffers::uoffset_t start_;
   void add_acrossSpatial(int32_t acrossSpatial) {
@@ -4289,7 +4172,6 @@ struct NormalizeBuilder {
         : fbb_(_fbb) {
     start_ = fbb_.StartTable();
   }
-  NormalizeBuilder &operator=(const NormalizeBuilder &);
   flatbuffers::Offset<Normalize> Finish() {
     const auto end = fbb_.EndTable(start_);
     auto o = flatbuffers::Offset<Normalize>(end);
@@ -4330,17 +4212,15 @@ flatbuffers::Offset<Normalize> CreateNormalize(flatbuffers::FlatBufferBuilder &_
 
 struct EltwiseInt8T : public flatbuffers::NativeTable {
   typedef EltwiseInt8 TableType;
-  EltwiseType type;
-  std::unique_ptr<QuantizedFloatParamT> inputQuan0;
-  std::unique_ptr<QuantizedFloatParamT> inputQuan1;
-  std::unique_ptr<QuantizedFloatParamT> outputQuan;
-  EltwiseInt8T()
-      : type(EltwiseType_PROD) {
-  }
+  MNN::EltwiseType type = MNN::EltwiseType_PROD;
+  std::unique_ptr<MNN::QuantizedFloatParamT> inputQuan0{};
+  std::unique_ptr<MNN::QuantizedFloatParamT> inputQuan1{};
+  std::unique_ptr<MNN::QuantizedFloatParamT> outputQuan{};
 };
 
 struct EltwiseInt8 FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
   typedef EltwiseInt8T NativeTableType;
+  typedef EltwiseInt8Builder Builder;
   static const flatbuffers::TypeTable *MiniReflectTypeTable() {
     return EltwiseInt8TypeTable();
   }
@@ -4350,17 +4230,17 @@ struct EltwiseInt8 FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
     VT_INPUTQUAN1 = 8,
     VT_OUTPUTQUAN = 10
   };
-  EltwiseType type() const {
-    return static_cast<EltwiseType>(GetField<int8_t>(VT_TYPE, 0));
+  MNN::EltwiseType type() const {
+    return static_cast<MNN::EltwiseType>(GetField<int8_t>(VT_TYPE, 0));
   }
-  const QuantizedFloatParam *inputQuan0() const {
-    return GetPointer<const QuantizedFloatParam *>(VT_INPUTQUAN0);
+  const MNN::QuantizedFloatParam *inputQuan0() const {
+    return GetPointer<const MNN::QuantizedFloatParam *>(VT_INPUTQUAN0);
   }
-  const QuantizedFloatParam *inputQuan1() const {
-    return GetPointer<const QuantizedFloatParam *>(VT_INPUTQUAN1);
+  const MNN::QuantizedFloatParam *inputQuan1() const {
+    return GetPointer<const MNN::QuantizedFloatParam *>(VT_INPUTQUAN1);
   }
-  const QuantizedFloatParam *outputQuan() const {
-    return GetPointer<const QuantizedFloatParam *>(VT_OUTPUTQUAN);
+  const MNN::QuantizedFloatParam *outputQuan() const {
+    return GetPointer<const MNN::QuantizedFloatParam *>(VT_OUTPUTQUAN);
   }
   bool Verify(flatbuffers::Verifier &verifier) const {
     return VerifyTableStart(verifier) &&
@@ -4379,25 +4259,25 @@ struct EltwiseInt8 FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
 };
 
 struct EltwiseInt8Builder {
+  typedef EltwiseInt8 Table;
   flatbuffers::FlatBufferBuilder &fbb_;
   flatbuffers::uoffset_t start_;
-  void add_type(EltwiseType type) {
+  void add_type(MNN::EltwiseType type) {
     fbb_.AddElement<int8_t>(EltwiseInt8::VT_TYPE, static_cast<int8_t>(type), 0);
   }
-  void add_inputQuan0(flatbuffers::Offset<QuantizedFloatParam> inputQuan0) {
+  void add_inputQuan0(flatbuffers::Offset<MNN::QuantizedFloatParam> inputQuan0) {
     fbb_.AddOffset(EltwiseInt8::VT_INPUTQUAN0, inputQuan0);
   }
-  void add_inputQuan1(flatbuffers::Offset<QuantizedFloatParam> inputQuan1) {
+  void add_inputQuan1(flatbuffers::Offset<MNN::QuantizedFloatParam> inputQuan1) {
     fbb_.AddOffset(EltwiseInt8::VT_INPUTQUAN1, inputQuan1);
   }
-  void add_outputQuan(flatbuffers::Offset<QuantizedFloatParam> outputQuan) {
+  void add_outputQuan(flatbuffers::Offset<MNN::QuantizedFloatParam> outputQuan) {
     fbb_.AddOffset(EltwiseInt8::VT_OUTPUTQUAN, outputQuan);
   }
   explicit EltwiseInt8Builder(flatbuffers::FlatBufferBuilder &_fbb)
         : fbb_(_fbb) {
     start_ = fbb_.StartTable();
   }
-  EltwiseInt8Builder &operator=(const EltwiseInt8Builder &);
   flatbuffers::Offset<EltwiseInt8> Finish() {
     const auto end = fbb_.EndTable(start_);
     auto o = flatbuffers::Offset<EltwiseInt8>(end);
@@ -4407,10 +4287,10 @@ struct EltwiseInt8Builder {
 
 inline flatbuffers::Offset<EltwiseInt8> CreateEltwiseInt8(
     flatbuffers::FlatBufferBuilder &_fbb,
-    EltwiseType type = EltwiseType_PROD,
-    flatbuffers::Offset<QuantizedFloatParam> inputQuan0 = 0,
-    flatbuffers::Offset<QuantizedFloatParam> inputQuan1 = 0,
-    flatbuffers::Offset<QuantizedFloatParam> outputQuan = 0) {
+    MNN::EltwiseType type = MNN::EltwiseType_PROD,
+    flatbuffers::Offset<MNN::QuantizedFloatParam> inputQuan0 = 0,
+    flatbuffers::Offset<MNN::QuantizedFloatParam> inputQuan1 = 0,
+    flatbuffers::Offset<MNN::QuantizedFloatParam> outputQuan = 0) {
   EltwiseInt8Builder builder_(_fbb);
   builder_.add_outputQuan(outputQuan);
   builder_.add_inputQuan1(inputQuan1);
@@ -4422,30 +4302,30 @@ inline flatbuffers::Offset<EltwiseInt8> CreateEltwiseInt8(
 flatbuffers::Offset<EltwiseInt8> CreateEltwiseInt8(flatbuffers::FlatBufferBuilder &_fbb, const EltwiseInt8T *_o, const flatbuffers::rehasher_function_t *_rehasher = nullptr);
 
 inline Convolution2DCommonT *Convolution2DCommon::UnPack(const flatbuffers::resolver_function_t *_resolver) const {
-  auto _o = new Convolution2DCommonT();
-  UnPackTo(_o, _resolver);
-  return _o;
+  auto _o = std::unique_ptr<Convolution2DCommonT>(new Convolution2DCommonT());
+  UnPackTo(_o.get(), _resolver);
+  return _o.release();
 }
 
 inline void Convolution2DCommon::UnPackTo(Convolution2DCommonT *_o, const flatbuffers::resolver_function_t *_resolver) const {
   (void)_o;
   (void)_resolver;
-  { auto _e = padX(); _o->padX = _e; };
-  { auto _e = padY(); _o->padY = _e; };
-  { auto _e = kernelX(); _o->kernelX = _e; };
-  { auto _e = kernelY(); _o->kernelY = _e; };
-  { auto _e = strideX(); _o->strideX = _e; };
-  { auto _e = strideY(); _o->strideY = _e; };
-  { auto _e = dilateX(); _o->dilateX = _e; };
-  { auto _e = dilateY(); _o->dilateY = _e; };
-  { auto _e = padMode(); _o->padMode = _e; };
-  { auto _e = group(); _o->group = _e; };
-  { auto _e = outputCount(); _o->outputCount = _e; };
-  { auto _e = inputCount(); _o->inputCount = _e; };
-  { auto _e = relu(); _o->relu = _e; };
-  { auto _e = relu6(); _o->relu6 = _e; };
-  { auto _e = pads(); if (_e) { _o->pads.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->pads[_i] = _e->Get(_i); } } };
-  { auto _e = outPads(); if (_e) { _o->outPads.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->outPads[_i] = _e->Get(_i); } } };
+  { auto _e = padX(); _o->padX = _e; }
+  { auto _e = padY(); _o->padY = _e; }
+  { auto _e = kernelX(); _o->kernelX = _e; }
+  { auto _e = kernelY(); _o->kernelY = _e; }
+  { auto _e = strideX(); _o->strideX = _e; }
+  { auto _e = strideY(); _o->strideY = _e; }
+  { auto _e = dilateX(); _o->dilateX = _e; }
+  { auto _e = dilateY(); _o->dilateY = _e; }
+  { auto _e = padMode(); _o->padMode = _e; }
+  { auto _e = group(); _o->group = _e; }
+  { auto _e = outputCount(); _o->outputCount = _e; }
+  { auto _e = inputCount(); _o->inputCount = _e; }
+  { auto _e = relu(); _o->relu = _e; }
+  { auto _e = relu6(); _o->relu6 = _e; }
+  { auto _e = pads(); if (_e) { _o->pads.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->pads[_i] = _e->Get(_i); } } }
+  { auto _e = outPads(); if (_e) { _o->outPads.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->outPads[_i] = _e->Get(_i); } } }
 }
 
 inline flatbuffers::Offset<Convolution2DCommon> Convolution2DCommon::Pack(flatbuffers::FlatBufferBuilder &_fbb, const Convolution2DCommonT* _o, const flatbuffers::rehasher_function_t *_rehasher) {
@@ -4493,23 +4373,23 @@ inline flatbuffers::Offset<Convolution2DCommon> CreateConvolution2DCommon(flatbu
 }
 
 inline Convolution3DCommonT *Convolution3DCommon::UnPack(const flatbuffers::resolver_function_t *_resolver) const {
-  auto _o = new Convolution3DCommonT();
-  UnPackTo(_o, _resolver);
-  return _o;
+  auto _o = std::unique_ptr<Convolution3DCommonT>(new Convolution3DCommonT());
+  UnPackTo(_o.get(), _resolver);
+  return _o.release();
 }
 
 inline void Convolution3DCommon::UnPackTo(Convolution3DCommonT *_o, const flatbuffers::resolver_function_t *_resolver) const {
   (void)_o;
   (void)_resolver;
-  { auto _e = dilates(); if (_e) { _o->dilates.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->dilates[_i] = _e->Get(_i); } } };
-  { auto _e = strides(); if (_e) { _o->strides.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->strides[_i] = _e->Get(_i); } } };
-  { auto _e = kernels(); if (_e) { _o->kernels.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->kernels[_i] = _e->Get(_i); } } };
-  { auto _e = pads(); if (_e) { _o->pads.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->pads[_i] = _e->Get(_i); } } };
-  { auto _e = padMode(); _o->padMode = _e; };
-  { auto _e = inputCount(); _o->inputCount = _e; };
-  { auto _e = outputCount(); _o->outputCount = _e; };
-  { auto _e = relu(); _o->relu = _e; };
-  { auto _e = relu6(); _o->relu6 = _e; };
+  { auto _e = dilates(); if (_e) { _o->dilates.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->dilates[_i] = _e->Get(_i); } } }
+  { auto _e = strides(); if (_e) { _o->strides.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->strides[_i] = _e->Get(_i); } } }
+  { auto _e = kernels(); if (_e) { _o->kernels.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->kernels[_i] = _e->Get(_i); } } }
+  { auto _e = pads(); if (_e) { _o->pads.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->pads[_i] = _e->Get(_i); } } }
+  { auto _e = padMode(); _o->padMode = _e; }
+  { auto _e = inputCount(); _o->inputCount = _e; }
+  { auto _e = outputCount(); _o->outputCount = _e; }
+  { auto _e = relu(); _o->relu = _e; }
+  { auto _e = relu6(); _o->relu6 = _e; }
 }
 
 inline flatbuffers::Offset<Convolution3DCommon> Convolution3DCommon::Pack(flatbuffers::FlatBufferBuilder &_fbb, const Convolution3DCommonT* _o, const flatbuffers::rehasher_function_t *_rehasher) {
@@ -4543,25 +4423,25 @@ inline flatbuffers::Offset<Convolution3DCommon> CreateConvolution3DCommon(flatbu
 }
 
 inline IDSTQuanT *IDSTQuan::UnPack(const flatbuffers::resolver_function_t *_resolver) const {
-  auto _o = new IDSTQuanT();
-  UnPackTo(_o, _resolver);
-  return _o;
+  auto _o = std::unique_ptr<IDSTQuanT>(new IDSTQuanT());
+  UnPackTo(_o.get(), _resolver);
+  return _o.release();
 }
 
 inline void IDSTQuan::UnPackTo(IDSTQuanT *_o, const flatbuffers::resolver_function_t *_resolver) const {
   (void)_o;
   (void)_resolver;
-  { auto _e = buffer(); if (_e) { _o->buffer.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->buffer[_i] = _e->Get(_i); } } };
-  { auto _e = alpha(); if (_e) { _o->alpha.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->alpha[_i] = _e->Get(_i); } } };
-  { auto _e = type(); _o->type = _e; };
-  { auto _e = useInt32(); _o->useInt32 = _e; };
-  { auto _e = quantScale(); _o->quantScale = _e; };
-  { auto _e = scaleIn(); _o->scaleIn = _e; };
-  { auto _e = scaleOut(); _o->scaleOut = _e; };
-  { auto _e = aMax(); _o->aMax = _e; };
-  { auto _e = aMin(); _o->aMin = _e; };
-  { auto _e = readType(); _o->readType = _e; };
-  { auto _e = has_scaleInt(); _o->has_scaleInt = _e; };
+  { auto _e = buffer(); if (_e) { _o->buffer.resize(_e->size()); std::copy(_e->begin(), _e->end(), _o->buffer.begin()); } }
+  { auto _e = alpha(); if (_e) { _o->alpha.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->alpha[_i] = _e->Get(_i); } } }
+  { auto _e = type(); _o->type = _e; }
+  { auto _e = useInt32(); _o->useInt32 = _e; }
+  { auto _e = quantScale(); _o->quantScale = _e; }
+  { auto _e = scaleIn(); _o->scaleIn = _e; }
+  { auto _e = scaleOut(); _o->scaleOut = _e; }
+  { auto _e = aMax(); _o->aMax = _e; }
+  { auto _e = aMin(); _o->aMin = _e; }
+  { auto _e = readType(); _o->readType = _e; }
+  { auto _e = has_scaleInt(); _o->has_scaleInt = _e; }
 }
 
 inline flatbuffers::Offset<IDSTQuan> IDSTQuan::Pack(flatbuffers::FlatBufferBuilder &_fbb, const IDSTQuanT* _o, const flatbuffers::rehasher_function_t *_rehasher) {
@@ -4599,20 +4479,20 @@ inline flatbuffers::Offset<IDSTQuan> CreateIDSTQuan(flatbuffers::FlatBufferBuild
 }
 
 inline QuantizedFloatParamT *QuantizedFloatParam::UnPack(const flatbuffers::resolver_function_t *_resolver) const {
-  auto _o = new QuantizedFloatParamT();
-  UnPackTo(_o, _resolver);
-  return _o;
+  auto _o = std::unique_ptr<QuantizedFloatParamT>(new QuantizedFloatParamT());
+  UnPackTo(_o.get(), _resolver);
+  return _o.release();
 }
 
 inline void QuantizedFloatParam::UnPackTo(QuantizedFloatParamT *_o, const flatbuffers::resolver_function_t *_resolver) const {
   (void)_o;
   (void)_resolver;
-  { auto _e = weight(); if (_e) { _o->weight.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->weight[_i] = _e->Get(_i); } } };
-  { auto _e = bias(); if (_e) { _o->bias.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->bias[_i] = _e->Get(_i); } } };
-  { auto _e = scale(); if (_e) { _o->scale.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->scale[_i] = _e->Get(_i); } } };
-  { auto _e = tensorScale(); if (_e) { _o->tensorScale.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->tensorScale[_i] = _e->Get(_i); } } };
-  { auto _e = method(); _o->method = _e; };
-  { auto _e = nbits(); _o->nbits = _e; };
+  { auto _e = weight(); if (_e) { _o->weight.resize(_e->size()); std::copy(_e->begin(), _e->end(), _o->weight.begin()); } }
+  { auto _e = bias(); if (_e) { _o->bias.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->bias[_i] = _e->Get(_i); } } }
+  { auto _e = scale(); if (_e) { _o->scale.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->scale[_i] = _e->Get(_i); } } }
+  { auto _e = tensorScale(); if (_e) { _o->tensorScale.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->tensorScale[_i] = _e->Get(_i); } } }
+  { auto _e = method(); _o->method = _e; }
+  { auto _e = nbits(); _o->nbits = _e; }
 }
 
 inline flatbuffers::Offset<QuantizedFloatParam> QuantizedFloatParam::Pack(flatbuffers::FlatBufferBuilder &_fbb, const QuantizedFloatParamT* _o, const flatbuffers::rehasher_function_t *_rehasher) {
@@ -4640,19 +4520,19 @@ inline flatbuffers::Offset<QuantizedFloatParam> CreateQuantizedFloatParam(flatbu
 }
 
 inline Convolution2DT *Convolution2D::UnPack(const flatbuffers::resolver_function_t *_resolver) const {
-  auto _o = new Convolution2DT();
-  UnPackTo(_o, _resolver);
-  return _o;
+  auto _o = std::unique_ptr<Convolution2DT>(new Convolution2DT());
+  UnPackTo(_o.get(), _resolver);
+  return _o.release();
 }
 
 inline void Convolution2D::UnPackTo(Convolution2DT *_o, const flatbuffers::resolver_function_t *_resolver) const {
   (void)_o;
   (void)_resolver;
-  { auto _e = common(); if (_e) _o->common = std::unique_ptr<Convolution2DCommonT>(_e->UnPack(_resolver)); };
-  { auto _e = weight(); if (_e) { _o->weight.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->weight[_i] = _e->Get(_i); } } };
-  { auto _e = bias(); if (_e) { _o->bias.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->bias[_i] = _e->Get(_i); } } };
-  { auto _e = quanParameter(); if (_e) _o->quanParameter = std::unique_ptr<IDSTQuanT>(_e->UnPack(_resolver)); };
-  { auto _e = symmetricQuan(); if (_e) _o->symmetricQuan = std::unique_ptr<QuantizedFloatParamT>(_e->UnPack(_resolver)); };
+  { auto _e = common(); if (_e) _o->common = std::unique_ptr<MNN::Convolution2DCommonT>(_e->UnPack(_resolver)); }
+  { auto _e = weight(); if (_e) { _o->weight.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->weight[_i] = _e->Get(_i); } } }
+  { auto _e = bias(); if (_e) { _o->bias.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->bias[_i] = _e->Get(_i); } } }
+  { auto _e = quanParameter(); if (_e) _o->quanParameter = std::unique_ptr<MNN::IDSTQuanT>(_e->UnPack(_resolver)); }
+  { auto _e = symmetricQuan(); if (_e) _o->symmetricQuan = std::unique_ptr<MNN::QuantizedFloatParamT>(_e->UnPack(_resolver)); }
 }
 
 inline flatbuffers::Offset<Convolution2D> Convolution2D::Pack(flatbuffers::FlatBufferBuilder &_fbb, const Convolution2DT* _o, const flatbuffers::rehasher_function_t *_rehasher) {
@@ -4678,17 +4558,17 @@ inline flatbuffers::Offset<Convolution2D> CreateConvolution2D(flatbuffers::FlatB
 }
 
 inline Convolution3DT *Convolution3D::UnPack(const flatbuffers::resolver_function_t *_resolver) const {
-  auto _o = new Convolution3DT();
-  UnPackTo(_o, _resolver);
-  return _o;
+  auto _o = std::unique_ptr<Convolution3DT>(new Convolution3DT());
+  UnPackTo(_o.get(), _resolver);
+  return _o.release();
 }
 
 inline void Convolution3D::UnPackTo(Convolution3DT *_o, const flatbuffers::resolver_function_t *_resolver) const {
   (void)_o;
   (void)_resolver;
-  { auto _e = common(); if (_e) _o->common = std::unique_ptr<Convolution3DCommonT>(_e->UnPack(_resolver)); };
-  { auto _e = weight(); if (_e) { _o->weight.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->weight[_i] = _e->Get(_i); } } };
-  { auto _e = bias(); if (_e) { _o->bias.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->bias[_i] = _e->Get(_i); } } };
+  { auto _e = common(); if (_e) _o->common = std::unique_ptr<MNN::Convolution3DCommonT>(_e->UnPack(_resolver)); }
+  { auto _e = weight(); if (_e) { _o->weight.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->weight[_i] = _e->Get(_i); } } }
+  { auto _e = bias(); if (_e) { _o->bias.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->bias[_i] = _e->Get(_i); } } }
 }
 
 inline flatbuffers::Offset<Convolution3D> Convolution3D::Pack(flatbuffers::FlatBufferBuilder &_fbb, const Convolution3DT* _o, const flatbuffers::rehasher_function_t *_rehasher) {
@@ -4710,22 +4590,22 @@ inline flatbuffers::Offset<Convolution3D> CreateConvolution3D(flatbuffers::FlatB
 }
 
 inline InnerProductT *InnerProduct::UnPack(const flatbuffers::resolver_function_t *_resolver) const {
-  auto _o = new InnerProductT();
-  UnPackTo(_o, _resolver);
-  return _o;
+  auto _o = std::unique_ptr<InnerProductT>(new InnerProductT());
+  UnPackTo(_o.get(), _resolver);
+  return _o.release();
 }
 
 inline void InnerProduct::UnPackTo(InnerProductT *_o, const flatbuffers::resolver_function_t *_resolver) const {
   (void)_o;
   (void)_resolver;
-  { auto _e = outputCount(); _o->outputCount = _e; };
-  { auto _e = biasTerm(); _o->biasTerm = _e; };
-  { auto _e = weightSize(); _o->weightSize = _e; };
-  { auto _e = weight(); if (_e) { _o->weight.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->weight[_i] = _e->Get(_i); } } };
-  { auto _e = bias(); if (_e) { _o->bias.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->bias[_i] = _e->Get(_i); } } };
-  { auto _e = axis(); _o->axis = _e; };
-  { auto _e = transpose(); _o->transpose = _e; };
-  { auto _e = quanParameter(); if (_e) _o->quanParameter = std::unique_ptr<IDSTQuanT>(_e->UnPack(_resolver)); };
+  { auto _e = outputCount(); _o->outputCount = _e; }
+  { auto _e = biasTerm(); _o->biasTerm = _e; }
+  { auto _e = weightSize(); _o->weightSize = _e; }
+  { auto _e = weight(); if (_e) { _o->weight.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->weight[_i] = _e->Get(_i); } } }
+  { auto _e = bias(); if (_e) { _o->bias.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->bias[_i] = _e->Get(_i); } } }
+  { auto _e = axis(); _o->axis = _e; }
+  { auto _e = transpose(); _o->transpose = _e; }
+  { auto _e = quanParameter(); if (_e) _o->quanParameter = std::unique_ptr<MNN::IDSTQuanT>(_e->UnPack(_resolver)); }
 }
 
 inline flatbuffers::Offset<InnerProduct> InnerProduct::Pack(flatbuffers::FlatBufferBuilder &_fbb, const InnerProductT* _o, const flatbuffers::rehasher_function_t *_rehasher) {
@@ -4757,27 +4637,27 @@ inline flatbuffers::Offset<InnerProduct> CreateInnerProduct(flatbuffers::FlatBuf
 }
 
 inline PoolT *Pool::UnPack(const flatbuffers::resolver_function_t *_resolver) const {
-  auto _o = new PoolT();
-  UnPackTo(_o, _resolver);
-  return _o;
+  auto _o = std::unique_ptr<PoolT>(new PoolT());
+  UnPackTo(_o.get(), _resolver);
+  return _o.release();
 }
 
 inline void Pool::UnPackTo(PoolT *_o, const flatbuffers::resolver_function_t *_resolver) const {
   (void)_o;
   (void)_resolver;
-  { auto _e = padX(); _o->padX = _e; };
-  { auto _e = padY(); _o->padY = _e; };
-  { auto _e = isGlobal(); _o->isGlobal = _e; };
-  { auto _e = kernelX(); _o->kernelX = _e; };
-  { auto _e = kernelY(); _o->kernelY = _e; };
-  { auto _e = strideX(); _o->strideX = _e; };
-  { auto _e = strideY(); _o->strideY = _e; };
-  { auto _e = type(); _o->type = _e; };
-  { auto _e = padType(); _o->padType = _e; };
-  { auto _e = dataType(); _o->dataType = _e; };
-  { auto _e = ceilModel(); _o->ceilModel = _e; };
-  { auto _e = pads(); if (_e) { _o->pads.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->pads[_i] = _e->Get(_i); } } };
-  { auto _e = countType(); _o->countType = _e; };
+  { auto _e = padX(); _o->padX = _e; }
+  { auto _e = padY(); _o->padY = _e; }
+  { auto _e = isGlobal(); _o->isGlobal = _e; }
+  { auto _e = kernelX(); _o->kernelX = _e; }
+  { auto _e = kernelY(); _o->kernelY = _e; }
+  { auto _e = strideX(); _o->strideX = _e; }
+  { auto _e = strideY(); _o->strideY = _e; }
+  { auto _e = type(); _o->type = _e; }
+  { auto _e = padType(); _o->padType = _e; }
+  { auto _e = dataType(); _o->dataType = _e; }
+  { auto _e = ceilModel(); _o->ceilModel = _e; }
+  { auto _e = pads(); if (_e) { _o->pads.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->pads[_i] = _e->Get(_i); } } }
+  { auto _e = countType(); _o->countType = _e; }
 }
 
 inline flatbuffers::Offset<Pool> Pool::Pack(flatbuffers::FlatBufferBuilder &_fbb, const PoolT* _o, const flatbuffers::rehasher_function_t *_rehasher) {
@@ -4819,19 +4699,19 @@ inline flatbuffers::Offset<Pool> CreatePool(flatbuffers::FlatBufferBuilder &_fbb
 }
 
 inline Pool3DT *Pool3D::UnPack(const flatbuffers::resolver_function_t *_resolver) const {
-  auto _o = new Pool3DT();
-  UnPackTo(_o, _resolver);
-  return _o;
+  auto _o = std::unique_ptr<Pool3DT>(new Pool3DT());
+  UnPackTo(_o.get(), _resolver);
+  return _o.release();
 }
 
 inline void Pool3D::UnPackTo(Pool3DT *_o, const flatbuffers::resolver_function_t *_resolver) const {
   (void)_o;
   (void)_resolver;
-  { auto _e = strides(); if (_e) { _o->strides.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->strides[_i] = _e->Get(_i); } } };
-  { auto _e = kernels(); if (_e) { _o->kernels.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->kernels[_i] = _e->Get(_i); } } };
-  { auto _e = pads(); if (_e) { _o->pads.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->pads[_i] = _e->Get(_i); } } };
-  { auto _e = type(); _o->type = _e; };
-  { auto _e = padType(); _o->padType = _e; };
+  { auto _e = strides(); if (_e) { _o->strides.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->strides[_i] = _e->Get(_i); } } }
+  { auto _e = kernels(); if (_e) { _o->kernels.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->kernels[_i] = _e->Get(_i); } } }
+  { auto _e = pads(); if (_e) { _o->pads.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->pads[_i] = _e->Get(_i); } } }
+  { auto _e = type(); _o->type = _e; }
+  { auto _e = padType(); _o->padType = _e; }
 }
 
 inline flatbuffers::Offset<Pool3D> Pool3D::Pack(flatbuffers::FlatBufferBuilder &_fbb, const Pool3DT* _o, const flatbuffers::rehasher_function_t *_rehasher) {
@@ -4857,15 +4737,15 @@ inline flatbuffers::Offset<Pool3D> CreatePool3D(flatbuffers::FlatBufferBuilder &
 }
 
 inline ReluT *Relu::UnPack(const flatbuffers::resolver_function_t *_resolver) const {
-  auto _o = new ReluT();
-  UnPackTo(_o, _resolver);
-  return _o;
+  auto _o = std::unique_ptr<ReluT>(new ReluT());
+  UnPackTo(_o.get(), _resolver);
+  return _o.release();
 }
 
 inline void Relu::UnPackTo(ReluT *_o, const flatbuffers::resolver_function_t *_resolver) const {
   (void)_o;
   (void)_resolver;
-  { auto _e = slope(); _o->slope = _e; };
+  { auto _e = slope(); _o->slope = _e; }
 }
 
 inline flatbuffers::Offset<Relu> Relu::Pack(flatbuffers::FlatBufferBuilder &_fbb, const ReluT* _o, const flatbuffers::rehasher_function_t *_rehasher) {
@@ -4883,16 +4763,16 @@ inline flatbuffers::Offset<Relu> CreateRelu(flatbuffers::FlatBufferBuilder &_fbb
 }
 
 inline Relu6T *Relu6::UnPack(const flatbuffers::resolver_function_t *_resolver) const {
-  auto _o = new Relu6T();
-  UnPackTo(_o, _resolver);
-  return _o;
+  auto _o = std::unique_ptr<Relu6T>(new Relu6T());
+  UnPackTo(_o.get(), _resolver);
+  return _o.release();
 }
 
 inline void Relu6::UnPackTo(Relu6T *_o, const flatbuffers::resolver_function_t *_resolver) const {
   (void)_o;
   (void)_resolver;
-  { auto _e = minValue(); _o->minValue = _e; };
-  { auto _e = maxValue(); _o->maxValue = _e; };
+  { auto _e = minValue(); _o->minValue = _e; }
+  { auto _e = maxValue(); _o->maxValue = _e; }
 }
 
 inline flatbuffers::Offset<Relu6> Relu6::Pack(flatbuffers::FlatBufferBuilder &_fbb, const Relu6T* _o, const flatbuffers::rehasher_function_t *_rehasher) {
@@ -4912,16 +4792,16 @@ inline flatbuffers::Offset<Relu6> CreateRelu6(flatbuffers::FlatBufferBuilder &_f
 }
 
 inline PReluT *PRelu::UnPack(const flatbuffers::resolver_function_t *_resolver) const {
-  auto _o = new PReluT();
-  UnPackTo(_o, _resolver);
-  return _o;
+  auto _o = std::unique_ptr<PReluT>(new PReluT());
+  UnPackTo(_o.get(), _resolver);
+  return _o.release();
 }
 
 inline void PRelu::UnPackTo(PReluT *_o, const flatbuffers::resolver_function_t *_resolver) const {
   (void)_o;
   (void)_resolver;
-  { auto _e = slopeCount(); _o->slopeCount = _e; };
-  { auto _e = slope(); if (_e) { _o->slope.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->slope[_i] = _e->Get(_i); } } };
+  { auto _e = slopeCount(); _o->slopeCount = _e; }
+  { auto _e = slope(); if (_e) { _o->slope.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->slope[_i] = _e->Get(_i); } } }
 }
 
 inline flatbuffers::Offset<PRelu> PRelu::Pack(flatbuffers::FlatBufferBuilder &_fbb, const PReluT* _o, const flatbuffers::rehasher_function_t *_rehasher) {
@@ -4941,15 +4821,15 @@ inline flatbuffers::Offset<PRelu> CreatePRelu(flatbuffers::FlatBufferBuilder &_f
 }
 
 inline ELUT *ELU::UnPack(const flatbuffers::resolver_function_t *_resolver) const {
-  auto _o = new ELUT();
-  UnPackTo(_o, _resolver);
-  return _o;
+  auto _o = std::unique_ptr<ELUT>(new ELUT());
+  UnPackTo(_o.get(), _resolver);
+  return _o.release();
 }
 
 inline void ELU::UnPackTo(ELUT *_o, const flatbuffers::resolver_function_t *_resolver) const {
   (void)_o;
   (void)_resolver;
-  { auto _e = alpha(); _o->alpha = _e; };
+  { auto _e = alpha(); _o->alpha = _e; }
 }
 
 inline flatbuffers::Offset<ELU> ELU::Pack(flatbuffers::FlatBufferBuilder &_fbb, const ELUT* _o, const flatbuffers::rehasher_function_t *_rehasher) {
@@ -4967,18 +4847,18 @@ inline flatbuffers::Offset<ELU> CreateELU(flatbuffers::FlatBufferBuilder &_fbb,
 }
 
 inline LRNT *LRN::UnPack(const flatbuffers::resolver_function_t *_resolver) const {
-  auto _o = new LRNT();
-  UnPackTo(_o, _resolver);
-  return _o;
+  auto _o = std::unique_ptr<LRNT>(new LRNT());
+  UnPackTo(_o.get(), _resolver);
+  return _o.release();
 }
 
 inline void LRN::UnPackTo(LRNT *_o, const flatbuffers::resolver_function_t *_resolver) const {
   (void)_o;
   (void)_resolver;
-  { auto _e = regionType(); _o->regionType = _e; };
-  { auto _e = localSize(); _o->localSize = _e; };
-  { auto _e = alpha(); _o->alpha = _e; };
-  { auto _e = beta(); _o->beta = _e; };
+  { auto _e = regionType(); _o->regionType = _e; }
+  { auto _e = localSize(); _o->localSize = _e; }
+  { auto _e = alpha(); _o->alpha = _e; }
+  { auto _e = beta(); _o->beta = _e; }
 }
 
 inline flatbuffers::Offset<LRN> LRN::Pack(flatbuffers::FlatBufferBuilder &_fbb, const LRNT* _o, const flatbuffers::rehasher_function_t *_rehasher) {
@@ -5002,18 +4882,18 @@ inline flatbuffers::Offset<LRN> CreateLRN(flatbuffers::FlatBufferBuilder &_fbb,
 }
 
 inline ArgMaxT *ArgMax::UnPack(const flatbuffers::resolver_function_t *_resolver) const {
-  auto _o = new ArgMaxT();
-  UnPackTo(_o, _resolver);
-  return _o;
+  auto _o = std::unique_ptr<ArgMaxT>(new ArgMaxT());
+  UnPackTo(_o.get(), _resolver);
+  return _o.release();
 }
 
 inline void ArgMax::UnPackTo(ArgMaxT *_o, const flatbuffers::resolver_function_t *_resolver) const {
   (void)_o;
   (void)_resolver;
-  { auto _e = outMaxVal(); _o->outMaxVal = _e; };
-  { auto _e = topK(); _o->topK = _e; };
-  { auto _e = axis(); _o->axis = _e; };
-  { auto _e = softmaxThreshold(); _o->softmaxThreshold = _e; };
+  { auto _e = outMaxVal(); _o->outMaxVal = _e; }
+  { auto _e = topK(); _o->topK = _e; }
+  { auto _e = axis(); _o->axis = _e; }
+  { auto _e = softmaxThreshold(); _o->softmaxThreshold = _e; }
 }
 
 inline flatbuffers::Offset<ArgMax> ArgMax::Pack(flatbuffers::FlatBufferBuilder &_fbb, const ArgMaxT* _o, const flatbuffers::rehasher_function_t *_rehasher) {
@@ -5037,15 +4917,15 @@ inline flatbuffers::Offset<ArgMax> CreateArgMax(flatbuffers::FlatBufferBuilder &
 }
 
 inline AxisT *Axis::UnPack(const flatbuffers::resolver_function_t *_resolver) const {
-  auto _o = new AxisT();
-  UnPackTo(_o, _resolver);
-  return _o;
+  auto _o = std::unique_ptr<AxisT>(new AxisT());
+  UnPackTo(_o.get(), _resolver);
+  return _o.release();
 }
 
 inline void Axis::UnPackTo(AxisT *_o, const flatbuffers::resolver_function_t *_resolver) const {
   (void)_o;
   (void)_resolver;
-  { auto _e = axis(); _o->axis = _e; };
+  { auto _e = axis(); _o->axis = _e; }
 }
 
 inline flatbuffers::Offset<Axis> Axis::Pack(flatbuffers::FlatBufferBuilder &_fbb, const AxisT* _o, const flatbuffers::rehasher_function_t *_rehasher) {
@@ -5063,17 +4943,17 @@ inline flatbuffers::Offset<Axis> CreateAxis(flatbuffers::FlatBufferBuilder &_fbb
 }
 
 inline InputT *Input::UnPack(const flatbuffers::resolver_function_t *_resolver) const {
-  auto _o = new InputT();
-  UnPackTo(_o, _resolver);
-  return _o;
+  auto _o = std::unique_ptr<InputT>(new InputT());
+  UnPackTo(_o.get(), _resolver);
+  return _o.release();
 }
 
 inline void Input::UnPackTo(InputT *_o, const flatbuffers::resolver_function_t *_resolver) const {
   (void)_o;
   (void)_resolver;
-  { auto _e = dims(); if (_e) { _o->dims.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->dims[_i] = _e->Get(_i); } } };
-  { auto _e = dtype(); _o->dtype = _e; };
-  { auto _e = dformat(); _o->dformat = _e; };
+  { auto _e = dims(); if (_e) { _o->dims.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->dims[_i] = _e->Get(_i); } } }
+  { auto _e = dtype(); _o->dtype = _e; }
+  { auto _e = dformat(); _o->dformat = _e; }
 }
 
 inline flatbuffers::Offset<Input> Input::Pack(flatbuffers::FlatBufferBuilder &_fbb, const InputT* _o, const flatbuffers::rehasher_function_t *_rehasher) {
@@ -5095,23 +4975,23 @@ inline flatbuffers::Offset<Input> CreateInput(flatbuffers::FlatBufferBuilder &_f
 }
 
 inline LSTMT *LSTM::UnPack(const flatbuffers::resolver_function_t *_resolver) const {
-  auto _o = new LSTMT();
-  UnPackTo(_o, _resolver);
-  return _o;
+  auto _o = std::unique_ptr<LSTMT>(new LSTMT());
+  UnPackTo(_o.get(), _resolver);
+  return _o.release();
 }
 
 inline void LSTM::UnPackTo(LSTMT *_o, const flatbuffers::resolver_function_t *_resolver) const {
   (void)_o;
   (void)_resolver;
-  { auto _e = outputCount(); _o->outputCount = _e; };
-  { auto _e = weightSize(); _o->weightSize = _e; };
-  { auto _e = clippingThreshold(); _o->clippingThreshold = _e; };
-  { auto _e = weightI(); if (_e) _o->weightI = std::unique_ptr<BlobT>(_e->UnPack(_resolver)); };
-  { auto _e = weightH(); if (_e) _o->weightH = std::unique_ptr<BlobT>(_e->UnPack(_resolver)); };
-  { auto _e = bias(); if (_e) _o->bias = std::unique_ptr<BlobT>(_e->UnPack(_resolver)); };
-  { auto _e = weightIQ(); if (_e) _o->weightIQ = std::unique_ptr<BlobT>(_e->UnPack(_resolver)); };
-  { auto _e = weightIA(); if (_e) _o->weightIA = std::unique_ptr<BlobT>(_e->UnPack(_resolver)); };
-  { auto _e = quantScale(); _o->quantScale = _e; };
+  { auto _e = outputCount(); _o->outputCount = _e; }
+  { auto _e = weightSize(); _o->weightSize = _e; }
+  { auto _e = clippingThreshold(); _o->clippingThreshold = _e; }
+  { auto _e = weightI(); if (_e) _o->weightI = std::unique_ptr<MNN::BlobT>(_e->UnPack(_resolver)); }
+  { auto _e = weightH(); if (_e) _o->weightH = std::unique_ptr<MNN::BlobT>(_e->UnPack(_resolver)); }
+  { auto _e = bias(); if (_e) _o->bias = std::unique_ptr<MNN::BlobT>(_e->UnPack(_resolver)); }
+  { auto _e = weightIQ(); if (_e) _o->weightIQ = std::unique_ptr<MNN::BlobT>(_e->UnPack(_resolver)); }
+  { auto _e = weightIA(); if (_e) _o->weightIA = std::unique_ptr<MNN::BlobT>(_e->UnPack(_resolver)); }
+  { auto _e = quantScale(); _o->quantScale = _e; }
 }
 
 inline flatbuffers::Offset<LSTM> LSTM::Pack(flatbuffers::FlatBufferBuilder &_fbb, const LSTMT* _o, const flatbuffers::rehasher_function_t *_rehasher) {
@@ -5145,17 +5025,17 @@ inline flatbuffers::Offset<LSTM> CreateLSTM(flatbuffers::FlatBufferBuilder &_fbb
 }
 
 inline SliceT *Slice::UnPack(const flatbuffers::resolver_function_t *_resolver) const {
-  auto _o = new SliceT();
-  UnPackTo(_o, _resolver);
-  return _o;
+  auto _o = std::unique_ptr<SliceT>(new SliceT());
+  UnPackTo(_o.get(), _resolver);
+  return _o.release();
 }
 
 inline void Slice::UnPackTo(SliceT *_o, const flatbuffers::resolver_function_t *_resolver) const {
   (void)_o;
   (void)_resolver;
-  { auto _e = axis(); _o->axis = _e; };
-  { auto _e = slicePoints(); if (_e) { _o->slicePoints.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->slicePoints[_i] = _e->Get(_i); } } };
-  { auto _e = sourceType(); _o->sourceType = _e; };
+  { auto _e = axis(); _o->axis = _e; }
+  { auto _e = slicePoints(); if (_e) { _o->slicePoints.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->slicePoints[_i] = _e->Get(_i); } } }
+  { auto _e = sourceType(); _o->sourceType = _e; }
 }
 
 inline flatbuffers::Offset<Slice> Slice::Pack(flatbuffers::FlatBufferBuilder &_fbb, const SliceT* _o, const flatbuffers::rehasher_function_t *_rehasher) {
@@ -5177,22 +5057,22 @@ inline flatbuffers::Offset<Slice> CreateSlice(flatbuffers::FlatBufferBuilder &_f
 }
 
 inline BatchNormT *BatchNorm::UnPack(const flatbuffers::resolver_function_t *_resolver) const {
-  auto _o = new BatchNormT();
-  UnPackTo(_o, _resolver);
-  return _o;
+  auto _o = std::unique_ptr<BatchNormT>(new BatchNormT());
+  UnPackTo(_o.get(), _resolver);
+  return _o.release();
 }
 
 inline void BatchNorm::UnPackTo(BatchNormT *_o, const flatbuffers::resolver_function_t *_resolver) const {
   (void)_o;
   (void)_resolver;
-  { auto _e = channels(); _o->channels = _e; };
-  { auto _e = slopeData(); if (_e) { _o->slopeData.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->slopeData[_i] = _e->Get(_i); } } };
-  { auto _e = meanData(); if (_e) { _o->meanData.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->meanData[_i] = _e->Get(_i); } } };
-  { auto _e = varData(); if (_e) { _o->varData.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->varData[_i] = _e->Get(_i); } } };
-  { auto _e = biasData(); if (_e) { _o->biasData.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->biasData[_i] = _e->Get(_i); } } };
-  { auto _e = Adata(); if (_e) { _o->Adata.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->Adata[_i] = _e->Get(_i); } } };
-  { auto _e = Bdata(); if (_e) { _o->Bdata.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->Bdata[_i] = _e->Get(_i); } } };
-  { auto _e = epsilon(); _o->epsilon = _e; };
+  { auto _e = channels(); _o->channels = _e; }
+  { auto _e = slopeData(); if (_e) { _o->slopeData.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->slopeData[_i] = _e->Get(_i); } } }
+  { auto _e = meanData(); if (_e) { _o->meanData.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->meanData[_i] = _e->Get(_i); } } }
+  { auto _e = varData(); if (_e) { _o->varData.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->varData[_i] = _e->Get(_i); } } }
+  { auto _e = biasData(); if (_e) { _o->biasData.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->biasData[_i] = _e->Get(_i); } } }
+  { auto _e = Adata(); if (_e) { _o->Adata.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->Adata[_i] = _e->Get(_i); } } }
+  { auto _e = Bdata(); if (_e) { _o->Bdata.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->Bdata[_i] = _e->Get(_i); } } }
+  { auto _e = epsilon(); _o->epsilon = _e; }
 }
 
 inline flatbuffers::Offset<BatchNorm> BatchNorm::Pack(flatbuffers::FlatBufferBuilder &_fbb, const BatchNormT* _o, const flatbuffers::rehasher_function_t *_rehasher) {
@@ -5224,17 +5104,17 @@ inline flatbuffers::Offset<BatchNorm> CreateBatchNorm(flatbuffers::FlatBufferBui
 }
 
 inline ScaleT *Scale::UnPack(const flatbuffers::resolver_function_t *_resolver) const {
-  auto _o = new ScaleT();
-  UnPackTo(_o, _resolver);
-  return _o;
+  auto _o = std::unique_ptr<ScaleT>(new ScaleT());
+  UnPackTo(_o.get(), _resolver);
+  return _o.release();
 }
 
 inline void Scale::UnPackTo(ScaleT *_o, const flatbuffers::resolver_function_t *_resolver) const {
   (void)_o;
   (void)_resolver;
-  { auto _e = channels(); _o->channels = _e; };
-  { auto _e = scaleData(); if (_e) { _o->scaleData.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->scaleData[_i] = _e->Get(_i); } } };
-  { auto _e = biasData(); if (_e) { _o->biasData.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->biasData[_i] = _e->Get(_i); } } };
+  { auto _e = channels(); _o->channels = _e; }
+  { auto _e = scaleData(); if (_e) { _o->scaleData.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->scaleData[_i] = _e->Get(_i); } } }
+  { auto _e = biasData(); if (_e) { _o->biasData.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->biasData[_i] = _e->Get(_i); } } }
 }
 
 inline flatbuffers::Offset<Scale> Scale::Pack(flatbuffers::FlatBufferBuilder &_fbb, const ScaleT* _o, const flatbuffers::rehasher_function_t *_rehasher) {
@@ -5256,16 +5136,16 @@ inline flatbuffers::Offset<Scale> CreateScale(flatbuffers::FlatBufferBuilder &_f
 }
 
 inline EltwiseT *Eltwise::UnPack(const flatbuffers::resolver_function_t *_resolver) const {
-  auto _o = new EltwiseT();
-  UnPackTo(_o, _resolver);
-  return _o;
+  auto _o = std::unique_ptr<EltwiseT>(new EltwiseT());
+  UnPackTo(_o.get(), _resolver);
+  return _o.release();
 }
 
 inline void Eltwise::UnPackTo(EltwiseT *_o, const flatbuffers::resolver_function_t *_resolver) const {
   (void)_o;
   (void)_resolver;
-  { auto _e = type(); _o->type = _e; };
-  { auto _e = coeff(); if (_e) { _o->coeff.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->coeff[_i] = _e->Get(_i); } } };
+  { auto _e = type(); _o->type = _e; }
+  { auto _e = coeff(); if (_e) { _o->coeff.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->coeff[_i] = _e->Get(_i); } } }
 }
 
 inline flatbuffers::Offset<Eltwise> Eltwise::Pack(flatbuffers::FlatBufferBuilder &_fbb, const EltwiseT* _o, const flatbuffers::rehasher_function_t *_rehasher) {
@@ -5285,16 +5165,16 @@ inline flatbuffers::Offset<Eltwise> CreateEltwise(flatbuffers::FlatBufferBuilder
 }
 
 inline FlattenT *Flatten::UnPack(const flatbuffers::resolver_function_t *_resolver) const {
-  auto _o = new FlattenT();
-  UnPackTo(_o, _resolver);
-  return _o;
+  auto _o = std::unique_ptr<FlattenT>(new FlattenT());
+  UnPackTo(_o.get(), _resolver);
+  return _o.release();
 }
 
 inline void Flatten::UnPackTo(FlattenT *_o, const flatbuffers::resolver_function_t *_resolver) const {
   (void)_o;
   (void)_resolver;
-  { auto _e = axis(); _o->axis = _e; };
-  { auto _e = endAxis(); _o->endAxis = _e; };
+  { auto _e = axis(); _o->axis = _e; }
+  { auto _e = endAxis(); _o->endAxis = _e; }
 }
 
 inline flatbuffers::Offset<Flatten> Flatten::Pack(flatbuffers::FlatBufferBuilder &_fbb, const FlattenT* _o, const flatbuffers::rehasher_function_t *_rehasher) {
@@ -5314,15 +5194,15 @@ inline flatbuffers::Offset<Flatten> CreateFlatten(flatbuffers::FlatBufferBuilder
 }
 
 inline PermuteT *Permute::UnPack(const flatbuffers::resolver_function_t *_resolver) const {
-  auto _o = new PermuteT();
-  UnPackTo(_o, _resolver);
-  return _o;
+  auto _o = std::unique_ptr<PermuteT>(new PermuteT());
+  UnPackTo(_o.get(), _resolver);
+  return _o.release();
 }
 
 inline void Permute::UnPackTo(PermuteT *_o, const flatbuffers::resolver_function_t *_resolver) const {
   (void)_o;
   (void)_resolver;
-  { auto _e = dims(); if (_e) { _o->dims.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->dims[_i] = _e->Get(_i); } } };
+  { auto _e = dims(); if (_e) { _o->dims.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->dims[_i] = _e->Get(_i); } } }
 }
 
 inline flatbuffers::Offset<Permute> Permute::Pack(flatbuffers::FlatBufferBuilder &_fbb, const PermuteT* _o, const flatbuffers::rehasher_function_t *_rehasher) {
@@ -5340,16 +5220,16 @@ inline flatbuffers::Offset<Permute> CreatePermute(flatbuffers::FlatBufferBuilder
 }
 
 inline ReshapeT *Reshape::UnPack(const flatbuffers::resolver_function_t *_resolver) const {
-  auto _o = new ReshapeT();
-  UnPackTo(_o, _resolver);
-  return _o;
+  auto _o = std::unique_ptr<ReshapeT>(new ReshapeT());
+  UnPackTo(_o.get(), _resolver);
+  return _o.release();
 }
 
 inline void Reshape::UnPackTo(ReshapeT *_o, const flatbuffers::resolver_function_t *_resolver) const {
   (void)_o;
   (void)_resolver;
-  { auto _e = dims(); if (_e) { _o->dims.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->dims[_i] = _e->Get(_i); } } };
-  { auto _e = dimType(); _o->dimType = _e; };
+  { auto _e = dims(); if (_e) { _o->dims.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->dims[_i] = _e->Get(_i); } } }
+  { auto _e = dimType(); _o->dimType = _e; }
 }
 
 inline flatbuffers::Offset<Reshape> Reshape::Pack(flatbuffers::FlatBufferBuilder &_fbb, const ReshapeT* _o, const flatbuffers::rehasher_function_t *_rehasher) {
@@ -5369,24 +5249,24 @@ inline flatbuffers::Offset<Reshape> CreateReshape(flatbuffers::FlatBufferBuilder
 }
 
 inline DetectionOutputT *DetectionOutput::UnPack(const flatbuffers::resolver_function_t *_resolver) const {
-  auto _o = new DetectionOutputT();
-  UnPackTo(_o, _resolver);
-  return _o;
+  auto _o = std::unique_ptr<DetectionOutputT>(new DetectionOutputT());
+  UnPackTo(_o.get(), _resolver);
+  return _o.release();
 }
 
 inline void DetectionOutput::UnPackTo(DetectionOutputT *_o, const flatbuffers::resolver_function_t *_resolver) const {
   (void)_o;
   (void)_resolver;
-  { auto _e = classCount(); _o->classCount = _e; };
-  { auto _e = nmsThresholdold(); _o->nmsThresholdold = _e; };
-  { auto _e = nmsTopK(); _o->nmsTopK = _e; };
-  { auto _e = keepTopK(); _o->keepTopK = _e; };
-  { auto _e = confidenceThreshold(); _o->confidenceThreshold = _e; };
-  { auto _e = shareLocation(); _o->shareLocation = _e; };
-  { auto _e = backgroundLable(); _o->backgroundLable = _e; };
-  { auto _e = varianceEncodedTarget(); _o->varianceEncodedTarget = _e; };
-  { auto _e = codeType(); _o->codeType = _e; };
-  { auto _e = objectnessScore(); _o->objectnessScore = _e; };
+  { auto _e = classCount(); _o->classCount = _e; }
+  { auto _e = nmsThresholdold(); _o->nmsThresholdold = _e; }
+  { auto _e = nmsTopK(); _o->nmsTopK = _e; }
+  { auto _e = keepTopK(); _o->keepTopK = _e; }
+  { auto _e = confidenceThreshold(); _o->confidenceThreshold = _e; }
+  { auto _e = shareLocation(); _o->shareLocation = _e; }
+  { auto _e = backgroundLable(); _o->backgroundLable = _e; }
+  { auto _e = varianceEncodedTarget(); _o->varianceEncodedTarget = _e; }
+  { auto _e = codeType(); _o->codeType = _e; }
+  { auto _e = objectnessScore(); _o->objectnessScore = _e; }
 }
 
 inline flatbuffers::Offset<DetectionOutput> DetectionOutput::Pack(flatbuffers::FlatBufferBuilder &_fbb, const DetectionOutputT* _o, const flatbuffers::rehasher_function_t *_rehasher) {
@@ -5422,17 +5302,17 @@ inline flatbuffers::Offset<DetectionOutput> CreateDetectionOutput(flatbuffers::F
 }
 
 inline RoiPoolingT *RoiPooling::UnPack(const flatbuffers::resolver_function_t *_resolver) const {
-  auto _o = new RoiPoolingT();
-  UnPackTo(_o, _resolver);
-  return _o;
+  auto _o = std::unique_ptr<RoiPoolingT>(new RoiPoolingT());
+  UnPackTo(_o.get(), _resolver);
+  return _o.release();
 }
 
 inline void RoiPooling::UnPackTo(RoiPoolingT *_o, const flatbuffers::resolver_function_t *_resolver) const {
   (void)_o;
   (void)_resolver;
-  { auto _e = pooledWidth(); _o->pooledWidth = _e; };
-  { auto _e = pooledHeight(); _o->pooledHeight = _e; };
-  { auto _e = spatialScale(); _o->spatialScale = _e; };
+  { auto _e = pooledWidth(); _o->pooledWidth = _e; }
+  { auto _e = pooledHeight(); _o->pooledHeight = _e; }
+  { auto _e = spatialScale(); _o->spatialScale = _e; }
 }
 
 inline flatbuffers::Offset<RoiPooling> RoiPooling::Pack(flatbuffers::FlatBufferBuilder &_fbb, const RoiPoolingT* _o, const flatbuffers::rehasher_function_t *_rehasher) {
@@ -5454,23 +5334,23 @@ inline flatbuffers::Offset<RoiPooling> CreateRoiPooling(flatbuffers::FlatBufferB
 }
 
 inline ProposalT *Proposal::UnPack(const flatbuffers::resolver_function_t *_resolver) const {
-  auto _o = new ProposalT();
-  UnPackTo(_o, _resolver);
-  return _o;
+  auto _o = std::unique_ptr<ProposalT>(new ProposalT());
+  UnPackTo(_o.get(), _resolver);
+  return _o.release();
 }
 
 inline void Proposal::UnPackTo(ProposalT *_o, const flatbuffers::resolver_function_t *_resolver) const {
   (void)_o;
   (void)_resolver;
-  { auto _e = featStride(); _o->featStride = _e; };
-  { auto _e = baseSize(); _o->baseSize = _e; };
-  { auto _e = preNmsTopN(); _o->preNmsTopN = _e; };
-  { auto _e = afterNmsTopN(); _o->afterNmsTopN = _e; };
-  { auto _e = nmsThreshold(); _o->nmsThreshold = _e; };
-  { auto _e = minSize(); _o->minSize = _e; };
-  { auto _e = ratios(); if (_e) _o->ratios = std::unique_ptr<BlobT>(_e->UnPack(_resolver)); };
-  { auto _e = scales(); if (_e) _o->scales = std::unique_ptr<BlobT>(_e->UnPack(_resolver)); };
-  { auto _e = anchors(); if (_e) _o->anchors = std::unique_ptr<BlobT>(_e->UnPack(_resolver)); };
+  { auto _e = featStride(); _o->featStride = _e; }
+  { auto _e = baseSize(); _o->baseSize = _e; }
+  { auto _e = preNmsTopN(); _o->preNmsTopN = _e; }
+  { auto _e = afterNmsTopN(); _o->afterNmsTopN = _e; }
+  { auto _e = nmsThreshold(); _o->nmsThreshold = _e; }
+  { auto _e = minSize(); _o->minSize = _e; }
+  { auto _e = ratios(); if (_e) _o->ratios = std::unique_ptr<MNN::BlobT>(_e->UnPack(_resolver)); }
+  { auto _e = scales(); if (_e) _o->scales = std::unique_ptr<MNN::BlobT>(_e->UnPack(_resolver)); }
+  { auto _e = anchors(); if (_e) _o->anchors = std::unique_ptr<MNN::BlobT>(_e->UnPack(_resolver)); }
 }
 
 inline flatbuffers::Offset<Proposal> Proposal::Pack(flatbuffers::FlatBufferBuilder &_fbb, const ProposalT* _o, const flatbuffers::rehasher_function_t *_rehasher) {
@@ -5504,25 +5384,25 @@ inline flatbuffers::Offset<Proposal> CreateProposal(flatbuffers::FlatBufferBuild
 }
 
 inline InterpT *Interp::UnPack(const flatbuffers::resolver_function_t *_resolver) const {
-  auto _o = new InterpT();
-  UnPackTo(_o, _resolver);
-  return _o;
+  auto _o = std::unique_ptr<InterpT>(new InterpT());
+  UnPackTo(_o.get(), _resolver);
+  return _o.release();
 }
 
 inline void Interp::UnPackTo(InterpT *_o, const flatbuffers::resolver_function_t *_resolver) const {
   (void)_o;
   (void)_resolver;
-  { auto _e = widthScale(); _o->widthScale = _e; };
-  { auto _e = heightScale(); _o->heightScale = _e; };
-  { auto _e = outputWidth(); _o->outputWidth = _e; };
-  { auto _e = outputHeight(); _o->outputHeight = _e; };
-  { auto _e = resizeType(); _o->resizeType = _e; };
-  { auto _e = alignCorners(); _o->alignCorners = _e; };
-  { auto _e = halfPixelCenters(); _o->halfPixelCenters = _e; };
-  { auto _e = widthOffset(); _o->widthOffset = _e; };
-  { auto _e = heightOffset(); _o->heightOffset = _e; };
-  { auto _e = cubicCoeffA(); _o->cubicCoeffA = _e; };
-  { auto _e = ctm(); _o->ctm = _e; };
+  { auto _e = widthScale(); _o->widthScale = _e; }
+  { auto _e = heightScale(); _o->heightScale = _e; }
+  { auto _e = outputWidth(); _o->outputWidth = _e; }
+  { auto _e = outputHeight(); _o->outputHeight = _e; }
+  { auto _e = resizeType(); _o->resizeType = _e; }
+  { auto _e = alignCorners(); _o->alignCorners = _e; }
+  { auto _e = halfPixelCenters(); _o->halfPixelCenters = _e; }
+  { auto _e = widthOffset(); _o->widthOffset = _e; }
+  { auto _e = heightOffset(); _o->heightOffset = _e; }
+  { auto _e = cubicCoeffA(); _o->cubicCoeffA = _e; }
+  { auto _e = ctm(); _o->ctm = _e; }
 }
 
 inline flatbuffers::Offset<Interp> Interp::Pack(flatbuffers::FlatBufferBuilder &_fbb, const InterpT* _o, const flatbuffers::rehasher_function_t *_rehasher) {
@@ -5560,16 +5440,16 @@ inline flatbuffers::Offset<Interp> CreateInterp(flatbuffers::FlatBufferBuilder &
 }
 
 inline ResizeT *Resize::UnPack(const flatbuffers::resolver_function_t *_resolver) const {
-  auto _o = new ResizeT();
-  UnPackTo(_o, _resolver);
-  return _o;
+  auto _o = std::unique_ptr<ResizeT>(new ResizeT());
+  UnPackTo(_o.get(), _resolver);
+  return _o.release();
 }
 
 inline void Resize::UnPackTo(ResizeT *_o, const flatbuffers::resolver_function_t *_resolver) const {
   (void)_o;
   (void)_resolver;
-  { auto _e = xScale(); _o->xScale = _e; };
-  { auto _e = yScale(); _o->yScale = _e; };
+  { auto _e = xScale(); _o->xScale = _e; }
+  { auto _e = yScale(); _o->yScale = _e; }
 }
 
 inline flatbuffers::Offset<Resize> Resize::Pack(flatbuffers::FlatBufferBuilder &_fbb, const ResizeT* _o, const flatbuffers::rehasher_function_t *_rehasher) {
@@ -5589,25 +5469,25 @@ inline flatbuffers::Offset<Resize> CreateResize(flatbuffers::FlatBufferBuilder &
 }
 
 inline PriorBoxT *PriorBox::UnPack(const flatbuffers::resolver_function_t *_resolver) const {
-  auto _o = new PriorBoxT();
-  UnPackTo(_o, _resolver);
-  return _o;
+  auto _o = std::unique_ptr<PriorBoxT>(new PriorBoxT());
+  UnPackTo(_o.get(), _resolver);
+  return _o.release();
 }
 
 inline void PriorBox::UnPackTo(PriorBoxT *_o, const flatbuffers::resolver_function_t *_resolver) const {
   (void)_o;
   (void)_resolver;
-  { auto _e = minSizes(); if (_e) { _o->minSizes.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->minSizes[_i] = _e->Get(_i); } } };
-  { auto _e = maxSizes(); if (_e) { _o->maxSizes.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->maxSizes[_i] = _e->Get(_i); } } };
-  { auto _e = aspectRatios(); if (_e) { _o->aspectRatios.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->aspectRatios[_i] = _e->Get(_i); } } };
-  { auto _e = variances(); if (_e) { _o->variances.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->variances[_i] = _e->Get(_i); } } };
-  { auto _e = flip(); _o->flip = _e; };
-  { auto _e = clip(); _o->clip = _e; };
-  { auto _e = imageWidth(); _o->imageWidth = _e; };
-  { auto _e = imageHeight(); _o->imageHeight = _e; };
-  { auto _e = stepWidth(); _o->stepWidth = _e; };
-  { auto _e = stepHeight(); _o->stepHeight = _e; };
-  { auto _e = offset(); _o->offset = _e; };
+  { auto _e = minSizes(); if (_e) { _o->minSizes.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->minSizes[_i] = _e->Get(_i); } } }
+  { auto _e = maxSizes(); if (_e) { _o->maxSizes.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->maxSizes[_i] = _e->Get(_i); } } }
+  { auto _e = aspectRatios(); if (_e) { _o->aspectRatios.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->aspectRatios[_i] = _e->Get(_i); } } }
+  { auto _e = variances(); if (_e) { _o->variances.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->variances[_i] = _e->Get(_i); } } }
+  { auto _e = flip(); _o->flip = _e; }
+  { auto _e = clip(); _o->clip = _e; }
+  { auto _e = imageWidth(); _o->imageWidth = _e; }
+  { auto _e = imageHeight(); _o->imageHeight = _e; }
+  { auto _e = stepWidth(); _o->stepWidth = _e; }
+  { auto _e = stepHeight(); _o->stepHeight = _e; }
+  { auto _e = offset(); _o->offset = _e; }
 }
 
 inline flatbuffers::Offset<PriorBox> PriorBox::Pack(flatbuffers::FlatBufferBuilder &_fbb, const PriorBoxT* _o, const flatbuffers::rehasher_function_t *_rehasher) {
@@ -5645,18 +5525,18 @@ inline flatbuffers::Offset<PriorBox> CreatePriorBox(flatbuffers::FlatBufferBuild
 }
 
 inline NormalizeT *Normalize::UnPack(const flatbuffers::resolver_function_t *_resolver) const {
-  auto _o = new NormalizeT();
-  UnPackTo(_o, _resolver);
-  return _o;
+  auto _o = std::unique_ptr<NormalizeT>(new NormalizeT());
+  UnPackTo(_o.get(), _resolver);
+  return _o.release();
 }
 
 inline void Normalize::UnPackTo(NormalizeT *_o, const flatbuffers::resolver_function_t *_resolver) const {
   (void)_o;
   (void)_resolver;
-  { auto _e = acrossSpatial(); _o->acrossSpatial = _e; };
-  { auto _e = channelShared(); _o->channelShared = _e; };
-  { auto _e = eps(); _o->eps = _e; };
-  { auto _e = scale(); if (_e) { _o->scale.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->scale[_i] = _e->Get(_i); } } };
+  { auto _e = acrossSpatial(); _o->acrossSpatial = _e; }
+  { auto _e = channelShared(); _o->channelShared = _e; }
+  { auto _e = eps(); _o->eps = _e; }
+  { auto _e = scale(); if (_e) { _o->scale.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->scale[_i] = _e->Get(_i); } } }
 }
 
 inline flatbuffers::Offset<Normalize> Normalize::Pack(flatbuffers::FlatBufferBuilder &_fbb, const NormalizeT* _o, const flatbuffers::rehasher_function_t *_rehasher) {
@@ -5680,18 +5560,18 @@ inline flatbuffers::Offset<Normalize> CreateNormalize(flatbuffers::FlatBufferBui
 }
 
 inline EltwiseInt8T *EltwiseInt8::UnPack(const flatbuffers::resolver_function_t *_resolver) const {
-  auto _o = new EltwiseInt8T();
-  UnPackTo(_o, _resolver);
-  return _o;
+  auto _o = std::unique_ptr<EltwiseInt8T>(new EltwiseInt8T());
+  UnPackTo(_o.get(), _resolver);
+  return _o.release();
 }
 
 inline void EltwiseInt8::UnPackTo(EltwiseInt8T *_o, const flatbuffers::resolver_function_t *_resolver) const {
   (void)_o;
   (void)_resolver;
-  { auto _e = type(); _o->type = _e; };
-  { auto _e = inputQuan0(); if (_e) _o->inputQuan0 = std::unique_ptr<QuantizedFloatParamT>(_e->UnPack(_resolver)); };
-  { auto _e = inputQuan1(); if (_e) _o->inputQuan1 = std::unique_ptr<QuantizedFloatParamT>(_e->UnPack(_resolver)); };
-  { auto _e = outputQuan(); if (_e) _o->outputQuan = std::unique_ptr<QuantizedFloatParamT>(_e->UnPack(_resolver)); };
+  { auto _e = type(); _o->type = _e; }
+  { auto _e = inputQuan0(); if (_e) _o->inputQuan0 = std::unique_ptr<MNN::QuantizedFloatParamT>(_e->UnPack(_resolver)); }
+  { auto _e = inputQuan1(); if (_e) _o->inputQuan1 = std::unique_ptr<MNN::QuantizedFloatParamT>(_e->UnPack(_resolver)); }
+  { auto _e = outputQuan(); if (_e) _o->outputQuan = std::unique_ptr<MNN::QuantizedFloatParamT>(_e->UnPack(_resolver)); }
 }
 
 inline flatbuffers::Offset<EltwiseInt8> EltwiseInt8::Pack(flatbuffers::FlatBufferBuilder &_fbb, const EltwiseInt8T* _o, const flatbuffers::rehasher_function_t *_rehasher) {
@@ -5721,7 +5601,7 @@ inline const flatbuffers::TypeTable *PadModeTypeTable() {
     { flatbuffers::ET_CHAR, 0, 0 }
   };
   static const flatbuffers::TypeFunction type_refs[] = {
-    PadModeTypeTable
+    MNN::PadModeTypeTable
   };
   static const char * const names[] = {
     "CAFFE",
@@ -5729,7 +5609,7 @@ inline const flatbuffers::TypeTable *PadModeTypeTable() {
     "SAME"
   };
   static const flatbuffers::TypeTable tt = {
-    flatbuffers::ST_ENUM, 3, type_codes, type_refs, nullptr, names
+    flatbuffers::ST_ENUM, 3, type_codes, type_refs, nullptr, nullptr, names
   };
   return &tt;
 }
@@ -5740,14 +5620,14 @@ inline const flatbuffers::TypeTable *QuantizeAlgoTypeTable() {
     { flatbuffers::ET_CHAR, 0, 0 }
   };
   static const flatbuffers::TypeFunction type_refs[] = {
-    QuantizeAlgoTypeTable
+    MNN::QuantizeAlgoTypeTable
   };
   static const char * const names[] = {
     "DEFAULT",
     "OVERFLOW_AWARE"
   };
   static const flatbuffers::TypeTable tt = {
-    flatbuffers::ST_ENUM, 2, type_codes, type_refs, nullptr, names
+    flatbuffers::ST_ENUM, 2, type_codes, type_refs, nullptr, nullptr, names
   };
   return &tt;
 }
@@ -5758,14 +5638,14 @@ inline const flatbuffers::TypeTable *PoolTypeTypeTable() {
     { flatbuffers::ET_CHAR, 0, 0 }
   };
   static const flatbuffers::TypeFunction type_refs[] = {
-    PoolTypeTypeTable
+    MNN::PoolTypeTypeTable
   };
   static const char * const names[] = {
     "MAXPOOL",
     "AVEPOOL"
   };
   static const flatbuffers::TypeTable tt = {
-    flatbuffers::ST_ENUM, 2, type_codes, type_refs, nullptr, names
+    flatbuffers::ST_ENUM, 2, type_codes, type_refs, nullptr, nullptr, names
   };
   return &tt;
 }
@@ -5777,7 +5657,7 @@ inline const flatbuffers::TypeTable *PoolPadTypeTypeTable() {
     { flatbuffers::ET_CHAR, 0, 0 }
   };
   static const flatbuffers::TypeFunction type_refs[] = {
-    PoolPadTypeTypeTable
+    MNN::PoolPadTypeTypeTable
   };
   static const char * const names[] = {
     "CAFFE",
@@ -5785,7 +5665,7 @@ inline const flatbuffers::TypeTable *PoolPadTypeTypeTable() {
     "SAME"
   };
   static const flatbuffers::TypeTable tt = {
-    flatbuffers::ST_ENUM, 3, type_codes, type_refs, nullptr, names
+    flatbuffers::ST_ENUM, 3, type_codes, type_refs, nullptr, nullptr, names
   };
   return &tt;
 }
@@ -5797,7 +5677,7 @@ inline const flatbuffers::TypeTable *AvgPoolCountTypeTypeTable() {
     { flatbuffers::ET_CHAR, 0, 0 }
   };
   static const flatbuffers::TypeFunction type_refs[] = {
-    AvgPoolCountTypeTypeTable
+    MNN::AvgPoolCountTypeTypeTable
   };
   static const char * const names[] = {
     "DEFAULT",
@@ -5805,7 +5685,7 @@ inline const flatbuffers::TypeTable *AvgPoolCountTypeTypeTable() {
     "EXCLUDE_PADDING"
   };
   static const flatbuffers::TypeTable tt = {
-    flatbuffers::ST_ENUM, 3, type_codes, type_refs, nullptr, names
+    flatbuffers::ST_ENUM, 3, type_codes, type_refs, nullptr, nullptr, names
   };
   return &tt;
 }
@@ -5818,7 +5698,7 @@ inline const flatbuffers::TypeTable *EltwiseTypeTypeTable() {
     { flatbuffers::ET_CHAR, 0, 0 }
   };
   static const flatbuffers::TypeFunction type_refs[] = {
-    EltwiseTypeTypeTable
+    MNN::EltwiseTypeTypeTable
   };
   static const char * const names[] = {
     "PROD",
@@ -5827,7 +5707,7 @@ inline const flatbuffers::TypeTable *EltwiseTypeTypeTable() {
     "SUB"
   };
   static const flatbuffers::TypeTable tt = {
-    flatbuffers::ST_ENUM, 4, type_codes, type_refs, nullptr, names
+    flatbuffers::ST_ENUM, 4, type_codes, type_refs, nullptr, nullptr, names
   };
   return &tt;
 }
@@ -5843,7 +5723,7 @@ inline const flatbuffers::TypeTable *CoordinateTransformationModeTypeTable() {
     { flatbuffers::ET_CHAR, 0, 0 }
   };
   static const flatbuffers::TypeFunction type_refs[] = {
-    CoordinateTransformationModeTypeTable
+    MNN::CoordinateTransformationModeTypeTable
   };
   static const char * const names[] = {
     "NotSet",
@@ -5855,7 +5735,7 @@ inline const flatbuffers::TypeTable *CoordinateTransformationModeTypeTable() {
     "TensorflowCropAndResize"
   };
   static const flatbuffers::TypeTable tt = {
-    flatbuffers::ST_ENUM, 7, type_codes, type_refs, nullptr, names
+    flatbuffers::ST_ENUM, 7, type_codes, type_refs, nullptr, nullptr, names
   };
   return &tt;
 }
@@ -5880,7 +5760,7 @@ inline const flatbuffers::TypeTable *Convolution2DCommonTypeTable() {
     { flatbuffers::ET_INT, 1, -1 }
   };
   static const flatbuffers::TypeFunction type_refs[] = {
-    PadModeTypeTable
+    MNN::PadModeTypeTable
   };
   static const char * const names[] = {
     "padX",
@@ -5901,7 +5781,7 @@ inline const flatbuffers::TypeTable *Convolution2DCommonTypeTable() {
     "outPads"
   };
   static const flatbuffers::TypeTable tt = {
-    flatbuffers::ST_TABLE, 16, type_codes, type_refs, nullptr, names
+    flatbuffers::ST_TABLE, 16, type_codes, type_refs, nullptr, nullptr, names
   };
   return &tt;
 }
@@ -5919,7 +5799,7 @@ inline const flatbuffers::TypeTable *Convolution3DCommonTypeTable() {
     { flatbuffers::ET_BOOL, 0, -1 }
   };
   static const flatbuffers::TypeFunction type_refs[] = {
-    PadModeTypeTable
+    MNN::PadModeTypeTable
   };
   static const char * const names[] = {
     "dilates",
@@ -5933,7 +5813,7 @@ inline const flatbuffers::TypeTable *Convolution3DCommonTypeTable() {
     "relu6"
   };
   static const flatbuffers::TypeTable tt = {
-    flatbuffers::ST_TABLE, 9, type_codes, type_refs, nullptr, names
+    flatbuffers::ST_TABLE, 9, type_codes, type_refs, nullptr, nullptr, names
   };
   return &tt;
 }
@@ -5966,7 +5846,7 @@ inline const flatbuffers::TypeTable *IDSTQuanTypeTable() {
     "has_scaleInt"
   };
   static const flatbuffers::TypeTable tt = {
-    flatbuffers::ST_TABLE, 11, type_codes, nullptr, nullptr, names
+    flatbuffers::ST_TABLE, 11, type_codes, nullptr, nullptr, nullptr, names
   };
   return &tt;
 }
@@ -5981,7 +5861,7 @@ inline const flatbuffers::TypeTable *QuantizedFloatParamTypeTable() {
     { flatbuffers::ET_INT, 0, -1 }
   };
   static const flatbuffers::TypeFunction type_refs[] = {
-    QuantizeAlgoTypeTable
+    MNN::QuantizeAlgoTypeTable
   };
   static const char * const names[] = {
     "weight",
@@ -5992,7 +5872,7 @@ inline const flatbuffers::TypeTable *QuantizedFloatParamTypeTable() {
     "nbits"
   };
   static const flatbuffers::TypeTable tt = {
-    flatbuffers::ST_TABLE, 6, type_codes, type_refs, nullptr, names
+    flatbuffers::ST_TABLE, 6, type_codes, type_refs, nullptr, nullptr, names
   };
   return &tt;
 }
@@ -6006,9 +5886,9 @@ inline const flatbuffers::TypeTable *Convolution2DTypeTable() {
     { flatbuffers::ET_SEQUENCE, 0, 2 }
   };
   static const flatbuffers::TypeFunction type_refs[] = {
-    Convolution2DCommonTypeTable,
-    IDSTQuanTypeTable,
-    QuantizedFloatParamTypeTable
+    MNN::Convolution2DCommonTypeTable,
+    MNN::IDSTQuanTypeTable,
+    MNN::QuantizedFloatParamTypeTable
   };
   static const char * const names[] = {
     "common",
@@ -6018,7 +5898,7 @@ inline const flatbuffers::TypeTable *Convolution2DTypeTable() {
     "symmetricQuan"
   };
   static const flatbuffers::TypeTable tt = {
-    flatbuffers::ST_TABLE, 5, type_codes, type_refs, nullptr, names
+    flatbuffers::ST_TABLE, 5, type_codes, type_refs, nullptr, nullptr, names
   };
   return &tt;
 }
@@ -6030,7 +5910,7 @@ inline const flatbuffers::TypeTable *Convolution3DTypeTable() {
     { flatbuffers::ET_FLOAT, 1, -1 }
   };
   static const flatbuffers::TypeFunction type_refs[] = {
-    Convolution3DCommonTypeTable
+    MNN::Convolution3DCommonTypeTable
   };
   static const char * const names[] = {
     "common",
@@ -6038,7 +5918,7 @@ inline const flatbuffers::TypeTable *Convolution3DTypeTable() {
     "bias"
   };
   static const flatbuffers::TypeTable tt = {
-    flatbuffers::ST_TABLE, 3, type_codes, type_refs, nullptr, names
+    flatbuffers::ST_TABLE, 3, type_codes, type_refs, nullptr, nullptr, names
   };
   return &tt;
 }
@@ -6055,7 +5935,7 @@ inline const flatbuffers::TypeTable *InnerProductTypeTable() {
     { flatbuffers::ET_SEQUENCE, 0, 0 }
   };
   static const flatbuffers::TypeFunction type_refs[] = {
-    IDSTQuanTypeTable
+    MNN::IDSTQuanTypeTable
   };
   static const char * const names[] = {
     "outputCount",
@@ -6068,7 +5948,7 @@ inline const flatbuffers::TypeTable *InnerProductTypeTable() {
     "quanParameter"
   };
   static const flatbuffers::TypeTable tt = {
-    flatbuffers::ST_TABLE, 8, type_codes, type_refs, nullptr, names
+    flatbuffers::ST_TABLE, 8, type_codes, type_refs, nullptr, nullptr, names
   };
   return &tt;
 }
@@ -6090,10 +5970,10 @@ inline const flatbuffers::TypeTable *PoolTypeTable() {
     { flatbuffers::ET_CHAR, 0, 3 }
   };
   static const flatbuffers::TypeFunction type_refs[] = {
-    PoolTypeTypeTable,
-    PoolPadTypeTypeTable,
-    DataTypeTypeTable,
-    AvgPoolCountTypeTypeTable
+    MNN::PoolTypeTypeTable,
+    MNN::PoolPadTypeTypeTable,
+    MNN::DataTypeTypeTable,
+    MNN::AvgPoolCountTypeTypeTable
   };
   static const char * const names[] = {
     "padX",
@@ -6111,7 +5991,7 @@ inline const flatbuffers::TypeTable *PoolTypeTable() {
     "countType"
   };
   static const flatbuffers::TypeTable tt = {
-    flatbuffers::ST_TABLE, 13, type_codes, type_refs, nullptr, names
+    flatbuffers::ST_TABLE, 13, type_codes, type_refs, nullptr, nullptr, names
   };
   return &tt;
 }
@@ -6125,8 +6005,8 @@ inline const flatbuffers::TypeTable *Pool3DTypeTable() {
     { flatbuffers::ET_CHAR, 0, 1 }
   };
   static const flatbuffers::TypeFunction type_refs[] = {
-    PoolTypeTypeTable,
-    PoolPadTypeTypeTable
+    MNN::PoolTypeTypeTable,
+    MNN::PoolPadTypeTypeTable
   };
   static const char * const names[] = {
     "strides",
@@ -6136,7 +6016,7 @@ inline const flatbuffers::TypeTable *Pool3DTypeTable() {
     "padType"
   };
   static const flatbuffers::TypeTable tt = {
-    flatbuffers::ST_TABLE, 5, type_codes, type_refs, nullptr, names
+    flatbuffers::ST_TABLE, 5, type_codes, type_refs, nullptr, nullptr, names
   };
   return &tt;
 }
@@ -6149,7 +6029,7 @@ inline const flatbuffers::TypeTable *ReluTypeTable() {
     "slope"
   };
   static const flatbuffers::TypeTable tt = {
-    flatbuffers::ST_TABLE, 1, type_codes, nullptr, nullptr, names
+    flatbuffers::ST_TABLE, 1, type_codes, nullptr, nullptr, nullptr, names
   };
   return &tt;
 }
@@ -6164,7 +6044,7 @@ inline const flatbuffers::TypeTable *Relu6TypeTable() {
     "maxValue"
   };
   static const flatbuffers::TypeTable tt = {
-    flatbuffers::ST_TABLE, 2, type_codes, nullptr, nullptr, names
+    flatbuffers::ST_TABLE, 2, type_codes, nullptr, nullptr, nullptr, names
   };
   return &tt;
 }
@@ -6179,7 +6059,7 @@ inline const flatbuffers::TypeTable *PReluTypeTable() {
     "slope"
   };
   static const flatbuffers::TypeTable tt = {
-    flatbuffers::ST_TABLE, 2, type_codes, nullptr, nullptr, names
+    flatbuffers::ST_TABLE, 2, type_codes, nullptr, nullptr, nullptr, names
   };
   return &tt;
 }
@@ -6192,7 +6072,7 @@ inline const flatbuffers::TypeTable *ELUTypeTable() {
     "alpha"
   };
   static const flatbuffers::TypeTable tt = {
-    flatbuffers::ST_TABLE, 1, type_codes, nullptr, nullptr, names
+    flatbuffers::ST_TABLE, 1, type_codes, nullptr, nullptr, nullptr, names
   };
   return &tt;
 }
@@ -6211,7 +6091,7 @@ inline const flatbuffers::TypeTable *LRNTypeTable() {
     "beta"
   };
   static const flatbuffers::TypeTable tt = {
-    flatbuffers::ST_TABLE, 4, type_codes, nullptr, nullptr, names
+    flatbuffers::ST_TABLE, 4, type_codes, nullptr, nullptr, nullptr, names
   };
   return &tt;
 }
@@ -6230,7 +6110,7 @@ inline const flatbuffers::TypeTable *ArgMaxTypeTable() {
     "softmaxThreshold"
   };
   static const flatbuffers::TypeTable tt = {
-    flatbuffers::ST_TABLE, 4, type_codes, nullptr, nullptr, names
+    flatbuffers::ST_TABLE, 4, type_codes, nullptr, nullptr, nullptr, names
   };
   return &tt;
 }
@@ -6243,7 +6123,7 @@ inline const flatbuffers::TypeTable *AxisTypeTable() {
     "axis"
   };
   static const flatbuffers::TypeTable tt = {
-    flatbuffers::ST_TABLE, 1, type_codes, nullptr, nullptr, names
+    flatbuffers::ST_TABLE, 1, type_codes, nullptr, nullptr, nullptr, names
   };
   return &tt;
 }
@@ -6255,8 +6135,8 @@ inline const flatbuffers::TypeTable *InputTypeTable() {
     { flatbuffers::ET_CHAR, 0, 1 }
   };
   static const flatbuffers::TypeFunction type_refs[] = {
-    DataTypeTypeTable,
-    MNN_DATA_FORMATTypeTable
+    MNN::DataTypeTypeTable,
+    MNN::MNN_DATA_FORMATTypeTable
   };
   static const char * const names[] = {
     "dims",
@@ -6264,7 +6144,7 @@ inline const flatbuffers::TypeTable *InputTypeTable() {
     "dformat"
   };
   static const flatbuffers::TypeTable tt = {
-    flatbuffers::ST_TABLE, 3, type_codes, type_refs, nullptr, names
+    flatbuffers::ST_TABLE, 3, type_codes, type_refs, nullptr, nullptr, names
   };
   return &tt;
 }
@@ -6282,7 +6162,7 @@ inline const flatbuffers::TypeTable *LSTMTypeTable() {
     { flatbuffers::ET_FLOAT, 0, -1 }
   };
   static const flatbuffers::TypeFunction type_refs[] = {
-    BlobTypeTable
+    MNN::BlobTypeTable
   };
   static const char * const names[] = {
     "outputCount",
@@ -6296,7 +6176,7 @@ inline const flatbuffers::TypeTable *LSTMTypeTable() {
     "quantScale"
   };
   static const flatbuffers::TypeTable tt = {
-    flatbuffers::ST_TABLE, 9, type_codes, type_refs, nullptr, names
+    flatbuffers::ST_TABLE, 9, type_codes, type_refs, nullptr, nullptr, names
   };
   return &tt;
 }
@@ -6308,7 +6188,7 @@ inline const flatbuffers::TypeTable *SliceTypeTable() {
     { flatbuffers::ET_CHAR, 0, 0 }
   };
   static const flatbuffers::TypeFunction type_refs[] = {
-    NetSourceTypeTable
+    MNN::NetSourceTypeTable
   };
   static const char * const names[] = {
     "axis",
@@ -6316,7 +6196,7 @@ inline const flatbuffers::TypeTable *SliceTypeTable() {
     "sourceType"
   };
   static const flatbuffers::TypeTable tt = {
-    flatbuffers::ST_TABLE, 3, type_codes, type_refs, nullptr, names
+    flatbuffers::ST_TABLE, 3, type_codes, type_refs, nullptr, nullptr, names
   };
   return &tt;
 }
@@ -6343,7 +6223,7 @@ inline const flatbuffers::TypeTable *BatchNormTypeTable() {
     "epsilon"
   };
   static const flatbuffers::TypeTable tt = {
-    flatbuffers::ST_TABLE, 8, type_codes, nullptr, nullptr, names
+    flatbuffers::ST_TABLE, 8, type_codes, nullptr, nullptr, nullptr, names
   };
   return &tt;
 }
@@ -6360,7 +6240,7 @@ inline const flatbuffers::TypeTable *ScaleTypeTable() {
     "biasData"
   };
   static const flatbuffers::TypeTable tt = {
-    flatbuffers::ST_TABLE, 3, type_codes, nullptr, nullptr, names
+    flatbuffers::ST_TABLE, 3, type_codes, nullptr, nullptr, nullptr, names
   };
   return &tt;
 }
@@ -6371,14 +6251,14 @@ inline const flatbuffers::TypeTable *EltwiseTypeTable() {
     { flatbuffers::ET_FLOAT, 1, -1 }
   };
   static const flatbuffers::TypeFunction type_refs[] = {
-    EltwiseTypeTypeTable
+    MNN::EltwiseTypeTypeTable
   };
   static const char * const names[] = {
     "type",
     "coeff"
   };
   static const flatbuffers::TypeTable tt = {
-    flatbuffers::ST_TABLE, 2, type_codes, type_refs, nullptr, names
+    flatbuffers::ST_TABLE, 2, type_codes, type_refs, nullptr, nullptr, names
   };
   return &tt;
 }
@@ -6393,7 +6273,7 @@ inline const flatbuffers::TypeTable *FlattenTypeTable() {
     "endAxis"
   };
   static const flatbuffers::TypeTable tt = {
-    flatbuffers::ST_TABLE, 2, type_codes, nullptr, nullptr, names
+    flatbuffers::ST_TABLE, 2, type_codes, nullptr, nullptr, nullptr, names
   };
   return &tt;
 }
@@ -6406,7 +6286,7 @@ inline const flatbuffers::TypeTable *PermuteTypeTable() {
     "dims"
   };
   static const flatbuffers::TypeTable tt = {
-    flatbuffers::ST_TABLE, 1, type_codes, nullptr, nullptr, names
+    flatbuffers::ST_TABLE, 1, type_codes, nullptr, nullptr, nullptr, names
   };
   return &tt;
 }
@@ -6417,14 +6297,14 @@ inline const flatbuffers::TypeTable *ReshapeTypeTable() {
     { flatbuffers::ET_CHAR, 0, 0 }
   };
   static const flatbuffers::TypeFunction type_refs[] = {
-    MNN_DATA_FORMATTypeTable
+    MNN::MNN_DATA_FORMATTypeTable
   };
   static const char * const names[] = {
     "dims",
     "dimType"
   };
   static const flatbuffers::TypeTable tt = {
-    flatbuffers::ST_TABLE, 2, type_codes, type_refs, nullptr, names
+    flatbuffers::ST_TABLE, 2, type_codes, type_refs, nullptr, nullptr, names
   };
   return &tt;
 }
@@ -6455,7 +6335,7 @@ inline const flatbuffers::TypeTable *DetectionOutputTypeTable() {
     "objectnessScore"
   };
   static const flatbuffers::TypeTable tt = {
-    flatbuffers::ST_TABLE, 10, type_codes, nullptr, nullptr, names
+    flatbuffers::ST_TABLE, 10, type_codes, nullptr, nullptr, nullptr, names
   };
   return &tt;
 }
@@ -6472,7 +6352,7 @@ inline const flatbuffers::TypeTable *RoiPoolingTypeTable() {
     "spatialScale"
   };
   static const flatbuffers::TypeTable tt = {
-    flatbuffers::ST_TABLE, 3, type_codes, nullptr, nullptr, names
+    flatbuffers::ST_TABLE, 3, type_codes, nullptr, nullptr, nullptr, names
   };
   return &tt;
 }
@@ -6490,7 +6370,7 @@ inline const flatbuffers::TypeTable *ProposalTypeTable() {
     { flatbuffers::ET_SEQUENCE, 0, 0 }
   };
   static const flatbuffers::TypeFunction type_refs[] = {
-    BlobTypeTable
+    MNN::BlobTypeTable
   };
   static const char * const names[] = {
     "featStride",
@@ -6504,7 +6384,7 @@ inline const flatbuffers::TypeTable *ProposalTypeTable() {
     "anchors"
   };
   static const flatbuffers::TypeTable tt = {
-    flatbuffers::ST_TABLE, 9, type_codes, type_refs, nullptr, names
+    flatbuffers::ST_TABLE, 9, type_codes, type_refs, nullptr, nullptr, names
   };
   return &tt;
 }
@@ -6524,7 +6404,7 @@ inline const flatbuffers::TypeTable *InterpTypeTable() {
     { flatbuffers::ET_CHAR, 0, 0 }
   };
   static const flatbuffers::TypeFunction type_refs[] = {
-    CoordinateTransformationModeTypeTable
+    MNN::CoordinateTransformationModeTypeTable
   };
   static const char * const names[] = {
     "widthScale",
@@ -6540,7 +6420,7 @@ inline const flatbuffers::TypeTable *InterpTypeTable() {
     "ctm"
   };
   static const flatbuffers::TypeTable tt = {
-    flatbuffers::ST_TABLE, 11, type_codes, type_refs, nullptr, names
+    flatbuffers::ST_TABLE, 11, type_codes, type_refs, nullptr, nullptr, names
   };
   return &tt;
 }
@@ -6555,7 +6435,7 @@ inline const flatbuffers::TypeTable *ResizeTypeTable() {
     "yScale"
   };
   static const flatbuffers::TypeTable tt = {
-    flatbuffers::ST_TABLE, 2, type_codes, nullptr, nullptr, names
+    flatbuffers::ST_TABLE, 2, type_codes, nullptr, nullptr, nullptr, names
   };
   return &tt;
 }
@@ -6588,7 +6468,7 @@ inline const flatbuffers::TypeTable *PriorBoxTypeTable() {
     "offset"
   };
   static const flatbuffers::TypeTable tt = {
-    flatbuffers::ST_TABLE, 11, type_codes, nullptr, nullptr, names
+    flatbuffers::ST_TABLE, 11, type_codes, nullptr, nullptr, nullptr, names
   };
   return &tt;
 }
@@ -6607,7 +6487,7 @@ inline const flatbuffers::TypeTable *NormalizeTypeTable() {
     "scale"
   };
   static const flatbuffers::TypeTable tt = {
-    flatbuffers::ST_TABLE, 4, type_codes, nullptr, nullptr, names
+    flatbuffers::ST_TABLE, 4, type_codes, nullptr, nullptr, nullptr, names
   };
   return &tt;
 }
@@ -6620,8 +6500,8 @@ inline const flatbuffers::TypeTable *EltwiseInt8TypeTable() {
     { flatbuffers::ET_SEQUENCE, 0, 1 }
   };
   static const flatbuffers::TypeFunction type_refs[] = {
-    EltwiseTypeTypeTable,
-    QuantizedFloatParamTypeTable
+    MNN::EltwiseTypeTypeTable,
+    MNN::QuantizedFloatParamTypeTable
   };
   static const char * const names[] = {
     "type",
@@ -6630,7 +6510,7 @@ inline const flatbuffers::TypeTable *EltwiseInt8TypeTable() {
     "outputQuan"
   };
   static const flatbuffers::TypeTable tt = {
-    flatbuffers::ST_TABLE, 4, type_codes, type_refs, nullptr, names
+    flatbuffers::ST_TABLE, 4, type_codes, type_refs, nullptr, nullptr, names
   };
   return &tt;
 }
diff --git a/schema/current/GpuLibrary_generated.h b/schema/current/GpuLibrary_generated.h
index 321f816c..84c1e9f0 100644
--- a/schema/current/GpuLibrary_generated.h
+++ b/schema/current/GpuLibrary_generated.h
@@ -4,25 +4,31 @@
 #ifndef FLATBUFFERS_GENERATED_GPULIBRARY_MNN_H_
 #define FLATBUFFERS_GENERATED_GPULIBRARY_MNN_H_
 
+#include "flatbuffers/flatbuffers.h"
 
-#include "Tensor_generated.h"
 #include "Type_generated.h"
+#include "Tensor_generated.h"
 
 namespace MNN {
 
 struct GpuBuffer;
+struct GpuBufferBuilder;
 struct GpuBufferT;
 
 struct GpuPipeline;
+struct GpuPipelineBuilder;
 struct GpuPipelineT;
 
 struct GpuStage;
+struct GpuStageBuilder;
 struct GpuStageT;
 
 struct GpuFunction;
+struct GpuFunctionBuilder;
 struct GpuFunctionT;
 
 struct GpuLibrary;
+struct GpuLibraryBuilder;
 struct GpuLibraryT;
 
 inline const flatbuffers::TypeTable *GpuBufferTypeTable();
@@ -35,7 +41,7 @@ inline const flatbuffers::TypeTable *GpuFunctionTypeTable();
 
 inline const flatbuffers::TypeTable *GpuLibraryTypeTable();
 
-enum STORAGE_TYPE {
+enum STORAGE_TYPE : int8_t {
   STORAGE_TYPE_BUFFER = 0,
   STORAGE_TYPE_UNIFORM = 1,
   STORAGE_TYPE_IMAGE = 2,
@@ -53,7 +59,7 @@ inline const STORAGE_TYPE (&EnumValuesSTORAGE_TYPE())[3] {
 }
 
 inline const char * const *EnumNamesSTORAGE_TYPE() {
-  static const char * const names[] = {
+  static const char * const names[4] = {
     "BUFFER",
     "UNIFORM",
     "IMAGE",
@@ -63,12 +69,12 @@ inline const char * const *EnumNamesSTORAGE_TYPE() {
 }
 
 inline const char *EnumNameSTORAGE_TYPE(STORAGE_TYPE e) {
-  if (e < STORAGE_TYPE_BUFFER || e > STORAGE_TYPE_IMAGE) return "";
-  const size_t index = static_cast<int>(e);
+  if (flatbuffers::IsOutRange(e, STORAGE_TYPE_BUFFER, STORAGE_TYPE_IMAGE)) return "";
+  const size_t index = static_cast<size_t>(e);
   return EnumNamesSTORAGE_TYPE()[index];
 }
 
-enum ACCESS_TYPE {
+enum ACCESS_TYPE : int8_t {
   ACCESS_TYPE_READ_ONLY = 0,
   ACCESS_TYPE_WRITE_ONLY = 1,
   ACCESS_TYPE_READ_WRITE = 2,
@@ -86,7 +92,7 @@ inline const ACCESS_TYPE (&EnumValuesACCESS_TYPE())[3] {
 }
 
 inline const char * const *EnumNamesACCESS_TYPE() {
-  static const char * const names[] = {
+  static const char * const names[4] = {
     "READ_ONLY",
     "WRITE_ONLY",
     "READ_WRITE",
@@ -96,24 +102,21 @@ inline const char * const *EnumNamesACCESS_TYPE() {
 }
 
 inline const char *EnumNameACCESS_TYPE(ACCESS_TYPE e) {
-  if (e < ACCESS_TYPE_READ_ONLY || e > ACCESS_TYPE_READ_WRITE) return "";
-  const size_t index = static_cast<int>(e);
+  if (flatbuffers::IsOutRange(e, ACCESS_TYPE_READ_ONLY, ACCESS_TYPE_READ_WRITE)) return "";
+  const size_t index = static_cast<size_t>(e);
   return EnumNamesACCESS_TYPE()[index];
 }
 
 struct GpuBufferT : public flatbuffers::NativeTable {
   typedef GpuBuffer TableType;
-  ACCESS_TYPE access;
-  STORAGE_TYPE storage;
-  std::unique_ptr<BlobT> content;
-  GpuBufferT()
-      : access(ACCESS_TYPE_READ_ONLY),
-        storage(STORAGE_TYPE_BUFFER) {
-  }
+  MNN::ACCESS_TYPE access = MNN::ACCESS_TYPE_READ_ONLY;
+  MNN::STORAGE_TYPE storage = MNN::STORAGE_TYPE_BUFFER;
+  std::unique_ptr<MNN::BlobT> content{};
 };
 
 struct GpuBuffer FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
   typedef GpuBufferT NativeTableType;
+  typedef GpuBufferBuilder Builder;
   static const flatbuffers::TypeTable *MiniReflectTypeTable() {
     return GpuBufferTypeTable();
   }
@@ -122,14 +125,14 @@ struct GpuBuffer FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
     VT_STORAGE = 6,
     VT_CONTENT = 8
   };
-  ACCESS_TYPE access() const {
-    return static_cast<ACCESS_TYPE>(GetField<int8_t>(VT_ACCESS, 0));
+  MNN::ACCESS_TYPE access() const {
+    return static_cast<MNN::ACCESS_TYPE>(GetField<int8_t>(VT_ACCESS, 0));
   }
-  STORAGE_TYPE storage() const {
-    return static_cast<STORAGE_TYPE>(GetField<int8_t>(VT_STORAGE, 0));
+  MNN::STORAGE_TYPE storage() const {
+    return static_cast<MNN::STORAGE_TYPE>(GetField<int8_t>(VT_STORAGE, 0));
   }
-  const Blob *content() const {
-    return GetPointer<const Blob *>(VT_CONTENT);
+  const MNN::Blob *content() const {
+    return GetPointer<const MNN::Blob *>(VT_CONTENT);
   }
   bool Verify(flatbuffers::Verifier &verifier) const {
     return VerifyTableStart(verifier) &&
@@ -145,22 +148,22 @@ struct GpuBuffer FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
 };
 
 struct GpuBufferBuilder {
+  typedef GpuBuffer Table;
   flatbuffers::FlatBufferBuilder &fbb_;
   flatbuffers::uoffset_t start_;
-  void add_access(ACCESS_TYPE access) {
+  void add_access(MNN::ACCESS_TYPE access) {
     fbb_.AddElement<int8_t>(GpuBuffer::VT_ACCESS, static_cast<int8_t>(access), 0);
   }
-  void add_storage(STORAGE_TYPE storage) {
+  void add_storage(MNN::STORAGE_TYPE storage) {
     fbb_.AddElement<int8_t>(GpuBuffer::VT_STORAGE, static_cast<int8_t>(storage), 0);
   }
-  void add_content(flatbuffers::Offset<Blob> content) {
+  void add_content(flatbuffers::Offset<MNN::Blob> content) {
     fbb_.AddOffset(GpuBuffer::VT_CONTENT, content);
   }
   explicit GpuBufferBuilder(flatbuffers::FlatBufferBuilder &_fbb)
         : fbb_(_fbb) {
     start_ = fbb_.StartTable();
   }
-  GpuBufferBuilder &operator=(const GpuBufferBuilder &);
   flatbuffers::Offset<GpuBuffer> Finish() {
     const auto end = fbb_.EndTable(start_);
     auto o = flatbuffers::Offset<GpuBuffer>(end);
@@ -170,9 +173,9 @@ struct GpuBufferBuilder {
 
 inline flatbuffers::Offset<GpuBuffer> CreateGpuBuffer(
     flatbuffers::FlatBufferBuilder &_fbb,
-    ACCESS_TYPE access = ACCESS_TYPE_READ_ONLY,
-    STORAGE_TYPE storage = STORAGE_TYPE_BUFFER,
-    flatbuffers::Offset<Blob> content = 0) {
+    MNN::ACCESS_TYPE access = MNN::ACCESS_TYPE_READ_ONLY,
+    MNN::STORAGE_TYPE storage = MNN::STORAGE_TYPE_BUFFER,
+    flatbuffers::Offset<MNN::Blob> content = 0) {
   GpuBufferBuilder builder_(_fbb);
   builder_.add_content(content);
   builder_.add_storage(storage);
@@ -184,18 +187,17 @@ flatbuffers::Offset<GpuBuffer> CreateGpuBuffer(flatbuffers::FlatBufferBuilder &_
 
 struct GpuPipelineT : public flatbuffers::NativeTable {
   typedef GpuPipeline TableType;
-  std::vector<int32_t> localSize;
-  std::string key;
-  std::vector<int8_t> metal;
-  std::vector<int8_t> vulkan;
-  std::string openglComputeShader;
-  std::string openclKernel;
-  GpuPipelineT() {
-  }
+  std::vector<int32_t> localSize{};
+  std::string key{};
+  std::vector<int8_t> metal{};
+  std::vector<int8_t> vulkan{};
+  std::string openglComputeShader{};
+  std::string openclKernel{};
 };
 
 struct GpuPipeline FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
   typedef GpuPipelineT NativeTableType;
+  typedef GpuPipelineBuilder Builder;
   static const flatbuffers::TypeTable *MiniReflectTypeTable() {
     return GpuPipelineTypeTable();
   }
@@ -247,6 +249,7 @@ struct GpuPipeline FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
 };
 
 struct GpuPipelineBuilder {
+  typedef GpuPipeline Table;
   flatbuffers::FlatBufferBuilder &fbb_;
   flatbuffers::uoffset_t start_;
   void add_localSize(flatbuffers::Offset<flatbuffers::Vector<int32_t>> localSize) {
@@ -271,7 +274,6 @@ struct GpuPipelineBuilder {
         : fbb_(_fbb) {
     start_ = fbb_.StartTable();
   }
-  GpuPipelineBuilder &operator=(const GpuPipelineBuilder &);
   flatbuffers::Offset<GpuPipeline> Finish() {
     const auto end = fbb_.EndTable(start_);
     auto o = flatbuffers::Offset<GpuPipeline>(end);
@@ -325,23 +327,20 @@ flatbuffers::Offset<GpuPipeline> CreateGpuPipeline(flatbuffers::FlatBufferBuilde
 
 struct GpuStageT : public flatbuffers::NativeTable {
   typedef GpuStage TableType;
-  std::string pipeline;
-  std::vector<int32_t> groupSize;
-  std::vector<int32_t> inputIndexes;
-  std::vector<int32_t> outputIndexes;
-  std::vector<std::unique_ptr<GpuBufferT>> middleBuffer;
-  std::vector<std::unique_ptr<GpuBufferT>> constBuffer;
-  int32_t globalSizeIndex;
-  std::vector<int32_t> globalSizeDivide;
-  bool requireSize;
-  GpuStageT()
-      : globalSizeIndex(0),
-        requireSize(false) {
-  }
+  std::string pipeline{};
+  std::vector<int32_t> groupSize{};
+  std::vector<int32_t> inputIndexes{};
+  std::vector<int32_t> outputIndexes{};
+  std::vector<std::unique_ptr<MNN::GpuBufferT>> middleBuffer{};
+  std::vector<std::unique_ptr<MNN::GpuBufferT>> constBuffer{};
+  int32_t globalSizeIndex = 0;
+  std::vector<int32_t> globalSizeDivide{};
+  bool requireSize = false;
 };
 
 struct GpuStage FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
   typedef GpuStageT NativeTableType;
+  typedef GpuStageBuilder Builder;
   static const flatbuffers::TypeTable *MiniReflectTypeTable() {
     return GpuStageTypeTable();
   }
@@ -368,11 +367,11 @@ struct GpuStage FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
   const flatbuffers::Vector<int32_t> *outputIndexes() const {
     return GetPointer<const flatbuffers::Vector<int32_t> *>(VT_OUTPUTINDEXES);
   }
-  const flatbuffers::Vector<flatbuffers::Offset<GpuBuffer>> *middleBuffer() const {
-    return GetPointer<const flatbuffers::Vector<flatbuffers::Offset<GpuBuffer>> *>(VT_MIDDLEBUFFER);
+  const flatbuffers::Vector<flatbuffers::Offset<MNN::GpuBuffer>> *middleBuffer() const {
+    return GetPointer<const flatbuffers::Vector<flatbuffers::Offset<MNN::GpuBuffer>> *>(VT_MIDDLEBUFFER);
   }
-  const flatbuffers::Vector<flatbuffers::Offset<GpuBuffer>> *constBuffer() const {
-    return GetPointer<const flatbuffers::Vector<flatbuffers::Offset<GpuBuffer>> *>(VT_CONSTBUFFER);
+  const flatbuffers::Vector<flatbuffers::Offset<MNN::GpuBuffer>> *constBuffer() const {
+    return GetPointer<const flatbuffers::Vector<flatbuffers::Offset<MNN::GpuBuffer>> *>(VT_CONSTBUFFER);
   }
   int32_t globalSizeIndex() const {
     return GetField<int32_t>(VT_GLOBALSIZEINDEX, 0);
@@ -411,6 +410,7 @@ struct GpuStage FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
 };
 
 struct GpuStageBuilder {
+  typedef GpuStage Table;
   flatbuffers::FlatBufferBuilder &fbb_;
   flatbuffers::uoffset_t start_;
   void add_pipeline(flatbuffers::Offset<flatbuffers::String> pipeline) {
@@ -425,10 +425,10 @@ struct GpuStageBuilder {
   void add_outputIndexes(flatbuffers::Offset<flatbuffers::Vector<int32_t>> outputIndexes) {
     fbb_.AddOffset(GpuStage::VT_OUTPUTINDEXES, outputIndexes);
   }
-  void add_middleBuffer(flatbuffers::Offset<flatbuffers::Vector<flatbuffers::Offset<GpuBuffer>>> middleBuffer) {
+  void add_middleBuffer(flatbuffers::Offset<flatbuffers::Vector<flatbuffers::Offset<MNN::GpuBuffer>>> middleBuffer) {
     fbb_.AddOffset(GpuStage::VT_MIDDLEBUFFER, middleBuffer);
   }
-  void add_constBuffer(flatbuffers::Offset<flatbuffers::Vector<flatbuffers::Offset<GpuBuffer>>> constBuffer) {
+  void add_constBuffer(flatbuffers::Offset<flatbuffers::Vector<flatbuffers::Offset<MNN::GpuBuffer>>> constBuffer) {
     fbb_.AddOffset(GpuStage::VT_CONSTBUFFER, constBuffer);
   }
   void add_globalSizeIndex(int32_t globalSizeIndex) {
@@ -444,7 +444,6 @@ struct GpuStageBuilder {
         : fbb_(_fbb) {
     start_ = fbb_.StartTable();
   }
-  GpuStageBuilder &operator=(const GpuStageBuilder &);
   flatbuffers::Offset<GpuStage> Finish() {
     const auto end = fbb_.EndTable(start_);
     auto o = flatbuffers::Offset<GpuStage>(end);
@@ -458,8 +457,8 @@ inline flatbuffers::Offset<GpuStage> CreateGpuStage(
     flatbuffers::Offset<flatbuffers::Vector<int32_t>> groupSize = 0,
     flatbuffers::Offset<flatbuffers::Vector<int32_t>> inputIndexes = 0,
     flatbuffers::Offset<flatbuffers::Vector<int32_t>> outputIndexes = 0,
-    flatbuffers::Offset<flatbuffers::Vector<flatbuffers::Offset<GpuBuffer>>> middleBuffer = 0,
-    flatbuffers::Offset<flatbuffers::Vector<flatbuffers::Offset<GpuBuffer>>> constBuffer = 0,
+    flatbuffers::Offset<flatbuffers::Vector<flatbuffers::Offset<MNN::GpuBuffer>>> middleBuffer = 0,
+    flatbuffers::Offset<flatbuffers::Vector<flatbuffers::Offset<MNN::GpuBuffer>>> constBuffer = 0,
     int32_t globalSizeIndex = 0,
     flatbuffers::Offset<flatbuffers::Vector<int32_t>> globalSizeDivide = 0,
     bool requireSize = false) {
@@ -482,8 +481,8 @@ inline flatbuffers::Offset<GpuStage> CreateGpuStageDirect(
     const std::vector<int32_t> *groupSize = nullptr,
     const std::vector<int32_t> *inputIndexes = nullptr,
     const std::vector<int32_t> *outputIndexes = nullptr,
-    const std::vector<flatbuffers::Offset<GpuBuffer>> *middleBuffer = nullptr,
-    const std::vector<flatbuffers::Offset<GpuBuffer>> *constBuffer = nullptr,
+    const std::vector<flatbuffers::Offset<MNN::GpuBuffer>> *middleBuffer = nullptr,
+    const std::vector<flatbuffers::Offset<MNN::GpuBuffer>> *constBuffer = nullptr,
     int32_t globalSizeIndex = 0,
     const std::vector<int32_t> *globalSizeDivide = nullptr,
     bool requireSize = false) {
@@ -491,8 +490,8 @@ inline flatbuffers::Offset<GpuStage> CreateGpuStageDirect(
   auto groupSize__ = groupSize ? _fbb.CreateVector<int32_t>(*groupSize) : 0;
   auto inputIndexes__ = inputIndexes ? _fbb.CreateVector<int32_t>(*inputIndexes) : 0;
   auto outputIndexes__ = outputIndexes ? _fbb.CreateVector<int32_t>(*outputIndexes) : 0;
-  auto middleBuffer__ = middleBuffer ? _fbb.CreateVector<flatbuffers::Offset<GpuBuffer>>(*middleBuffer) : 0;
-  auto constBuffer__ = constBuffer ? _fbb.CreateVector<flatbuffers::Offset<GpuBuffer>>(*constBuffer) : 0;
+  auto middleBuffer__ = middleBuffer ? _fbb.CreateVector<flatbuffers::Offset<MNN::GpuBuffer>>(*middleBuffer) : 0;
+  auto constBuffer__ = constBuffer ? _fbb.CreateVector<flatbuffers::Offset<MNN::GpuBuffer>>(*constBuffer) : 0;
   auto globalSizeDivide__ = globalSizeDivide ? _fbb.CreateVector<int32_t>(*globalSizeDivide) : 0;
   return MNN::CreateGpuStage(
       _fbb,
@@ -511,14 +510,13 @@ flatbuffers::Offset<GpuStage> CreateGpuStage(flatbuffers::FlatBufferBuilder &_fb
 
 struct GpuFunctionT : public flatbuffers::NativeTable {
   typedef GpuFunction TableType;
-  std::vector<std::unique_ptr<GpuStageT>> stags;
-  std::string name;
-  GpuFunctionT() {
-  }
+  std::vector<std::unique_ptr<MNN::GpuStageT>> stags{};
+  std::string name{};
 };
 
 struct GpuFunction FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
   typedef GpuFunctionT NativeTableType;
+  typedef GpuFunctionBuilder Builder;
   static const flatbuffers::TypeTable *MiniReflectTypeTable() {
     return GpuFunctionTypeTable();
   }
@@ -526,8 +524,8 @@ struct GpuFunction FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
     VT_STAGS = 4,
     VT_NAME = 6
   };
-  const flatbuffers::Vector<flatbuffers::Offset<GpuStage>> *stags() const {
-    return GetPointer<const flatbuffers::Vector<flatbuffers::Offset<GpuStage>> *>(VT_STAGS);
+  const flatbuffers::Vector<flatbuffers::Offset<MNN::GpuStage>> *stags() const {
+    return GetPointer<const flatbuffers::Vector<flatbuffers::Offset<MNN::GpuStage>> *>(VT_STAGS);
   }
   const flatbuffers::String *name() const {
     return GetPointer<const flatbuffers::String *>(VT_NAME);
@@ -547,9 +545,10 @@ struct GpuFunction FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
 };
 
 struct GpuFunctionBuilder {
+  typedef GpuFunction Table;
   flatbuffers::FlatBufferBuilder &fbb_;
   flatbuffers::uoffset_t start_;
-  void add_stags(flatbuffers::Offset<flatbuffers::Vector<flatbuffers::Offset<GpuStage>>> stags) {
+  void add_stags(flatbuffers::Offset<flatbuffers::Vector<flatbuffers::Offset<MNN::GpuStage>>> stags) {
     fbb_.AddOffset(GpuFunction::VT_STAGS, stags);
   }
   void add_name(flatbuffers::Offset<flatbuffers::String> name) {
@@ -559,7 +558,6 @@ struct GpuFunctionBuilder {
         : fbb_(_fbb) {
     start_ = fbb_.StartTable();
   }
-  GpuFunctionBuilder &operator=(const GpuFunctionBuilder &);
   flatbuffers::Offset<GpuFunction> Finish() {
     const auto end = fbb_.EndTable(start_);
     auto o = flatbuffers::Offset<GpuFunction>(end);
@@ -569,7 +567,7 @@ struct GpuFunctionBuilder {
 
 inline flatbuffers::Offset<GpuFunction> CreateGpuFunction(
     flatbuffers::FlatBufferBuilder &_fbb,
-    flatbuffers::Offset<flatbuffers::Vector<flatbuffers::Offset<GpuStage>>> stags = 0,
+    flatbuffers::Offset<flatbuffers::Vector<flatbuffers::Offset<MNN::GpuStage>>> stags = 0,
     flatbuffers::Offset<flatbuffers::String> name = 0) {
   GpuFunctionBuilder builder_(_fbb);
   builder_.add_name(name);
@@ -579,9 +577,9 @@ inline flatbuffers::Offset<GpuFunction> CreateGpuFunction(
 
 inline flatbuffers::Offset<GpuFunction> CreateGpuFunctionDirect(
     flatbuffers::FlatBufferBuilder &_fbb,
-    const std::vector<flatbuffers::Offset<GpuStage>> *stags = nullptr,
+    const std::vector<flatbuffers::Offset<MNN::GpuStage>> *stags = nullptr,
     const char *name = nullptr) {
-  auto stags__ = stags ? _fbb.CreateVector<flatbuffers::Offset<GpuStage>>(*stags) : 0;
+  auto stags__ = stags ? _fbb.CreateVector<flatbuffers::Offset<MNN::GpuStage>>(*stags) : 0;
   auto name__ = name ? _fbb.CreateString(name) : 0;
   return MNN::CreateGpuFunction(
       _fbb,
@@ -593,15 +591,14 @@ flatbuffers::Offset<GpuFunction> CreateGpuFunction(flatbuffers::FlatBufferBuilde
 
 struct GpuLibraryT : public flatbuffers::NativeTable {
   typedef GpuLibrary TableType;
-  std::vector<std::unique_ptr<GpuFunctionT>> functions;
-  std::vector<std::unique_ptr<GpuPipelineT>> pipeline;
-  std::string name;
-  GpuLibraryT() {
-  }
+  std::vector<std::unique_ptr<MNN::GpuFunctionT>> functions{};
+  std::vector<std::unique_ptr<MNN::GpuPipelineT>> pipeline{};
+  std::string name{};
 };
 
 struct GpuLibrary FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
   typedef GpuLibraryT NativeTableType;
+  typedef GpuLibraryBuilder Builder;
   static const flatbuffers::TypeTable *MiniReflectTypeTable() {
     return GpuLibraryTypeTable();
   }
@@ -610,11 +607,11 @@ struct GpuLibrary FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
     VT_PIPELINE = 6,
     VT_NAME = 8
   };
-  const flatbuffers::Vector<flatbuffers::Offset<GpuFunction>> *functions() const {
-    return GetPointer<const flatbuffers::Vector<flatbuffers::Offset<GpuFunction>> *>(VT_FUNCTIONS);
+  const flatbuffers::Vector<flatbuffers::Offset<MNN::GpuFunction>> *functions() const {
+    return GetPointer<const flatbuffers::Vector<flatbuffers::Offset<MNN::GpuFunction>> *>(VT_FUNCTIONS);
   }
-  const flatbuffers::Vector<flatbuffers::Offset<GpuPipeline>> *pipeline() const {
-    return GetPointer<const flatbuffers::Vector<flatbuffers::Offset<GpuPipeline>> *>(VT_PIPELINE);
+  const flatbuffers::Vector<flatbuffers::Offset<MNN::GpuPipeline>> *pipeline() const {
+    return GetPointer<const flatbuffers::Vector<flatbuffers::Offset<MNN::GpuPipeline>> *>(VT_PIPELINE);
   }
   const flatbuffers::String *name() const {
     return GetPointer<const flatbuffers::String *>(VT_NAME);
@@ -637,12 +634,13 @@ struct GpuLibrary FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
 };
 
 struct GpuLibraryBuilder {
+  typedef GpuLibrary Table;
   flatbuffers::FlatBufferBuilder &fbb_;
   flatbuffers::uoffset_t start_;
-  void add_functions(flatbuffers::Offset<flatbuffers::Vector<flatbuffers::Offset<GpuFunction>>> functions) {
+  void add_functions(flatbuffers::Offset<flatbuffers::Vector<flatbuffers::Offset<MNN::GpuFunction>>> functions) {
     fbb_.AddOffset(GpuLibrary::VT_FUNCTIONS, functions);
   }
-  void add_pipeline(flatbuffers::Offset<flatbuffers::Vector<flatbuffers::Offset<GpuPipeline>>> pipeline) {
+  void add_pipeline(flatbuffers::Offset<flatbuffers::Vector<flatbuffers::Offset<MNN::GpuPipeline>>> pipeline) {
     fbb_.AddOffset(GpuLibrary::VT_PIPELINE, pipeline);
   }
   void add_name(flatbuffers::Offset<flatbuffers::String> name) {
@@ -652,7 +650,6 @@ struct GpuLibraryBuilder {
         : fbb_(_fbb) {
     start_ = fbb_.StartTable();
   }
-  GpuLibraryBuilder &operator=(const GpuLibraryBuilder &);
   flatbuffers::Offset<GpuLibrary> Finish() {
     const auto end = fbb_.EndTable(start_);
     auto o = flatbuffers::Offset<GpuLibrary>(end);
@@ -662,8 +659,8 @@ struct GpuLibraryBuilder {
 
 inline flatbuffers::Offset<GpuLibrary> CreateGpuLibrary(
     flatbuffers::FlatBufferBuilder &_fbb,
-    flatbuffers::Offset<flatbuffers::Vector<flatbuffers::Offset<GpuFunction>>> functions = 0,
-    flatbuffers::Offset<flatbuffers::Vector<flatbuffers::Offset<GpuPipeline>>> pipeline = 0,
+    flatbuffers::Offset<flatbuffers::Vector<flatbuffers::Offset<MNN::GpuFunction>>> functions = 0,
+    flatbuffers::Offset<flatbuffers::Vector<flatbuffers::Offset<MNN::GpuPipeline>>> pipeline = 0,
     flatbuffers::Offset<flatbuffers::String> name = 0) {
   GpuLibraryBuilder builder_(_fbb);
   builder_.add_name(name);
@@ -674,11 +671,11 @@ inline flatbuffers::Offset<GpuLibrary> CreateGpuLibrary(
 
 inline flatbuffers::Offset<GpuLibrary> CreateGpuLibraryDirect(
     flatbuffers::FlatBufferBuilder &_fbb,
-    const std::vector<flatbuffers::Offset<GpuFunction>> *functions = nullptr,
-    const std::vector<flatbuffers::Offset<GpuPipeline>> *pipeline = nullptr,
+    const std::vector<flatbuffers::Offset<MNN::GpuFunction>> *functions = nullptr,
+    const std::vector<flatbuffers::Offset<MNN::GpuPipeline>> *pipeline = nullptr,
     const char *name = nullptr) {
-  auto functions__ = functions ? _fbb.CreateVector<flatbuffers::Offset<GpuFunction>>(*functions) : 0;
-  auto pipeline__ = pipeline ? _fbb.CreateVector<flatbuffers::Offset<GpuPipeline>>(*pipeline) : 0;
+  auto functions__ = functions ? _fbb.CreateVector<flatbuffers::Offset<MNN::GpuFunction>>(*functions) : 0;
+  auto pipeline__ = pipeline ? _fbb.CreateVector<flatbuffers::Offset<MNN::GpuPipeline>>(*pipeline) : 0;
   auto name__ = name ? _fbb.CreateString(name) : 0;
   return MNN::CreateGpuLibrary(
       _fbb,
@@ -690,17 +687,17 @@ inline flatbuffers::Offset<GpuLibrary> CreateGpuLibraryDirect(
 flatbuffers::Offset<GpuLibrary> CreateGpuLibrary(flatbuffers::FlatBufferBuilder &_fbb, const GpuLibraryT *_o, const flatbuffers::rehasher_function_t *_rehasher = nullptr);
 
 inline GpuBufferT *GpuBuffer::UnPack(const flatbuffers::resolver_function_t *_resolver) const {
-  auto _o = new GpuBufferT();
-  UnPackTo(_o, _resolver);
-  return _o;
+  auto _o = std::unique_ptr<GpuBufferT>(new GpuBufferT());
+  UnPackTo(_o.get(), _resolver);
+  return _o.release();
 }
 
 inline void GpuBuffer::UnPackTo(GpuBufferT *_o, const flatbuffers::resolver_function_t *_resolver) const {
   (void)_o;
   (void)_resolver;
-  { auto _e = access(); _o->access = _e; };
-  { auto _e = storage(); _o->storage = _e; };
-  { auto _e = content(); if (_e) _o->content = std::unique_ptr<BlobT>(_e->UnPack(_resolver)); };
+  { auto _e = access(); _o->access = _e; }
+  { auto _e = storage(); _o->storage = _e; }
+  { auto _e = content(); if (_e) _o->content = std::unique_ptr<MNN::BlobT>(_e->UnPack(_resolver)); }
 }
 
 inline flatbuffers::Offset<GpuBuffer> GpuBuffer::Pack(flatbuffers::FlatBufferBuilder &_fbb, const GpuBufferT* _o, const flatbuffers::rehasher_function_t *_rehasher) {
@@ -722,20 +719,20 @@ inline flatbuffers::Offset<GpuBuffer> CreateGpuBuffer(flatbuffers::FlatBufferBui
 }
 
 inline GpuPipelineT *GpuPipeline::UnPack(const flatbuffers::resolver_function_t *_resolver) const {
-  auto _o = new GpuPipelineT();
-  UnPackTo(_o, _resolver);
-  return _o;
+  auto _o = std::unique_ptr<GpuPipelineT>(new GpuPipelineT());
+  UnPackTo(_o.get(), _resolver);
+  return _o.release();
 }
 
 inline void GpuPipeline::UnPackTo(GpuPipelineT *_o, const flatbuffers::resolver_function_t *_resolver) const {
   (void)_o;
   (void)_resolver;
-  { auto _e = localSize(); if (_e) { _o->localSize.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->localSize[_i] = _e->Get(_i); } } };
-  { auto _e = key(); if (_e) _o->key = _e->str(); };
-  { auto _e = metal(); if (_e) { _o->metal.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->metal[_i] = _e->Get(_i); } } };
-  { auto _e = vulkan(); if (_e) { _o->vulkan.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->vulkan[_i] = _e->Get(_i); } } };
-  { auto _e = openglComputeShader(); if (_e) _o->openglComputeShader = _e->str(); };
-  { auto _e = openclKernel(); if (_e) _o->openclKernel = _e->str(); };
+  { auto _e = localSize(); if (_e) { _o->localSize.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->localSize[_i] = _e->Get(_i); } } }
+  { auto _e = key(); if (_e) _o->key = _e->str(); }
+  { auto _e = metal(); if (_e) { _o->metal.resize(_e->size()); std::copy(_e->begin(), _e->end(), _o->metal.begin()); } }
+  { auto _e = vulkan(); if (_e) { _o->vulkan.resize(_e->size()); std::copy(_e->begin(), _e->end(), _o->vulkan.begin()); } }
+  { auto _e = openglComputeShader(); if (_e) _o->openglComputeShader = _e->str(); }
+  { auto _e = openclKernel(); if (_e) _o->openclKernel = _e->str(); }
 }
 
 inline flatbuffers::Offset<GpuPipeline> GpuPipeline::Pack(flatbuffers::FlatBufferBuilder &_fbb, const GpuPipelineT* _o, const flatbuffers::rehasher_function_t *_rehasher) {
@@ -763,23 +760,23 @@ inline flatbuffers::Offset<GpuPipeline> CreateGpuPipeline(flatbuffers::FlatBuffe
 }
 
 inline GpuStageT *GpuStage::UnPack(const flatbuffers::resolver_function_t *_resolver) const {
-  auto _o = new GpuStageT();
-  UnPackTo(_o, _resolver);
-  return _o;
+  auto _o = std::unique_ptr<GpuStageT>(new GpuStageT());
+  UnPackTo(_o.get(), _resolver);
+  return _o.release();
 }
 
 inline void GpuStage::UnPackTo(GpuStageT *_o, const flatbuffers::resolver_function_t *_resolver) const {
   (void)_o;
   (void)_resolver;
-  { auto _e = pipeline(); if (_e) _o->pipeline = _e->str(); };
-  { auto _e = groupSize(); if (_e) { _o->groupSize.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->groupSize[_i] = _e->Get(_i); } } };
-  { auto _e = inputIndexes(); if (_e) { _o->inputIndexes.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->inputIndexes[_i] = _e->Get(_i); } } };
-  { auto _e = outputIndexes(); if (_e) { _o->outputIndexes.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->outputIndexes[_i] = _e->Get(_i); } } };
-  { auto _e = middleBuffer(); if (_e) { _o->middleBuffer.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->middleBuffer[_i] = std::unique_ptr<GpuBufferT>(_e->Get(_i)->UnPack(_resolver)); } } };
-  { auto _e = constBuffer(); if (_e) { _o->constBuffer.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->constBuffer[_i] = std::unique_ptr<GpuBufferT>(_e->Get(_i)->UnPack(_resolver)); } } };
-  { auto _e = globalSizeIndex(); _o->globalSizeIndex = _e; };
-  { auto _e = globalSizeDivide(); if (_e) { _o->globalSizeDivide.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->globalSizeDivide[_i] = _e->Get(_i); } } };
-  { auto _e = requireSize(); _o->requireSize = _e; };
+  { auto _e = pipeline(); if (_e) _o->pipeline = _e->str(); }
+  { auto _e = groupSize(); if (_e) { _o->groupSize.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->groupSize[_i] = _e->Get(_i); } } }
+  { auto _e = inputIndexes(); if (_e) { _o->inputIndexes.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->inputIndexes[_i] = _e->Get(_i); } } }
+  { auto _e = outputIndexes(); if (_e) { _o->outputIndexes.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->outputIndexes[_i] = _e->Get(_i); } } }
+  { auto _e = middleBuffer(); if (_e) { _o->middleBuffer.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->middleBuffer[_i] = std::unique_ptr<MNN::GpuBufferT>(_e->Get(_i)->UnPack(_resolver)); } } }
+  { auto _e = constBuffer(); if (_e) { _o->constBuffer.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->constBuffer[_i] = std::unique_ptr<MNN::GpuBufferT>(_e->Get(_i)->UnPack(_resolver)); } } }
+  { auto _e = globalSizeIndex(); _o->globalSizeIndex = _e; }
+  { auto _e = globalSizeDivide(); if (_e) { _o->globalSizeDivide.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->globalSizeDivide[_i] = _e->Get(_i); } } }
+  { auto _e = requireSize(); _o->requireSize = _e; }
 }
 
 inline flatbuffers::Offset<GpuStage> GpuStage::Pack(flatbuffers::FlatBufferBuilder &_fbb, const GpuStageT* _o, const flatbuffers::rehasher_function_t *_rehasher) {
@@ -794,8 +791,8 @@ inline flatbuffers::Offset<GpuStage> CreateGpuStage(flatbuffers::FlatBufferBuild
   auto _groupSize = _o->groupSize.size() ? _fbb.CreateVector(_o->groupSize) : 0;
   auto _inputIndexes = _o->inputIndexes.size() ? _fbb.CreateVector(_o->inputIndexes) : 0;
   auto _outputIndexes = _o->outputIndexes.size() ? _fbb.CreateVector(_o->outputIndexes) : 0;
-  auto _middleBuffer = _o->middleBuffer.size() ? _fbb.CreateVector<flatbuffers::Offset<GpuBuffer>> (_o->middleBuffer.size(), [](size_t i, _VectorArgs *__va) { return CreateGpuBuffer(*__va->__fbb, __va->__o->middleBuffer[i].get(), __va->__rehasher); }, &_va ) : 0;
-  auto _constBuffer = _o->constBuffer.size() ? _fbb.CreateVector<flatbuffers::Offset<GpuBuffer>> (_o->constBuffer.size(), [](size_t i, _VectorArgs *__va) { return CreateGpuBuffer(*__va->__fbb, __va->__o->constBuffer[i].get(), __va->__rehasher); }, &_va ) : 0;
+  auto _middleBuffer = _o->middleBuffer.size() ? _fbb.CreateVector<flatbuffers::Offset<MNN::GpuBuffer>> (_o->middleBuffer.size(), [](size_t i, _VectorArgs *__va) { return CreateGpuBuffer(*__va->__fbb, __va->__o->middleBuffer[i].get(), __va->__rehasher); }, &_va ) : 0;
+  auto _constBuffer = _o->constBuffer.size() ? _fbb.CreateVector<flatbuffers::Offset<MNN::GpuBuffer>> (_o->constBuffer.size(), [](size_t i, _VectorArgs *__va) { return CreateGpuBuffer(*__va->__fbb, __va->__o->constBuffer[i].get(), __va->__rehasher); }, &_va ) : 0;
   auto _globalSizeIndex = _o->globalSizeIndex;
   auto _globalSizeDivide = _o->globalSizeDivide.size() ? _fbb.CreateVector(_o->globalSizeDivide) : 0;
   auto _requireSize = _o->requireSize;
@@ -813,16 +810,16 @@ inline flatbuffers::Offset<GpuStage> CreateGpuStage(flatbuffers::FlatBufferBuild
 }
 
 inline GpuFunctionT *GpuFunction::UnPack(const flatbuffers::resolver_function_t *_resolver) const {
-  auto _o = new GpuFunctionT();
-  UnPackTo(_o, _resolver);
-  return _o;
+  auto _o = std::unique_ptr<GpuFunctionT>(new GpuFunctionT());
+  UnPackTo(_o.get(), _resolver);
+  return _o.release();
 }
 
 inline void GpuFunction::UnPackTo(GpuFunctionT *_o, const flatbuffers::resolver_function_t *_resolver) const {
   (void)_o;
   (void)_resolver;
-  { auto _e = stags(); if (_e) { _o->stags.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->stags[_i] = std::unique_ptr<GpuStageT>(_e->Get(_i)->UnPack(_resolver)); } } };
-  { auto _e = name(); if (_e) _o->name = _e->str(); };
+  { auto _e = stags(); if (_e) { _o->stags.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->stags[_i] = std::unique_ptr<MNN::GpuStageT>(_e->Get(_i)->UnPack(_resolver)); } } }
+  { auto _e = name(); if (_e) _o->name = _e->str(); }
 }
 
 inline flatbuffers::Offset<GpuFunction> GpuFunction::Pack(flatbuffers::FlatBufferBuilder &_fbb, const GpuFunctionT* _o, const flatbuffers::rehasher_function_t *_rehasher) {
@@ -833,7 +830,7 @@ inline flatbuffers::Offset<GpuFunction> CreateGpuFunction(flatbuffers::FlatBuffe
   (void)_rehasher;
   (void)_o;
   struct _VectorArgs { flatbuffers::FlatBufferBuilder *__fbb; const GpuFunctionT* __o; const flatbuffers::rehasher_function_t *__rehasher; } _va = { &_fbb, _o, _rehasher}; (void)_va;
-  auto _stags = _o->stags.size() ? _fbb.CreateVector<flatbuffers::Offset<GpuStage>> (_o->stags.size(), [](size_t i, _VectorArgs *__va) { return CreateGpuStage(*__va->__fbb, __va->__o->stags[i].get(), __va->__rehasher); }, &_va ) : 0;
+  auto _stags = _o->stags.size() ? _fbb.CreateVector<flatbuffers::Offset<MNN::GpuStage>> (_o->stags.size(), [](size_t i, _VectorArgs *__va) { return CreateGpuStage(*__va->__fbb, __va->__o->stags[i].get(), __va->__rehasher); }, &_va ) : 0;
   auto _name = _o->name.empty() ? 0 : _fbb.CreateString(_o->name);
   return MNN::CreateGpuFunction(
       _fbb,
@@ -842,17 +839,17 @@ inline flatbuffers::Offset<GpuFunction> CreateGpuFunction(flatbuffers::FlatBuffe
 }
 
 inline GpuLibraryT *GpuLibrary::UnPack(const flatbuffers::resolver_function_t *_resolver) const {
-  auto _o = new GpuLibraryT();
-  UnPackTo(_o, _resolver);
-  return _o;
+  auto _o = std::unique_ptr<GpuLibraryT>(new GpuLibraryT());
+  UnPackTo(_o.get(), _resolver);
+  return _o.release();
 }
 
 inline void GpuLibrary::UnPackTo(GpuLibraryT *_o, const flatbuffers::resolver_function_t *_resolver) const {
   (void)_o;
   (void)_resolver;
-  { auto _e = functions(); if (_e) { _o->functions.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->functions[_i] = std::unique_ptr<GpuFunctionT>(_e->Get(_i)->UnPack(_resolver)); } } };
-  { auto _e = pipeline(); if (_e) { _o->pipeline.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->pipeline[_i] = std::unique_ptr<GpuPipelineT>(_e->Get(_i)->UnPack(_resolver)); } } };
-  { auto _e = name(); if (_e) _o->name = _e->str(); };
+  { auto _e = functions(); if (_e) { _o->functions.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->functions[_i] = std::unique_ptr<MNN::GpuFunctionT>(_e->Get(_i)->UnPack(_resolver)); } } }
+  { auto _e = pipeline(); if (_e) { _o->pipeline.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->pipeline[_i] = std::unique_ptr<MNN::GpuPipelineT>(_e->Get(_i)->UnPack(_resolver)); } } }
+  { auto _e = name(); if (_e) _o->name = _e->str(); }
 }
 
 inline flatbuffers::Offset<GpuLibrary> GpuLibrary::Pack(flatbuffers::FlatBufferBuilder &_fbb, const GpuLibraryT* _o, const flatbuffers::rehasher_function_t *_rehasher) {
@@ -863,8 +860,8 @@ inline flatbuffers::Offset<GpuLibrary> CreateGpuLibrary(flatbuffers::FlatBufferB
   (void)_rehasher;
   (void)_o;
   struct _VectorArgs { flatbuffers::FlatBufferBuilder *__fbb; const GpuLibraryT* __o; const flatbuffers::rehasher_function_t *__rehasher; } _va = { &_fbb, _o, _rehasher}; (void)_va;
-  auto _functions = _o->functions.size() ? _fbb.CreateVector<flatbuffers::Offset<GpuFunction>> (_o->functions.size(), [](size_t i, _VectorArgs *__va) { return CreateGpuFunction(*__va->__fbb, __va->__o->functions[i].get(), __va->__rehasher); }, &_va ) : 0;
-  auto _pipeline = _o->pipeline.size() ? _fbb.CreateVector<flatbuffers::Offset<GpuPipeline>> (_o->pipeline.size(), [](size_t i, _VectorArgs *__va) { return CreateGpuPipeline(*__va->__fbb, __va->__o->pipeline[i].get(), __va->__rehasher); }, &_va ) : 0;
+  auto _functions = _o->functions.size() ? _fbb.CreateVector<flatbuffers::Offset<MNN::GpuFunction>> (_o->functions.size(), [](size_t i, _VectorArgs *__va) { return CreateGpuFunction(*__va->__fbb, __va->__o->functions[i].get(), __va->__rehasher); }, &_va ) : 0;
+  auto _pipeline = _o->pipeline.size() ? _fbb.CreateVector<flatbuffers::Offset<MNN::GpuPipeline>> (_o->pipeline.size(), [](size_t i, _VectorArgs *__va) { return CreateGpuPipeline(*__va->__fbb, __va->__o->pipeline[i].get(), __va->__rehasher); }, &_va ) : 0;
   auto _name = _o->name.empty() ? 0 : _fbb.CreateString(_o->name);
   return MNN::CreateGpuLibrary(
       _fbb,
@@ -880,7 +877,7 @@ inline const flatbuffers::TypeTable *STORAGE_TYPETypeTable() {
     { flatbuffers::ET_CHAR, 0, 0 }
   };
   static const flatbuffers::TypeFunction type_refs[] = {
-    STORAGE_TYPETypeTable
+    MNN::STORAGE_TYPETypeTable
   };
   static const char * const names[] = {
     "BUFFER",
@@ -888,7 +885,7 @@ inline const flatbuffers::TypeTable *STORAGE_TYPETypeTable() {
     "IMAGE"
   };
   static const flatbuffers::TypeTable tt = {
-    flatbuffers::ST_ENUM, 3, type_codes, type_refs, nullptr, names
+    flatbuffers::ST_ENUM, 3, type_codes, type_refs, nullptr, nullptr, names
   };
   return &tt;
 }
@@ -900,7 +897,7 @@ inline const flatbuffers::TypeTable *ACCESS_TYPETypeTable() {
     { flatbuffers::ET_CHAR, 0, 0 }
   };
   static const flatbuffers::TypeFunction type_refs[] = {
-    ACCESS_TYPETypeTable
+    MNN::ACCESS_TYPETypeTable
   };
   static const char * const names[] = {
     "READ_ONLY",
@@ -908,7 +905,7 @@ inline const flatbuffers::TypeTable *ACCESS_TYPETypeTable() {
     "READ_WRITE"
   };
   static const flatbuffers::TypeTable tt = {
-    flatbuffers::ST_ENUM, 3, type_codes, type_refs, nullptr, names
+    flatbuffers::ST_ENUM, 3, type_codes, type_refs, nullptr, nullptr, names
   };
   return &tt;
 }
@@ -920,9 +917,9 @@ inline const flatbuffers::TypeTable *GpuBufferTypeTable() {
     { flatbuffers::ET_SEQUENCE, 0, 2 }
   };
   static const flatbuffers::TypeFunction type_refs[] = {
-    ACCESS_TYPETypeTable,
-    STORAGE_TYPETypeTable,
-    BlobTypeTable
+    MNN::ACCESS_TYPETypeTable,
+    MNN::STORAGE_TYPETypeTable,
+    MNN::BlobTypeTable
   };
   static const char * const names[] = {
     "access",
@@ -930,7 +927,7 @@ inline const flatbuffers::TypeTable *GpuBufferTypeTable() {
     "content"
   };
   static const flatbuffers::TypeTable tt = {
-    flatbuffers::ST_TABLE, 3, type_codes, type_refs, nullptr, names
+    flatbuffers::ST_TABLE, 3, type_codes, type_refs, nullptr, nullptr, names
   };
   return &tt;
 }
@@ -953,7 +950,7 @@ inline const flatbuffers::TypeTable *GpuPipelineTypeTable() {
     "openclKernel"
   };
   static const flatbuffers::TypeTable tt = {
-    flatbuffers::ST_TABLE, 6, type_codes, nullptr, nullptr, names
+    flatbuffers::ST_TABLE, 6, type_codes, nullptr, nullptr, nullptr, names
   };
   return &tt;
 }
@@ -971,7 +968,7 @@ inline const flatbuffers::TypeTable *GpuStageTypeTable() {
     { flatbuffers::ET_BOOL, 0, -1 }
   };
   static const flatbuffers::TypeFunction type_refs[] = {
-    GpuBufferTypeTable
+    MNN::GpuBufferTypeTable
   };
   static const char * const names[] = {
     "pipeline",
@@ -985,7 +982,7 @@ inline const flatbuffers::TypeTable *GpuStageTypeTable() {
     "requireSize"
   };
   static const flatbuffers::TypeTable tt = {
-    flatbuffers::ST_TABLE, 9, type_codes, type_refs, nullptr, names
+    flatbuffers::ST_TABLE, 9, type_codes, type_refs, nullptr, nullptr, names
   };
   return &tt;
 }
@@ -996,14 +993,14 @@ inline const flatbuffers::TypeTable *GpuFunctionTypeTable() {
     { flatbuffers::ET_STRING, 0, -1 }
   };
   static const flatbuffers::TypeFunction type_refs[] = {
-    GpuStageTypeTable
+    MNN::GpuStageTypeTable
   };
   static const char * const names[] = {
     "stags",
     "name"
   };
   static const flatbuffers::TypeTable tt = {
-    flatbuffers::ST_TABLE, 2, type_codes, type_refs, nullptr, names
+    flatbuffers::ST_TABLE, 2, type_codes, type_refs, nullptr, nullptr, names
   };
   return &tt;
 }
@@ -1015,8 +1012,8 @@ inline const flatbuffers::TypeTable *GpuLibraryTypeTable() {
     { flatbuffers::ET_STRING, 0, -1 }
   };
   static const flatbuffers::TypeFunction type_refs[] = {
-    GpuFunctionTypeTable,
-    GpuPipelineTypeTable
+    MNN::GpuFunctionTypeTable,
+    MNN::GpuPipelineTypeTable
   };
   static const char * const names[] = {
     "functions",
@@ -1024,7 +1021,7 @@ inline const flatbuffers::TypeTable *GpuLibraryTypeTable() {
     "name"
   };
   static const flatbuffers::TypeTable tt = {
-    flatbuffers::ST_TABLE, 3, type_codes, type_refs, nullptr, names
+    flatbuffers::ST_TABLE, 3, type_codes, type_refs, nullptr, nullptr, names
   };
   return &tt;
 }
diff --git a/schema/current/MNN_generated.h b/schema/current/MNN_generated.h
index 63a1d207..d5552b87 100644
--- a/schema/current/MNN_generated.h
+++ b/schema/current/MNN_generated.h
@@ -4,48 +4,60 @@
 #ifndef FLATBUFFERS_GENERATED_MNN_MNN_H_
 #define FLATBUFFERS_GENERATED_MNN_MNN_H_
 
+#include "flatbuffers/flatbuffers.h"
 
-#include "CaffeOp_generated.h"
-#include "GpuLibrary_generated.h"
 #include "TFQuantizeOp_generated.h"
-#include "Tensor_generated.h"
-#include "TensorflowOp_generated.h"
 #include "Type_generated.h"
 #include "UserDefine_generated.h"
+#include "CaffeOp_generated.h"
+#include "GpuLibrary_generated.h"
+#include "TensorflowOp_generated.h"
+#include "Tensor_generated.h"
 
 namespace MNN {
 
 struct Plugin;
+struct PluginBuilder;
 struct PluginT;
 
 struct Extra;
+struct ExtraBuilder;
 struct ExtraT;
 
 struct StringVec;
+struct StringVecBuilder;
 struct StringVecT;
 
 struct WhileParam;
+struct WhileParamBuilder;
 struct WhileParamT;
 
 struct IfParam;
+struct IfParamBuilder;
 struct IfParamT;
 
 struct Op;
+struct OpBuilder;
 struct OpT;
 
 struct View;
+struct ViewBuilder;
 struct ViewT;
 
 struct Region;
+struct RegionBuilder;
 struct RegionT;
 
 struct TensorDescribe;
+struct TensorDescribeBuilder;
 struct TensorDescribeT;
 
 struct SubGraphProto;
+struct SubGraphProtoBuilder;
 struct SubGraphProtoT;
 
 struct Net;
+struct NetBuilder;
 struct NetT;
 
 inline const flatbuffers::TypeTable *PluginTypeTable();
@@ -70,7 +82,7 @@ inline const flatbuffers::TypeTable *SubGraphProtoTypeTable();
 
 inline const flatbuffers::TypeTable *NetTypeTable();
 
-enum OpType {
+enum OpType : int32_t {
   OpType_AbsVal = 0,
   OpType_QuantizedAdd = 1,
   OpType_ArgMax = 2,
@@ -382,7 +394,7 @@ inline const OpType (&EnumValuesOpType())[150] {
 }
 
 inline const char * const *EnumNamesOpType() {
-  static const char * const names[] = {
+  static const char * const names[605] = {
     "AbsVal",
     "QuantizedAdd",
     "ArgMax",
@@ -993,12 +1005,12 @@ inline const char * const *EnumNamesOpType() {
 }
 
 inline const char *EnumNameOpType(OpType e) {
-  if (e < OpType_AbsVal || e > OpType_LayerNorm) return "";
-  const size_t index = static_cast<int>(e);
+  if (flatbuffers::IsOutRange(e, OpType_AbsVal, OpType_LayerNorm)) return "";
+  const size_t index = static_cast<size_t>(e);
   return EnumNamesOpType()[index];
 }
 
-enum OpParameter {
+enum OpParameter : uint8_t {
   OpParameter_NONE = 0,
   OpParameter_QuantizedAdd = 1,
   OpParameter_ArgMax = 2,
@@ -1188,7 +1200,7 @@ inline const OpParameter (&EnumValuesOpParameter())[89] {
 }
 
 inline const char * const *EnumNamesOpParameter() {
-  static const char * const names[] = {
+  static const char * const names[90] = {
     "NONE",
     "QuantizedAdd",
     "ArgMax",
@@ -1284,8 +1296,8 @@ inline const char * const *EnumNamesOpParameter() {
 }
 
 inline const char *EnumNameOpParameter(OpParameter e) {
-  if (e < OpParameter_NONE || e > OpParameter_LayerNorm) return "";
-  const size_t index = static_cast<int>(e);
+  if (flatbuffers::IsOutRange(e, OpParameter_NONE, OpParameter_LayerNorm)) return "";
+  const size_t index = static_cast<size_t>(e);
   return EnumNamesOpParameter()[index];
 }
 
@@ -1293,355 +1305,355 @@ template<typename T> struct OpParameterTraits {
   static const OpParameter enum_value = OpParameter_NONE;
 };
 
-template<> struct OpParameterTraits<QuantizedAdd> {
+template<> struct OpParameterTraits<MNN::QuantizedAdd> {
   static const OpParameter enum_value = OpParameter_QuantizedAdd;
 };
 
-template<> struct OpParameterTraits<ArgMax> {
+template<> struct OpParameterTraits<MNN::ArgMax> {
   static const OpParameter enum_value = OpParameter_ArgMax;
 };
 
-template<> struct OpParameterTraits<AsString> {
+template<> struct OpParameterTraits<MNN::AsString> {
   static const OpParameter enum_value = OpParameter_AsString;
 };
 
-template<> struct OpParameterTraits<Axis> {
+template<> struct OpParameterTraits<MNN::Axis> {
   static const OpParameter enum_value = OpParameter_Axis;
 };
 
-template<> struct OpParameterTraits<BatchNorm> {
+template<> struct OpParameterTraits<MNN::BatchNorm> {
   static const OpParameter enum_value = OpParameter_BatchNorm;
 };
 
-template<> struct OpParameterTraits<BinaryOp> {
+template<> struct OpParameterTraits<MNN::BinaryOp> {
   static const OpParameter enum_value = OpParameter_BinaryOp;
 };
 
-template<> struct OpParameterTraits<Blob> {
+template<> struct OpParameterTraits<MNN::Blob> {
   static const OpParameter enum_value = OpParameter_Blob;
 };
 
-template<> struct OpParameterTraits<CastParam> {
+template<> struct OpParameterTraits<MNN::CastParam> {
   static const OpParameter enum_value = OpParameter_CastParam;
 };
 
-template<> struct OpParameterTraits<Convolution2D> {
+template<> struct OpParameterTraits<MNN::Convolution2D> {
   static const OpParameter enum_value = OpParameter_Convolution2D;
 };
 
-template<> struct OpParameterTraits<Crop> {
+template<> struct OpParameterTraits<MNN::Crop> {
   static const OpParameter enum_value = OpParameter_Crop;
 };
 
-template<> struct OpParameterTraits<CropAndResize> {
+template<> struct OpParameterTraits<MNN::CropAndResize> {
   static const OpParameter enum_value = OpParameter_CropAndResize;
 };
 
-template<> struct OpParameterTraits<Dequantize> {
+template<> struct OpParameterTraits<MNN::Dequantize> {
   static const OpParameter enum_value = OpParameter_Dequantize;
 };
 
-template<> struct OpParameterTraits<DetectionOutput> {
+template<> struct OpParameterTraits<MNN::DetectionOutput> {
   static const OpParameter enum_value = OpParameter_DetectionOutput;
 };
 
-template<> struct OpParameterTraits<Eltwise> {
+template<> struct OpParameterTraits<MNN::Eltwise> {
   static const OpParameter enum_value = OpParameter_Eltwise;
 };
 
-template<> struct OpParameterTraits<ExpandDims> {
+template<> struct OpParameterTraits<MNN::ExpandDims> {
   static const OpParameter enum_value = OpParameter_ExpandDims;
 };
 
-template<> struct OpParameterTraits<Fill> {
+template<> struct OpParameterTraits<MNN::Fill> {
   static const OpParameter enum_value = OpParameter_Fill;
 };
 
-template<> struct OpParameterTraits<Flatten> {
+template<> struct OpParameterTraits<MNN::Flatten> {
   static const OpParameter enum_value = OpParameter_Flatten;
 };
 
-template<> struct OpParameterTraits<Gather> {
+template<> struct OpParameterTraits<MNN::Gather> {
   static const OpParameter enum_value = OpParameter_Gather;
 };
 
-template<> struct OpParameterTraits<GatherV2> {
+template<> struct OpParameterTraits<MNN::GatherV2> {
   static const OpParameter enum_value = OpParameter_GatherV2;
 };
 
-template<> struct OpParameterTraits<InnerProduct> {
+template<> struct OpParameterTraits<MNN::InnerProduct> {
   static const OpParameter enum_value = OpParameter_InnerProduct;
 };
 
-template<> struct OpParameterTraits<Input> {
+template<> struct OpParameterTraits<MNN::Input> {
   static const OpParameter enum_value = OpParameter_Input;
 };
 
-template<> struct OpParameterTraits<Interp> {
+template<> struct OpParameterTraits<MNN::Interp> {
   static const OpParameter enum_value = OpParameter_Interp;
 };
 
-template<> struct OpParameterTraits<LRN> {
+template<> struct OpParameterTraits<MNN::LRN> {
   static const OpParameter enum_value = OpParameter_LRN;
 };
 
-template<> struct OpParameterTraits<LSTM> {
+template<> struct OpParameterTraits<MNN::LSTM> {
   static const OpParameter enum_value = OpParameter_LSTM;
 };
 
-template<> struct OpParameterTraits<MatMul> {
+template<> struct OpParameterTraits<MNN::MatMul> {
   static const OpParameter enum_value = OpParameter_MatMul;
 };
 
-template<> struct OpParameterTraits<NonMaxSuppressionV2> {
+template<> struct OpParameterTraits<MNN::NonMaxSuppressionV2> {
   static const OpParameter enum_value = OpParameter_NonMaxSuppressionV2;
 };
 
-template<> struct OpParameterTraits<Normalize> {
+template<> struct OpParameterTraits<MNN::Normalize> {
   static const OpParameter enum_value = OpParameter_Normalize;
 };
 
-template<> struct OpParameterTraits<PackParam> {
+template<> struct OpParameterTraits<MNN::PackParam> {
   static const OpParameter enum_value = OpParameter_PackParam;
 };
 
-template<> struct OpParameterTraits<Permute> {
+template<> struct OpParameterTraits<MNN::Permute> {
   static const OpParameter enum_value = OpParameter_Permute;
 };
 
-template<> struct OpParameterTraits<Plugin> {
+template<> struct OpParameterTraits<MNN::Plugin> {
   static const OpParameter enum_value = OpParameter_Plugin;
 };
 
-template<> struct OpParameterTraits<Pool> {
+template<> struct OpParameterTraits<MNN::Pool> {
   static const OpParameter enum_value = OpParameter_Pool;
 };
 
-template<> struct OpParameterTraits<PRelu> {
+template<> struct OpParameterTraits<MNN::PRelu> {
   static const OpParameter enum_value = OpParameter_PRelu;
 };
 
-template<> struct OpParameterTraits<PriorBox> {
+template<> struct OpParameterTraits<MNN::PriorBox> {
   static const OpParameter enum_value = OpParameter_PriorBox;
 };
 
-template<> struct OpParameterTraits<Proposal> {
+template<> struct OpParameterTraits<MNN::Proposal> {
   static const OpParameter enum_value = OpParameter_Proposal;
 };
 
-template<> struct OpParameterTraits<QuantizedAvgPool> {
+template<> struct OpParameterTraits<MNN::QuantizedAvgPool> {
   static const OpParameter enum_value = OpParameter_QuantizedAvgPool;
 };
 
-template<> struct OpParameterTraits<QuantizedBiasAdd> {
+template<> struct OpParameterTraits<MNN::QuantizedBiasAdd> {
   static const OpParameter enum_value = OpParameter_QuantizedBiasAdd;
 };
 
-template<> struct OpParameterTraits<QuantizedConcat> {
+template<> struct OpParameterTraits<MNN::QuantizedConcat> {
   static const OpParameter enum_value = OpParameter_QuantizedConcat;
 };
 
-template<> struct OpParameterTraits<QuantizedLogistic> {
+template<> struct OpParameterTraits<MNN::QuantizedLogistic> {
   static const OpParameter enum_value = OpParameter_QuantizedLogistic;
 };
 
-template<> struct OpParameterTraits<QuantizedMatMul> {
+template<> struct OpParameterTraits<MNN::QuantizedMatMul> {
   static const OpParameter enum_value = OpParameter_QuantizedMatMul;
 };
 
-template<> struct OpParameterTraits<QuantizedMaxPool> {
+template<> struct OpParameterTraits<MNN::QuantizedMaxPool> {
   static const OpParameter enum_value = OpParameter_QuantizedMaxPool;
 };
 
-template<> struct OpParameterTraits<QuantizedRelu> {
+template<> struct OpParameterTraits<MNN::QuantizedRelu> {
   static const OpParameter enum_value = OpParameter_QuantizedRelu;
 };
 
-template<> struct OpParameterTraits<QuantizedRelu6> {
+template<> struct OpParameterTraits<MNN::QuantizedRelu6> {
   static const OpParameter enum_value = OpParameter_QuantizedRelu6;
 };
 
-template<> struct OpParameterTraits<QuantizedReshape> {
+template<> struct OpParameterTraits<MNN::QuantizedReshape> {
   static const OpParameter enum_value = OpParameter_QuantizedReshape;
 };
 
-template<> struct OpParameterTraits<QuantizedSoftmax> {
+template<> struct OpParameterTraits<MNN::QuantizedSoftmax> {
   static const OpParameter enum_value = OpParameter_QuantizedSoftmax;
 };
 
-template<> struct OpParameterTraits<QuantizeMaxMin> {
+template<> struct OpParameterTraits<MNN::QuantizeMaxMin> {
   static const OpParameter enum_value = OpParameter_QuantizeMaxMin;
 };
 
-template<> struct OpParameterTraits<QuantizeV2> {
+template<> struct OpParameterTraits<MNN::QuantizeV2> {
   static const OpParameter enum_value = OpParameter_QuantizeV2;
 };
 
-template<> struct OpParameterTraits<Range> {
+template<> struct OpParameterTraits<MNN::Range> {
   static const OpParameter enum_value = OpParameter_Range;
 };
 
-template<> struct OpParameterTraits<Rank> {
+template<> struct OpParameterTraits<MNN::Rank> {
   static const OpParameter enum_value = OpParameter_Rank;
 };
 
-template<> struct OpParameterTraits<ReduceJoin> {
+template<> struct OpParameterTraits<MNN::ReduceJoin> {
   static const OpParameter enum_value = OpParameter_ReduceJoin;
 };
 
-template<> struct OpParameterTraits<ReductionParam> {
+template<> struct OpParameterTraits<MNN::ReductionParam> {
   static const OpParameter enum_value = OpParameter_ReductionParam;
 };
 
-template<> struct OpParameterTraits<Relu> {
+template<> struct OpParameterTraits<MNN::Relu> {
   static const OpParameter enum_value = OpParameter_Relu;
 };
 
-template<> struct OpParameterTraits<Relu6> {
+template<> struct OpParameterTraits<MNN::Relu6> {
   static const OpParameter enum_value = OpParameter_Relu6;
 };
 
-template<> struct OpParameterTraits<RequantizationRange> {
+template<> struct OpParameterTraits<MNN::RequantizationRange> {
   static const OpParameter enum_value = OpParameter_RequantizationRange;
 };
 
-template<> struct OpParameterTraits<Requantize> {
+template<> struct OpParameterTraits<MNN::Requantize> {
   static const OpParameter enum_value = OpParameter_Requantize;
 };
 
-template<> struct OpParameterTraits<Reshape> {
+template<> struct OpParameterTraits<MNN::Reshape> {
   static const OpParameter enum_value = OpParameter_Reshape;
 };
 
-template<> struct OpParameterTraits<Resize> {
+template<> struct OpParameterTraits<MNN::Resize> {
   static const OpParameter enum_value = OpParameter_Resize;
 };
 
-template<> struct OpParameterTraits<RoiPooling> {
+template<> struct OpParameterTraits<MNN::RoiPooling> {
   static const OpParameter enum_value = OpParameter_RoiPooling;
 };
 
-template<> struct OpParameterTraits<Scale> {
+template<> struct OpParameterTraits<MNN::Scale> {
   static const OpParameter enum_value = OpParameter_Scale;
 };
 
-template<> struct OpParameterTraits<Selu> {
+template<> struct OpParameterTraits<MNN::Selu> {
   static const OpParameter enum_value = OpParameter_Selu;
 };
 
-template<> struct OpParameterTraits<Size> {
+template<> struct OpParameterTraits<MNN::Size> {
   static const OpParameter enum_value = OpParameter_Size;
 };
 
-template<> struct OpParameterTraits<Slice> {
+template<> struct OpParameterTraits<MNN::Slice> {
   static const OpParameter enum_value = OpParameter_Slice;
 };
 
-template<> struct OpParameterTraits<SliceTf> {
+template<> struct OpParameterTraits<MNN::SliceTf> {
   static const OpParameter enum_value = OpParameter_SliceTf;
 };
 
-template<> struct OpParameterTraits<SpaceBatch> {
+template<> struct OpParameterTraits<MNN::SpaceBatch> {
   static const OpParameter enum_value = OpParameter_SpaceBatch;
 };
 
-template<> struct OpParameterTraits<SqueezeParam> {
+template<> struct OpParameterTraits<MNN::SqueezeParam> {
   static const OpParameter enum_value = OpParameter_SqueezeParam;
 };
 
-template<> struct OpParameterTraits<StridedSliceParam> {
+template<> struct OpParameterTraits<MNN::StridedSliceParam> {
   static const OpParameter enum_value = OpParameter_StridedSliceParam;
 };
 
-template<> struct OpParameterTraits<TensorConvertInfo> {
+template<> struct OpParameterTraits<MNN::TensorConvertInfo> {
   static const OpParameter enum_value = OpParameter_TensorConvertInfo;
 };
 
-template<> struct OpParameterTraits<TfQuantizedConv2D> {
+template<> struct OpParameterTraits<MNN::TfQuantizedConv2D> {
   static const OpParameter enum_value = OpParameter_TfQuantizedConv2D;
 };
 
-template<> struct OpParameterTraits<TopKV2> {
+template<> struct OpParameterTraits<MNN::TopKV2> {
   static const OpParameter enum_value = OpParameter_TopKV2;
 };
 
-template<> struct OpParameterTraits<Transpose> {
+template<> struct OpParameterTraits<MNN::Transpose> {
   static const OpParameter enum_value = OpParameter_Transpose;
 };
 
-template<> struct OpParameterTraits<UnaryOp> {
+template<> struct OpParameterTraits<MNN::UnaryOp> {
   static const OpParameter enum_value = OpParameter_UnaryOp;
 };
 
-template<> struct OpParameterTraits<MomentsParam> {
+template<> struct OpParameterTraits<MNN::MomentsParam> {
   static const OpParameter enum_value = OpParameter_MomentsParam;
 };
 
-template<> struct OpParameterTraits<RNNParam> {
+template<> struct OpParameterTraits<MNN::RNNParam> {
   static const OpParameter enum_value = OpParameter_RNNParam;
 };
 
-template<> struct OpParameterTraits<BatchMatMulParam> {
+template<> struct OpParameterTraits<MNN::BatchMatMulParam> {
   static const OpParameter enum_value = OpParameter_BatchMatMulParam;
 };
 
-template<> struct OpParameterTraits<QuantizedFloatParam> {
+template<> struct OpParameterTraits<MNN::QuantizedFloatParam> {
   static const OpParameter enum_value = OpParameter_QuantizedFloatParam;
 };
 
-template<> struct OpParameterTraits<DepthSpaceParam> {
+template<> struct OpParameterTraits<MNN::DepthSpaceParam> {
   static const OpParameter enum_value = OpParameter_DepthSpaceParam;
 };
 
-template<> struct OpParameterTraits<EltwiseInt8> {
+template<> struct OpParameterTraits<MNN::EltwiseInt8> {
   static const OpParameter enum_value = OpParameter_EltwiseInt8;
 };
 
-template<> struct OpParameterTraits<ReverseSequenceParam> {
+template<> struct OpParameterTraits<MNN::ReverseSequenceParam> {
   static const OpParameter enum_value = OpParameter_ReverseSequenceParam;
 };
 
-template<> struct OpParameterTraits<Extra> {
+template<> struct OpParameterTraits<MNN::Extra> {
   static const OpParameter enum_value = OpParameter_Extra;
 };
 
-template<> struct OpParameterTraits<Pool3D> {
+template<> struct OpParameterTraits<MNN::Pool3D> {
   static const OpParameter enum_value = OpParameter_Pool3D;
 };
 
-template<> struct OpParameterTraits<Convolution3D> {
+template<> struct OpParameterTraits<MNN::Convolution3D> {
   static const OpParameter enum_value = OpParameter_Convolution3D;
 };
 
-template<> struct OpParameterTraits<ELU> {
+template<> struct OpParameterTraits<MNN::ELU> {
   static const OpParameter enum_value = OpParameter_ELU;
 };
 
-template<> struct OpParameterTraits<DetectionPostProcessParam> {
+template<> struct OpParameterTraits<MNN::DetectionPostProcessParam> {
   static const OpParameter enum_value = OpParameter_DetectionPostProcessParam;
 };
 
-template<> struct OpParameterTraits<OneHotParam> {
+template<> struct OpParameterTraits<MNN::OneHotParam> {
   static const OpParameter enum_value = OpParameter_OneHotParam;
 };
 
-template<> struct OpParameterTraits<PadParam> {
+template<> struct OpParameterTraits<MNN::PadParam> {
   static const OpParameter enum_value = OpParameter_PadParam;
 };
 
-template<> struct OpParameterTraits<WhileParam> {
+template<> struct OpParameterTraits<MNN::WhileParam> {
   static const OpParameter enum_value = OpParameter_WhileParam;
 };
 
-template<> struct OpParameterTraits<IfParam> {
+template<> struct OpParameterTraits<MNN::IfParam> {
   static const OpParameter enum_value = OpParameter_IfParam;
 };
 
-template<> struct OpParameterTraits<RandomUniform> {
+template<> struct OpParameterTraits<MNN::RandomUniform> {
   static const OpParameter enum_value = OpParameter_RandomUniform;
 };
 
-template<> struct OpParameterTraits<LayerNorm> {
+template<> struct OpParameterTraits<MNN::LayerNorm> {
   static const OpParameter enum_value = OpParameter_LayerNorm;
 };
 
@@ -1653,8 +1665,8 @@ struct OpParameterUnion {
   OpParameterUnion(OpParameterUnion&& u) FLATBUFFERS_NOEXCEPT :
     type(OpParameter_NONE), value(nullptr)
     { std::swap(type, u.type); std::swap(value, u.value); }
-  OpParameterUnion(const OpParameterUnion &) FLATBUFFERS_NOEXCEPT;
-  OpParameterUnion &operator=(const OpParameterUnion &u) FLATBUFFERS_NOEXCEPT
+  OpParameterUnion(const OpParameterUnion &);
+  OpParameterUnion &operator=(const OpParameterUnion &u)
     { OpParameterUnion t(u); std::swap(type, t.type); std::swap(value, t.value); return *this; }
   OpParameterUnion &operator=(OpParameterUnion &&u) FLATBUFFERS_NOEXCEPT
     { std::swap(type, u.type); std::swap(value, u.value); return *this; }
@@ -1665,10 +1677,11 @@ struct OpParameterUnion {
 #ifndef FLATBUFFERS_CPP98_STL
   template <typename T>
   void Set(T&& val) {
+    using RT = typename std::remove_reference<T>::type;
     Reset();
-    type = OpParameterTraits<typename T::TableType>::enum_value;
+    type = OpParameterTraits<typename RT::TableType>::enum_value;
     if (type != OpParameter_NONE) {
-      value = new T(std::forward<T>(val));
+      value = new RT(std::forward<T>(val));
     }
   }
 #endif  // FLATBUFFERS_CPP98_STL
@@ -1676,716 +1689,716 @@ struct OpParameterUnion {
   static void *UnPack(const void *obj, OpParameter type, const flatbuffers::resolver_function_t *resolver);
   flatbuffers::Offset<void> Pack(flatbuffers::FlatBufferBuilder &_fbb, const flatbuffers::rehasher_function_t *_rehasher = nullptr) const;
 
-  QuantizedAddT *AsQuantizedAdd() {
+  MNN::QuantizedAddT *AsQuantizedAdd() {
     return type == OpParameter_QuantizedAdd ?
-      reinterpret_cast<QuantizedAddT *>(value) : nullptr;
+      reinterpret_cast<MNN::QuantizedAddT *>(value) : nullptr;
   }
-  const QuantizedAddT *AsQuantizedAdd() const {
+  const MNN::QuantizedAddT *AsQuantizedAdd() const {
     return type == OpParameter_QuantizedAdd ?
-      reinterpret_cast<const QuantizedAddT *>(value) : nullptr;
+      reinterpret_cast<const MNN::QuantizedAddT *>(value) : nullptr;
   }
-  ArgMaxT *AsArgMax() {
+  MNN::ArgMaxT *AsArgMax() {
     return type == OpParameter_ArgMax ?
-      reinterpret_cast<ArgMaxT *>(value) : nullptr;
+      reinterpret_cast<MNN::ArgMaxT *>(value) : nullptr;
   }
-  const ArgMaxT *AsArgMax() const {
+  const MNN::ArgMaxT *AsArgMax() const {
     return type == OpParameter_ArgMax ?
-      reinterpret_cast<const ArgMaxT *>(value) : nullptr;
+      reinterpret_cast<const MNN::ArgMaxT *>(value) : nullptr;
   }
-  AsStringT *AsAsString() {
+  MNN::AsStringT *AsAsString() {
     return type == OpParameter_AsString ?
-      reinterpret_cast<AsStringT *>(value) : nullptr;
+      reinterpret_cast<MNN::AsStringT *>(value) : nullptr;
   }
-  const AsStringT *AsAsString() const {
+  const MNN::AsStringT *AsAsString() const {
     return type == OpParameter_AsString ?
-      reinterpret_cast<const AsStringT *>(value) : nullptr;
+      reinterpret_cast<const MNN::AsStringT *>(value) : nullptr;
   }
-  AxisT *AsAxis() {
+  MNN::AxisT *AsAxis() {
     return type == OpParameter_Axis ?
-      reinterpret_cast<AxisT *>(value) : nullptr;
+      reinterpret_cast<MNN::AxisT *>(value) : nullptr;
   }
-  const AxisT *AsAxis() const {
+  const MNN::AxisT *AsAxis() const {
     return type == OpParameter_Axis ?
-      reinterpret_cast<const AxisT *>(value) : nullptr;
+      reinterpret_cast<const MNN::AxisT *>(value) : nullptr;
   }
-  BatchNormT *AsBatchNorm() {
+  MNN::BatchNormT *AsBatchNorm() {
     return type == OpParameter_BatchNorm ?
-      reinterpret_cast<BatchNormT *>(value) : nullptr;
+      reinterpret_cast<MNN::BatchNormT *>(value) : nullptr;
   }
-  const BatchNormT *AsBatchNorm() const {
+  const MNN::BatchNormT *AsBatchNorm() const {
     return type == OpParameter_BatchNorm ?
-      reinterpret_cast<const BatchNormT *>(value) : nullptr;
+      reinterpret_cast<const MNN::BatchNormT *>(value) : nullptr;
   }
-  BinaryOpT *AsBinaryOp() {
+  MNN::BinaryOpT *AsBinaryOp() {
     return type == OpParameter_BinaryOp ?
-      reinterpret_cast<BinaryOpT *>(value) : nullptr;
+      reinterpret_cast<MNN::BinaryOpT *>(value) : nullptr;
   }
-  const BinaryOpT *AsBinaryOp() const {
+  const MNN::BinaryOpT *AsBinaryOp() const {
     return type == OpParameter_BinaryOp ?
-      reinterpret_cast<const BinaryOpT *>(value) : nullptr;
+      reinterpret_cast<const MNN::BinaryOpT *>(value) : nullptr;
   }
-  BlobT *AsBlob() {
+  MNN::BlobT *AsBlob() {
     return type == OpParameter_Blob ?
-      reinterpret_cast<BlobT *>(value) : nullptr;
+      reinterpret_cast<MNN::BlobT *>(value) : nullptr;
   }
-  const BlobT *AsBlob() const {
+  const MNN::BlobT *AsBlob() const {
     return type == OpParameter_Blob ?
-      reinterpret_cast<const BlobT *>(value) : nullptr;
+      reinterpret_cast<const MNN::BlobT *>(value) : nullptr;
   }
-  CastParamT *AsCastParam() {
+  MNN::CastParamT *AsCastParam() {
     return type == OpParameter_CastParam ?
-      reinterpret_cast<CastParamT *>(value) : nullptr;
+      reinterpret_cast<MNN::CastParamT *>(value) : nullptr;
   }
-  const CastParamT *AsCastParam() const {
+  const MNN::CastParamT *AsCastParam() const {
     return type == OpParameter_CastParam ?
-      reinterpret_cast<const CastParamT *>(value) : nullptr;
+      reinterpret_cast<const MNN::CastParamT *>(value) : nullptr;
   }
-  Convolution2DT *AsConvolution2D() {
+  MNN::Convolution2DT *AsConvolution2D() {
     return type == OpParameter_Convolution2D ?
-      reinterpret_cast<Convolution2DT *>(value) : nullptr;
+      reinterpret_cast<MNN::Convolution2DT *>(value) : nullptr;
   }
-  const Convolution2DT *AsConvolution2D() const {
+  const MNN::Convolution2DT *AsConvolution2D() const {
     return type == OpParameter_Convolution2D ?
-      reinterpret_cast<const Convolution2DT *>(value) : nullptr;
+      reinterpret_cast<const MNN::Convolution2DT *>(value) : nullptr;
   }
-  CropT *AsCrop() {
+  MNN::CropT *AsCrop() {
     return type == OpParameter_Crop ?
-      reinterpret_cast<CropT *>(value) : nullptr;
+      reinterpret_cast<MNN::CropT *>(value) : nullptr;
   }
-  const CropT *AsCrop() const {
+  const MNN::CropT *AsCrop() const {
     return type == OpParameter_Crop ?
-      reinterpret_cast<const CropT *>(value) : nullptr;
+      reinterpret_cast<const MNN::CropT *>(value) : nullptr;
   }
-  CropAndResizeT *AsCropAndResize() {
+  MNN::CropAndResizeT *AsCropAndResize() {
     return type == OpParameter_CropAndResize ?
-      reinterpret_cast<CropAndResizeT *>(value) : nullptr;
+      reinterpret_cast<MNN::CropAndResizeT *>(value) : nullptr;
   }
-  const CropAndResizeT *AsCropAndResize() const {
+  const MNN::CropAndResizeT *AsCropAndResize() const {
     return type == OpParameter_CropAndResize ?
-      reinterpret_cast<const CropAndResizeT *>(value) : nullptr;
+      reinterpret_cast<const MNN::CropAndResizeT *>(value) : nullptr;
   }
-  DequantizeT *AsDequantize() {
+  MNN::DequantizeT *AsDequantize() {
     return type == OpParameter_Dequantize ?
-      reinterpret_cast<DequantizeT *>(value) : nullptr;
+      reinterpret_cast<MNN::DequantizeT *>(value) : nullptr;
   }
-  const DequantizeT *AsDequantize() const {
+  const MNN::DequantizeT *AsDequantize() const {
     return type == OpParameter_Dequantize ?
-      reinterpret_cast<const DequantizeT *>(value) : nullptr;
+      reinterpret_cast<const MNN::DequantizeT *>(value) : nullptr;
   }
-  DetectionOutputT *AsDetectionOutput() {
+  MNN::DetectionOutputT *AsDetectionOutput() {
     return type == OpParameter_DetectionOutput ?
-      reinterpret_cast<DetectionOutputT *>(value) : nullptr;
+      reinterpret_cast<MNN::DetectionOutputT *>(value) : nullptr;
   }
-  const DetectionOutputT *AsDetectionOutput() const {
+  const MNN::DetectionOutputT *AsDetectionOutput() const {
     return type == OpParameter_DetectionOutput ?
-      reinterpret_cast<const DetectionOutputT *>(value) : nullptr;
+      reinterpret_cast<const MNN::DetectionOutputT *>(value) : nullptr;
   }
-  EltwiseT *AsEltwise() {
+  MNN::EltwiseT *AsEltwise() {
     return type == OpParameter_Eltwise ?
-      reinterpret_cast<EltwiseT *>(value) : nullptr;
+      reinterpret_cast<MNN::EltwiseT *>(value) : nullptr;
   }
-  const EltwiseT *AsEltwise() const {
+  const MNN::EltwiseT *AsEltwise() const {
     return type == OpParameter_Eltwise ?
-      reinterpret_cast<const EltwiseT *>(value) : nullptr;
+      reinterpret_cast<const MNN::EltwiseT *>(value) : nullptr;
   }
-  ExpandDimsT *AsExpandDims() {
+  MNN::ExpandDimsT *AsExpandDims() {
     return type == OpParameter_ExpandDims ?
-      reinterpret_cast<ExpandDimsT *>(value) : nullptr;
+      reinterpret_cast<MNN::ExpandDimsT *>(value) : nullptr;
   }
-  const ExpandDimsT *AsExpandDims() const {
+  const MNN::ExpandDimsT *AsExpandDims() const {
     return type == OpParameter_ExpandDims ?
-      reinterpret_cast<const ExpandDimsT *>(value) : nullptr;
+      reinterpret_cast<const MNN::ExpandDimsT *>(value) : nullptr;
   }
-  FillT *AsFill() {
+  MNN::FillT *AsFill() {
     return type == OpParameter_Fill ?
-      reinterpret_cast<FillT *>(value) : nullptr;
+      reinterpret_cast<MNN::FillT *>(value) : nullptr;
   }
-  const FillT *AsFill() const {
+  const MNN::FillT *AsFill() const {
     return type == OpParameter_Fill ?
-      reinterpret_cast<const FillT *>(value) : nullptr;
+      reinterpret_cast<const MNN::FillT *>(value) : nullptr;
   }
-  FlattenT *AsFlatten() {
+  MNN::FlattenT *AsFlatten() {
     return type == OpParameter_Flatten ?
-      reinterpret_cast<FlattenT *>(value) : nullptr;
+      reinterpret_cast<MNN::FlattenT *>(value) : nullptr;
   }
-  const FlattenT *AsFlatten() const {
+  const MNN::FlattenT *AsFlatten() const {
     return type == OpParameter_Flatten ?
-      reinterpret_cast<const FlattenT *>(value) : nullptr;
+      reinterpret_cast<const MNN::FlattenT *>(value) : nullptr;
   }
-  GatherT *AsGather() {
+  MNN::GatherT *AsGather() {
     return type == OpParameter_Gather ?
-      reinterpret_cast<GatherT *>(value) : nullptr;
+      reinterpret_cast<MNN::GatherT *>(value) : nullptr;
   }
-  const GatherT *AsGather() const {
+  const MNN::GatherT *AsGather() const {
     return type == OpParameter_Gather ?
-      reinterpret_cast<const GatherT *>(value) : nullptr;
+      reinterpret_cast<const MNN::GatherT *>(value) : nullptr;
   }
-  GatherV2T *AsGatherV2() {
+  MNN::GatherV2T *AsGatherV2() {
     return type == OpParameter_GatherV2 ?
-      reinterpret_cast<GatherV2T *>(value) : nullptr;
+      reinterpret_cast<MNN::GatherV2T *>(value) : nullptr;
   }
-  const GatherV2T *AsGatherV2() const {
+  const MNN::GatherV2T *AsGatherV2() const {
     return type == OpParameter_GatherV2 ?
-      reinterpret_cast<const GatherV2T *>(value) : nullptr;
+      reinterpret_cast<const MNN::GatherV2T *>(value) : nullptr;
   }
-  InnerProductT *AsInnerProduct() {
+  MNN::InnerProductT *AsInnerProduct() {
     return type == OpParameter_InnerProduct ?
-      reinterpret_cast<InnerProductT *>(value) : nullptr;
+      reinterpret_cast<MNN::InnerProductT *>(value) : nullptr;
   }
-  const InnerProductT *AsInnerProduct() const {
+  const MNN::InnerProductT *AsInnerProduct() const {
     return type == OpParameter_InnerProduct ?
-      reinterpret_cast<const InnerProductT *>(value) : nullptr;
+      reinterpret_cast<const MNN::InnerProductT *>(value) : nullptr;
   }
-  InputT *AsInput() {
+  MNN::InputT *AsInput() {
     return type == OpParameter_Input ?
-      reinterpret_cast<InputT *>(value) : nullptr;
+      reinterpret_cast<MNN::InputT *>(value) : nullptr;
   }
-  const InputT *AsInput() const {
+  const MNN::InputT *AsInput() const {
     return type == OpParameter_Input ?
-      reinterpret_cast<const InputT *>(value) : nullptr;
+      reinterpret_cast<const MNN::InputT *>(value) : nullptr;
   }
-  InterpT *AsInterp() {
+  MNN::InterpT *AsInterp() {
     return type == OpParameter_Interp ?
-      reinterpret_cast<InterpT *>(value) : nullptr;
+      reinterpret_cast<MNN::InterpT *>(value) : nullptr;
   }
-  const InterpT *AsInterp() const {
+  const MNN::InterpT *AsInterp() const {
     return type == OpParameter_Interp ?
-      reinterpret_cast<const InterpT *>(value) : nullptr;
+      reinterpret_cast<const MNN::InterpT *>(value) : nullptr;
   }
-  LRNT *AsLRN() {
+  MNN::LRNT *AsLRN() {
     return type == OpParameter_LRN ?
-      reinterpret_cast<LRNT *>(value) : nullptr;
+      reinterpret_cast<MNN::LRNT *>(value) : nullptr;
   }
-  const LRNT *AsLRN() const {
+  const MNN::LRNT *AsLRN() const {
     return type == OpParameter_LRN ?
-      reinterpret_cast<const LRNT *>(value) : nullptr;
+      reinterpret_cast<const MNN::LRNT *>(value) : nullptr;
   }
-  LSTMT *AsLSTM() {
+  MNN::LSTMT *AsLSTM() {
     return type == OpParameter_LSTM ?
-      reinterpret_cast<LSTMT *>(value) : nullptr;
+      reinterpret_cast<MNN::LSTMT *>(value) : nullptr;
   }
-  const LSTMT *AsLSTM() const {
+  const MNN::LSTMT *AsLSTM() const {
     return type == OpParameter_LSTM ?
-      reinterpret_cast<const LSTMT *>(value) : nullptr;
+      reinterpret_cast<const MNN::LSTMT *>(value) : nullptr;
   }
-  MatMulT *AsMatMul() {
+  MNN::MatMulT *AsMatMul() {
     return type == OpParameter_MatMul ?
-      reinterpret_cast<MatMulT *>(value) : nullptr;
+      reinterpret_cast<MNN::MatMulT *>(value) : nullptr;
   }
-  const MatMulT *AsMatMul() const {
+  const MNN::MatMulT *AsMatMul() const {
     return type == OpParameter_MatMul ?
-      reinterpret_cast<const MatMulT *>(value) : nullptr;
+      reinterpret_cast<const MNN::MatMulT *>(value) : nullptr;
   }
-  NonMaxSuppressionV2T *AsNonMaxSuppressionV2() {
+  MNN::NonMaxSuppressionV2T *AsNonMaxSuppressionV2() {
     return type == OpParameter_NonMaxSuppressionV2 ?
-      reinterpret_cast<NonMaxSuppressionV2T *>(value) : nullptr;
+      reinterpret_cast<MNN::NonMaxSuppressionV2T *>(value) : nullptr;
   }
-  const NonMaxSuppressionV2T *AsNonMaxSuppressionV2() const {
+  const MNN::NonMaxSuppressionV2T *AsNonMaxSuppressionV2() const {
     return type == OpParameter_NonMaxSuppressionV2 ?
-      reinterpret_cast<const NonMaxSuppressionV2T *>(value) : nullptr;
+      reinterpret_cast<const MNN::NonMaxSuppressionV2T *>(value) : nullptr;
   }
-  NormalizeT *AsNormalize() {
+  MNN::NormalizeT *AsNormalize() {
     return type == OpParameter_Normalize ?
-      reinterpret_cast<NormalizeT *>(value) : nullptr;
+      reinterpret_cast<MNN::NormalizeT *>(value) : nullptr;
   }
-  const NormalizeT *AsNormalize() const {
+  const MNN::NormalizeT *AsNormalize() const {
     return type == OpParameter_Normalize ?
-      reinterpret_cast<const NormalizeT *>(value) : nullptr;
+      reinterpret_cast<const MNN::NormalizeT *>(value) : nullptr;
   }
-  PackParamT *AsPackParam() {
+  MNN::PackParamT *AsPackParam() {
     return type == OpParameter_PackParam ?
-      reinterpret_cast<PackParamT *>(value) : nullptr;
+      reinterpret_cast<MNN::PackParamT *>(value) : nullptr;
   }
-  const PackParamT *AsPackParam() const {
+  const MNN::PackParamT *AsPackParam() const {
     return type == OpParameter_PackParam ?
-      reinterpret_cast<const PackParamT *>(value) : nullptr;
+      reinterpret_cast<const MNN::PackParamT *>(value) : nullptr;
   }
-  PermuteT *AsPermute() {
+  MNN::PermuteT *AsPermute() {
     return type == OpParameter_Permute ?
-      reinterpret_cast<PermuteT *>(value) : nullptr;
+      reinterpret_cast<MNN::PermuteT *>(value) : nullptr;
   }
-  const PermuteT *AsPermute() const {
+  const MNN::PermuteT *AsPermute() const {
     return type == OpParameter_Permute ?
-      reinterpret_cast<const PermuteT *>(value) : nullptr;
+      reinterpret_cast<const MNN::PermuteT *>(value) : nullptr;
   }
-  PluginT *AsPlugin() {
+  MNN::PluginT *AsPlugin() {
     return type == OpParameter_Plugin ?
-      reinterpret_cast<PluginT *>(value) : nullptr;
+      reinterpret_cast<MNN::PluginT *>(value) : nullptr;
   }
-  const PluginT *AsPlugin() const {
+  const MNN::PluginT *AsPlugin() const {
     return type == OpParameter_Plugin ?
-      reinterpret_cast<const PluginT *>(value) : nullptr;
+      reinterpret_cast<const MNN::PluginT *>(value) : nullptr;
   }
-  PoolT *AsPool() {
+  MNN::PoolT *AsPool() {
     return type == OpParameter_Pool ?
-      reinterpret_cast<PoolT *>(value) : nullptr;
+      reinterpret_cast<MNN::PoolT *>(value) : nullptr;
   }
-  const PoolT *AsPool() const {
+  const MNN::PoolT *AsPool() const {
     return type == OpParameter_Pool ?
-      reinterpret_cast<const PoolT *>(value) : nullptr;
+      reinterpret_cast<const MNN::PoolT *>(value) : nullptr;
   }
-  PReluT *AsPRelu() {
+  MNN::PReluT *AsPRelu() {
     return type == OpParameter_PRelu ?
-      reinterpret_cast<PReluT *>(value) : nullptr;
+      reinterpret_cast<MNN::PReluT *>(value) : nullptr;
   }
-  const PReluT *AsPRelu() const {
+  const MNN::PReluT *AsPRelu() const {
     return type == OpParameter_PRelu ?
-      reinterpret_cast<const PReluT *>(value) : nullptr;
+      reinterpret_cast<const MNN::PReluT *>(value) : nullptr;
   }
-  PriorBoxT *AsPriorBox() {
+  MNN::PriorBoxT *AsPriorBox() {
     return type == OpParameter_PriorBox ?
-      reinterpret_cast<PriorBoxT *>(value) : nullptr;
+      reinterpret_cast<MNN::PriorBoxT *>(value) : nullptr;
   }
-  const PriorBoxT *AsPriorBox() const {
+  const MNN::PriorBoxT *AsPriorBox() const {
     return type == OpParameter_PriorBox ?
-      reinterpret_cast<const PriorBoxT *>(value) : nullptr;
+      reinterpret_cast<const MNN::PriorBoxT *>(value) : nullptr;
   }
-  ProposalT *AsProposal() {
+  MNN::ProposalT *AsProposal() {
     return type == OpParameter_Proposal ?
-      reinterpret_cast<ProposalT *>(value) : nullptr;
+      reinterpret_cast<MNN::ProposalT *>(value) : nullptr;
   }
-  const ProposalT *AsProposal() const {
+  const MNN::ProposalT *AsProposal() const {
     return type == OpParameter_Proposal ?
-      reinterpret_cast<const ProposalT *>(value) : nullptr;
+      reinterpret_cast<const MNN::ProposalT *>(value) : nullptr;
   }
-  QuantizedAvgPoolT *AsQuantizedAvgPool() {
+  MNN::QuantizedAvgPoolT *AsQuantizedAvgPool() {
     return type == OpParameter_QuantizedAvgPool ?
-      reinterpret_cast<QuantizedAvgPoolT *>(value) : nullptr;
+      reinterpret_cast<MNN::QuantizedAvgPoolT *>(value) : nullptr;
   }
-  const QuantizedAvgPoolT *AsQuantizedAvgPool() const {
+  const MNN::QuantizedAvgPoolT *AsQuantizedAvgPool() const {
     return type == OpParameter_QuantizedAvgPool ?
-      reinterpret_cast<const QuantizedAvgPoolT *>(value) : nullptr;
+      reinterpret_cast<const MNN::QuantizedAvgPoolT *>(value) : nullptr;
   }
-  QuantizedBiasAddT *AsQuantizedBiasAdd() {
+  MNN::QuantizedBiasAddT *AsQuantizedBiasAdd() {
     return type == OpParameter_QuantizedBiasAdd ?
-      reinterpret_cast<QuantizedBiasAddT *>(value) : nullptr;
+      reinterpret_cast<MNN::QuantizedBiasAddT *>(value) : nullptr;
   }
-  const QuantizedBiasAddT *AsQuantizedBiasAdd() const {
+  const MNN::QuantizedBiasAddT *AsQuantizedBiasAdd() const {
     return type == OpParameter_QuantizedBiasAdd ?
-      reinterpret_cast<const QuantizedBiasAddT *>(value) : nullptr;
+      reinterpret_cast<const MNN::QuantizedBiasAddT *>(value) : nullptr;
   }
-  QuantizedConcatT *AsQuantizedConcat() {
+  MNN::QuantizedConcatT *AsQuantizedConcat() {
     return type == OpParameter_QuantizedConcat ?
-      reinterpret_cast<QuantizedConcatT *>(value) : nullptr;
+      reinterpret_cast<MNN::QuantizedConcatT *>(value) : nullptr;
   }
-  const QuantizedConcatT *AsQuantizedConcat() const {
+  const MNN::QuantizedConcatT *AsQuantizedConcat() const {
     return type == OpParameter_QuantizedConcat ?
-      reinterpret_cast<const QuantizedConcatT *>(value) : nullptr;
+      reinterpret_cast<const MNN::QuantizedConcatT *>(value) : nullptr;
   }
-  QuantizedLogisticT *AsQuantizedLogistic() {
+  MNN::QuantizedLogisticT *AsQuantizedLogistic() {
     return type == OpParameter_QuantizedLogistic ?
-      reinterpret_cast<QuantizedLogisticT *>(value) : nullptr;
+      reinterpret_cast<MNN::QuantizedLogisticT *>(value) : nullptr;
   }
-  const QuantizedLogisticT *AsQuantizedLogistic() const {
+  const MNN::QuantizedLogisticT *AsQuantizedLogistic() const {
     return type == OpParameter_QuantizedLogistic ?
-      reinterpret_cast<const QuantizedLogisticT *>(value) : nullptr;
+      reinterpret_cast<const MNN::QuantizedLogisticT *>(value) : nullptr;
   }
-  QuantizedMatMulT *AsQuantizedMatMul() {
+  MNN::QuantizedMatMulT *AsQuantizedMatMul() {
     return type == OpParameter_QuantizedMatMul ?
-      reinterpret_cast<QuantizedMatMulT *>(value) : nullptr;
+      reinterpret_cast<MNN::QuantizedMatMulT *>(value) : nullptr;
   }
-  const QuantizedMatMulT *AsQuantizedMatMul() const {
+  const MNN::QuantizedMatMulT *AsQuantizedMatMul() const {
     return type == OpParameter_QuantizedMatMul ?
-      reinterpret_cast<const QuantizedMatMulT *>(value) : nullptr;
+      reinterpret_cast<const MNN::QuantizedMatMulT *>(value) : nullptr;
   }
-  QuantizedMaxPoolT *AsQuantizedMaxPool() {
+  MNN::QuantizedMaxPoolT *AsQuantizedMaxPool() {
     return type == OpParameter_QuantizedMaxPool ?
-      reinterpret_cast<QuantizedMaxPoolT *>(value) : nullptr;
+      reinterpret_cast<MNN::QuantizedMaxPoolT *>(value) : nullptr;
   }
-  const QuantizedMaxPoolT *AsQuantizedMaxPool() const {
+  const MNN::QuantizedMaxPoolT *AsQuantizedMaxPool() const {
     return type == OpParameter_QuantizedMaxPool ?
-      reinterpret_cast<const QuantizedMaxPoolT *>(value) : nullptr;
+      reinterpret_cast<const MNN::QuantizedMaxPoolT *>(value) : nullptr;
   }
-  QuantizedReluT *AsQuantizedRelu() {
+  MNN::QuantizedReluT *AsQuantizedRelu() {
     return type == OpParameter_QuantizedRelu ?
-      reinterpret_cast<QuantizedReluT *>(value) : nullptr;
+      reinterpret_cast<MNN::QuantizedReluT *>(value) : nullptr;
   }
-  const QuantizedReluT *AsQuantizedRelu() const {
+  const MNN::QuantizedReluT *AsQuantizedRelu() const {
     return type == OpParameter_QuantizedRelu ?
-      reinterpret_cast<const QuantizedReluT *>(value) : nullptr;
+      reinterpret_cast<const MNN::QuantizedReluT *>(value) : nullptr;
   }
-  QuantizedRelu6T *AsQuantizedRelu6() {
+  MNN::QuantizedRelu6T *AsQuantizedRelu6() {
     return type == OpParameter_QuantizedRelu6 ?
-      reinterpret_cast<QuantizedRelu6T *>(value) : nullptr;
+      reinterpret_cast<MNN::QuantizedRelu6T *>(value) : nullptr;
   }
-  const QuantizedRelu6T *AsQuantizedRelu6() const {
+  const MNN::QuantizedRelu6T *AsQuantizedRelu6() const {
     return type == OpParameter_QuantizedRelu6 ?
-      reinterpret_cast<const QuantizedRelu6T *>(value) : nullptr;
+      reinterpret_cast<const MNN::QuantizedRelu6T *>(value) : nullptr;
   }
-  QuantizedReshapeT *AsQuantizedReshape() {
+  MNN::QuantizedReshapeT *AsQuantizedReshape() {
     return type == OpParameter_QuantizedReshape ?
-      reinterpret_cast<QuantizedReshapeT *>(value) : nullptr;
+      reinterpret_cast<MNN::QuantizedReshapeT *>(value) : nullptr;
   }
-  const QuantizedReshapeT *AsQuantizedReshape() const {
+  const MNN::QuantizedReshapeT *AsQuantizedReshape() const {
     return type == OpParameter_QuantizedReshape ?
-      reinterpret_cast<const QuantizedReshapeT *>(value) : nullptr;
+      reinterpret_cast<const MNN::QuantizedReshapeT *>(value) : nullptr;
   }
-  QuantizedSoftmaxT *AsQuantizedSoftmax() {
+  MNN::QuantizedSoftmaxT *AsQuantizedSoftmax() {
     return type == OpParameter_QuantizedSoftmax ?
-      reinterpret_cast<QuantizedSoftmaxT *>(value) : nullptr;
+      reinterpret_cast<MNN::QuantizedSoftmaxT *>(value) : nullptr;
   }
-  const QuantizedSoftmaxT *AsQuantizedSoftmax() const {
+  const MNN::QuantizedSoftmaxT *AsQuantizedSoftmax() const {
     return type == OpParameter_QuantizedSoftmax ?
-      reinterpret_cast<const QuantizedSoftmaxT *>(value) : nullptr;
+      reinterpret_cast<const MNN::QuantizedSoftmaxT *>(value) : nullptr;
   }
-  QuantizeMaxMinT *AsQuantizeMaxMin() {
+  MNN::QuantizeMaxMinT *AsQuantizeMaxMin() {
     return type == OpParameter_QuantizeMaxMin ?
-      reinterpret_cast<QuantizeMaxMinT *>(value) : nullptr;
+      reinterpret_cast<MNN::QuantizeMaxMinT *>(value) : nullptr;
   }
-  const QuantizeMaxMinT *AsQuantizeMaxMin() const {
+  const MNN::QuantizeMaxMinT *AsQuantizeMaxMin() const {
     return type == OpParameter_QuantizeMaxMin ?
-      reinterpret_cast<const QuantizeMaxMinT *>(value) : nullptr;
+      reinterpret_cast<const MNN::QuantizeMaxMinT *>(value) : nullptr;
   }
-  QuantizeV2T *AsQuantizeV2() {
+  MNN::QuantizeV2T *AsQuantizeV2() {
     return type == OpParameter_QuantizeV2 ?
-      reinterpret_cast<QuantizeV2T *>(value) : nullptr;
+      reinterpret_cast<MNN::QuantizeV2T *>(value) : nullptr;
   }
-  const QuantizeV2T *AsQuantizeV2() const {
+  const MNN::QuantizeV2T *AsQuantizeV2() const {
     return type == OpParameter_QuantizeV2 ?
-      reinterpret_cast<const QuantizeV2T *>(value) : nullptr;
+      reinterpret_cast<const MNN::QuantizeV2T *>(value) : nullptr;
   }
-  RangeT *AsRange() {
+  MNN::RangeT *AsRange() {
     return type == OpParameter_Range ?
-      reinterpret_cast<RangeT *>(value) : nullptr;
+      reinterpret_cast<MNN::RangeT *>(value) : nullptr;
   }
-  const RangeT *AsRange() const {
+  const MNN::RangeT *AsRange() const {
     return type == OpParameter_Range ?
-      reinterpret_cast<const RangeT *>(value) : nullptr;
+      reinterpret_cast<const MNN::RangeT *>(value) : nullptr;
   }
-  RankT *AsRank() {
+  MNN::RankT *AsRank() {
     return type == OpParameter_Rank ?
-      reinterpret_cast<RankT *>(value) : nullptr;
+      reinterpret_cast<MNN::RankT *>(value) : nullptr;
   }
-  const RankT *AsRank() const {
+  const MNN::RankT *AsRank() const {
     return type == OpParameter_Rank ?
-      reinterpret_cast<const RankT *>(value) : nullptr;
+      reinterpret_cast<const MNN::RankT *>(value) : nullptr;
   }
-  ReduceJoinT *AsReduceJoin() {
+  MNN::ReduceJoinT *AsReduceJoin() {
     return type == OpParameter_ReduceJoin ?
-      reinterpret_cast<ReduceJoinT *>(value) : nullptr;
+      reinterpret_cast<MNN::ReduceJoinT *>(value) : nullptr;
   }
-  const ReduceJoinT *AsReduceJoin() const {
+  const MNN::ReduceJoinT *AsReduceJoin() const {
     return type == OpParameter_ReduceJoin ?
-      reinterpret_cast<const ReduceJoinT *>(value) : nullptr;
+      reinterpret_cast<const MNN::ReduceJoinT *>(value) : nullptr;
   }
-  ReductionParamT *AsReductionParam() {
+  MNN::ReductionParamT *AsReductionParam() {
     return type == OpParameter_ReductionParam ?
-      reinterpret_cast<ReductionParamT *>(value) : nullptr;
+      reinterpret_cast<MNN::ReductionParamT *>(value) : nullptr;
   }
-  const ReductionParamT *AsReductionParam() const {
+  const MNN::ReductionParamT *AsReductionParam() const {
     return type == OpParameter_ReductionParam ?
-      reinterpret_cast<const ReductionParamT *>(value) : nullptr;
+      reinterpret_cast<const MNN::ReductionParamT *>(value) : nullptr;
   }
-  ReluT *AsRelu() {
+  MNN::ReluT *AsRelu() {
     return type == OpParameter_Relu ?
-      reinterpret_cast<ReluT *>(value) : nullptr;
+      reinterpret_cast<MNN::ReluT *>(value) : nullptr;
   }
-  const ReluT *AsRelu() const {
+  const MNN::ReluT *AsRelu() const {
     return type == OpParameter_Relu ?
-      reinterpret_cast<const ReluT *>(value) : nullptr;
+      reinterpret_cast<const MNN::ReluT *>(value) : nullptr;
   }
-  Relu6T *AsRelu6() {
+  MNN::Relu6T *AsRelu6() {
     return type == OpParameter_Relu6 ?
-      reinterpret_cast<Relu6T *>(value) : nullptr;
+      reinterpret_cast<MNN::Relu6T *>(value) : nullptr;
   }
-  const Relu6T *AsRelu6() const {
+  const MNN::Relu6T *AsRelu6() const {
     return type == OpParameter_Relu6 ?
-      reinterpret_cast<const Relu6T *>(value) : nullptr;
+      reinterpret_cast<const MNN::Relu6T *>(value) : nullptr;
   }
-  RequantizationRangeT *AsRequantizationRange() {
+  MNN::RequantizationRangeT *AsRequantizationRange() {
     return type == OpParameter_RequantizationRange ?
-      reinterpret_cast<RequantizationRangeT *>(value) : nullptr;
+      reinterpret_cast<MNN::RequantizationRangeT *>(value) : nullptr;
   }
-  const RequantizationRangeT *AsRequantizationRange() const {
+  const MNN::RequantizationRangeT *AsRequantizationRange() const {
     return type == OpParameter_RequantizationRange ?
-      reinterpret_cast<const RequantizationRangeT *>(value) : nullptr;
+      reinterpret_cast<const MNN::RequantizationRangeT *>(value) : nullptr;
   }
-  RequantizeT *AsRequantize() {
+  MNN::RequantizeT *AsRequantize() {
     return type == OpParameter_Requantize ?
-      reinterpret_cast<RequantizeT *>(value) : nullptr;
+      reinterpret_cast<MNN::RequantizeT *>(value) : nullptr;
   }
-  const RequantizeT *AsRequantize() const {
+  const MNN::RequantizeT *AsRequantize() const {
     return type == OpParameter_Requantize ?
-      reinterpret_cast<const RequantizeT *>(value) : nullptr;
+      reinterpret_cast<const MNN::RequantizeT *>(value) : nullptr;
   }
-  ReshapeT *AsReshape() {
+  MNN::ReshapeT *AsReshape() {
     return type == OpParameter_Reshape ?
-      reinterpret_cast<ReshapeT *>(value) : nullptr;
+      reinterpret_cast<MNN::ReshapeT *>(value) : nullptr;
   }
-  const ReshapeT *AsReshape() const {
+  const MNN::ReshapeT *AsReshape() const {
     return type == OpParameter_Reshape ?
-      reinterpret_cast<const ReshapeT *>(value) : nullptr;
+      reinterpret_cast<const MNN::ReshapeT *>(value) : nullptr;
   }
-  ResizeT *AsResize() {
+  MNN::ResizeT *AsResize() {
     return type == OpParameter_Resize ?
-      reinterpret_cast<ResizeT *>(value) : nullptr;
+      reinterpret_cast<MNN::ResizeT *>(value) : nullptr;
   }
-  const ResizeT *AsResize() const {
+  const MNN::ResizeT *AsResize() const {
     return type == OpParameter_Resize ?
-      reinterpret_cast<const ResizeT *>(value) : nullptr;
+      reinterpret_cast<const MNN::ResizeT *>(value) : nullptr;
   }
-  RoiPoolingT *AsRoiPooling() {
+  MNN::RoiPoolingT *AsRoiPooling() {
     return type == OpParameter_RoiPooling ?
-      reinterpret_cast<RoiPoolingT *>(value) : nullptr;
+      reinterpret_cast<MNN::RoiPoolingT *>(value) : nullptr;
   }
-  const RoiPoolingT *AsRoiPooling() const {
+  const MNN::RoiPoolingT *AsRoiPooling() const {
     return type == OpParameter_RoiPooling ?
-      reinterpret_cast<const RoiPoolingT *>(value) : nullptr;
+      reinterpret_cast<const MNN::RoiPoolingT *>(value) : nullptr;
   }
-  ScaleT *AsScale() {
+  MNN::ScaleT *AsScale() {
     return type == OpParameter_Scale ?
-      reinterpret_cast<ScaleT *>(value) : nullptr;
+      reinterpret_cast<MNN::ScaleT *>(value) : nullptr;
   }
-  const ScaleT *AsScale() const {
+  const MNN::ScaleT *AsScale() const {
     return type == OpParameter_Scale ?
-      reinterpret_cast<const ScaleT *>(value) : nullptr;
+      reinterpret_cast<const MNN::ScaleT *>(value) : nullptr;
   }
-  SeluT *AsSelu() {
+  MNN::SeluT *AsSelu() {
     return type == OpParameter_Selu ?
-      reinterpret_cast<SeluT *>(value) : nullptr;
+      reinterpret_cast<MNN::SeluT *>(value) : nullptr;
   }
-  const SeluT *AsSelu() const {
+  const MNN::SeluT *AsSelu() const {
     return type == OpParameter_Selu ?
-      reinterpret_cast<const SeluT *>(value) : nullptr;
+      reinterpret_cast<const MNN::SeluT *>(value) : nullptr;
   }
-  SizeT *AsSize() {
+  MNN::SizeT *AsSize() {
     return type == OpParameter_Size ?
-      reinterpret_cast<SizeT *>(value) : nullptr;
+      reinterpret_cast<MNN::SizeT *>(value) : nullptr;
   }
-  const SizeT *AsSize() const {
+  const MNN::SizeT *AsSize() const {
     return type == OpParameter_Size ?
-      reinterpret_cast<const SizeT *>(value) : nullptr;
+      reinterpret_cast<const MNN::SizeT *>(value) : nullptr;
   }
-  SliceT *AsSlice() {
+  MNN::SliceT *AsSlice() {
     return type == OpParameter_Slice ?
-      reinterpret_cast<SliceT *>(value) : nullptr;
+      reinterpret_cast<MNN::SliceT *>(value) : nullptr;
   }
-  const SliceT *AsSlice() const {
+  const MNN::SliceT *AsSlice() const {
     return type == OpParameter_Slice ?
-      reinterpret_cast<const SliceT *>(value) : nullptr;
+      reinterpret_cast<const MNN::SliceT *>(value) : nullptr;
   }
-  SliceTfT *AsSliceTf() {
+  MNN::SliceTfT *AsSliceTf() {
     return type == OpParameter_SliceTf ?
-      reinterpret_cast<SliceTfT *>(value) : nullptr;
+      reinterpret_cast<MNN::SliceTfT *>(value) : nullptr;
   }
-  const SliceTfT *AsSliceTf() const {
+  const MNN::SliceTfT *AsSliceTf() const {
     return type == OpParameter_SliceTf ?
-      reinterpret_cast<const SliceTfT *>(value) : nullptr;
+      reinterpret_cast<const MNN::SliceTfT *>(value) : nullptr;
   }
-  SpaceBatchT *AsSpaceBatch() {
+  MNN::SpaceBatchT *AsSpaceBatch() {
     return type == OpParameter_SpaceBatch ?
-      reinterpret_cast<SpaceBatchT *>(value) : nullptr;
+      reinterpret_cast<MNN::SpaceBatchT *>(value) : nullptr;
   }
-  const SpaceBatchT *AsSpaceBatch() const {
+  const MNN::SpaceBatchT *AsSpaceBatch() const {
     return type == OpParameter_SpaceBatch ?
-      reinterpret_cast<const SpaceBatchT *>(value) : nullptr;
+      reinterpret_cast<const MNN::SpaceBatchT *>(value) : nullptr;
   }
-  SqueezeParamT *AsSqueezeParam() {
+  MNN::SqueezeParamT *AsSqueezeParam() {
     return type == OpParameter_SqueezeParam ?
-      reinterpret_cast<SqueezeParamT *>(value) : nullptr;
+      reinterpret_cast<MNN::SqueezeParamT *>(value) : nullptr;
   }
-  const SqueezeParamT *AsSqueezeParam() const {
+  const MNN::SqueezeParamT *AsSqueezeParam() const {
     return type == OpParameter_SqueezeParam ?
-      reinterpret_cast<const SqueezeParamT *>(value) : nullptr;
+      reinterpret_cast<const MNN::SqueezeParamT *>(value) : nullptr;
   }
-  StridedSliceParamT *AsStridedSliceParam() {
+  MNN::StridedSliceParamT *AsStridedSliceParam() {
     return type == OpParameter_StridedSliceParam ?
-      reinterpret_cast<StridedSliceParamT *>(value) : nullptr;
+      reinterpret_cast<MNN::StridedSliceParamT *>(value) : nullptr;
   }
-  const StridedSliceParamT *AsStridedSliceParam() const {
+  const MNN::StridedSliceParamT *AsStridedSliceParam() const {
     return type == OpParameter_StridedSliceParam ?
-      reinterpret_cast<const StridedSliceParamT *>(value) : nullptr;
+      reinterpret_cast<const MNN::StridedSliceParamT *>(value) : nullptr;
   }
-  TensorConvertInfoT *AsTensorConvertInfo() {
+  MNN::TensorConvertInfoT *AsTensorConvertInfo() {
     return type == OpParameter_TensorConvertInfo ?
-      reinterpret_cast<TensorConvertInfoT *>(value) : nullptr;
+      reinterpret_cast<MNN::TensorConvertInfoT *>(value) : nullptr;
   }
-  const TensorConvertInfoT *AsTensorConvertInfo() const {
+  const MNN::TensorConvertInfoT *AsTensorConvertInfo() const {
     return type == OpParameter_TensorConvertInfo ?
-      reinterpret_cast<const TensorConvertInfoT *>(value) : nullptr;
+      reinterpret_cast<const MNN::TensorConvertInfoT *>(value) : nullptr;
   }
-  TfQuantizedConv2DT *AsTfQuantizedConv2D() {
+  MNN::TfQuantizedConv2DT *AsTfQuantizedConv2D() {
     return type == OpParameter_TfQuantizedConv2D ?
-      reinterpret_cast<TfQuantizedConv2DT *>(value) : nullptr;
+      reinterpret_cast<MNN::TfQuantizedConv2DT *>(value) : nullptr;
   }
-  const TfQuantizedConv2DT *AsTfQuantizedConv2D() const {
+  const MNN::TfQuantizedConv2DT *AsTfQuantizedConv2D() const {
     return type == OpParameter_TfQuantizedConv2D ?
-      reinterpret_cast<const TfQuantizedConv2DT *>(value) : nullptr;
+      reinterpret_cast<const MNN::TfQuantizedConv2DT *>(value) : nullptr;
   }
-  TopKV2T *AsTopKV2() {
+  MNN::TopKV2T *AsTopKV2() {
     return type == OpParameter_TopKV2 ?
-      reinterpret_cast<TopKV2T *>(value) : nullptr;
+      reinterpret_cast<MNN::TopKV2T *>(value) : nullptr;
   }
-  const TopKV2T *AsTopKV2() const {
+  const MNN::TopKV2T *AsTopKV2() const {
     return type == OpParameter_TopKV2 ?
-      reinterpret_cast<const TopKV2T *>(value) : nullptr;
+      reinterpret_cast<const MNN::TopKV2T *>(value) : nullptr;
   }
-  TransposeT *AsTranspose() {
+  MNN::TransposeT *AsTranspose() {
     return type == OpParameter_Transpose ?
-      reinterpret_cast<TransposeT *>(value) : nullptr;
+      reinterpret_cast<MNN::TransposeT *>(value) : nullptr;
   }
-  const TransposeT *AsTranspose() const {
+  const MNN::TransposeT *AsTranspose() const {
     return type == OpParameter_Transpose ?
-      reinterpret_cast<const TransposeT *>(value) : nullptr;
+      reinterpret_cast<const MNN::TransposeT *>(value) : nullptr;
   }
-  UnaryOpT *AsUnaryOp() {
+  MNN::UnaryOpT *AsUnaryOp() {
     return type == OpParameter_UnaryOp ?
-      reinterpret_cast<UnaryOpT *>(value) : nullptr;
+      reinterpret_cast<MNN::UnaryOpT *>(value) : nullptr;
   }
-  const UnaryOpT *AsUnaryOp() const {
+  const MNN::UnaryOpT *AsUnaryOp() const {
     return type == OpParameter_UnaryOp ?
-      reinterpret_cast<const UnaryOpT *>(value) : nullptr;
+      reinterpret_cast<const MNN::UnaryOpT *>(value) : nullptr;
   }
-  MomentsParamT *AsMomentsParam() {
+  MNN::MomentsParamT *AsMomentsParam() {
     return type == OpParameter_MomentsParam ?
-      reinterpret_cast<MomentsParamT *>(value) : nullptr;
+      reinterpret_cast<MNN::MomentsParamT *>(value) : nullptr;
   }
-  const MomentsParamT *AsMomentsParam() const {
+  const MNN::MomentsParamT *AsMomentsParam() const {
     return type == OpParameter_MomentsParam ?
-      reinterpret_cast<const MomentsParamT *>(value) : nullptr;
+      reinterpret_cast<const MNN::MomentsParamT *>(value) : nullptr;
   }
-  RNNParamT *AsRNNParam() {
+  MNN::RNNParamT *AsRNNParam() {
     return type == OpParameter_RNNParam ?
-      reinterpret_cast<RNNParamT *>(value) : nullptr;
+      reinterpret_cast<MNN::RNNParamT *>(value) : nullptr;
   }
-  const RNNParamT *AsRNNParam() const {
+  const MNN::RNNParamT *AsRNNParam() const {
     return type == OpParameter_RNNParam ?
-      reinterpret_cast<const RNNParamT *>(value) : nullptr;
+      reinterpret_cast<const MNN::RNNParamT *>(value) : nullptr;
   }
-  BatchMatMulParamT *AsBatchMatMulParam() {
+  MNN::BatchMatMulParamT *AsBatchMatMulParam() {
     return type == OpParameter_BatchMatMulParam ?
-      reinterpret_cast<BatchMatMulParamT *>(value) : nullptr;
+      reinterpret_cast<MNN::BatchMatMulParamT *>(value) : nullptr;
   }
-  const BatchMatMulParamT *AsBatchMatMulParam() const {
+  const MNN::BatchMatMulParamT *AsBatchMatMulParam() const {
     return type == OpParameter_BatchMatMulParam ?
-      reinterpret_cast<const BatchMatMulParamT *>(value) : nullptr;
+      reinterpret_cast<const MNN::BatchMatMulParamT *>(value) : nullptr;
   }
-  QuantizedFloatParamT *AsQuantizedFloatParam() {
+  MNN::QuantizedFloatParamT *AsQuantizedFloatParam() {
     return type == OpParameter_QuantizedFloatParam ?
-      reinterpret_cast<QuantizedFloatParamT *>(value) : nullptr;
+      reinterpret_cast<MNN::QuantizedFloatParamT *>(value) : nullptr;
   }
-  const QuantizedFloatParamT *AsQuantizedFloatParam() const {
+  const MNN::QuantizedFloatParamT *AsQuantizedFloatParam() const {
     return type == OpParameter_QuantizedFloatParam ?
-      reinterpret_cast<const QuantizedFloatParamT *>(value) : nullptr;
+      reinterpret_cast<const MNN::QuantizedFloatParamT *>(value) : nullptr;
   }
-  DepthSpaceParamT *AsDepthSpaceParam() {
+  MNN::DepthSpaceParamT *AsDepthSpaceParam() {
     return type == OpParameter_DepthSpaceParam ?
-      reinterpret_cast<DepthSpaceParamT *>(value) : nullptr;
+      reinterpret_cast<MNN::DepthSpaceParamT *>(value) : nullptr;
   }
-  const DepthSpaceParamT *AsDepthSpaceParam() const {
+  const MNN::DepthSpaceParamT *AsDepthSpaceParam() const {
     return type == OpParameter_DepthSpaceParam ?
-      reinterpret_cast<const DepthSpaceParamT *>(value) : nullptr;
+      reinterpret_cast<const MNN::DepthSpaceParamT *>(value) : nullptr;
   }
-  EltwiseInt8T *AsEltwiseInt8() {
+  MNN::EltwiseInt8T *AsEltwiseInt8() {
     return type == OpParameter_EltwiseInt8 ?
-      reinterpret_cast<EltwiseInt8T *>(value) : nullptr;
+      reinterpret_cast<MNN::EltwiseInt8T *>(value) : nullptr;
   }
-  const EltwiseInt8T *AsEltwiseInt8() const {
+  const MNN::EltwiseInt8T *AsEltwiseInt8() const {
     return type == OpParameter_EltwiseInt8 ?
-      reinterpret_cast<const EltwiseInt8T *>(value) : nullptr;
+      reinterpret_cast<const MNN::EltwiseInt8T *>(value) : nullptr;
   }
-  ReverseSequenceParamT *AsReverseSequenceParam() {
+  MNN::ReverseSequenceParamT *AsReverseSequenceParam() {
     return type == OpParameter_ReverseSequenceParam ?
-      reinterpret_cast<ReverseSequenceParamT *>(value) : nullptr;
+      reinterpret_cast<MNN::ReverseSequenceParamT *>(value) : nullptr;
   }
-  const ReverseSequenceParamT *AsReverseSequenceParam() const {
+  const MNN::ReverseSequenceParamT *AsReverseSequenceParam() const {
     return type == OpParameter_ReverseSequenceParam ?
-      reinterpret_cast<const ReverseSequenceParamT *>(value) : nullptr;
+      reinterpret_cast<const MNN::ReverseSequenceParamT *>(value) : nullptr;
   }
-  ExtraT *AsExtra() {
+  MNN::ExtraT *AsExtra() {
     return type == OpParameter_Extra ?
-      reinterpret_cast<ExtraT *>(value) : nullptr;
+      reinterpret_cast<MNN::ExtraT *>(value) : nullptr;
   }
-  const ExtraT *AsExtra() const {
+  const MNN::ExtraT *AsExtra() const {
     return type == OpParameter_Extra ?
-      reinterpret_cast<const ExtraT *>(value) : nullptr;
+      reinterpret_cast<const MNN::ExtraT *>(value) : nullptr;
   }
-  Pool3DT *AsPool3D() {
+  MNN::Pool3DT *AsPool3D() {
     return type == OpParameter_Pool3D ?
-      reinterpret_cast<Pool3DT *>(value) : nullptr;
+      reinterpret_cast<MNN::Pool3DT *>(value) : nullptr;
   }
-  const Pool3DT *AsPool3D() const {
+  const MNN::Pool3DT *AsPool3D() const {
     return type == OpParameter_Pool3D ?
-      reinterpret_cast<const Pool3DT *>(value) : nullptr;
+      reinterpret_cast<const MNN::Pool3DT *>(value) : nullptr;
   }
-  Convolution3DT *AsConvolution3D() {
+  MNN::Convolution3DT *AsConvolution3D() {
     return type == OpParameter_Convolution3D ?
-      reinterpret_cast<Convolution3DT *>(value) : nullptr;
+      reinterpret_cast<MNN::Convolution3DT *>(value) : nullptr;
   }
-  const Convolution3DT *AsConvolution3D() const {
+  const MNN::Convolution3DT *AsConvolution3D() const {
     return type == OpParameter_Convolution3D ?
-      reinterpret_cast<const Convolution3DT *>(value) : nullptr;
+      reinterpret_cast<const MNN::Convolution3DT *>(value) : nullptr;
   }
-  ELUT *AsELU() {
+  MNN::ELUT *AsELU() {
     return type == OpParameter_ELU ?
-      reinterpret_cast<ELUT *>(value) : nullptr;
+      reinterpret_cast<MNN::ELUT *>(value) : nullptr;
   }
-  const ELUT *AsELU() const {
+  const MNN::ELUT *AsELU() const {
     return type == OpParameter_ELU ?
-      reinterpret_cast<const ELUT *>(value) : nullptr;
+      reinterpret_cast<const MNN::ELUT *>(value) : nullptr;
   }
-  DetectionPostProcessParamT *AsDetectionPostProcessParam() {
+  MNN::DetectionPostProcessParamT *AsDetectionPostProcessParam() {
     return type == OpParameter_DetectionPostProcessParam ?
-      reinterpret_cast<DetectionPostProcessParamT *>(value) : nullptr;
+      reinterpret_cast<MNN::DetectionPostProcessParamT *>(value) : nullptr;
   }
-  const DetectionPostProcessParamT *AsDetectionPostProcessParam() const {
+  const MNN::DetectionPostProcessParamT *AsDetectionPostProcessParam() const {
     return type == OpParameter_DetectionPostProcessParam ?
-      reinterpret_cast<const DetectionPostProcessParamT *>(value) : nullptr;
+      reinterpret_cast<const MNN::DetectionPostProcessParamT *>(value) : nullptr;
   }
-  OneHotParamT *AsOneHotParam() {
+  MNN::OneHotParamT *AsOneHotParam() {
     return type == OpParameter_OneHotParam ?
-      reinterpret_cast<OneHotParamT *>(value) : nullptr;
+      reinterpret_cast<MNN::OneHotParamT *>(value) : nullptr;
   }
-  const OneHotParamT *AsOneHotParam() const {
+  const MNN::OneHotParamT *AsOneHotParam() const {
     return type == OpParameter_OneHotParam ?
-      reinterpret_cast<const OneHotParamT *>(value) : nullptr;
+      reinterpret_cast<const MNN::OneHotParamT *>(value) : nullptr;
   }
-  PadParamT *AsPadParam() {
+  MNN::PadParamT *AsPadParam() {
     return type == OpParameter_PadParam ?
-      reinterpret_cast<PadParamT *>(value) : nullptr;
+      reinterpret_cast<MNN::PadParamT *>(value) : nullptr;
   }
-  const PadParamT *AsPadParam() const {
+  const MNN::PadParamT *AsPadParam() const {
     return type == OpParameter_PadParam ?
-      reinterpret_cast<const PadParamT *>(value) : nullptr;
+      reinterpret_cast<const MNN::PadParamT *>(value) : nullptr;
   }
-  WhileParamT *AsWhileParam() {
+  MNN::WhileParamT *AsWhileParam() {
     return type == OpParameter_WhileParam ?
-      reinterpret_cast<WhileParamT *>(value) : nullptr;
+      reinterpret_cast<MNN::WhileParamT *>(value) : nullptr;
   }
-  const WhileParamT *AsWhileParam() const {
+  const MNN::WhileParamT *AsWhileParam() const {
     return type == OpParameter_WhileParam ?
-      reinterpret_cast<const WhileParamT *>(value) : nullptr;
+      reinterpret_cast<const MNN::WhileParamT *>(value) : nullptr;
   }
-  IfParamT *AsIfParam() {
+  MNN::IfParamT *AsIfParam() {
     return type == OpParameter_IfParam ?
-      reinterpret_cast<IfParamT *>(value) : nullptr;
+      reinterpret_cast<MNN::IfParamT *>(value) : nullptr;
   }
-  const IfParamT *AsIfParam() const {
+  const MNN::IfParamT *AsIfParam() const {
     return type == OpParameter_IfParam ?
-      reinterpret_cast<const IfParamT *>(value) : nullptr;
+      reinterpret_cast<const MNN::IfParamT *>(value) : nullptr;
   }
-  RandomUniformT *AsRandomUniform() {
+  MNN::RandomUniformT *AsRandomUniform() {
     return type == OpParameter_RandomUniform ?
-      reinterpret_cast<RandomUniformT *>(value) : nullptr;
+      reinterpret_cast<MNN::RandomUniformT *>(value) : nullptr;
   }
-  const RandomUniformT *AsRandomUniform() const {
+  const MNN::RandomUniformT *AsRandomUniform() const {
     return type == OpParameter_RandomUniform ?
-      reinterpret_cast<const RandomUniformT *>(value) : nullptr;
+      reinterpret_cast<const MNN::RandomUniformT *>(value) : nullptr;
   }
-  LayerNormT *AsLayerNorm() {
+  MNN::LayerNormT *AsLayerNorm() {
     return type == OpParameter_LayerNorm ?
-      reinterpret_cast<LayerNormT *>(value) : nullptr;
+      reinterpret_cast<MNN::LayerNormT *>(value) : nullptr;
   }
-  const LayerNormT *AsLayerNorm() const {
+  const MNN::LayerNormT *AsLayerNorm() const {
     return type == OpParameter_LayerNorm ?
-      reinterpret_cast<const LayerNormT *>(value) : nullptr;
+      reinterpret_cast<const MNN::LayerNormT *>(value) : nullptr;
   }
 };
 
 bool VerifyOpParameter(flatbuffers::Verifier &verifier, const void *obj, OpParameter type);
 bool VerifyOpParameterVector(flatbuffers::Verifier &verifier, const flatbuffers::Vector<flatbuffers::Offset<void>> *values, const flatbuffers::Vector<uint8_t> *types);
 
-enum ForwardType {
+enum ForwardType : int8_t {
   ForwardType_CPU = 0,
   ForwardType_METAL = 1,
   ForwardType_OPENCL = 2,
@@ -2407,7 +2420,7 @@ inline const ForwardType (&EnumValuesForwardType())[5] {
 }
 
 inline const char * const *EnumNamesForwardType() {
-  static const char * const names[] = {
+  static const char * const names[6] = {
     "CPU",
     "METAL",
     "OPENCL",
@@ -2419,12 +2432,12 @@ inline const char * const *EnumNamesForwardType() {
 }
 
 inline const char *EnumNameForwardType(ForwardType e) {
-  if (e < ForwardType_CPU || e > ForwardType_VULKAN) return "";
-  const size_t index = static_cast<int>(e);
+  if (flatbuffers::IsOutRange(e, ForwardType_CPU, ForwardType_VULKAN)) return "";
+  const size_t index = static_cast<size_t>(e);
   return EnumNamesForwardType()[index];
 }
 
-enum Usage {
+enum Usage : int8_t {
   Usage_INFERENCE = 0,
   Usage_TRAIN = 1,
   Usage_INFERENCE_STATIC = 2,
@@ -2442,7 +2455,7 @@ inline const Usage (&EnumValuesUsage())[3] {
 }
 
 inline const char * const *EnumNamesUsage() {
-  static const char * const names[] = {
+  static const char * const names[4] = {
     "INFERENCE",
     "TRAIN",
     "INFERENCE_STATIC",
@@ -2452,21 +2465,20 @@ inline const char * const *EnumNamesUsage() {
 }
 
 inline const char *EnumNameUsage(Usage e) {
-  if (e < Usage_INFERENCE || e > Usage_INFERENCE_STATIC) return "";
-  const size_t index = static_cast<int>(e);
+  if (flatbuffers::IsOutRange(e, Usage_INFERENCE, Usage_INFERENCE_STATIC)) return "";
+  const size_t index = static_cast<size_t>(e);
   return EnumNamesUsage()[index];
 }
 
 struct PluginT : public flatbuffers::NativeTable {
   typedef Plugin TableType;
-  std::string type;
-  std::vector<std::unique_ptr<AttributeT>> attr;
-  PluginT() {
-  }
+  std::string type{};
+  std::vector<std::unique_ptr<MNN::AttributeT>> attr{};
 };
 
 struct Plugin FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
   typedef PluginT NativeTableType;
+  typedef PluginBuilder Builder;
   static const flatbuffers::TypeTable *MiniReflectTypeTable() {
     return PluginTypeTable();
   }
@@ -2477,8 +2489,8 @@ struct Plugin FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
   const flatbuffers::String *type() const {
     return GetPointer<const flatbuffers::String *>(VT_TYPE);
   }
-  const flatbuffers::Vector<flatbuffers::Offset<Attribute>> *attr() const {
-    return GetPointer<const flatbuffers::Vector<flatbuffers::Offset<Attribute>> *>(VT_ATTR);
+  const flatbuffers::Vector<flatbuffers::Offset<MNN::Attribute>> *attr() const {
+    return GetPointer<const flatbuffers::Vector<flatbuffers::Offset<MNN::Attribute>> *>(VT_ATTR);
   }
   bool Verify(flatbuffers::Verifier &verifier) const {
     return VerifyTableStart(verifier) &&
@@ -2495,19 +2507,19 @@ struct Plugin FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
 };
 
 struct PluginBuilder {
+  typedef Plugin Table;
   flatbuffers::FlatBufferBuilder &fbb_;
   flatbuffers::uoffset_t start_;
   void add_type(flatbuffers::Offset<flatbuffers::String> type) {
     fbb_.AddOffset(Plugin::VT_TYPE, type);
   }
-  void add_attr(flatbuffers::Offset<flatbuffers::Vector<flatbuffers::Offset<Attribute>>> attr) {
+  void add_attr(flatbuffers::Offset<flatbuffers::Vector<flatbuffers::Offset<MNN::Attribute>>> attr) {
     fbb_.AddOffset(Plugin::VT_ATTR, attr);
   }
   explicit PluginBuilder(flatbuffers::FlatBufferBuilder &_fbb)
         : fbb_(_fbb) {
     start_ = fbb_.StartTable();
   }
-  PluginBuilder &operator=(const PluginBuilder &);
   flatbuffers::Offset<Plugin> Finish() {
     const auto end = fbb_.EndTable(start_);
     auto o = flatbuffers::Offset<Plugin>(end);
@@ -2518,7 +2530,7 @@ struct PluginBuilder {
 inline flatbuffers::Offset<Plugin> CreatePlugin(
     flatbuffers::FlatBufferBuilder &_fbb,
     flatbuffers::Offset<flatbuffers::String> type = 0,
-    flatbuffers::Offset<flatbuffers::Vector<flatbuffers::Offset<Attribute>>> attr = 0) {
+    flatbuffers::Offset<flatbuffers::Vector<flatbuffers::Offset<MNN::Attribute>>> attr = 0) {
   PluginBuilder builder_(_fbb);
   builder_.add_attr(attr);
   builder_.add_type(type);
@@ -2528,9 +2540,9 @@ inline flatbuffers::Offset<Plugin> CreatePlugin(
 inline flatbuffers::Offset<Plugin> CreatePluginDirect(
     flatbuffers::FlatBufferBuilder &_fbb,
     const char *type = nullptr,
-    const std::vector<flatbuffers::Offset<Attribute>> *attr = nullptr) {
+    const std::vector<flatbuffers::Offset<MNN::Attribute>> *attr = nullptr) {
   auto type__ = type ? _fbb.CreateString(type) : 0;
-  auto attr__ = attr ? _fbb.CreateVector<flatbuffers::Offset<Attribute>>(*attr) : 0;
+  auto attr__ = attr ? _fbb.CreateVector<flatbuffers::Offset<MNN::Attribute>>(*attr) : 0;
   return MNN::CreatePlugin(
       _fbb,
       type__,
@@ -2541,16 +2553,15 @@ flatbuffers::Offset<Plugin> CreatePlugin(flatbuffers::FlatBufferBuilder &_fbb, c
 
 struct ExtraT : public flatbuffers::NativeTable {
   typedef Extra TableType;
-  std::string type;
-  std::string engine;
-  std::vector<int8_t> info;
-  std::vector<std::unique_ptr<AttributeT>> attr;
-  ExtraT() {
-  }
+  std::string type{};
+  std::string engine{};
+  std::vector<int8_t> info{};
+  std::vector<std::unique_ptr<MNN::AttributeT>> attr{};
 };
 
 struct Extra FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
   typedef ExtraT NativeTableType;
+  typedef ExtraBuilder Builder;
   static const flatbuffers::TypeTable *MiniReflectTypeTable() {
     return ExtraTypeTable();
   }
@@ -2569,8 +2580,8 @@ struct Extra FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
   const flatbuffers::Vector<int8_t> *info() const {
     return GetPointer<const flatbuffers::Vector<int8_t> *>(VT_INFO);
   }
-  const flatbuffers::Vector<flatbuffers::Offset<Attribute>> *attr() const {
-    return GetPointer<const flatbuffers::Vector<flatbuffers::Offset<Attribute>> *>(VT_ATTR);
+  const flatbuffers::Vector<flatbuffers::Offset<MNN::Attribute>> *attr() const {
+    return GetPointer<const flatbuffers::Vector<flatbuffers::Offset<MNN::Attribute>> *>(VT_ATTR);
   }
   bool Verify(flatbuffers::Verifier &verifier) const {
     return VerifyTableStart(verifier) &&
@@ -2591,6 +2602,7 @@ struct Extra FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
 };
 
 struct ExtraBuilder {
+  typedef Extra Table;
   flatbuffers::FlatBufferBuilder &fbb_;
   flatbuffers::uoffset_t start_;
   void add_type(flatbuffers::Offset<flatbuffers::String> type) {
@@ -2602,14 +2614,13 @@ struct ExtraBuilder {
   void add_info(flatbuffers::Offset<flatbuffers::Vector<int8_t>> info) {
     fbb_.AddOffset(Extra::VT_INFO, info);
   }
-  void add_attr(flatbuffers::Offset<flatbuffers::Vector<flatbuffers::Offset<Attribute>>> attr) {
+  void add_attr(flatbuffers::Offset<flatbuffers::Vector<flatbuffers::Offset<MNN::Attribute>>> attr) {
     fbb_.AddOffset(Extra::VT_ATTR, attr);
   }
   explicit ExtraBuilder(flatbuffers::FlatBufferBuilder &_fbb)
         : fbb_(_fbb) {
     start_ = fbb_.StartTable();
   }
-  ExtraBuilder &operator=(const ExtraBuilder &);
   flatbuffers::Offset<Extra> Finish() {
     const auto end = fbb_.EndTable(start_);
     auto o = flatbuffers::Offset<Extra>(end);
@@ -2622,7 +2633,7 @@ inline flatbuffers::Offset<Extra> CreateExtra(
     flatbuffers::Offset<flatbuffers::String> type = 0,
     flatbuffers::Offset<flatbuffers::String> engine = 0,
     flatbuffers::Offset<flatbuffers::Vector<int8_t>> info = 0,
-    flatbuffers::Offset<flatbuffers::Vector<flatbuffers::Offset<Attribute>>> attr = 0) {
+    flatbuffers::Offset<flatbuffers::Vector<flatbuffers::Offset<MNN::Attribute>>> attr = 0) {
   ExtraBuilder builder_(_fbb);
   builder_.add_attr(attr);
   builder_.add_info(info);
@@ -2636,11 +2647,11 @@ inline flatbuffers::Offset<Extra> CreateExtraDirect(
     const char *type = nullptr,
     const char *engine = nullptr,
     const std::vector<int8_t> *info = nullptr,
-    const std::vector<flatbuffers::Offset<Attribute>> *attr = nullptr) {
+    const std::vector<flatbuffers::Offset<MNN::Attribute>> *attr = nullptr) {
   auto type__ = type ? _fbb.CreateString(type) : 0;
   auto engine__ = engine ? _fbb.CreateString(engine) : 0;
   auto info__ = info ? _fbb.CreateVector<int8_t>(*info) : 0;
-  auto attr__ = attr ? _fbb.CreateVector<flatbuffers::Offset<Attribute>>(*attr) : 0;
+  auto attr__ = attr ? _fbb.CreateVector<flatbuffers::Offset<MNN::Attribute>>(*attr) : 0;
   return MNN::CreateExtra(
       _fbb,
       type__,
@@ -2653,13 +2664,12 @@ flatbuffers::Offset<Extra> CreateExtra(flatbuffers::FlatBufferBuilder &_fbb, con
 
 struct StringVecT : public flatbuffers::NativeTable {
   typedef StringVec TableType;
-  std::vector<std::string> data;
-  StringVecT() {
-  }
+  std::vector<std::string> data{};
 };
 
 struct StringVec FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
   typedef StringVecT NativeTableType;
+  typedef StringVecBuilder Builder;
   static const flatbuffers::TypeTable *MiniReflectTypeTable() {
     return StringVecTypeTable();
   }
@@ -2682,6 +2692,7 @@ struct StringVec FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
 };
 
 struct StringVecBuilder {
+  typedef StringVec Table;
   flatbuffers::FlatBufferBuilder &fbb_;
   flatbuffers::uoffset_t start_;
   void add_data(flatbuffers::Offset<flatbuffers::Vector<flatbuffers::Offset<flatbuffers::String>>> data) {
@@ -2691,7 +2702,6 @@ struct StringVecBuilder {
         : fbb_(_fbb) {
     start_ = fbb_.StartTable();
   }
-  StringVecBuilder &operator=(const StringVecBuilder &);
   flatbuffers::Offset<StringVec> Finish() {
     const auto end = fbb_.EndTable(start_);
     auto o = flatbuffers::Offset<StringVec>(end);
@@ -2720,17 +2730,16 @@ flatbuffers::Offset<StringVec> CreateStringVec(flatbuffers::FlatBufferBuilder &_
 
 struct WhileParamT : public flatbuffers::NativeTable {
   typedef WhileParam TableType;
-  std::string cond_graph;
-  std::string body_graph;
-  std::vector<std::unique_ptr<StringVecT>> aliases_inputs;
-  std::vector<std::string> aliases_outputs;
-  std::vector<std::unique_ptr<StringVecT>> aliases_updates;
-  WhileParamT() {
-  }
+  std::string cond_graph{};
+  std::string body_graph{};
+  std::vector<std::unique_ptr<MNN::StringVecT>> aliases_inputs{};
+  std::vector<std::string> aliases_outputs{};
+  std::vector<std::unique_ptr<MNN::StringVecT>> aliases_updates{};
 };
 
 struct WhileParam FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
   typedef WhileParamT NativeTableType;
+  typedef WhileParamBuilder Builder;
   static const flatbuffers::TypeTable *MiniReflectTypeTable() {
     return WhileParamTypeTable();
   }
@@ -2747,14 +2756,14 @@ struct WhileParam FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
   const flatbuffers::String *body_graph() const {
     return GetPointer<const flatbuffers::String *>(VT_BODY_GRAPH);
   }
-  const flatbuffers::Vector<flatbuffers::Offset<StringVec>> *aliases_inputs() const {
-    return GetPointer<const flatbuffers::Vector<flatbuffers::Offset<StringVec>> *>(VT_ALIASES_INPUTS);
+  const flatbuffers::Vector<flatbuffers::Offset<MNN::StringVec>> *aliases_inputs() const {
+    return GetPointer<const flatbuffers::Vector<flatbuffers::Offset<MNN::StringVec>> *>(VT_ALIASES_INPUTS);
   }
   const flatbuffers::Vector<flatbuffers::Offset<flatbuffers::String>> *aliases_outputs() const {
     return GetPointer<const flatbuffers::Vector<flatbuffers::Offset<flatbuffers::String>> *>(VT_ALIASES_OUTPUTS);
   }
-  const flatbuffers::Vector<flatbuffers::Offset<StringVec>> *aliases_updates() const {
-    return GetPointer<const flatbuffers::Vector<flatbuffers::Offset<StringVec>> *>(VT_ALIASES_UPDATES);
+  const flatbuffers::Vector<flatbuffers::Offset<MNN::StringVec>> *aliases_updates() const {
+    return GetPointer<const flatbuffers::Vector<flatbuffers::Offset<MNN::StringVec>> *>(VT_ALIASES_UPDATES);
   }
   bool Verify(flatbuffers::Verifier &verifier) const {
     return VerifyTableStart(verifier) &&
@@ -2779,6 +2788,7 @@ struct WhileParam FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
 };
 
 struct WhileParamBuilder {
+  typedef WhileParam Table;
   flatbuffers::FlatBufferBuilder &fbb_;
   flatbuffers::uoffset_t start_;
   void add_cond_graph(flatbuffers::Offset<flatbuffers::String> cond_graph) {
@@ -2787,20 +2797,19 @@ struct WhileParamBuilder {
   void add_body_graph(flatbuffers::Offset<flatbuffers::String> body_graph) {
     fbb_.AddOffset(WhileParam::VT_BODY_GRAPH, body_graph);
   }
-  void add_aliases_inputs(flatbuffers::Offset<flatbuffers::Vector<flatbuffers::Offset<StringVec>>> aliases_inputs) {
+  void add_aliases_inputs(flatbuffers::Offset<flatbuffers::Vector<flatbuffers::Offset<MNN::StringVec>>> aliases_inputs) {
     fbb_.AddOffset(WhileParam::VT_ALIASES_INPUTS, aliases_inputs);
   }
   void add_aliases_outputs(flatbuffers::Offset<flatbuffers::Vector<flatbuffers::Offset<flatbuffers::String>>> aliases_outputs) {
     fbb_.AddOffset(WhileParam::VT_ALIASES_OUTPUTS, aliases_outputs);
   }
-  void add_aliases_updates(flatbuffers::Offset<flatbuffers::Vector<flatbuffers::Offset<StringVec>>> aliases_updates) {
+  void add_aliases_updates(flatbuffers::Offset<flatbuffers::Vector<flatbuffers::Offset<MNN::StringVec>>> aliases_updates) {
     fbb_.AddOffset(WhileParam::VT_ALIASES_UPDATES, aliases_updates);
   }
   explicit WhileParamBuilder(flatbuffers::FlatBufferBuilder &_fbb)
         : fbb_(_fbb) {
     start_ = fbb_.StartTable();
   }
-  WhileParamBuilder &operator=(const WhileParamBuilder &);
   flatbuffers::Offset<WhileParam> Finish() {
     const auto end = fbb_.EndTable(start_);
     auto o = flatbuffers::Offset<WhileParam>(end);
@@ -2812,9 +2821,9 @@ inline flatbuffers::Offset<WhileParam> CreateWhileParam(
     flatbuffers::FlatBufferBuilder &_fbb,
     flatbuffers::Offset<flatbuffers::String> cond_graph = 0,
     flatbuffers::Offset<flatbuffers::String> body_graph = 0,
-    flatbuffers::Offset<flatbuffers::Vector<flatbuffers::Offset<StringVec>>> aliases_inputs = 0,
+    flatbuffers::Offset<flatbuffers::Vector<flatbuffers::Offset<MNN::StringVec>>> aliases_inputs = 0,
     flatbuffers::Offset<flatbuffers::Vector<flatbuffers::Offset<flatbuffers::String>>> aliases_outputs = 0,
-    flatbuffers::Offset<flatbuffers::Vector<flatbuffers::Offset<StringVec>>> aliases_updates = 0) {
+    flatbuffers::Offset<flatbuffers::Vector<flatbuffers::Offset<MNN::StringVec>>> aliases_updates = 0) {
   WhileParamBuilder builder_(_fbb);
   builder_.add_aliases_updates(aliases_updates);
   builder_.add_aliases_outputs(aliases_outputs);
@@ -2828,14 +2837,14 @@ inline flatbuffers::Offset<WhileParam> CreateWhileParamDirect(
     flatbuffers::FlatBufferBuilder &_fbb,
     const char *cond_graph = nullptr,
     const char *body_graph = nullptr,
-    const std::vector<flatbuffers::Offset<StringVec>> *aliases_inputs = nullptr,
+    const std::vector<flatbuffers::Offset<MNN::StringVec>> *aliases_inputs = nullptr,
     const std::vector<flatbuffers::Offset<flatbuffers::String>> *aliases_outputs = nullptr,
-    const std::vector<flatbuffers::Offset<StringVec>> *aliases_updates = nullptr) {
+    const std::vector<flatbuffers::Offset<MNN::StringVec>> *aliases_updates = nullptr) {
   auto cond_graph__ = cond_graph ? _fbb.CreateString(cond_graph) : 0;
   auto body_graph__ = body_graph ? _fbb.CreateString(body_graph) : 0;
-  auto aliases_inputs__ = aliases_inputs ? _fbb.CreateVector<flatbuffers::Offset<StringVec>>(*aliases_inputs) : 0;
+  auto aliases_inputs__ = aliases_inputs ? _fbb.CreateVector<flatbuffers::Offset<MNN::StringVec>>(*aliases_inputs) : 0;
   auto aliases_outputs__ = aliases_outputs ? _fbb.CreateVector<flatbuffers::Offset<flatbuffers::String>>(*aliases_outputs) : 0;
-  auto aliases_updates__ = aliases_updates ? _fbb.CreateVector<flatbuffers::Offset<StringVec>>(*aliases_updates) : 0;
+  auto aliases_updates__ = aliases_updates ? _fbb.CreateVector<flatbuffers::Offset<MNN::StringVec>>(*aliases_updates) : 0;
   return MNN::CreateWhileParam(
       _fbb,
       cond_graph__,
@@ -2849,16 +2858,15 @@ flatbuffers::Offset<WhileParam> CreateWhileParam(flatbuffers::FlatBufferBuilder
 
 struct IfParamT : public flatbuffers::NativeTable {
   typedef IfParam TableType;
-  std::string then_graph;
-  std::string else_graph;
-  std::vector<std::unique_ptr<StringVecT>> aliases_inputs;
-  std::vector<std::unique_ptr<StringVecT>> aliases_outputs;
-  IfParamT() {
-  }
+  std::string then_graph{};
+  std::string else_graph{};
+  std::vector<std::unique_ptr<MNN::StringVecT>> aliases_inputs{};
+  std::vector<std::unique_ptr<MNN::StringVecT>> aliases_outputs{};
 };
 
 struct IfParam FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
   typedef IfParamT NativeTableType;
+  typedef IfParamBuilder Builder;
   static const flatbuffers::TypeTable *MiniReflectTypeTable() {
     return IfParamTypeTable();
   }
@@ -2874,11 +2882,11 @@ struct IfParam FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
   const flatbuffers::String *else_graph() const {
     return GetPointer<const flatbuffers::String *>(VT_ELSE_GRAPH);
   }
-  const flatbuffers::Vector<flatbuffers::Offset<StringVec>> *aliases_inputs() const {
-    return GetPointer<const flatbuffers::Vector<flatbuffers::Offset<StringVec>> *>(VT_ALIASES_INPUTS);
+  const flatbuffers::Vector<flatbuffers::Offset<MNN::StringVec>> *aliases_inputs() const {
+    return GetPointer<const flatbuffers::Vector<flatbuffers::Offset<MNN::StringVec>> *>(VT_ALIASES_INPUTS);
   }
-  const flatbuffers::Vector<flatbuffers::Offset<StringVec>> *aliases_outputs() const {
-    return GetPointer<const flatbuffers::Vector<flatbuffers::Offset<StringVec>> *>(VT_ALIASES_OUTPUTS);
+  const flatbuffers::Vector<flatbuffers::Offset<MNN::StringVec>> *aliases_outputs() const {
+    return GetPointer<const flatbuffers::Vector<flatbuffers::Offset<MNN::StringVec>> *>(VT_ALIASES_OUTPUTS);
   }
   bool Verify(flatbuffers::Verifier &verifier) const {
     return VerifyTableStart(verifier) &&
@@ -2900,6 +2908,7 @@ struct IfParam FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
 };
 
 struct IfParamBuilder {
+  typedef IfParam Table;
   flatbuffers::FlatBufferBuilder &fbb_;
   flatbuffers::uoffset_t start_;
   void add_then_graph(flatbuffers::Offset<flatbuffers::String> then_graph) {
@@ -2908,17 +2917,16 @@ struct IfParamBuilder {
   void add_else_graph(flatbuffers::Offset<flatbuffers::String> else_graph) {
     fbb_.AddOffset(IfParam::VT_ELSE_GRAPH, else_graph);
   }
-  void add_aliases_inputs(flatbuffers::Offset<flatbuffers::Vector<flatbuffers::Offset<StringVec>>> aliases_inputs) {
+  void add_aliases_inputs(flatbuffers::Offset<flatbuffers::Vector<flatbuffers::Offset<MNN::StringVec>>> aliases_inputs) {
     fbb_.AddOffset(IfParam::VT_ALIASES_INPUTS, aliases_inputs);
   }
-  void add_aliases_outputs(flatbuffers::Offset<flatbuffers::Vector<flatbuffers::Offset<StringVec>>> aliases_outputs) {
+  void add_aliases_outputs(flatbuffers::Offset<flatbuffers::Vector<flatbuffers::Offset<MNN::StringVec>>> aliases_outputs) {
     fbb_.AddOffset(IfParam::VT_ALIASES_OUTPUTS, aliases_outputs);
   }
   explicit IfParamBuilder(flatbuffers::FlatBufferBuilder &_fbb)
         : fbb_(_fbb) {
     start_ = fbb_.StartTable();
   }
-  IfParamBuilder &operator=(const IfParamBuilder &);
   flatbuffers::Offset<IfParam> Finish() {
     const auto end = fbb_.EndTable(start_);
     auto o = flatbuffers::Offset<IfParam>(end);
@@ -2930,8 +2938,8 @@ inline flatbuffers::Offset<IfParam> CreateIfParam(
     flatbuffers::FlatBufferBuilder &_fbb,
     flatbuffers::Offset<flatbuffers::String> then_graph = 0,
     flatbuffers::Offset<flatbuffers::String> else_graph = 0,
-    flatbuffers::Offset<flatbuffers::Vector<flatbuffers::Offset<StringVec>>> aliases_inputs = 0,
-    flatbuffers::Offset<flatbuffers::Vector<flatbuffers::Offset<StringVec>>> aliases_outputs = 0) {
+    flatbuffers::Offset<flatbuffers::Vector<flatbuffers::Offset<MNN::StringVec>>> aliases_inputs = 0,
+    flatbuffers::Offset<flatbuffers::Vector<flatbuffers::Offset<MNN::StringVec>>> aliases_outputs = 0) {
   IfParamBuilder builder_(_fbb);
   builder_.add_aliases_outputs(aliases_outputs);
   builder_.add_aliases_inputs(aliases_inputs);
@@ -2944,12 +2952,12 @@ inline flatbuffers::Offset<IfParam> CreateIfParamDirect(
     flatbuffers::FlatBufferBuilder &_fbb,
     const char *then_graph = nullptr,
     const char *else_graph = nullptr,
-    const std::vector<flatbuffers::Offset<StringVec>> *aliases_inputs = nullptr,
-    const std::vector<flatbuffers::Offset<StringVec>> *aliases_outputs = nullptr) {
+    const std::vector<flatbuffers::Offset<MNN::StringVec>> *aliases_inputs = nullptr,
+    const std::vector<flatbuffers::Offset<MNN::StringVec>> *aliases_outputs = nullptr) {
   auto then_graph__ = then_graph ? _fbb.CreateString(then_graph) : 0;
   auto else_graph__ = else_graph ? _fbb.CreateString(else_graph) : 0;
-  auto aliases_inputs__ = aliases_inputs ? _fbb.CreateVector<flatbuffers::Offset<StringVec>>(*aliases_inputs) : 0;
-  auto aliases_outputs__ = aliases_outputs ? _fbb.CreateVector<flatbuffers::Offset<StringVec>>(*aliases_outputs) : 0;
+  auto aliases_inputs__ = aliases_inputs ? _fbb.CreateVector<flatbuffers::Offset<MNN::StringVec>>(*aliases_inputs) : 0;
+  auto aliases_outputs__ = aliases_outputs ? _fbb.CreateVector<flatbuffers::Offset<MNN::StringVec>>(*aliases_outputs) : 0;
   return MNN::CreateIfParam(
       _fbb,
       then_graph__,
@@ -2962,20 +2970,17 @@ flatbuffers::Offset<IfParam> CreateIfParam(flatbuffers::FlatBufferBuilder &_fbb,
 
 struct OpT : public flatbuffers::NativeTable {
   typedef Op TableType;
-  std::vector<int32_t> inputIndexes;
-  OpParameterUnion main;
-  std::string name;
-  std::vector<int32_t> outputIndexes;
-  OpType type;
-  MNN_DATA_FORMAT defaultDimentionFormat;
-  OpT()
-      : type(OpType_AbsVal),
-        defaultDimentionFormat(MNN_DATA_FORMAT_NHWC) {
-  }
+  std::vector<int32_t> inputIndexes{};
+  MNN::OpParameterUnion main{};
+  std::string name{};
+  std::vector<int32_t> outputIndexes{};
+  MNN::OpType type = MNN::OpType_AbsVal;
+  MNN::MNN_DATA_FORMAT defaultDimentionFormat = MNN::MNN_DATA_FORMAT_NHWC;
 };
 
 struct Op FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
   typedef OpT NativeTableType;
+  typedef OpBuilder Builder;
   static const flatbuffers::TypeTable *MiniReflectTypeTable() {
     return OpTypeTable();
   }
@@ -2991,276 +2996,276 @@ struct Op FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
   const flatbuffers::Vector<int32_t> *inputIndexes() const {
     return GetPointer<const flatbuffers::Vector<int32_t> *>(VT_INPUTINDEXES);
   }
-  OpParameter main_type() const {
-    return static_cast<OpParameter>(GetField<uint8_t>(VT_MAIN_TYPE, 0));
+  MNN::OpParameter main_type() const {
+    return static_cast<MNN::OpParameter>(GetField<uint8_t>(VT_MAIN_TYPE, 0));
   }
   const void *main() const {
     return GetPointer<const void *>(VT_MAIN);
   }
   template<typename T> const T *main_as() const;
-  const QuantizedAdd *main_as_QuantizedAdd() const {
-    return main_type() == OpParameter_QuantizedAdd ? static_cast<const QuantizedAdd *>(main()) : nullptr;
+  const MNN::QuantizedAdd *main_as_QuantizedAdd() const {
+    return main_type() == MNN::OpParameter_QuantizedAdd ? static_cast<const MNN::QuantizedAdd *>(main()) : nullptr;
   }
-  const ArgMax *main_as_ArgMax() const {
-    return main_type() == OpParameter_ArgMax ? static_cast<const ArgMax *>(main()) : nullptr;
+  const MNN::ArgMax *main_as_ArgMax() const {
+    return main_type() == MNN::OpParameter_ArgMax ? static_cast<const MNN::ArgMax *>(main()) : nullptr;
   }
-  const AsString *main_as_AsString() const {
-    return main_type() == OpParameter_AsString ? static_cast<const AsString *>(main()) : nullptr;
+  const MNN::AsString *main_as_AsString() const {
+    return main_type() == MNN::OpParameter_AsString ? static_cast<const MNN::AsString *>(main()) : nullptr;
   }
-  const Axis *main_as_Axis() const {
-    return main_type() == OpParameter_Axis ? static_cast<const Axis *>(main()) : nullptr;
+  const MNN::Axis *main_as_Axis() const {
+    return main_type() == MNN::OpParameter_Axis ? static_cast<const MNN::Axis *>(main()) : nullptr;
   }
-  const BatchNorm *main_as_BatchNorm() const {
-    return main_type() == OpParameter_BatchNorm ? static_cast<const BatchNorm *>(main()) : nullptr;
+  const MNN::BatchNorm *main_as_BatchNorm() const {
+    return main_type() == MNN::OpParameter_BatchNorm ? static_cast<const MNN::BatchNorm *>(main()) : nullptr;
   }
-  const BinaryOp *main_as_BinaryOp() const {
-    return main_type() == OpParameter_BinaryOp ? static_cast<const BinaryOp *>(main()) : nullptr;
+  const MNN::BinaryOp *main_as_BinaryOp() const {
+    return main_type() == MNN::OpParameter_BinaryOp ? static_cast<const MNN::BinaryOp *>(main()) : nullptr;
   }
-  const Blob *main_as_Blob() const {
-    return main_type() == OpParameter_Blob ? static_cast<const Blob *>(main()) : nullptr;
+  const MNN::Blob *main_as_Blob() const {
+    return main_type() == MNN::OpParameter_Blob ? static_cast<const MNN::Blob *>(main()) : nullptr;
   }
-  const CastParam *main_as_CastParam() const {
-    return main_type() == OpParameter_CastParam ? static_cast<const CastParam *>(main()) : nullptr;
+  const MNN::CastParam *main_as_CastParam() const {
+    return main_type() == MNN::OpParameter_CastParam ? static_cast<const MNN::CastParam *>(main()) : nullptr;
   }
-  const Convolution2D *main_as_Convolution2D() const {
-    return main_type() == OpParameter_Convolution2D ? static_cast<const Convolution2D *>(main()) : nullptr;
+  const MNN::Convolution2D *main_as_Convolution2D() const {
+    return main_type() == MNN::OpParameter_Convolution2D ? static_cast<const MNN::Convolution2D *>(main()) : nullptr;
   }
-  const Crop *main_as_Crop() const {
-    return main_type() == OpParameter_Crop ? static_cast<const Crop *>(main()) : nullptr;
+  const MNN::Crop *main_as_Crop() const {
+    return main_type() == MNN::OpParameter_Crop ? static_cast<const MNN::Crop *>(main()) : nullptr;
   }
-  const CropAndResize *main_as_CropAndResize() const {
-    return main_type() == OpParameter_CropAndResize ? static_cast<const CropAndResize *>(main()) : nullptr;
+  const MNN::CropAndResize *main_as_CropAndResize() const {
+    return main_type() == MNN::OpParameter_CropAndResize ? static_cast<const MNN::CropAndResize *>(main()) : nullptr;
   }
-  const Dequantize *main_as_Dequantize() const {
-    return main_type() == OpParameter_Dequantize ? static_cast<const Dequantize *>(main()) : nullptr;
+  const MNN::Dequantize *main_as_Dequantize() const {
+    return main_type() == MNN::OpParameter_Dequantize ? static_cast<const MNN::Dequantize *>(main()) : nullptr;
   }
-  const DetectionOutput *main_as_DetectionOutput() const {
-    return main_type() == OpParameter_DetectionOutput ? static_cast<const DetectionOutput *>(main()) : nullptr;
+  const MNN::DetectionOutput *main_as_DetectionOutput() const {
+    return main_type() == MNN::OpParameter_DetectionOutput ? static_cast<const MNN::DetectionOutput *>(main()) : nullptr;
   }
-  const Eltwise *main_as_Eltwise() const {
-    return main_type() == OpParameter_Eltwise ? static_cast<const Eltwise *>(main()) : nullptr;
+  const MNN::Eltwise *main_as_Eltwise() const {
+    return main_type() == MNN::OpParameter_Eltwise ? static_cast<const MNN::Eltwise *>(main()) : nullptr;
   }
-  const ExpandDims *main_as_ExpandDims() const {
-    return main_type() == OpParameter_ExpandDims ? static_cast<const ExpandDims *>(main()) : nullptr;
+  const MNN::ExpandDims *main_as_ExpandDims() const {
+    return main_type() == MNN::OpParameter_ExpandDims ? static_cast<const MNN::ExpandDims *>(main()) : nullptr;
   }
-  const Fill *main_as_Fill() const {
-    return main_type() == OpParameter_Fill ? static_cast<const Fill *>(main()) : nullptr;
+  const MNN::Fill *main_as_Fill() const {
+    return main_type() == MNN::OpParameter_Fill ? static_cast<const MNN::Fill *>(main()) : nullptr;
   }
-  const Flatten *main_as_Flatten() const {
-    return main_type() == OpParameter_Flatten ? static_cast<const Flatten *>(main()) : nullptr;
+  const MNN::Flatten *main_as_Flatten() const {
+    return main_type() == MNN::OpParameter_Flatten ? static_cast<const MNN::Flatten *>(main()) : nullptr;
   }
-  const Gather *main_as_Gather() const {
-    return main_type() == OpParameter_Gather ? static_cast<const Gather *>(main()) : nullptr;
+  const MNN::Gather *main_as_Gather() const {
+    return main_type() == MNN::OpParameter_Gather ? static_cast<const MNN::Gather *>(main()) : nullptr;
   }
-  const GatherV2 *main_as_GatherV2() const {
-    return main_type() == OpParameter_GatherV2 ? static_cast<const GatherV2 *>(main()) : nullptr;
+  const MNN::GatherV2 *main_as_GatherV2() const {
+    return main_type() == MNN::OpParameter_GatherV2 ? static_cast<const MNN::GatherV2 *>(main()) : nullptr;
   }
-  const InnerProduct *main_as_InnerProduct() const {
-    return main_type() == OpParameter_InnerProduct ? static_cast<const InnerProduct *>(main()) : nullptr;
+  const MNN::InnerProduct *main_as_InnerProduct() const {
+    return main_type() == MNN::OpParameter_InnerProduct ? static_cast<const MNN::InnerProduct *>(main()) : nullptr;
   }
-  const Input *main_as_Input() const {
-    return main_type() == OpParameter_Input ? static_cast<const Input *>(main()) : nullptr;
+  const MNN::Input *main_as_Input() const {
+    return main_type() == MNN::OpParameter_Input ? static_cast<const MNN::Input *>(main()) : nullptr;
   }
-  const Interp *main_as_Interp() const {
-    return main_type() == OpParameter_Interp ? static_cast<const Interp *>(main()) : nullptr;
+  const MNN::Interp *main_as_Interp() const {
+    return main_type() == MNN::OpParameter_Interp ? static_cast<const MNN::Interp *>(main()) : nullptr;
   }
-  const LRN *main_as_LRN() const {
-    return main_type() == OpParameter_LRN ? static_cast<const LRN *>(main()) : nullptr;
+  const MNN::LRN *main_as_LRN() const {
+    return main_type() == MNN::OpParameter_LRN ? static_cast<const MNN::LRN *>(main()) : nullptr;
   }
-  const LSTM *main_as_LSTM() const {
-    return main_type() == OpParameter_LSTM ? static_cast<const LSTM *>(main()) : nullptr;
+  const MNN::LSTM *main_as_LSTM() const {
+    return main_type() == MNN::OpParameter_LSTM ? static_cast<const MNN::LSTM *>(main()) : nullptr;
   }
-  const MatMul *main_as_MatMul() const {
-    return main_type() == OpParameter_MatMul ? static_cast<const MatMul *>(main()) : nullptr;
+  const MNN::MatMul *main_as_MatMul() const {
+    return main_type() == MNN::OpParameter_MatMul ? static_cast<const MNN::MatMul *>(main()) : nullptr;
   }
-  const NonMaxSuppressionV2 *main_as_NonMaxSuppressionV2() const {
-    return main_type() == OpParameter_NonMaxSuppressionV2 ? static_cast<const NonMaxSuppressionV2 *>(main()) : nullptr;
+  const MNN::NonMaxSuppressionV2 *main_as_NonMaxSuppressionV2() const {
+    return main_type() == MNN::OpParameter_NonMaxSuppressionV2 ? static_cast<const MNN::NonMaxSuppressionV2 *>(main()) : nullptr;
   }
-  const Normalize *main_as_Normalize() const {
-    return main_type() == OpParameter_Normalize ? static_cast<const Normalize *>(main()) : nullptr;
+  const MNN::Normalize *main_as_Normalize() const {
+    return main_type() == MNN::OpParameter_Normalize ? static_cast<const MNN::Normalize *>(main()) : nullptr;
   }
-  const PackParam *main_as_PackParam() const {
-    return main_type() == OpParameter_PackParam ? static_cast<const PackParam *>(main()) : nullptr;
+  const MNN::PackParam *main_as_PackParam() const {
+    return main_type() == MNN::OpParameter_PackParam ? static_cast<const MNN::PackParam *>(main()) : nullptr;
   }
-  const Permute *main_as_Permute() const {
-    return main_type() == OpParameter_Permute ? static_cast<const Permute *>(main()) : nullptr;
+  const MNN::Permute *main_as_Permute() const {
+    return main_type() == MNN::OpParameter_Permute ? static_cast<const MNN::Permute *>(main()) : nullptr;
   }
-  const Plugin *main_as_Plugin() const {
-    return main_type() == OpParameter_Plugin ? static_cast<const Plugin *>(main()) : nullptr;
+  const MNN::Plugin *main_as_Plugin() const {
+    return main_type() == MNN::OpParameter_Plugin ? static_cast<const MNN::Plugin *>(main()) : nullptr;
   }
-  const Pool *main_as_Pool() const {
-    return main_type() == OpParameter_Pool ? static_cast<const Pool *>(main()) : nullptr;
+  const MNN::Pool *main_as_Pool() const {
+    return main_type() == MNN::OpParameter_Pool ? static_cast<const MNN::Pool *>(main()) : nullptr;
   }
-  const PRelu *main_as_PRelu() const {
-    return main_type() == OpParameter_PRelu ? static_cast<const PRelu *>(main()) : nullptr;
+  const MNN::PRelu *main_as_PRelu() const {
+    return main_type() == MNN::OpParameter_PRelu ? static_cast<const MNN::PRelu *>(main()) : nullptr;
   }
-  const PriorBox *main_as_PriorBox() const {
-    return main_type() == OpParameter_PriorBox ? static_cast<const PriorBox *>(main()) : nullptr;
+  const MNN::PriorBox *main_as_PriorBox() const {
+    return main_type() == MNN::OpParameter_PriorBox ? static_cast<const MNN::PriorBox *>(main()) : nullptr;
   }
-  const Proposal *main_as_Proposal() const {
-    return main_type() == OpParameter_Proposal ? static_cast<const Proposal *>(main()) : nullptr;
+  const MNN::Proposal *main_as_Proposal() const {
+    return main_type() == MNN::OpParameter_Proposal ? static_cast<const MNN::Proposal *>(main()) : nullptr;
   }
-  const QuantizedAvgPool *main_as_QuantizedAvgPool() const {
-    return main_type() == OpParameter_QuantizedAvgPool ? static_cast<const QuantizedAvgPool *>(main()) : nullptr;
+  const MNN::QuantizedAvgPool *main_as_QuantizedAvgPool() const {
+    return main_type() == MNN::OpParameter_QuantizedAvgPool ? static_cast<const MNN::QuantizedAvgPool *>(main()) : nullptr;
   }
-  const QuantizedBiasAdd *main_as_QuantizedBiasAdd() const {
-    return main_type() == OpParameter_QuantizedBiasAdd ? static_cast<const QuantizedBiasAdd *>(main()) : nullptr;
+  const MNN::QuantizedBiasAdd *main_as_QuantizedBiasAdd() const {
+    return main_type() == MNN::OpParameter_QuantizedBiasAdd ? static_cast<const MNN::QuantizedBiasAdd *>(main()) : nullptr;
   }
-  const QuantizedConcat *main_as_QuantizedConcat() const {
-    return main_type() == OpParameter_QuantizedConcat ? static_cast<const QuantizedConcat *>(main()) : nullptr;
+  const MNN::QuantizedConcat *main_as_QuantizedConcat() const {
+    return main_type() == MNN::OpParameter_QuantizedConcat ? static_cast<const MNN::QuantizedConcat *>(main()) : nullptr;
   }
-  const QuantizedLogistic *main_as_QuantizedLogistic() const {
-    return main_type() == OpParameter_QuantizedLogistic ? static_cast<const QuantizedLogistic *>(main()) : nullptr;
+  const MNN::QuantizedLogistic *main_as_QuantizedLogistic() const {
+    return main_type() == MNN::OpParameter_QuantizedLogistic ? static_cast<const MNN::QuantizedLogistic *>(main()) : nullptr;
   }
-  const QuantizedMatMul *main_as_QuantizedMatMul() const {
-    return main_type() == OpParameter_QuantizedMatMul ? static_cast<const QuantizedMatMul *>(main()) : nullptr;
+  const MNN::QuantizedMatMul *main_as_QuantizedMatMul() const {
+    return main_type() == MNN::OpParameter_QuantizedMatMul ? static_cast<const MNN::QuantizedMatMul *>(main()) : nullptr;
   }
-  const QuantizedMaxPool *main_as_QuantizedMaxPool() const {
-    return main_type() == OpParameter_QuantizedMaxPool ? static_cast<const QuantizedMaxPool *>(main()) : nullptr;
+  const MNN::QuantizedMaxPool *main_as_QuantizedMaxPool() const {
+    return main_type() == MNN::OpParameter_QuantizedMaxPool ? static_cast<const MNN::QuantizedMaxPool *>(main()) : nullptr;
   }
-  const QuantizedRelu *main_as_QuantizedRelu() const {
-    return main_type() == OpParameter_QuantizedRelu ? static_cast<const QuantizedRelu *>(main()) : nullptr;
+  const MNN::QuantizedRelu *main_as_QuantizedRelu() const {
+    return main_type() == MNN::OpParameter_QuantizedRelu ? static_cast<const MNN::QuantizedRelu *>(main()) : nullptr;
   }
-  const QuantizedRelu6 *main_as_QuantizedRelu6() const {
-    return main_type() == OpParameter_QuantizedRelu6 ? static_cast<const QuantizedRelu6 *>(main()) : nullptr;
+  const MNN::QuantizedRelu6 *main_as_QuantizedRelu6() const {
+    return main_type() == MNN::OpParameter_QuantizedRelu6 ? static_cast<const MNN::QuantizedRelu6 *>(main()) : nullptr;
   }
-  const QuantizedReshape *main_as_QuantizedReshape() const {
-    return main_type() == OpParameter_QuantizedReshape ? static_cast<const QuantizedReshape *>(main()) : nullptr;
+  const MNN::QuantizedReshape *main_as_QuantizedReshape() const {
+    return main_type() == MNN::OpParameter_QuantizedReshape ? static_cast<const MNN::QuantizedReshape *>(main()) : nullptr;
   }
-  const QuantizedSoftmax *main_as_QuantizedSoftmax() const {
-    return main_type() == OpParameter_QuantizedSoftmax ? static_cast<const QuantizedSoftmax *>(main()) : nullptr;
+  const MNN::QuantizedSoftmax *main_as_QuantizedSoftmax() const {
+    return main_type() == MNN::OpParameter_QuantizedSoftmax ? static_cast<const MNN::QuantizedSoftmax *>(main()) : nullptr;
   }
-  const QuantizeMaxMin *main_as_QuantizeMaxMin() const {
-    return main_type() == OpParameter_QuantizeMaxMin ? static_cast<const QuantizeMaxMin *>(main()) : nullptr;
+  const MNN::QuantizeMaxMin *main_as_QuantizeMaxMin() const {
+    return main_type() == MNN::OpParameter_QuantizeMaxMin ? static_cast<const MNN::QuantizeMaxMin *>(main()) : nullptr;
   }
-  const QuantizeV2 *main_as_QuantizeV2() const {
-    return main_type() == OpParameter_QuantizeV2 ? static_cast<const QuantizeV2 *>(main()) : nullptr;
+  const MNN::QuantizeV2 *main_as_QuantizeV2() const {
+    return main_type() == MNN::OpParameter_QuantizeV2 ? static_cast<const MNN::QuantizeV2 *>(main()) : nullptr;
   }
-  const Range *main_as_Range() const {
-    return main_type() == OpParameter_Range ? static_cast<const Range *>(main()) : nullptr;
+  const MNN::Range *main_as_Range() const {
+    return main_type() == MNN::OpParameter_Range ? static_cast<const MNN::Range *>(main()) : nullptr;
   }
-  const Rank *main_as_Rank() const {
-    return main_type() == OpParameter_Rank ? static_cast<const Rank *>(main()) : nullptr;
+  const MNN::Rank *main_as_Rank() const {
+    return main_type() == MNN::OpParameter_Rank ? static_cast<const MNN::Rank *>(main()) : nullptr;
   }
-  const ReduceJoin *main_as_ReduceJoin() const {
-    return main_type() == OpParameter_ReduceJoin ? static_cast<const ReduceJoin *>(main()) : nullptr;
+  const MNN::ReduceJoin *main_as_ReduceJoin() const {
+    return main_type() == MNN::OpParameter_ReduceJoin ? static_cast<const MNN::ReduceJoin *>(main()) : nullptr;
   }
-  const ReductionParam *main_as_ReductionParam() const {
-    return main_type() == OpParameter_ReductionParam ? static_cast<const ReductionParam *>(main()) : nullptr;
+  const MNN::ReductionParam *main_as_ReductionParam() const {
+    return main_type() == MNN::OpParameter_ReductionParam ? static_cast<const MNN::ReductionParam *>(main()) : nullptr;
   }
-  const Relu *main_as_Relu() const {
-    return main_type() == OpParameter_Relu ? static_cast<const Relu *>(main()) : nullptr;
+  const MNN::Relu *main_as_Relu() const {
+    return main_type() == MNN::OpParameter_Relu ? static_cast<const MNN::Relu *>(main()) : nullptr;
   }
-  const Relu6 *main_as_Relu6() const {
-    return main_type() == OpParameter_Relu6 ? static_cast<const Relu6 *>(main()) : nullptr;
+  const MNN::Relu6 *main_as_Relu6() const {
+    return main_type() == MNN::OpParameter_Relu6 ? static_cast<const MNN::Relu6 *>(main()) : nullptr;
   }
-  const RequantizationRange *main_as_RequantizationRange() const {
-    return main_type() == OpParameter_RequantizationRange ? static_cast<const RequantizationRange *>(main()) : nullptr;
+  const MNN::RequantizationRange *main_as_RequantizationRange() const {
+    return main_type() == MNN::OpParameter_RequantizationRange ? static_cast<const MNN::RequantizationRange *>(main()) : nullptr;
   }
-  const Requantize *main_as_Requantize() const {
-    return main_type() == OpParameter_Requantize ? static_cast<const Requantize *>(main()) : nullptr;
+  const MNN::Requantize *main_as_Requantize() const {
+    return main_type() == MNN::OpParameter_Requantize ? static_cast<const MNN::Requantize *>(main()) : nullptr;
   }
-  const Reshape *main_as_Reshape() const {
-    return main_type() == OpParameter_Reshape ? static_cast<const Reshape *>(main()) : nullptr;
+  const MNN::Reshape *main_as_Reshape() const {
+    return main_type() == MNN::OpParameter_Reshape ? static_cast<const MNN::Reshape *>(main()) : nullptr;
   }
-  const Resize *main_as_Resize() const {
-    return main_type() == OpParameter_Resize ? static_cast<const Resize *>(main()) : nullptr;
+  const MNN::Resize *main_as_Resize() const {
+    return main_type() == MNN::OpParameter_Resize ? static_cast<const MNN::Resize *>(main()) : nullptr;
   }
-  const RoiPooling *main_as_RoiPooling() const {
-    return main_type() == OpParameter_RoiPooling ? static_cast<const RoiPooling *>(main()) : nullptr;
+  const MNN::RoiPooling *main_as_RoiPooling() const {
+    return main_type() == MNN::OpParameter_RoiPooling ? static_cast<const MNN::RoiPooling *>(main()) : nullptr;
   }
-  const Scale *main_as_Scale() const {
-    return main_type() == OpParameter_Scale ? static_cast<const Scale *>(main()) : nullptr;
+  const MNN::Scale *main_as_Scale() const {
+    return main_type() == MNN::OpParameter_Scale ? static_cast<const MNN::Scale *>(main()) : nullptr;
   }
-  const Selu *main_as_Selu() const {
-    return main_type() == OpParameter_Selu ? static_cast<const Selu *>(main()) : nullptr;
+  const MNN::Selu *main_as_Selu() const {
+    return main_type() == MNN::OpParameter_Selu ? static_cast<const MNN::Selu *>(main()) : nullptr;
   }
-  const Size *main_as_Size() const {
-    return main_type() == OpParameter_Size ? static_cast<const Size *>(main()) : nullptr;
+  const MNN::Size *main_as_Size() const {
+    return main_type() == MNN::OpParameter_Size ? static_cast<const MNN::Size *>(main()) : nullptr;
   }
-  const Slice *main_as_Slice() const {
-    return main_type() == OpParameter_Slice ? static_cast<const Slice *>(main()) : nullptr;
+  const MNN::Slice *main_as_Slice() const {
+    return main_type() == MNN::OpParameter_Slice ? static_cast<const MNN::Slice *>(main()) : nullptr;
   }
-  const SliceTf *main_as_SliceTf() const {
-    return main_type() == OpParameter_SliceTf ? static_cast<const SliceTf *>(main()) : nullptr;
+  const MNN::SliceTf *main_as_SliceTf() const {
+    return main_type() == MNN::OpParameter_SliceTf ? static_cast<const MNN::SliceTf *>(main()) : nullptr;
   }
-  const SpaceBatch *main_as_SpaceBatch() const {
-    return main_type() == OpParameter_SpaceBatch ? static_cast<const SpaceBatch *>(main()) : nullptr;
+  const MNN::SpaceBatch *main_as_SpaceBatch() const {
+    return main_type() == MNN::OpParameter_SpaceBatch ? static_cast<const MNN::SpaceBatch *>(main()) : nullptr;
   }
-  const SqueezeParam *main_as_SqueezeParam() const {
-    return main_type() == OpParameter_SqueezeParam ? static_cast<const SqueezeParam *>(main()) : nullptr;
+  const MNN::SqueezeParam *main_as_SqueezeParam() const {
+    return main_type() == MNN::OpParameter_SqueezeParam ? static_cast<const MNN::SqueezeParam *>(main()) : nullptr;
   }
-  const StridedSliceParam *main_as_StridedSliceParam() const {
-    return main_type() == OpParameter_StridedSliceParam ? static_cast<const StridedSliceParam *>(main()) : nullptr;
+  const MNN::StridedSliceParam *main_as_StridedSliceParam() const {
+    return main_type() == MNN::OpParameter_StridedSliceParam ? static_cast<const MNN::StridedSliceParam *>(main()) : nullptr;
   }
-  const TensorConvertInfo *main_as_TensorConvertInfo() const {
-    return main_type() == OpParameter_TensorConvertInfo ? static_cast<const TensorConvertInfo *>(main()) : nullptr;
+  const MNN::TensorConvertInfo *main_as_TensorConvertInfo() const {
+    return main_type() == MNN::OpParameter_TensorConvertInfo ? static_cast<const MNN::TensorConvertInfo *>(main()) : nullptr;
   }
-  const TfQuantizedConv2D *main_as_TfQuantizedConv2D() const {
-    return main_type() == OpParameter_TfQuantizedConv2D ? static_cast<const TfQuantizedConv2D *>(main()) : nullptr;
+  const MNN::TfQuantizedConv2D *main_as_TfQuantizedConv2D() const {
+    return main_type() == MNN::OpParameter_TfQuantizedConv2D ? static_cast<const MNN::TfQuantizedConv2D *>(main()) : nullptr;
   }
-  const TopKV2 *main_as_TopKV2() const {
-    return main_type() == OpParameter_TopKV2 ? static_cast<const TopKV2 *>(main()) : nullptr;
+  const MNN::TopKV2 *main_as_TopKV2() const {
+    return main_type() == MNN::OpParameter_TopKV2 ? static_cast<const MNN::TopKV2 *>(main()) : nullptr;
   }
-  const Transpose *main_as_Transpose() const {
-    return main_type() == OpParameter_Transpose ? static_cast<const Transpose *>(main()) : nullptr;
+  const MNN::Transpose *main_as_Transpose() const {
+    return main_type() == MNN::OpParameter_Transpose ? static_cast<const MNN::Transpose *>(main()) : nullptr;
   }
-  const UnaryOp *main_as_UnaryOp() const {
-    return main_type() == OpParameter_UnaryOp ? static_cast<const UnaryOp *>(main()) : nullptr;
+  const MNN::UnaryOp *main_as_UnaryOp() const {
+    return main_type() == MNN::OpParameter_UnaryOp ? static_cast<const MNN::UnaryOp *>(main()) : nullptr;
   }
-  const MomentsParam *main_as_MomentsParam() const {
-    return main_type() == OpParameter_MomentsParam ? static_cast<const MomentsParam *>(main()) : nullptr;
+  const MNN::MomentsParam *main_as_MomentsParam() const {
+    return main_type() == MNN::OpParameter_MomentsParam ? static_cast<const MNN::MomentsParam *>(main()) : nullptr;
   }
-  const RNNParam *main_as_RNNParam() const {
-    return main_type() == OpParameter_RNNParam ? static_cast<const RNNParam *>(main()) : nullptr;
+  const MNN::RNNParam *main_as_RNNParam() const {
+    return main_type() == MNN::OpParameter_RNNParam ? static_cast<const MNN::RNNParam *>(main()) : nullptr;
   }
-  const BatchMatMulParam *main_as_BatchMatMulParam() const {
-    return main_type() == OpParameter_BatchMatMulParam ? static_cast<const BatchMatMulParam *>(main()) : nullptr;
+  const MNN::BatchMatMulParam *main_as_BatchMatMulParam() const {
+    return main_type() == MNN::OpParameter_BatchMatMulParam ? static_cast<const MNN::BatchMatMulParam *>(main()) : nullptr;
   }
-  const QuantizedFloatParam *main_as_QuantizedFloatParam() const {
-    return main_type() == OpParameter_QuantizedFloatParam ? static_cast<const QuantizedFloatParam *>(main()) : nullptr;
+  const MNN::QuantizedFloatParam *main_as_QuantizedFloatParam() const {
+    return main_type() == MNN::OpParameter_QuantizedFloatParam ? static_cast<const MNN::QuantizedFloatParam *>(main()) : nullptr;
   }
-  const DepthSpaceParam *main_as_DepthSpaceParam() const {
-    return main_type() == OpParameter_DepthSpaceParam ? static_cast<const DepthSpaceParam *>(main()) : nullptr;
+  const MNN::DepthSpaceParam *main_as_DepthSpaceParam() const {
+    return main_type() == MNN::OpParameter_DepthSpaceParam ? static_cast<const MNN::DepthSpaceParam *>(main()) : nullptr;
   }
-  const EltwiseInt8 *main_as_EltwiseInt8() const {
-    return main_type() == OpParameter_EltwiseInt8 ? static_cast<const EltwiseInt8 *>(main()) : nullptr;
+  const MNN::EltwiseInt8 *main_as_EltwiseInt8() const {
+    return main_type() == MNN::OpParameter_EltwiseInt8 ? static_cast<const MNN::EltwiseInt8 *>(main()) : nullptr;
   }
-  const ReverseSequenceParam *main_as_ReverseSequenceParam() const {
-    return main_type() == OpParameter_ReverseSequenceParam ? static_cast<const ReverseSequenceParam *>(main()) : nullptr;
+  const MNN::ReverseSequenceParam *main_as_ReverseSequenceParam() const {
+    return main_type() == MNN::OpParameter_ReverseSequenceParam ? static_cast<const MNN::ReverseSequenceParam *>(main()) : nullptr;
   }
-  const Extra *main_as_Extra() const {
-    return main_type() == OpParameter_Extra ? static_cast<const Extra *>(main()) : nullptr;
+  const MNN::Extra *main_as_Extra() const {
+    return main_type() == MNN::OpParameter_Extra ? static_cast<const MNN::Extra *>(main()) : nullptr;
   }
-  const Pool3D *main_as_Pool3D() const {
-    return main_type() == OpParameter_Pool3D ? static_cast<const Pool3D *>(main()) : nullptr;
+  const MNN::Pool3D *main_as_Pool3D() const {
+    return main_type() == MNN::OpParameter_Pool3D ? static_cast<const MNN::Pool3D *>(main()) : nullptr;
   }
-  const Convolution3D *main_as_Convolution3D() const {
-    return main_type() == OpParameter_Convolution3D ? static_cast<const Convolution3D *>(main()) : nullptr;
+  const MNN::Convolution3D *main_as_Convolution3D() const {
+    return main_type() == MNN::OpParameter_Convolution3D ? static_cast<const MNN::Convolution3D *>(main()) : nullptr;
   }
-  const ELU *main_as_ELU() const {
-    return main_type() == OpParameter_ELU ? static_cast<const ELU *>(main()) : nullptr;
+  const MNN::ELU *main_as_ELU() const {
+    return main_type() == MNN::OpParameter_ELU ? static_cast<const MNN::ELU *>(main()) : nullptr;
   }
-  const DetectionPostProcessParam *main_as_DetectionPostProcessParam() const {
-    return main_type() == OpParameter_DetectionPostProcessParam ? static_cast<const DetectionPostProcessParam *>(main()) : nullptr;
+  const MNN::DetectionPostProcessParam *main_as_DetectionPostProcessParam() const {
+    return main_type() == MNN::OpParameter_DetectionPostProcessParam ? static_cast<const MNN::DetectionPostProcessParam *>(main()) : nullptr;
   }
-  const OneHotParam *main_as_OneHotParam() const {
-    return main_type() == OpParameter_OneHotParam ? static_cast<const OneHotParam *>(main()) : nullptr;
+  const MNN::OneHotParam *main_as_OneHotParam() const {
+    return main_type() == MNN::OpParameter_OneHotParam ? static_cast<const MNN::OneHotParam *>(main()) : nullptr;
   }
-  const PadParam *main_as_PadParam() const {
-    return main_type() == OpParameter_PadParam ? static_cast<const PadParam *>(main()) : nullptr;
+  const MNN::PadParam *main_as_PadParam() const {
+    return main_type() == MNN::OpParameter_PadParam ? static_cast<const MNN::PadParam *>(main()) : nullptr;
   }
-  const WhileParam *main_as_WhileParam() const {
-    return main_type() == OpParameter_WhileParam ? static_cast<const WhileParam *>(main()) : nullptr;
+  const MNN::WhileParam *main_as_WhileParam() const {
+    return main_type() == MNN::OpParameter_WhileParam ? static_cast<const MNN::WhileParam *>(main()) : nullptr;
   }
-  const IfParam *main_as_IfParam() const {
-    return main_type() == OpParameter_IfParam ? static_cast<const IfParam *>(main()) : nullptr;
+  const MNN::IfParam *main_as_IfParam() const {
+    return main_type() == MNN::OpParameter_IfParam ? static_cast<const MNN::IfParam *>(main()) : nullptr;
   }
-  const RandomUniform *main_as_RandomUniform() const {
-    return main_type() == OpParameter_RandomUniform ? static_cast<const RandomUniform *>(main()) : nullptr;
+  const MNN::RandomUniform *main_as_RandomUniform() const {
+    return main_type() == MNN::OpParameter_RandomUniform ? static_cast<const MNN::RandomUniform *>(main()) : nullptr;
   }
-  const LayerNorm *main_as_LayerNorm() const {
-    return main_type() == OpParameter_LayerNorm ? static_cast<const LayerNorm *>(main()) : nullptr;
+  const MNN::LayerNorm *main_as_LayerNorm() const {
+    return main_type() == MNN::OpParameter_LayerNorm ? static_cast<const MNN::LayerNorm *>(main()) : nullptr;
   }
   const flatbuffers::String *name() const {
     return GetPointer<const flatbuffers::String *>(VT_NAME);
@@ -3268,11 +3273,11 @@ struct Op FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
   const flatbuffers::Vector<int32_t> *outputIndexes() const {
     return GetPointer<const flatbuffers::Vector<int32_t> *>(VT_OUTPUTINDEXES);
   }
-  OpType type() const {
-    return static_cast<OpType>(GetField<int32_t>(VT_TYPE, 0));
+  MNN::OpType type() const {
+    return static_cast<MNN::OpType>(GetField<int32_t>(VT_TYPE, 0));
   }
-  MNN_DATA_FORMAT defaultDimentionFormat() const {
-    return static_cast<MNN_DATA_FORMAT>(GetField<int8_t>(VT_DEFAULTDIMENTIONFORMAT, 1));
+  MNN::MNN_DATA_FORMAT defaultDimentionFormat() const {
+    return static_cast<MNN::MNN_DATA_FORMAT>(GetField<int8_t>(VT_DEFAULTDIMENTIONFORMAT, 1));
   }
   bool Verify(flatbuffers::Verifier &verifier) const {
     return VerifyTableStart(verifier) &&
@@ -3294,365 +3299,366 @@ struct Op FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
   static flatbuffers::Offset<Op> Pack(flatbuffers::FlatBufferBuilder &_fbb, const OpT* _o, const flatbuffers::rehasher_function_t *_rehasher = nullptr);
 };
 
-template<> inline const QuantizedAdd *Op::main_as<QuantizedAdd>() const {
+template<> inline const MNN::QuantizedAdd *Op::main_as<MNN::QuantizedAdd>() const {
   return main_as_QuantizedAdd();
 }
 
-template<> inline const ArgMax *Op::main_as<ArgMax>() const {
+template<> inline const MNN::ArgMax *Op::main_as<MNN::ArgMax>() const {
   return main_as_ArgMax();
 }
 
-template<> inline const AsString *Op::main_as<AsString>() const {
+template<> inline const MNN::AsString *Op::main_as<MNN::AsString>() const {
   return main_as_AsString();
 }
 
-template<> inline const Axis *Op::main_as<Axis>() const {
+template<> inline const MNN::Axis *Op::main_as<MNN::Axis>() const {
   return main_as_Axis();
 }
 
-template<> inline const BatchNorm *Op::main_as<BatchNorm>() const {
+template<> inline const MNN::BatchNorm *Op::main_as<MNN::BatchNorm>() const {
   return main_as_BatchNorm();
 }
 
-template<> inline const BinaryOp *Op::main_as<BinaryOp>() const {
+template<> inline const MNN::BinaryOp *Op::main_as<MNN::BinaryOp>() const {
   return main_as_BinaryOp();
 }
 
-template<> inline const Blob *Op::main_as<Blob>() const {
+template<> inline const MNN::Blob *Op::main_as<MNN::Blob>() const {
   return main_as_Blob();
 }
 
-template<> inline const CastParam *Op::main_as<CastParam>() const {
+template<> inline const MNN::CastParam *Op::main_as<MNN::CastParam>() const {
   return main_as_CastParam();
 }
 
-template<> inline const Convolution2D *Op::main_as<Convolution2D>() const {
+template<> inline const MNN::Convolution2D *Op::main_as<MNN::Convolution2D>() const {
   return main_as_Convolution2D();
 }
 
-template<> inline const Crop *Op::main_as<Crop>() const {
+template<> inline const MNN::Crop *Op::main_as<MNN::Crop>() const {
   return main_as_Crop();
 }
 
-template<> inline const CropAndResize *Op::main_as<CropAndResize>() const {
+template<> inline const MNN::CropAndResize *Op::main_as<MNN::CropAndResize>() const {
   return main_as_CropAndResize();
 }
 
-template<> inline const Dequantize *Op::main_as<Dequantize>() const {
+template<> inline const MNN::Dequantize *Op::main_as<MNN::Dequantize>() const {
   return main_as_Dequantize();
 }
 
-template<> inline const DetectionOutput *Op::main_as<DetectionOutput>() const {
+template<> inline const MNN::DetectionOutput *Op::main_as<MNN::DetectionOutput>() const {
   return main_as_DetectionOutput();
 }
 
-template<> inline const Eltwise *Op::main_as<Eltwise>() const {
+template<> inline const MNN::Eltwise *Op::main_as<MNN::Eltwise>() const {
   return main_as_Eltwise();
 }
 
-template<> inline const ExpandDims *Op::main_as<ExpandDims>() const {
+template<> inline const MNN::ExpandDims *Op::main_as<MNN::ExpandDims>() const {
   return main_as_ExpandDims();
 }
 
-template<> inline const Fill *Op::main_as<Fill>() const {
+template<> inline const MNN::Fill *Op::main_as<MNN::Fill>() const {
   return main_as_Fill();
 }
 
-template<> inline const Flatten *Op::main_as<Flatten>() const {
+template<> inline const MNN::Flatten *Op::main_as<MNN::Flatten>() const {
   return main_as_Flatten();
 }
 
-template<> inline const Gather *Op::main_as<Gather>() const {
+template<> inline const MNN::Gather *Op::main_as<MNN::Gather>() const {
   return main_as_Gather();
 }
 
-template<> inline const GatherV2 *Op::main_as<GatherV2>() const {
+template<> inline const MNN::GatherV2 *Op::main_as<MNN::GatherV2>() const {
   return main_as_GatherV2();
 }
 
-template<> inline const InnerProduct *Op::main_as<InnerProduct>() const {
+template<> inline const MNN::InnerProduct *Op::main_as<MNN::InnerProduct>() const {
   return main_as_InnerProduct();
 }
 
-template<> inline const Input *Op::main_as<Input>() const {
+template<> inline const MNN::Input *Op::main_as<MNN::Input>() const {
   return main_as_Input();
 }
 
-template<> inline const Interp *Op::main_as<Interp>() const {
+template<> inline const MNN::Interp *Op::main_as<MNN::Interp>() const {
   return main_as_Interp();
 }
 
-template<> inline const LRN *Op::main_as<LRN>() const {
+template<> inline const MNN::LRN *Op::main_as<MNN::LRN>() const {
   return main_as_LRN();
 }
 
-template<> inline const LSTM *Op::main_as<LSTM>() const {
+template<> inline const MNN::LSTM *Op::main_as<MNN::LSTM>() const {
   return main_as_LSTM();
 }
 
-template<> inline const MatMul *Op::main_as<MatMul>() const {
+template<> inline const MNN::MatMul *Op::main_as<MNN::MatMul>() const {
   return main_as_MatMul();
 }
 
-template<> inline const NonMaxSuppressionV2 *Op::main_as<NonMaxSuppressionV2>() const {
+template<> inline const MNN::NonMaxSuppressionV2 *Op::main_as<MNN::NonMaxSuppressionV2>() const {
   return main_as_NonMaxSuppressionV2();
 }
 
-template<> inline const Normalize *Op::main_as<Normalize>() const {
+template<> inline const MNN::Normalize *Op::main_as<MNN::Normalize>() const {
   return main_as_Normalize();
 }
 
-template<> inline const PackParam *Op::main_as<PackParam>() const {
+template<> inline const MNN::PackParam *Op::main_as<MNN::PackParam>() const {
   return main_as_PackParam();
 }
 
-template<> inline const Permute *Op::main_as<Permute>() const {
+template<> inline const MNN::Permute *Op::main_as<MNN::Permute>() const {
   return main_as_Permute();
 }
 
-template<> inline const Plugin *Op::main_as<Plugin>() const {
+template<> inline const MNN::Plugin *Op::main_as<MNN::Plugin>() const {
   return main_as_Plugin();
 }
 
-template<> inline const Pool *Op::main_as<Pool>() const {
+template<> inline const MNN::Pool *Op::main_as<MNN::Pool>() const {
   return main_as_Pool();
 }
 
-template<> inline const PRelu *Op::main_as<PRelu>() const {
+template<> inline const MNN::PRelu *Op::main_as<MNN::PRelu>() const {
   return main_as_PRelu();
 }
 
-template<> inline const PriorBox *Op::main_as<PriorBox>() const {
+template<> inline const MNN::PriorBox *Op::main_as<MNN::PriorBox>() const {
   return main_as_PriorBox();
 }
 
-template<> inline const Proposal *Op::main_as<Proposal>() const {
+template<> inline const MNN::Proposal *Op::main_as<MNN::Proposal>() const {
   return main_as_Proposal();
 }
 
-template<> inline const QuantizedAvgPool *Op::main_as<QuantizedAvgPool>() const {
+template<> inline const MNN::QuantizedAvgPool *Op::main_as<MNN::QuantizedAvgPool>() const {
   return main_as_QuantizedAvgPool();
 }
 
-template<> inline const QuantizedBiasAdd *Op::main_as<QuantizedBiasAdd>() const {
+template<> inline const MNN::QuantizedBiasAdd *Op::main_as<MNN::QuantizedBiasAdd>() const {
   return main_as_QuantizedBiasAdd();
 }
 
-template<> inline const QuantizedConcat *Op::main_as<QuantizedConcat>() const {
+template<> inline const MNN::QuantizedConcat *Op::main_as<MNN::QuantizedConcat>() const {
   return main_as_QuantizedConcat();
 }
 
-template<> inline const QuantizedLogistic *Op::main_as<QuantizedLogistic>() const {
+template<> inline const MNN::QuantizedLogistic *Op::main_as<MNN::QuantizedLogistic>() const {
   return main_as_QuantizedLogistic();
 }
 
-template<> inline const QuantizedMatMul *Op::main_as<QuantizedMatMul>() const {
+template<> inline const MNN::QuantizedMatMul *Op::main_as<MNN::QuantizedMatMul>() const {
   return main_as_QuantizedMatMul();
 }
 
-template<> inline const QuantizedMaxPool *Op::main_as<QuantizedMaxPool>() const {
+template<> inline const MNN::QuantizedMaxPool *Op::main_as<MNN::QuantizedMaxPool>() const {
   return main_as_QuantizedMaxPool();
 }
 
-template<> inline const QuantizedRelu *Op::main_as<QuantizedRelu>() const {
+template<> inline const MNN::QuantizedRelu *Op::main_as<MNN::QuantizedRelu>() const {
   return main_as_QuantizedRelu();
 }
 
-template<> inline const QuantizedRelu6 *Op::main_as<QuantizedRelu6>() const {
+template<> inline const MNN::QuantizedRelu6 *Op::main_as<MNN::QuantizedRelu6>() const {
   return main_as_QuantizedRelu6();
 }
 
-template<> inline const QuantizedReshape *Op::main_as<QuantizedReshape>() const {
+template<> inline const MNN::QuantizedReshape *Op::main_as<MNN::QuantizedReshape>() const {
   return main_as_QuantizedReshape();
 }
 
-template<> inline const QuantizedSoftmax *Op::main_as<QuantizedSoftmax>() const {
+template<> inline const MNN::QuantizedSoftmax *Op::main_as<MNN::QuantizedSoftmax>() const {
   return main_as_QuantizedSoftmax();
 }
 
-template<> inline const QuantizeMaxMin *Op::main_as<QuantizeMaxMin>() const {
+template<> inline const MNN::QuantizeMaxMin *Op::main_as<MNN::QuantizeMaxMin>() const {
   return main_as_QuantizeMaxMin();
 }
 
-template<> inline const QuantizeV2 *Op::main_as<QuantizeV2>() const {
+template<> inline const MNN::QuantizeV2 *Op::main_as<MNN::QuantizeV2>() const {
   return main_as_QuantizeV2();
 }
 
-template<> inline const Range *Op::main_as<Range>() const {
+template<> inline const MNN::Range *Op::main_as<MNN::Range>() const {
   return main_as_Range();
 }
 
-template<> inline const Rank *Op::main_as<Rank>() const {
+template<> inline const MNN::Rank *Op::main_as<MNN::Rank>() const {
   return main_as_Rank();
 }
 
-template<> inline const ReduceJoin *Op::main_as<ReduceJoin>() const {
+template<> inline const MNN::ReduceJoin *Op::main_as<MNN::ReduceJoin>() const {
   return main_as_ReduceJoin();
 }
 
-template<> inline const ReductionParam *Op::main_as<ReductionParam>() const {
+template<> inline const MNN::ReductionParam *Op::main_as<MNN::ReductionParam>() const {
   return main_as_ReductionParam();
 }
 
-template<> inline const Relu *Op::main_as<Relu>() const {
+template<> inline const MNN::Relu *Op::main_as<MNN::Relu>() const {
   return main_as_Relu();
 }
 
-template<> inline const Relu6 *Op::main_as<Relu6>() const {
+template<> inline const MNN::Relu6 *Op::main_as<MNN::Relu6>() const {
   return main_as_Relu6();
 }
 
-template<> inline const RequantizationRange *Op::main_as<RequantizationRange>() const {
+template<> inline const MNN::RequantizationRange *Op::main_as<MNN::RequantizationRange>() const {
   return main_as_RequantizationRange();
 }
 
-template<> inline const Requantize *Op::main_as<Requantize>() const {
+template<> inline const MNN::Requantize *Op::main_as<MNN::Requantize>() const {
   return main_as_Requantize();
 }
 
-template<> inline const Reshape *Op::main_as<Reshape>() const {
+template<> inline const MNN::Reshape *Op::main_as<MNN::Reshape>() const {
   return main_as_Reshape();
 }
 
-template<> inline const Resize *Op::main_as<Resize>() const {
+template<> inline const MNN::Resize *Op::main_as<MNN::Resize>() const {
   return main_as_Resize();
 }
 
-template<> inline const RoiPooling *Op::main_as<RoiPooling>() const {
+template<> inline const MNN::RoiPooling *Op::main_as<MNN::RoiPooling>() const {
   return main_as_RoiPooling();
 }
 
-template<> inline const Scale *Op::main_as<Scale>() const {
+template<> inline const MNN::Scale *Op::main_as<MNN::Scale>() const {
   return main_as_Scale();
 }
 
-template<> inline const Selu *Op::main_as<Selu>() const {
+template<> inline const MNN::Selu *Op::main_as<MNN::Selu>() const {
   return main_as_Selu();
 }
 
-template<> inline const Size *Op::main_as<Size>() const {
+template<> inline const MNN::Size *Op::main_as<MNN::Size>() const {
   return main_as_Size();
 }
 
-template<> inline const Slice *Op::main_as<Slice>() const {
+template<> inline const MNN::Slice *Op::main_as<MNN::Slice>() const {
   return main_as_Slice();
 }
 
-template<> inline const SliceTf *Op::main_as<SliceTf>() const {
+template<> inline const MNN::SliceTf *Op::main_as<MNN::SliceTf>() const {
   return main_as_SliceTf();
 }
 
-template<> inline const SpaceBatch *Op::main_as<SpaceBatch>() const {
+template<> inline const MNN::SpaceBatch *Op::main_as<MNN::SpaceBatch>() const {
   return main_as_SpaceBatch();
 }
 
-template<> inline const SqueezeParam *Op::main_as<SqueezeParam>() const {
+template<> inline const MNN::SqueezeParam *Op::main_as<MNN::SqueezeParam>() const {
   return main_as_SqueezeParam();
 }
 
-template<> inline const StridedSliceParam *Op::main_as<StridedSliceParam>() const {
+template<> inline const MNN::StridedSliceParam *Op::main_as<MNN::StridedSliceParam>() const {
   return main_as_StridedSliceParam();
 }
 
-template<> inline const TensorConvertInfo *Op::main_as<TensorConvertInfo>() const {
+template<> inline const MNN::TensorConvertInfo *Op::main_as<MNN::TensorConvertInfo>() const {
   return main_as_TensorConvertInfo();
 }
 
-template<> inline const TfQuantizedConv2D *Op::main_as<TfQuantizedConv2D>() const {
+template<> inline const MNN::TfQuantizedConv2D *Op::main_as<MNN::TfQuantizedConv2D>() const {
   return main_as_TfQuantizedConv2D();
 }
 
-template<> inline const TopKV2 *Op::main_as<TopKV2>() const {
+template<> inline const MNN::TopKV2 *Op::main_as<MNN::TopKV2>() const {
   return main_as_TopKV2();
 }
 
-template<> inline const Transpose *Op::main_as<Transpose>() const {
+template<> inline const MNN::Transpose *Op::main_as<MNN::Transpose>() const {
   return main_as_Transpose();
 }
 
-template<> inline const UnaryOp *Op::main_as<UnaryOp>() const {
+template<> inline const MNN::UnaryOp *Op::main_as<MNN::UnaryOp>() const {
   return main_as_UnaryOp();
 }
 
-template<> inline const MomentsParam *Op::main_as<MomentsParam>() const {
+template<> inline const MNN::MomentsParam *Op::main_as<MNN::MomentsParam>() const {
   return main_as_MomentsParam();
 }
 
-template<> inline const RNNParam *Op::main_as<RNNParam>() const {
+template<> inline const MNN::RNNParam *Op::main_as<MNN::RNNParam>() const {
   return main_as_RNNParam();
 }
 
-template<> inline const BatchMatMulParam *Op::main_as<BatchMatMulParam>() const {
+template<> inline const MNN::BatchMatMulParam *Op::main_as<MNN::BatchMatMulParam>() const {
   return main_as_BatchMatMulParam();
 }
 
-template<> inline const QuantizedFloatParam *Op::main_as<QuantizedFloatParam>() const {
+template<> inline const MNN::QuantizedFloatParam *Op::main_as<MNN::QuantizedFloatParam>() const {
   return main_as_QuantizedFloatParam();
 }
 
-template<> inline const DepthSpaceParam *Op::main_as<DepthSpaceParam>() const {
+template<> inline const MNN::DepthSpaceParam *Op::main_as<MNN::DepthSpaceParam>() const {
   return main_as_DepthSpaceParam();
 }
 
-template<> inline const EltwiseInt8 *Op::main_as<EltwiseInt8>() const {
+template<> inline const MNN::EltwiseInt8 *Op::main_as<MNN::EltwiseInt8>() const {
   return main_as_EltwiseInt8();
 }
 
-template<> inline const ReverseSequenceParam *Op::main_as<ReverseSequenceParam>() const {
+template<> inline const MNN::ReverseSequenceParam *Op::main_as<MNN::ReverseSequenceParam>() const {
   return main_as_ReverseSequenceParam();
 }
 
-template<> inline const Extra *Op::main_as<Extra>() const {
+template<> inline const MNN::Extra *Op::main_as<MNN::Extra>() const {
   return main_as_Extra();
 }
 
-template<> inline const Pool3D *Op::main_as<Pool3D>() const {
+template<> inline const MNN::Pool3D *Op::main_as<MNN::Pool3D>() const {
   return main_as_Pool3D();
 }
 
-template<> inline const Convolution3D *Op::main_as<Convolution3D>() const {
+template<> inline const MNN::Convolution3D *Op::main_as<MNN::Convolution3D>() const {
   return main_as_Convolution3D();
 }
 
-template<> inline const ELU *Op::main_as<ELU>() const {
+template<> inline const MNN::ELU *Op::main_as<MNN::ELU>() const {
   return main_as_ELU();
 }
 
-template<> inline const DetectionPostProcessParam *Op::main_as<DetectionPostProcessParam>() const {
+template<> inline const MNN::DetectionPostProcessParam *Op::main_as<MNN::DetectionPostProcessParam>() const {
   return main_as_DetectionPostProcessParam();
 }
 
-template<> inline const OneHotParam *Op::main_as<OneHotParam>() const {
+template<> inline const MNN::OneHotParam *Op::main_as<MNN::OneHotParam>() const {
   return main_as_OneHotParam();
 }
 
-template<> inline const PadParam *Op::main_as<PadParam>() const {
+template<> inline const MNN::PadParam *Op::main_as<MNN::PadParam>() const {
   return main_as_PadParam();
 }
 
-template<> inline const WhileParam *Op::main_as<WhileParam>() const {
+template<> inline const MNN::WhileParam *Op::main_as<MNN::WhileParam>() const {
   return main_as_WhileParam();
 }
 
-template<> inline const IfParam *Op::main_as<IfParam>() const {
+template<> inline const MNN::IfParam *Op::main_as<MNN::IfParam>() const {
   return main_as_IfParam();
 }
 
-template<> inline const RandomUniform *Op::main_as<RandomUniform>() const {
+template<> inline const MNN::RandomUniform *Op::main_as<MNN::RandomUniform>() const {
   return main_as_RandomUniform();
 }
 
-template<> inline const LayerNorm *Op::main_as<LayerNorm>() const {
+template<> inline const MNN::LayerNorm *Op::main_as<MNN::LayerNorm>() const {
   return main_as_LayerNorm();
 }
 
 struct OpBuilder {
+  typedef Op Table;
   flatbuffers::FlatBufferBuilder &fbb_;
   flatbuffers::uoffset_t start_;
   void add_inputIndexes(flatbuffers::Offset<flatbuffers::Vector<int32_t>> inputIndexes) {
     fbb_.AddOffset(Op::VT_INPUTINDEXES, inputIndexes);
   }
-  void add_main_type(OpParameter main_type) {
+  void add_main_type(MNN::OpParameter main_type) {
     fbb_.AddElement<uint8_t>(Op::VT_MAIN_TYPE, static_cast<uint8_t>(main_type), 0);
   }
   void add_main(flatbuffers::Offset<void> main) {
@@ -3664,17 +3670,16 @@ struct OpBuilder {
   void add_outputIndexes(flatbuffers::Offset<flatbuffers::Vector<int32_t>> outputIndexes) {
     fbb_.AddOffset(Op::VT_OUTPUTINDEXES, outputIndexes);
   }
-  void add_type(OpType type) {
+  void add_type(MNN::OpType type) {
     fbb_.AddElement<int32_t>(Op::VT_TYPE, static_cast<int32_t>(type), 0);
   }
-  void add_defaultDimentionFormat(MNN_DATA_FORMAT defaultDimentionFormat) {
+  void add_defaultDimentionFormat(MNN::MNN_DATA_FORMAT defaultDimentionFormat) {
     fbb_.AddElement<int8_t>(Op::VT_DEFAULTDIMENTIONFORMAT, static_cast<int8_t>(defaultDimentionFormat), 1);
   }
   explicit OpBuilder(flatbuffers::FlatBufferBuilder &_fbb)
         : fbb_(_fbb) {
     start_ = fbb_.StartTable();
   }
-  OpBuilder &operator=(const OpBuilder &);
   flatbuffers::Offset<Op> Finish() {
     const auto end = fbb_.EndTable(start_);
     auto o = flatbuffers::Offset<Op>(end);
@@ -3685,12 +3690,12 @@ struct OpBuilder {
 inline flatbuffers::Offset<Op> CreateOp(
     flatbuffers::FlatBufferBuilder &_fbb,
     flatbuffers::Offset<flatbuffers::Vector<int32_t>> inputIndexes = 0,
-    OpParameter main_type = OpParameter_NONE,
+    MNN::OpParameter main_type = MNN::OpParameter_NONE,
     flatbuffers::Offset<void> main = 0,
     flatbuffers::Offset<flatbuffers::String> name = 0,
     flatbuffers::Offset<flatbuffers::Vector<int32_t>> outputIndexes = 0,
-    OpType type = OpType_AbsVal,
-    MNN_DATA_FORMAT defaultDimentionFormat = MNN_DATA_FORMAT_NHWC) {
+    MNN::OpType type = MNN::OpType_AbsVal,
+    MNN::MNN_DATA_FORMAT defaultDimentionFormat = MNN::MNN_DATA_FORMAT_NHWC) {
   OpBuilder builder_(_fbb);
   builder_.add_type(type);
   builder_.add_outputIndexes(outputIndexes);
@@ -3705,12 +3710,12 @@ inline flatbuffers::Offset<Op> CreateOp(
 inline flatbuffers::Offset<Op> CreateOpDirect(
     flatbuffers::FlatBufferBuilder &_fbb,
     const std::vector<int32_t> *inputIndexes = nullptr,
-    OpParameter main_type = OpParameter_NONE,
+    MNN::OpParameter main_type = MNN::OpParameter_NONE,
     flatbuffers::Offset<void> main = 0,
     const char *name = nullptr,
     const std::vector<int32_t> *outputIndexes = nullptr,
-    OpType type = OpType_AbsVal,
-    MNN_DATA_FORMAT defaultDimentionFormat = MNN_DATA_FORMAT_NHWC) {
+    MNN::OpType type = MNN::OpType_AbsVal,
+    MNN::MNN_DATA_FORMAT defaultDimentionFormat = MNN::MNN_DATA_FORMAT_NHWC) {
   auto inputIndexes__ = inputIndexes ? _fbb.CreateVector<int32_t>(*inputIndexes) : 0;
   auto name__ = name ? _fbb.CreateString(name) : 0;
   auto outputIndexes__ = outputIndexes ? _fbb.CreateVector<int32_t>(*outputIndexes) : 0;
@@ -3729,15 +3734,13 @@ flatbuffers::Offset<Op> CreateOp(flatbuffers::FlatBufferBuilder &_fbb, const OpT
 
 struct ViewT : public flatbuffers::NativeTable {
   typedef View TableType;
-  int32_t offset;
-  std::vector<int32_t> stride;
-  ViewT()
-      : offset(0) {
-  }
+  int32_t offset = 0;
+  std::vector<int32_t> stride{};
 };
 
 struct View FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
   typedef ViewT NativeTableType;
+  typedef ViewBuilder Builder;
   static const flatbuffers::TypeTable *MiniReflectTypeTable() {
     return ViewTypeTable();
   }
@@ -3764,6 +3767,7 @@ struct View FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
 };
 
 struct ViewBuilder {
+  typedef View Table;
   flatbuffers::FlatBufferBuilder &fbb_;
   flatbuffers::uoffset_t start_;
   void add_offset(int32_t offset) {
@@ -3776,7 +3780,6 @@ struct ViewBuilder {
         : fbb_(_fbb) {
     start_ = fbb_.StartTable();
   }
-  ViewBuilder &operator=(const ViewBuilder &);
   flatbuffers::Offset<View> Finish() {
     const auto end = fbb_.EndTable(start_);
     auto o = flatbuffers::Offset<View>(end);
@@ -3809,17 +3812,15 @@ flatbuffers::Offset<View> CreateView(flatbuffers::FlatBufferBuilder &_fbb, const
 
 struct RegionT : public flatbuffers::NativeTable {
   typedef Region TableType;
-  std::unique_ptr<ViewT> src;
-  std::unique_ptr<ViewT> dst;
-  std::vector<int32_t> size;
-  int32_t origin;
-  RegionT()
-      : origin(0) {
-  }
+  std::unique_ptr<MNN::ViewT> src{};
+  std::unique_ptr<MNN::ViewT> dst{};
+  std::vector<int32_t> size{};
+  int32_t origin = 0;
 };
 
 struct Region FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
   typedef RegionT NativeTableType;
+  typedef RegionBuilder Builder;
   static const flatbuffers::TypeTable *MiniReflectTypeTable() {
     return RegionTypeTable();
   }
@@ -3829,11 +3830,11 @@ struct Region FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
     VT_SIZE = 8,
     VT_ORIGIN = 10
   };
-  const View *src() const {
-    return GetPointer<const View *>(VT_SRC);
+  const MNN::View *src() const {
+    return GetPointer<const MNN::View *>(VT_SRC);
   }
-  const View *dst() const {
-    return GetPointer<const View *>(VT_DST);
+  const MNN::View *dst() const {
+    return GetPointer<const MNN::View *>(VT_DST);
   }
   const flatbuffers::Vector<int32_t> *size() const {
     return GetPointer<const flatbuffers::Vector<int32_t> *>(VT_SIZE);
@@ -3858,12 +3859,13 @@ struct Region FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
 };
 
 struct RegionBuilder {
+  typedef Region Table;
   flatbuffers::FlatBufferBuilder &fbb_;
   flatbuffers::uoffset_t start_;
-  void add_src(flatbuffers::Offset<View> src) {
+  void add_src(flatbuffers::Offset<MNN::View> src) {
     fbb_.AddOffset(Region::VT_SRC, src);
   }
-  void add_dst(flatbuffers::Offset<View> dst) {
+  void add_dst(flatbuffers::Offset<MNN::View> dst) {
     fbb_.AddOffset(Region::VT_DST, dst);
   }
   void add_size(flatbuffers::Offset<flatbuffers::Vector<int32_t>> size) {
@@ -3876,7 +3878,6 @@ struct RegionBuilder {
         : fbb_(_fbb) {
     start_ = fbb_.StartTable();
   }
-  RegionBuilder &operator=(const RegionBuilder &);
   flatbuffers::Offset<Region> Finish() {
     const auto end = fbb_.EndTable(start_);
     auto o = flatbuffers::Offset<Region>(end);
@@ -3886,8 +3887,8 @@ struct RegionBuilder {
 
 inline flatbuffers::Offset<Region> CreateRegion(
     flatbuffers::FlatBufferBuilder &_fbb,
-    flatbuffers::Offset<View> src = 0,
-    flatbuffers::Offset<View> dst = 0,
+    flatbuffers::Offset<MNN::View> src = 0,
+    flatbuffers::Offset<MNN::View> dst = 0,
     flatbuffers::Offset<flatbuffers::Vector<int32_t>> size = 0,
     int32_t origin = 0) {
   RegionBuilder builder_(_fbb);
@@ -3900,8 +3901,8 @@ inline flatbuffers::Offset<Region> CreateRegion(
 
 inline flatbuffers::Offset<Region> CreateRegionDirect(
     flatbuffers::FlatBufferBuilder &_fbb,
-    flatbuffers::Offset<View> src = 0,
-    flatbuffers::Offset<View> dst = 0,
+    flatbuffers::Offset<MNN::View> src = 0,
+    flatbuffers::Offset<MNN::View> dst = 0,
     const std::vector<int32_t> *size = nullptr,
     int32_t origin = 0) {
   auto size__ = size ? _fbb.CreateVector<int32_t>(*size) : 0;
@@ -3917,17 +3918,15 @@ flatbuffers::Offset<Region> CreateRegion(flatbuffers::FlatBufferBuilder &_fbb, c
 
 struct TensorDescribeT : public flatbuffers::NativeTable {
   typedef TensorDescribe TableType;
-  std::unique_ptr<BlobT> blob;
-  int32_t index;
-  std::string name;
-  std::vector<std::unique_ptr<RegionT>> regions;
-  TensorDescribeT()
-      : index(0) {
-  }
+  std::unique_ptr<MNN::BlobT> blob{};
+  int32_t index = 0;
+  std::string name{};
+  std::vector<std::unique_ptr<MNN::RegionT>> regions{};
 };
 
 struct TensorDescribe FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
   typedef TensorDescribeT NativeTableType;
+  typedef TensorDescribeBuilder Builder;
   static const flatbuffers::TypeTable *MiniReflectTypeTable() {
     return TensorDescribeTypeTable();
   }
@@ -3937,8 +3936,8 @@ struct TensorDescribe FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
     VT_NAME = 8,
     VT_REGIONS = 10
   };
-  const Blob *blob() const {
-    return GetPointer<const Blob *>(VT_BLOB);
+  const MNN::Blob *blob() const {
+    return GetPointer<const MNN::Blob *>(VT_BLOB);
   }
   int32_t index() const {
     return GetField<int32_t>(VT_INDEX, 0);
@@ -3946,8 +3945,8 @@ struct TensorDescribe FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
   const flatbuffers::String *name() const {
     return GetPointer<const flatbuffers::String *>(VT_NAME);
   }
-  const flatbuffers::Vector<flatbuffers::Offset<Region>> *regions() const {
-    return GetPointer<const flatbuffers::Vector<flatbuffers::Offset<Region>> *>(VT_REGIONS);
+  const flatbuffers::Vector<flatbuffers::Offset<MNN::Region>> *regions() const {
+    return GetPointer<const flatbuffers::Vector<flatbuffers::Offset<MNN::Region>> *>(VT_REGIONS);
   }
   bool Verify(flatbuffers::Verifier &verifier) const {
     return VerifyTableStart(verifier) &&
@@ -3967,9 +3966,10 @@ struct TensorDescribe FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
 };
 
 struct TensorDescribeBuilder {
+  typedef TensorDescribe Table;
   flatbuffers::FlatBufferBuilder &fbb_;
   flatbuffers::uoffset_t start_;
-  void add_blob(flatbuffers::Offset<Blob> blob) {
+  void add_blob(flatbuffers::Offset<MNN::Blob> blob) {
     fbb_.AddOffset(TensorDescribe::VT_BLOB, blob);
   }
   void add_index(int32_t index) {
@@ -3978,14 +3978,13 @@ struct TensorDescribeBuilder {
   void add_name(flatbuffers::Offset<flatbuffers::String> name) {
     fbb_.AddOffset(TensorDescribe::VT_NAME, name);
   }
-  void add_regions(flatbuffers::Offset<flatbuffers::Vector<flatbuffers::Offset<Region>>> regions) {
+  void add_regions(flatbuffers::Offset<flatbuffers::Vector<flatbuffers::Offset<MNN::Region>>> regions) {
     fbb_.AddOffset(TensorDescribe::VT_REGIONS, regions);
   }
   explicit TensorDescribeBuilder(flatbuffers::FlatBufferBuilder &_fbb)
         : fbb_(_fbb) {
     start_ = fbb_.StartTable();
   }
-  TensorDescribeBuilder &operator=(const TensorDescribeBuilder &);
   flatbuffers::Offset<TensorDescribe> Finish() {
     const auto end = fbb_.EndTable(start_);
     auto o = flatbuffers::Offset<TensorDescribe>(end);
@@ -3995,10 +3994,10 @@ struct TensorDescribeBuilder {
 
 inline flatbuffers::Offset<TensorDescribe> CreateTensorDescribe(
     flatbuffers::FlatBufferBuilder &_fbb,
-    flatbuffers::Offset<Blob> blob = 0,
+    flatbuffers::Offset<MNN::Blob> blob = 0,
     int32_t index = 0,
     flatbuffers::Offset<flatbuffers::String> name = 0,
-    flatbuffers::Offset<flatbuffers::Vector<flatbuffers::Offset<Region>>> regions = 0) {
+    flatbuffers::Offset<flatbuffers::Vector<flatbuffers::Offset<MNN::Region>>> regions = 0) {
   TensorDescribeBuilder builder_(_fbb);
   builder_.add_regions(regions);
   builder_.add_name(name);
@@ -4009,12 +4008,12 @@ inline flatbuffers::Offset<TensorDescribe> CreateTensorDescribe(
 
 inline flatbuffers::Offset<TensorDescribe> CreateTensorDescribeDirect(
     flatbuffers::FlatBufferBuilder &_fbb,
-    flatbuffers::Offset<Blob> blob = 0,
+    flatbuffers::Offset<MNN::Blob> blob = 0,
     int32_t index = 0,
     const char *name = nullptr,
-    const std::vector<flatbuffers::Offset<Region>> *regions = nullptr) {
+    const std::vector<flatbuffers::Offset<MNN::Region>> *regions = nullptr) {
   auto name__ = name ? _fbb.CreateString(name) : 0;
-  auto regions__ = regions ? _fbb.CreateVector<flatbuffers::Offset<Region>>(*regions) : 0;
+  auto regions__ = regions ? _fbb.CreateVector<flatbuffers::Offset<MNN::Region>>(*regions) : 0;
   return MNN::CreateTensorDescribe(
       _fbb,
       blob,
@@ -4027,17 +4026,16 @@ flatbuffers::Offset<TensorDescribe> CreateTensorDescribe(flatbuffers::FlatBuffer
 
 struct SubGraphProtoT : public flatbuffers::NativeTable {
   typedef SubGraphProto TableType;
-  std::string name;
-  std::vector<int32_t> inputs;
-  std::vector<int32_t> outputs;
-  std::vector<std::string> tensors;
-  std::vector<std::unique_ptr<OpT>> nodes;
-  SubGraphProtoT() {
-  }
+  std::string name{};
+  std::vector<int32_t> inputs{};
+  std::vector<int32_t> outputs{};
+  std::vector<std::string> tensors{};
+  std::vector<std::unique_ptr<MNN::OpT>> nodes{};
 };
 
 struct SubGraphProto FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
   typedef SubGraphProtoT NativeTableType;
+  typedef SubGraphProtoBuilder Builder;
   static const flatbuffers::TypeTable *MiniReflectTypeTable() {
     return SubGraphProtoTypeTable();
   }
@@ -4060,8 +4058,8 @@ struct SubGraphProto FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
   const flatbuffers::Vector<flatbuffers::Offset<flatbuffers::String>> *tensors() const {
     return GetPointer<const flatbuffers::Vector<flatbuffers::Offset<flatbuffers::String>> *>(VT_TENSORS);
   }
-  const flatbuffers::Vector<flatbuffers::Offset<Op>> *nodes() const {
-    return GetPointer<const flatbuffers::Vector<flatbuffers::Offset<Op>> *>(VT_NODES);
+  const flatbuffers::Vector<flatbuffers::Offset<MNN::Op>> *nodes() const {
+    return GetPointer<const flatbuffers::Vector<flatbuffers::Offset<MNN::Op>> *>(VT_NODES);
   }
   bool Verify(flatbuffers::Verifier &verifier) const {
     return VerifyTableStart(verifier) &&
@@ -4085,6 +4083,7 @@ struct SubGraphProto FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
 };
 
 struct SubGraphProtoBuilder {
+  typedef SubGraphProto Table;
   flatbuffers::FlatBufferBuilder &fbb_;
   flatbuffers::uoffset_t start_;
   void add_name(flatbuffers::Offset<flatbuffers::String> name) {
@@ -4099,14 +4098,13 @@ struct SubGraphProtoBuilder {
   void add_tensors(flatbuffers::Offset<flatbuffers::Vector<flatbuffers::Offset<flatbuffers::String>>> tensors) {
     fbb_.AddOffset(SubGraphProto::VT_TENSORS, tensors);
   }
-  void add_nodes(flatbuffers::Offset<flatbuffers::Vector<flatbuffers::Offset<Op>>> nodes) {
+  void add_nodes(flatbuffers::Offset<flatbuffers::Vector<flatbuffers::Offset<MNN::Op>>> nodes) {
     fbb_.AddOffset(SubGraphProto::VT_NODES, nodes);
   }
   explicit SubGraphProtoBuilder(flatbuffers::FlatBufferBuilder &_fbb)
         : fbb_(_fbb) {
     start_ = fbb_.StartTable();
   }
-  SubGraphProtoBuilder &operator=(const SubGraphProtoBuilder &);
   flatbuffers::Offset<SubGraphProto> Finish() {
     const auto end = fbb_.EndTable(start_);
     auto o = flatbuffers::Offset<SubGraphProto>(end);
@@ -4120,7 +4118,7 @@ inline flatbuffers::Offset<SubGraphProto> CreateSubGraphProto(
     flatbuffers::Offset<flatbuffers::Vector<int32_t>> inputs = 0,
     flatbuffers::Offset<flatbuffers::Vector<int32_t>> outputs = 0,
     flatbuffers::Offset<flatbuffers::Vector<flatbuffers::Offset<flatbuffers::String>>> tensors = 0,
-    flatbuffers::Offset<flatbuffers::Vector<flatbuffers::Offset<Op>>> nodes = 0) {
+    flatbuffers::Offset<flatbuffers::Vector<flatbuffers::Offset<MNN::Op>>> nodes = 0) {
   SubGraphProtoBuilder builder_(_fbb);
   builder_.add_nodes(nodes);
   builder_.add_tensors(tensors);
@@ -4136,12 +4134,12 @@ inline flatbuffers::Offset<SubGraphProto> CreateSubGraphProtoDirect(
     const std::vector<int32_t> *inputs = nullptr,
     const std::vector<int32_t> *outputs = nullptr,
     const std::vector<flatbuffers::Offset<flatbuffers::String>> *tensors = nullptr,
-    const std::vector<flatbuffers::Offset<Op>> *nodes = nullptr) {
+    const std::vector<flatbuffers::Offset<MNN::Op>> *nodes = nullptr) {
   auto name__ = name ? _fbb.CreateString(name) : 0;
   auto inputs__ = inputs ? _fbb.CreateVector<int32_t>(*inputs) : 0;
   auto outputs__ = outputs ? _fbb.CreateVector<int32_t>(*outputs) : 0;
   auto tensors__ = tensors ? _fbb.CreateVector<flatbuffers::Offset<flatbuffers::String>>(*tensors) : 0;
-  auto nodes__ = nodes ? _fbb.CreateVector<flatbuffers::Offset<Op>>(*nodes) : 0;
+  auto nodes__ = nodes ? _fbb.CreateVector<flatbuffers::Offset<MNN::Op>>(*nodes) : 0;
   return MNN::CreateSubGraphProto(
       _fbb,
       name__,
@@ -4155,27 +4153,22 @@ flatbuffers::Offset<SubGraphProto> CreateSubGraphProto(flatbuffers::FlatBufferBu
 
 struct NetT : public flatbuffers::NativeTable {
   typedef Net TableType;
-  std::string bizCode;
-  std::vector<std::unique_ptr<TensorDescribeT>> extraTensorDescribe;
-  std::unique_ptr<GpuLibraryT> gpulibrary;
-  std::vector<std::unique_ptr<OpT>> oplists;
-  std::vector<std::string> outputName;
-  ForwardType preferForwardType;
-  NetSource sourceType;
-  std::vector<std::string> tensorName;
-  int32_t tensorNumber;
-  Usage usage;
-  std::vector<std::unique_ptr<SubGraphProtoT>> subgraphs;
-  NetT()
-      : preferForwardType(ForwardType_CPU),
-        sourceType(NetSource_CAFFE),
-        tensorNumber(0),
-        usage(Usage_INFERENCE) {
-  }
+  std::string bizCode{};
+  std::vector<std::unique_ptr<MNN::TensorDescribeT>> extraTensorDescribe{};
+  std::unique_ptr<MNN::GpuLibraryT> gpulibrary{};
+  std::vector<std::unique_ptr<MNN::OpT>> oplists{};
+  std::vector<std::string> outputName{};
+  MNN::ForwardType preferForwardType = MNN::ForwardType_CPU;
+  MNN::NetSource sourceType = MNN::NetSource_CAFFE;
+  std::vector<std::string> tensorName{};
+  int32_t tensorNumber = 0;
+  MNN::Usage usage = MNN::Usage_INFERENCE;
+  std::vector<std::unique_ptr<MNN::SubGraphProtoT>> subgraphs{};
 };
 
 struct Net FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
   typedef NetT NativeTableType;
+  typedef NetBuilder Builder;
   static const flatbuffers::TypeTable *MiniReflectTypeTable() {
     return NetTypeTable();
   }
@@ -4195,23 +4188,23 @@ struct Net FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
   const flatbuffers::String *bizCode() const {
     return GetPointer<const flatbuffers::String *>(VT_BIZCODE);
   }
-  const flatbuffers::Vector<flatbuffers::Offset<TensorDescribe>> *extraTensorDescribe() const {
-    return GetPointer<const flatbuffers::Vector<flatbuffers::Offset<TensorDescribe>> *>(VT_EXTRATENSORDESCRIBE);
+  const flatbuffers::Vector<flatbuffers::Offset<MNN::TensorDescribe>> *extraTensorDescribe() const {
+    return GetPointer<const flatbuffers::Vector<flatbuffers::Offset<MNN::TensorDescribe>> *>(VT_EXTRATENSORDESCRIBE);
   }
-  const GpuLibrary *gpulibrary() const {
-    return GetPointer<const GpuLibrary *>(VT_GPULIBRARY);
+  const MNN::GpuLibrary *gpulibrary() const {
+    return GetPointer<const MNN::GpuLibrary *>(VT_GPULIBRARY);
   }
-  const flatbuffers::Vector<flatbuffers::Offset<Op>> *oplists() const {
-    return GetPointer<const flatbuffers::Vector<flatbuffers::Offset<Op>> *>(VT_OPLISTS);
+  const flatbuffers::Vector<flatbuffers::Offset<MNN::Op>> *oplists() const {
+    return GetPointer<const flatbuffers::Vector<flatbuffers::Offset<MNN::Op>> *>(VT_OPLISTS);
   }
   const flatbuffers::Vector<flatbuffers::Offset<flatbuffers::String>> *outputName() const {
     return GetPointer<const flatbuffers::Vector<flatbuffers::Offset<flatbuffers::String>> *>(VT_OUTPUTNAME);
   }
-  ForwardType preferForwardType() const {
-    return static_cast<ForwardType>(GetField<int8_t>(VT_PREFERFORWARDTYPE, 0));
+  MNN::ForwardType preferForwardType() const {
+    return static_cast<MNN::ForwardType>(GetField<int8_t>(VT_PREFERFORWARDTYPE, 0));
   }
-  NetSource sourceType() const {
-    return static_cast<NetSource>(GetField<int8_t>(VT_SOURCETYPE, 0));
+  MNN::NetSource sourceType() const {
+    return static_cast<MNN::NetSource>(GetField<int8_t>(VT_SOURCETYPE, 0));
   }
   const flatbuffers::Vector<flatbuffers::Offset<flatbuffers::String>> *tensorName() const {
     return GetPointer<const flatbuffers::Vector<flatbuffers::Offset<flatbuffers::String>> *>(VT_TENSORNAME);
@@ -4219,11 +4212,11 @@ struct Net FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
   int32_t tensorNumber() const {
     return GetField<int32_t>(VT_TENSORNUMBER, 0);
   }
-  Usage usage() const {
-    return static_cast<Usage>(GetField<int8_t>(VT_USAGE, 0));
+  MNN::Usage usage() const {
+    return static_cast<MNN::Usage>(GetField<int8_t>(VT_USAGE, 0));
   }
-  const flatbuffers::Vector<flatbuffers::Offset<SubGraphProto>> *subgraphs() const {
-    return GetPointer<const flatbuffers::Vector<flatbuffers::Offset<SubGraphProto>> *>(VT_SUBGRAPHS);
+  const flatbuffers::Vector<flatbuffers::Offset<MNN::SubGraphProto>> *subgraphs() const {
+    return GetPointer<const flatbuffers::Vector<flatbuffers::Offset<MNN::SubGraphProto>> *>(VT_SUBGRAPHS);
   }
   bool Verify(flatbuffers::Verifier &verifier) const {
     return VerifyTableStart(verifier) &&
@@ -4258,27 +4251,28 @@ struct Net FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
 };
 
 struct NetBuilder {
+  typedef Net Table;
   flatbuffers::FlatBufferBuilder &fbb_;
   flatbuffers::uoffset_t start_;
   void add_bizCode(flatbuffers::Offset<flatbuffers::String> bizCode) {
     fbb_.AddOffset(Net::VT_BIZCODE, bizCode);
   }
-  void add_extraTensorDescribe(flatbuffers::Offset<flatbuffers::Vector<flatbuffers::Offset<TensorDescribe>>> extraTensorDescribe) {
+  void add_extraTensorDescribe(flatbuffers::Offset<flatbuffers::Vector<flatbuffers::Offset<MNN::TensorDescribe>>> extraTensorDescribe) {
     fbb_.AddOffset(Net::VT_EXTRATENSORDESCRIBE, extraTensorDescribe);
   }
-  void add_gpulibrary(flatbuffers::Offset<GpuLibrary> gpulibrary) {
+  void add_gpulibrary(flatbuffers::Offset<MNN::GpuLibrary> gpulibrary) {
     fbb_.AddOffset(Net::VT_GPULIBRARY, gpulibrary);
   }
-  void add_oplists(flatbuffers::Offset<flatbuffers::Vector<flatbuffers::Offset<Op>>> oplists) {
+  void add_oplists(flatbuffers::Offset<flatbuffers::Vector<flatbuffers::Offset<MNN::Op>>> oplists) {
     fbb_.AddOffset(Net::VT_OPLISTS, oplists);
   }
   void add_outputName(flatbuffers::Offset<flatbuffers::Vector<flatbuffers::Offset<flatbuffers::String>>> outputName) {
     fbb_.AddOffset(Net::VT_OUTPUTNAME, outputName);
   }
-  void add_preferForwardType(ForwardType preferForwardType) {
+  void add_preferForwardType(MNN::ForwardType preferForwardType) {
     fbb_.AddElement<int8_t>(Net::VT_PREFERFORWARDTYPE, static_cast<int8_t>(preferForwardType), 0);
   }
-  void add_sourceType(NetSource sourceType) {
+  void add_sourceType(MNN::NetSource sourceType) {
     fbb_.AddElement<int8_t>(Net::VT_SOURCETYPE, static_cast<int8_t>(sourceType), 0);
   }
   void add_tensorName(flatbuffers::Offset<flatbuffers::Vector<flatbuffers::Offset<flatbuffers::String>>> tensorName) {
@@ -4287,17 +4281,16 @@ struct NetBuilder {
   void add_tensorNumber(int32_t tensorNumber) {
     fbb_.AddElement<int32_t>(Net::VT_TENSORNUMBER, tensorNumber, 0);
   }
-  void add_usage(Usage usage) {
+  void add_usage(MNN::Usage usage) {
     fbb_.AddElement<int8_t>(Net::VT_USAGE, static_cast<int8_t>(usage), 0);
   }
-  void add_subgraphs(flatbuffers::Offset<flatbuffers::Vector<flatbuffers::Offset<SubGraphProto>>> subgraphs) {
+  void add_subgraphs(flatbuffers::Offset<flatbuffers::Vector<flatbuffers::Offset<MNN::SubGraphProto>>> subgraphs) {
     fbb_.AddOffset(Net::VT_SUBGRAPHS, subgraphs);
   }
   explicit NetBuilder(flatbuffers::FlatBufferBuilder &_fbb)
         : fbb_(_fbb) {
     start_ = fbb_.StartTable();
   }
-  NetBuilder &operator=(const NetBuilder &);
   flatbuffers::Offset<Net> Finish() {
     const auto end = fbb_.EndTable(start_);
     auto o = flatbuffers::Offset<Net>(end);
@@ -4308,16 +4301,16 @@ struct NetBuilder {
 inline flatbuffers::Offset<Net> CreateNet(
     flatbuffers::FlatBufferBuilder &_fbb,
     flatbuffers::Offset<flatbuffers::String> bizCode = 0,
-    flatbuffers::Offset<flatbuffers::Vector<flatbuffers::Offset<TensorDescribe>>> extraTensorDescribe = 0,
-    flatbuffers::Offset<GpuLibrary> gpulibrary = 0,
-    flatbuffers::Offset<flatbuffers::Vector<flatbuffers::Offset<Op>>> oplists = 0,
+    flatbuffers::Offset<flatbuffers::Vector<flatbuffers::Offset<MNN::TensorDescribe>>> extraTensorDescribe = 0,
+    flatbuffers::Offset<MNN::GpuLibrary> gpulibrary = 0,
+    flatbuffers::Offset<flatbuffers::Vector<flatbuffers::Offset<MNN::Op>>> oplists = 0,
     flatbuffers::Offset<flatbuffers::Vector<flatbuffers::Offset<flatbuffers::String>>> outputName = 0,
-    ForwardType preferForwardType = ForwardType_CPU,
-    NetSource sourceType = NetSource_CAFFE,
+    MNN::ForwardType preferForwardType = MNN::ForwardType_CPU,
+    MNN::NetSource sourceType = MNN::NetSource_CAFFE,
     flatbuffers::Offset<flatbuffers::Vector<flatbuffers::Offset<flatbuffers::String>>> tensorName = 0,
     int32_t tensorNumber = 0,
-    Usage usage = Usage_INFERENCE,
-    flatbuffers::Offset<flatbuffers::Vector<flatbuffers::Offset<SubGraphProto>>> subgraphs = 0) {
+    MNN::Usage usage = MNN::Usage_INFERENCE,
+    flatbuffers::Offset<flatbuffers::Vector<flatbuffers::Offset<MNN::SubGraphProto>>> subgraphs = 0) {
   NetBuilder builder_(_fbb);
   builder_.add_subgraphs(subgraphs);
   builder_.add_tensorNumber(tensorNumber);
@@ -4336,22 +4329,22 @@ inline flatbuffers::Offset<Net> CreateNet(
 inline flatbuffers::Offset<Net> CreateNetDirect(
     flatbuffers::FlatBufferBuilder &_fbb,
     const char *bizCode = nullptr,
-    const std::vector<flatbuffers::Offset<TensorDescribe>> *extraTensorDescribe = nullptr,
-    flatbuffers::Offset<GpuLibrary> gpulibrary = 0,
-    const std::vector<flatbuffers::Offset<Op>> *oplists = nullptr,
+    const std::vector<flatbuffers::Offset<MNN::TensorDescribe>> *extraTensorDescribe = nullptr,
+    flatbuffers::Offset<MNN::GpuLibrary> gpulibrary = 0,
+    const std::vector<flatbuffers::Offset<MNN::Op>> *oplists = nullptr,
     const std::vector<flatbuffers::Offset<flatbuffers::String>> *outputName = nullptr,
-    ForwardType preferForwardType = ForwardType_CPU,
-    NetSource sourceType = NetSource_CAFFE,
+    MNN::ForwardType preferForwardType = MNN::ForwardType_CPU,
+    MNN::NetSource sourceType = MNN::NetSource_CAFFE,
     const std::vector<flatbuffers::Offset<flatbuffers::String>> *tensorName = nullptr,
     int32_t tensorNumber = 0,
-    Usage usage = Usage_INFERENCE,
-    const std::vector<flatbuffers::Offset<SubGraphProto>> *subgraphs = nullptr) {
+    MNN::Usage usage = MNN::Usage_INFERENCE,
+    const std::vector<flatbuffers::Offset<MNN::SubGraphProto>> *subgraphs = nullptr) {
   auto bizCode__ = bizCode ? _fbb.CreateString(bizCode) : 0;
-  auto extraTensorDescribe__ = extraTensorDescribe ? _fbb.CreateVector<flatbuffers::Offset<TensorDescribe>>(*extraTensorDescribe) : 0;
-  auto oplists__ = oplists ? _fbb.CreateVector<flatbuffers::Offset<Op>>(*oplists) : 0;
+  auto extraTensorDescribe__ = extraTensorDescribe ? _fbb.CreateVector<flatbuffers::Offset<MNN::TensorDescribe>>(*extraTensorDescribe) : 0;
+  auto oplists__ = oplists ? _fbb.CreateVector<flatbuffers::Offset<MNN::Op>>(*oplists) : 0;
   auto outputName__ = outputName ? _fbb.CreateVector<flatbuffers::Offset<flatbuffers::String>>(*outputName) : 0;
   auto tensorName__ = tensorName ? _fbb.CreateVector<flatbuffers::Offset<flatbuffers::String>>(*tensorName) : 0;
-  auto subgraphs__ = subgraphs ? _fbb.CreateVector<flatbuffers::Offset<SubGraphProto>>(*subgraphs) : 0;
+  auto subgraphs__ = subgraphs ? _fbb.CreateVector<flatbuffers::Offset<MNN::SubGraphProto>>(*subgraphs) : 0;
   return MNN::CreateNet(
       _fbb,
       bizCode__,
@@ -4370,16 +4363,16 @@ inline flatbuffers::Offset<Net> CreateNetDirect(
 flatbuffers::Offset<Net> CreateNet(flatbuffers::FlatBufferBuilder &_fbb, const NetT *_o, const flatbuffers::rehasher_function_t *_rehasher = nullptr);
 
 inline PluginT *Plugin::UnPack(const flatbuffers::resolver_function_t *_resolver) const {
-  auto _o = new PluginT();
-  UnPackTo(_o, _resolver);
-  return _o;
+  auto _o = std::unique_ptr<PluginT>(new PluginT());
+  UnPackTo(_o.get(), _resolver);
+  return _o.release();
 }
 
 inline void Plugin::UnPackTo(PluginT *_o, const flatbuffers::resolver_function_t *_resolver) const {
   (void)_o;
   (void)_resolver;
-  { auto _e = type(); if (_e) _o->type = _e->str(); };
-  { auto _e = attr(); if (_e) { _o->attr.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->attr[_i] = std::unique_ptr<AttributeT>(_e->Get(_i)->UnPack(_resolver)); } } };
+  { auto _e = type(); if (_e) _o->type = _e->str(); }
+  { auto _e = attr(); if (_e) { _o->attr.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->attr[_i] = std::unique_ptr<MNN::AttributeT>(_e->Get(_i)->UnPack(_resolver)); } } }
 }
 
 inline flatbuffers::Offset<Plugin> Plugin::Pack(flatbuffers::FlatBufferBuilder &_fbb, const PluginT* _o, const flatbuffers::rehasher_function_t *_rehasher) {
@@ -4391,7 +4384,7 @@ inline flatbuffers::Offset<Plugin> CreatePlugin(flatbuffers::FlatBufferBuilder &
   (void)_o;
   struct _VectorArgs { flatbuffers::FlatBufferBuilder *__fbb; const PluginT* __o; const flatbuffers::rehasher_function_t *__rehasher; } _va = { &_fbb, _o, _rehasher}; (void)_va;
   auto _type = _o->type.empty() ? 0 : _fbb.CreateString(_o->type);
-  auto _attr = _o->attr.size() ? _fbb.CreateVector<flatbuffers::Offset<Attribute>> (_o->attr.size(), [](size_t i, _VectorArgs *__va) { return CreateAttribute(*__va->__fbb, __va->__o->attr[i].get(), __va->__rehasher); }, &_va ) : 0;
+  auto _attr = _o->attr.size() ? _fbb.CreateVector<flatbuffers::Offset<MNN::Attribute>> (_o->attr.size(), [](size_t i, _VectorArgs *__va) { return CreateAttribute(*__va->__fbb, __va->__o->attr[i].get(), __va->__rehasher); }, &_va ) : 0;
   return MNN::CreatePlugin(
       _fbb,
       _type,
@@ -4399,18 +4392,18 @@ inline flatbuffers::Offset<Plugin> CreatePlugin(flatbuffers::FlatBufferBuilder &
 }
 
 inline ExtraT *Extra::UnPack(const flatbuffers::resolver_function_t *_resolver) const {
-  auto _o = new ExtraT();
-  UnPackTo(_o, _resolver);
-  return _o;
+  auto _o = std::unique_ptr<ExtraT>(new ExtraT());
+  UnPackTo(_o.get(), _resolver);
+  return _o.release();
 }
 
 inline void Extra::UnPackTo(ExtraT *_o, const flatbuffers::resolver_function_t *_resolver) const {
   (void)_o;
   (void)_resolver;
-  { auto _e = type(); if (_e) _o->type = _e->str(); };
-  { auto _e = engine(); if (_e) _o->engine = _e->str(); };
-  { auto _e = info(); if (_e) { _o->info.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->info[_i] = _e->Get(_i); } } };
-  { auto _e = attr(); if (_e) { _o->attr.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->attr[_i] = std::unique_ptr<AttributeT>(_e->Get(_i)->UnPack(_resolver)); } } };
+  { auto _e = type(); if (_e) _o->type = _e->str(); }
+  { auto _e = engine(); if (_e) _o->engine = _e->str(); }
+  { auto _e = info(); if (_e) { _o->info.resize(_e->size()); std::copy(_e->begin(), _e->end(), _o->info.begin()); } }
+  { auto _e = attr(); if (_e) { _o->attr.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->attr[_i] = std::unique_ptr<MNN::AttributeT>(_e->Get(_i)->UnPack(_resolver)); } } }
 }
 
 inline flatbuffers::Offset<Extra> Extra::Pack(flatbuffers::FlatBufferBuilder &_fbb, const ExtraT* _o, const flatbuffers::rehasher_function_t *_rehasher) {
@@ -4424,7 +4417,7 @@ inline flatbuffers::Offset<Extra> CreateExtra(flatbuffers::FlatBufferBuilder &_f
   auto _type = _o->type.empty() ? 0 : _fbb.CreateString(_o->type);
   auto _engine = _o->engine.empty() ? 0 : _fbb.CreateString(_o->engine);
   auto _info = _o->info.size() ? _fbb.CreateVector(_o->info) : 0;
-  auto _attr = _o->attr.size() ? _fbb.CreateVector<flatbuffers::Offset<Attribute>> (_o->attr.size(), [](size_t i, _VectorArgs *__va) { return CreateAttribute(*__va->__fbb, __va->__o->attr[i].get(), __va->__rehasher); }, &_va ) : 0;
+  auto _attr = _o->attr.size() ? _fbb.CreateVector<flatbuffers::Offset<MNN::Attribute>> (_o->attr.size(), [](size_t i, _VectorArgs *__va) { return CreateAttribute(*__va->__fbb, __va->__o->attr[i].get(), __va->__rehasher); }, &_va ) : 0;
   return MNN::CreateExtra(
       _fbb,
       _type,
@@ -4434,15 +4427,15 @@ inline flatbuffers::Offset<Extra> CreateExtra(flatbuffers::FlatBufferBuilder &_f
 }
 
 inline StringVecT *StringVec::UnPack(const flatbuffers::resolver_function_t *_resolver) const {
-  auto _o = new StringVecT();
-  UnPackTo(_o, _resolver);
-  return _o;
+  auto _o = std::unique_ptr<StringVecT>(new StringVecT());
+  UnPackTo(_o.get(), _resolver);
+  return _o.release();
 }
 
 inline void StringVec::UnPackTo(StringVecT *_o, const flatbuffers::resolver_function_t *_resolver) const {
   (void)_o;
   (void)_resolver;
-  { auto _e = data(); if (_e) { _o->data.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->data[_i] = _e->Get(_i)->str(); } } };
+  { auto _e = data(); if (_e) { _o->data.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->data[_i] = _e->Get(_i)->str(); } } }
 }
 
 inline flatbuffers::Offset<StringVec> StringVec::Pack(flatbuffers::FlatBufferBuilder &_fbb, const StringVecT* _o, const flatbuffers::rehasher_function_t *_rehasher) {
@@ -4460,19 +4453,19 @@ inline flatbuffers::Offset<StringVec> CreateStringVec(flatbuffers::FlatBufferBui
 }
 
 inline WhileParamT *WhileParam::UnPack(const flatbuffers::resolver_function_t *_resolver) const {
-  auto _o = new WhileParamT();
-  UnPackTo(_o, _resolver);
-  return _o;
+  auto _o = std::unique_ptr<WhileParamT>(new WhileParamT());
+  UnPackTo(_o.get(), _resolver);
+  return _o.release();
 }
 
 inline void WhileParam::UnPackTo(WhileParamT *_o, const flatbuffers::resolver_function_t *_resolver) const {
   (void)_o;
   (void)_resolver;
-  { auto _e = cond_graph(); if (_e) _o->cond_graph = _e->str(); };
-  { auto _e = body_graph(); if (_e) _o->body_graph = _e->str(); };
-  { auto _e = aliases_inputs(); if (_e) { _o->aliases_inputs.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->aliases_inputs[_i] = std::unique_ptr<StringVecT>(_e->Get(_i)->UnPack(_resolver)); } } };
-  { auto _e = aliases_outputs(); if (_e) { _o->aliases_outputs.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->aliases_outputs[_i] = _e->Get(_i)->str(); } } };
-  { auto _e = aliases_updates(); if (_e) { _o->aliases_updates.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->aliases_updates[_i] = std::unique_ptr<StringVecT>(_e->Get(_i)->UnPack(_resolver)); } } };
+  { auto _e = cond_graph(); if (_e) _o->cond_graph = _e->str(); }
+  { auto _e = body_graph(); if (_e) _o->body_graph = _e->str(); }
+  { auto _e = aliases_inputs(); if (_e) { _o->aliases_inputs.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->aliases_inputs[_i] = std::unique_ptr<MNN::StringVecT>(_e->Get(_i)->UnPack(_resolver)); } } }
+  { auto _e = aliases_outputs(); if (_e) { _o->aliases_outputs.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->aliases_outputs[_i] = _e->Get(_i)->str(); } } }
+  { auto _e = aliases_updates(); if (_e) { _o->aliases_updates.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->aliases_updates[_i] = std::unique_ptr<MNN::StringVecT>(_e->Get(_i)->UnPack(_resolver)); } } }
 }
 
 inline flatbuffers::Offset<WhileParam> WhileParam::Pack(flatbuffers::FlatBufferBuilder &_fbb, const WhileParamT* _o, const flatbuffers::rehasher_function_t *_rehasher) {
@@ -4485,9 +4478,9 @@ inline flatbuffers::Offset<WhileParam> CreateWhileParam(flatbuffers::FlatBufferB
   struct _VectorArgs { flatbuffers::FlatBufferBuilder *__fbb; const WhileParamT* __o; const flatbuffers::rehasher_function_t *__rehasher; } _va = { &_fbb, _o, _rehasher}; (void)_va;
   auto _cond_graph = _o->cond_graph.empty() ? 0 : _fbb.CreateString(_o->cond_graph);
   auto _body_graph = _o->body_graph.empty() ? 0 : _fbb.CreateString(_o->body_graph);
-  auto _aliases_inputs = _o->aliases_inputs.size() ? _fbb.CreateVector<flatbuffers::Offset<StringVec>> (_o->aliases_inputs.size(), [](size_t i, _VectorArgs *__va) { return CreateStringVec(*__va->__fbb, __va->__o->aliases_inputs[i].get(), __va->__rehasher); }, &_va ) : 0;
+  auto _aliases_inputs = _o->aliases_inputs.size() ? _fbb.CreateVector<flatbuffers::Offset<MNN::StringVec>> (_o->aliases_inputs.size(), [](size_t i, _VectorArgs *__va) { return CreateStringVec(*__va->__fbb, __va->__o->aliases_inputs[i].get(), __va->__rehasher); }, &_va ) : 0;
   auto _aliases_outputs = _o->aliases_outputs.size() ? _fbb.CreateVectorOfStrings(_o->aliases_outputs) : 0;
-  auto _aliases_updates = _o->aliases_updates.size() ? _fbb.CreateVector<flatbuffers::Offset<StringVec>> (_o->aliases_updates.size(), [](size_t i, _VectorArgs *__va) { return CreateStringVec(*__va->__fbb, __va->__o->aliases_updates[i].get(), __va->__rehasher); }, &_va ) : 0;
+  auto _aliases_updates = _o->aliases_updates.size() ? _fbb.CreateVector<flatbuffers::Offset<MNN::StringVec>> (_o->aliases_updates.size(), [](size_t i, _VectorArgs *__va) { return CreateStringVec(*__va->__fbb, __va->__o->aliases_updates[i].get(), __va->__rehasher); }, &_va ) : 0;
   return MNN::CreateWhileParam(
       _fbb,
       _cond_graph,
@@ -4498,18 +4491,18 @@ inline flatbuffers::Offset<WhileParam> CreateWhileParam(flatbuffers::FlatBufferB
 }
 
 inline IfParamT *IfParam::UnPack(const flatbuffers::resolver_function_t *_resolver) const {
-  auto _o = new IfParamT();
-  UnPackTo(_o, _resolver);
-  return _o;
+  auto _o = std::unique_ptr<IfParamT>(new IfParamT());
+  UnPackTo(_o.get(), _resolver);
+  return _o.release();
 }
 
 inline void IfParam::UnPackTo(IfParamT *_o, const flatbuffers::resolver_function_t *_resolver) const {
   (void)_o;
   (void)_resolver;
-  { auto _e = then_graph(); if (_e) _o->then_graph = _e->str(); };
-  { auto _e = else_graph(); if (_e) _o->else_graph = _e->str(); };
-  { auto _e = aliases_inputs(); if (_e) { _o->aliases_inputs.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->aliases_inputs[_i] = std::unique_ptr<StringVecT>(_e->Get(_i)->UnPack(_resolver)); } } };
-  { auto _e = aliases_outputs(); if (_e) { _o->aliases_outputs.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->aliases_outputs[_i] = std::unique_ptr<StringVecT>(_e->Get(_i)->UnPack(_resolver)); } } };
+  { auto _e = then_graph(); if (_e) _o->then_graph = _e->str(); }
+  { auto _e = else_graph(); if (_e) _o->else_graph = _e->str(); }
+  { auto _e = aliases_inputs(); if (_e) { _o->aliases_inputs.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->aliases_inputs[_i] = std::unique_ptr<MNN::StringVecT>(_e->Get(_i)->UnPack(_resolver)); } } }
+  { auto _e = aliases_outputs(); if (_e) { _o->aliases_outputs.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->aliases_outputs[_i] = std::unique_ptr<MNN::StringVecT>(_e->Get(_i)->UnPack(_resolver)); } } }
 }
 
 inline flatbuffers::Offset<IfParam> IfParam::Pack(flatbuffers::FlatBufferBuilder &_fbb, const IfParamT* _o, const flatbuffers::rehasher_function_t *_rehasher) {
@@ -4522,8 +4515,8 @@ inline flatbuffers::Offset<IfParam> CreateIfParam(flatbuffers::FlatBufferBuilder
   struct _VectorArgs { flatbuffers::FlatBufferBuilder *__fbb; const IfParamT* __o; const flatbuffers::rehasher_function_t *__rehasher; } _va = { &_fbb, _o, _rehasher}; (void)_va;
   auto _then_graph = _o->then_graph.empty() ? 0 : _fbb.CreateString(_o->then_graph);
   auto _else_graph = _o->else_graph.empty() ? 0 : _fbb.CreateString(_o->else_graph);
-  auto _aliases_inputs = _o->aliases_inputs.size() ? _fbb.CreateVector<flatbuffers::Offset<StringVec>> (_o->aliases_inputs.size(), [](size_t i, _VectorArgs *__va) { return CreateStringVec(*__va->__fbb, __va->__o->aliases_inputs[i].get(), __va->__rehasher); }, &_va ) : 0;
-  auto _aliases_outputs = _o->aliases_outputs.size() ? _fbb.CreateVector<flatbuffers::Offset<StringVec>> (_o->aliases_outputs.size(), [](size_t i, _VectorArgs *__va) { return CreateStringVec(*__va->__fbb, __va->__o->aliases_outputs[i].get(), __va->__rehasher); }, &_va ) : 0;
+  auto _aliases_inputs = _o->aliases_inputs.size() ? _fbb.CreateVector<flatbuffers::Offset<MNN::StringVec>> (_o->aliases_inputs.size(), [](size_t i, _VectorArgs *__va) { return CreateStringVec(*__va->__fbb, __va->__o->aliases_inputs[i].get(), __va->__rehasher); }, &_va ) : 0;
+  auto _aliases_outputs = _o->aliases_outputs.size() ? _fbb.CreateVector<flatbuffers::Offset<MNN::StringVec>> (_o->aliases_outputs.size(), [](size_t i, _VectorArgs *__va) { return CreateStringVec(*__va->__fbb, __va->__o->aliases_outputs[i].get(), __va->__rehasher); }, &_va ) : 0;
   return MNN::CreateIfParam(
       _fbb,
       _then_graph,
@@ -4533,21 +4526,21 @@ inline flatbuffers::Offset<IfParam> CreateIfParam(flatbuffers::FlatBufferBuilder
 }
 
 inline OpT *Op::UnPack(const flatbuffers::resolver_function_t *_resolver) const {
-  auto _o = new OpT();
-  UnPackTo(_o, _resolver);
-  return _o;
+  auto _o = std::unique_ptr<OpT>(new OpT());
+  UnPackTo(_o.get(), _resolver);
+  return _o.release();
 }
 
 inline void Op::UnPackTo(OpT *_o, const flatbuffers::resolver_function_t *_resolver) const {
   (void)_o;
   (void)_resolver;
-  { auto _e = inputIndexes(); if (_e) { _o->inputIndexes.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->inputIndexes[_i] = _e->Get(_i); } } };
-  { auto _e = main_type(); _o->main.type = _e; };
-  { auto _e = main(); if (_e) _o->main.value = OpParameterUnion::UnPack(_e, main_type(), _resolver); };
-  { auto _e = name(); if (_e) _o->name = _e->str(); };
-  { auto _e = outputIndexes(); if (_e) { _o->outputIndexes.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->outputIndexes[_i] = _e->Get(_i); } } };
-  { auto _e = type(); _o->type = _e; };
-  { auto _e = defaultDimentionFormat(); _o->defaultDimentionFormat = _e; };
+  { auto _e = inputIndexes(); if (_e) { _o->inputIndexes.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->inputIndexes[_i] = _e->Get(_i); } } }
+  { auto _e = main_type(); _o->main.type = _e; }
+  { auto _e = main(); if (_e) _o->main.value = MNN::OpParameterUnion::UnPack(_e, main_type(), _resolver); }
+  { auto _e = name(); if (_e) _o->name = _e->str(); }
+  { auto _e = outputIndexes(); if (_e) { _o->outputIndexes.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->outputIndexes[_i] = _e->Get(_i); } } }
+  { auto _e = type(); _o->type = _e; }
+  { auto _e = defaultDimentionFormat(); _o->defaultDimentionFormat = _e; }
 }
 
 inline flatbuffers::Offset<Op> Op::Pack(flatbuffers::FlatBufferBuilder &_fbb, const OpT* _o, const flatbuffers::rehasher_function_t *_rehasher) {
@@ -4577,16 +4570,16 @@ inline flatbuffers::Offset<Op> CreateOp(flatbuffers::FlatBufferBuilder &_fbb, co
 }
 
 inline ViewT *View::UnPack(const flatbuffers::resolver_function_t *_resolver) const {
-  auto _o = new ViewT();
-  UnPackTo(_o, _resolver);
-  return _o;
+  auto _o = std::unique_ptr<ViewT>(new ViewT());
+  UnPackTo(_o.get(), _resolver);
+  return _o.release();
 }
 
 inline void View::UnPackTo(ViewT *_o, const flatbuffers::resolver_function_t *_resolver) const {
   (void)_o;
   (void)_resolver;
-  { auto _e = offset(); _o->offset = _e; };
-  { auto _e = stride(); if (_e) { _o->stride.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->stride[_i] = _e->Get(_i); } } };
+  { auto _e = offset(); _o->offset = _e; }
+  { auto _e = stride(); if (_e) { _o->stride.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->stride[_i] = _e->Get(_i); } } }
 }
 
 inline flatbuffers::Offset<View> View::Pack(flatbuffers::FlatBufferBuilder &_fbb, const ViewT* _o, const flatbuffers::rehasher_function_t *_rehasher) {
@@ -4606,18 +4599,18 @@ inline flatbuffers::Offset<View> CreateView(flatbuffers::FlatBufferBuilder &_fbb
 }
 
 inline RegionT *Region::UnPack(const flatbuffers::resolver_function_t *_resolver) const {
-  auto _o = new RegionT();
-  UnPackTo(_o, _resolver);
-  return _o;
+  auto _o = std::unique_ptr<RegionT>(new RegionT());
+  UnPackTo(_o.get(), _resolver);
+  return _o.release();
 }
 
 inline void Region::UnPackTo(RegionT *_o, const flatbuffers::resolver_function_t *_resolver) const {
   (void)_o;
   (void)_resolver;
-  { auto _e = src(); if (_e) _o->src = std::unique_ptr<ViewT>(_e->UnPack(_resolver)); };
-  { auto _e = dst(); if (_e) _o->dst = std::unique_ptr<ViewT>(_e->UnPack(_resolver)); };
-  { auto _e = size(); if (_e) { _o->size.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->size[_i] = _e->Get(_i); } } };
-  { auto _e = origin(); _o->origin = _e; };
+  { auto _e = src(); if (_e) _o->src = std::unique_ptr<MNN::ViewT>(_e->UnPack(_resolver)); }
+  { auto _e = dst(); if (_e) _o->dst = std::unique_ptr<MNN::ViewT>(_e->UnPack(_resolver)); }
+  { auto _e = size(); if (_e) { _o->size.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->size[_i] = _e->Get(_i); } } }
+  { auto _e = origin(); _o->origin = _e; }
 }
 
 inline flatbuffers::Offset<Region> Region::Pack(flatbuffers::FlatBufferBuilder &_fbb, const RegionT* _o, const flatbuffers::rehasher_function_t *_rehasher) {
@@ -4641,18 +4634,18 @@ inline flatbuffers::Offset<Region> CreateRegion(flatbuffers::FlatBufferBuilder &
 }
 
 inline TensorDescribeT *TensorDescribe::UnPack(const flatbuffers::resolver_function_t *_resolver) const {
-  auto _o = new TensorDescribeT();
-  UnPackTo(_o, _resolver);
-  return _o;
+  auto _o = std::unique_ptr<TensorDescribeT>(new TensorDescribeT());
+  UnPackTo(_o.get(), _resolver);
+  return _o.release();
 }
 
 inline void TensorDescribe::UnPackTo(TensorDescribeT *_o, const flatbuffers::resolver_function_t *_resolver) const {
   (void)_o;
   (void)_resolver;
-  { auto _e = blob(); if (_e) _o->blob = std::unique_ptr<BlobT>(_e->UnPack(_resolver)); };
-  { auto _e = index(); _o->index = _e; };
-  { auto _e = name(); if (_e) _o->name = _e->str(); };
-  { auto _e = regions(); if (_e) { _o->regions.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->regions[_i] = std::unique_ptr<RegionT>(_e->Get(_i)->UnPack(_resolver)); } } };
+  { auto _e = blob(); if (_e) _o->blob = std::unique_ptr<MNN::BlobT>(_e->UnPack(_resolver)); }
+  { auto _e = index(); _o->index = _e; }
+  { auto _e = name(); if (_e) _o->name = _e->str(); }
+  { auto _e = regions(); if (_e) { _o->regions.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->regions[_i] = std::unique_ptr<MNN::RegionT>(_e->Get(_i)->UnPack(_resolver)); } } }
 }
 
 inline flatbuffers::Offset<TensorDescribe> TensorDescribe::Pack(flatbuffers::FlatBufferBuilder &_fbb, const TensorDescribeT* _o, const flatbuffers::rehasher_function_t *_rehasher) {
@@ -4666,7 +4659,7 @@ inline flatbuffers::Offset<TensorDescribe> CreateTensorDescribe(flatbuffers::Fla
   auto _blob = _o->blob ? CreateBlob(_fbb, _o->blob.get(), _rehasher) : 0;
   auto _index = _o->index;
   auto _name = _o->name.empty() ? 0 : _fbb.CreateString(_o->name);
-  auto _regions = _o->regions.size() ? _fbb.CreateVector<flatbuffers::Offset<Region>> (_o->regions.size(), [](size_t i, _VectorArgs *__va) { return CreateRegion(*__va->__fbb, __va->__o->regions[i].get(), __va->__rehasher); }, &_va ) : 0;
+  auto _regions = _o->regions.size() ? _fbb.CreateVector<flatbuffers::Offset<MNN::Region>> (_o->regions.size(), [](size_t i, _VectorArgs *__va) { return CreateRegion(*__va->__fbb, __va->__o->regions[i].get(), __va->__rehasher); }, &_va ) : 0;
   return MNN::CreateTensorDescribe(
       _fbb,
       _blob,
@@ -4676,19 +4669,19 @@ inline flatbuffers::Offset<TensorDescribe> CreateTensorDescribe(flatbuffers::Fla
 }
 
 inline SubGraphProtoT *SubGraphProto::UnPack(const flatbuffers::resolver_function_t *_resolver) const {
-  auto _o = new SubGraphProtoT();
-  UnPackTo(_o, _resolver);
-  return _o;
+  auto _o = std::unique_ptr<SubGraphProtoT>(new SubGraphProtoT());
+  UnPackTo(_o.get(), _resolver);
+  return _o.release();
 }
 
 inline void SubGraphProto::UnPackTo(SubGraphProtoT *_o, const flatbuffers::resolver_function_t *_resolver) const {
   (void)_o;
   (void)_resolver;
-  { auto _e = name(); if (_e) _o->name = _e->str(); };
-  { auto _e = inputs(); if (_e) { _o->inputs.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->inputs[_i] = _e->Get(_i); } } };
-  { auto _e = outputs(); if (_e) { _o->outputs.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->outputs[_i] = _e->Get(_i); } } };
-  { auto _e = tensors(); if (_e) { _o->tensors.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->tensors[_i] = _e->Get(_i)->str(); } } };
-  { auto _e = nodes(); if (_e) { _o->nodes.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->nodes[_i] = std::unique_ptr<OpT>(_e->Get(_i)->UnPack(_resolver)); } } };
+  { auto _e = name(); if (_e) _o->name = _e->str(); }
+  { auto _e = inputs(); if (_e) { _o->inputs.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->inputs[_i] = _e->Get(_i); } } }
+  { auto _e = outputs(); if (_e) { _o->outputs.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->outputs[_i] = _e->Get(_i); } } }
+  { auto _e = tensors(); if (_e) { _o->tensors.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->tensors[_i] = _e->Get(_i)->str(); } } }
+  { auto _e = nodes(); if (_e) { _o->nodes.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->nodes[_i] = std::unique_ptr<MNN::OpT>(_e->Get(_i)->UnPack(_resolver)); } } }
 }
 
 inline flatbuffers::Offset<SubGraphProto> SubGraphProto::Pack(flatbuffers::FlatBufferBuilder &_fbb, const SubGraphProtoT* _o, const flatbuffers::rehasher_function_t *_rehasher) {
@@ -4703,7 +4696,7 @@ inline flatbuffers::Offset<SubGraphProto> CreateSubGraphProto(flatbuffers::FlatB
   auto _inputs = _o->inputs.size() ? _fbb.CreateVector(_o->inputs) : 0;
   auto _outputs = _o->outputs.size() ? _fbb.CreateVector(_o->outputs) : 0;
   auto _tensors = _o->tensors.size() ? _fbb.CreateVectorOfStrings(_o->tensors) : 0;
-  auto _nodes = _o->nodes.size() ? _fbb.CreateVector<flatbuffers::Offset<Op>> (_o->nodes.size(), [](size_t i, _VectorArgs *__va) { return CreateOp(*__va->__fbb, __va->__o->nodes[i].get(), __va->__rehasher); }, &_va ) : 0;
+  auto _nodes = _o->nodes.size() ? _fbb.CreateVector<flatbuffers::Offset<MNN::Op>> (_o->nodes.size(), [](size_t i, _VectorArgs *__va) { return CreateOp(*__va->__fbb, __va->__o->nodes[i].get(), __va->__rehasher); }, &_va ) : 0;
   return MNN::CreateSubGraphProto(
       _fbb,
       _name,
@@ -4714,25 +4707,25 @@ inline flatbuffers::Offset<SubGraphProto> CreateSubGraphProto(flatbuffers::FlatB
 }
 
 inline NetT *Net::UnPack(const flatbuffers::resolver_function_t *_resolver) const {
-  auto _o = new NetT();
-  UnPackTo(_o, _resolver);
-  return _o;
+  auto _o = std::unique_ptr<NetT>(new NetT());
+  UnPackTo(_o.get(), _resolver);
+  return _o.release();
 }
 
 inline void Net::UnPackTo(NetT *_o, const flatbuffers::resolver_function_t *_resolver) const {
   (void)_o;
   (void)_resolver;
-  { auto _e = bizCode(); if (_e) _o->bizCode = _e->str(); };
-  { auto _e = extraTensorDescribe(); if (_e) { _o->extraTensorDescribe.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->extraTensorDescribe[_i] = std::unique_ptr<TensorDescribeT>(_e->Get(_i)->UnPack(_resolver)); } } };
-  { auto _e = gpulibrary(); if (_e) _o->gpulibrary = std::unique_ptr<GpuLibraryT>(_e->UnPack(_resolver)); };
-  { auto _e = oplists(); if (_e) { _o->oplists.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->oplists[_i] = std::unique_ptr<OpT>(_e->Get(_i)->UnPack(_resolver)); } } };
-  { auto _e = outputName(); if (_e) { _o->outputName.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->outputName[_i] = _e->Get(_i)->str(); } } };
-  { auto _e = preferForwardType(); _o->preferForwardType = _e; };
-  { auto _e = sourceType(); _o->sourceType = _e; };
-  { auto _e = tensorName(); if (_e) { _o->tensorName.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->tensorName[_i] = _e->Get(_i)->str(); } } };
-  { auto _e = tensorNumber(); _o->tensorNumber = _e; };
-  { auto _e = usage(); _o->usage = _e; };
-  { auto _e = subgraphs(); if (_e) { _o->subgraphs.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->subgraphs[_i] = std::unique_ptr<SubGraphProtoT>(_e->Get(_i)->UnPack(_resolver)); } } };
+  { auto _e = bizCode(); if (_e) _o->bizCode = _e->str(); }
+  { auto _e = extraTensorDescribe(); if (_e) { _o->extraTensorDescribe.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->extraTensorDescribe[_i] = std::unique_ptr<MNN::TensorDescribeT>(_e->Get(_i)->UnPack(_resolver)); } } }
+  { auto _e = gpulibrary(); if (_e) _o->gpulibrary = std::unique_ptr<MNN::GpuLibraryT>(_e->UnPack(_resolver)); }
+  { auto _e = oplists(); if (_e) { _o->oplists.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->oplists[_i] = std::unique_ptr<MNN::OpT>(_e->Get(_i)->UnPack(_resolver)); } } }
+  { auto _e = outputName(); if (_e) { _o->outputName.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->outputName[_i] = _e->Get(_i)->str(); } } }
+  { auto _e = preferForwardType(); _o->preferForwardType = _e; }
+  { auto _e = sourceType(); _o->sourceType = _e; }
+  { auto _e = tensorName(); if (_e) { _o->tensorName.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->tensorName[_i] = _e->Get(_i)->str(); } } }
+  { auto _e = tensorNumber(); _o->tensorNumber = _e; }
+  { auto _e = usage(); _o->usage = _e; }
+  { auto _e = subgraphs(); if (_e) { _o->subgraphs.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->subgraphs[_i] = std::unique_ptr<MNN::SubGraphProtoT>(_e->Get(_i)->UnPack(_resolver)); } } }
 }
 
 inline flatbuffers::Offset<Net> Net::Pack(flatbuffers::FlatBufferBuilder &_fbb, const NetT* _o, const flatbuffers::rehasher_function_t *_rehasher) {
@@ -4744,16 +4737,16 @@ inline flatbuffers::Offset<Net> CreateNet(flatbuffers::FlatBufferBuilder &_fbb,
   (void)_o;
   struct _VectorArgs { flatbuffers::FlatBufferBuilder *__fbb; const NetT* __o; const flatbuffers::rehasher_function_t *__rehasher; } _va = { &_fbb, _o, _rehasher}; (void)_va;
   auto _bizCode = _o->bizCode.empty() ? 0 : _fbb.CreateString(_o->bizCode);
-  auto _extraTensorDescribe = _o->extraTensorDescribe.size() ? _fbb.CreateVector<flatbuffers::Offset<TensorDescribe>> (_o->extraTensorDescribe.size(), [](size_t i, _VectorArgs *__va) { return CreateTensorDescribe(*__va->__fbb, __va->__o->extraTensorDescribe[i].get(), __va->__rehasher); }, &_va ) : 0;
+  auto _extraTensorDescribe = _o->extraTensorDescribe.size() ? _fbb.CreateVector<flatbuffers::Offset<MNN::TensorDescribe>> (_o->extraTensorDescribe.size(), [](size_t i, _VectorArgs *__va) { return CreateTensorDescribe(*__va->__fbb, __va->__o->extraTensorDescribe[i].get(), __va->__rehasher); }, &_va ) : 0;
   auto _gpulibrary = _o->gpulibrary ? CreateGpuLibrary(_fbb, _o->gpulibrary.get(), _rehasher) : 0;
-  auto _oplists = _o->oplists.size() ? _fbb.CreateVector<flatbuffers::Offset<Op>> (_o->oplists.size(), [](size_t i, _VectorArgs *__va) { return CreateOp(*__va->__fbb, __va->__o->oplists[i].get(), __va->__rehasher); }, &_va ) : 0;
+  auto _oplists = _o->oplists.size() ? _fbb.CreateVector<flatbuffers::Offset<MNN::Op>> (_o->oplists.size(), [](size_t i, _VectorArgs *__va) { return CreateOp(*__va->__fbb, __va->__o->oplists[i].get(), __va->__rehasher); }, &_va ) : 0;
   auto _outputName = _o->outputName.size() ? _fbb.CreateVectorOfStrings(_o->outputName) : 0;
   auto _preferForwardType = _o->preferForwardType;
   auto _sourceType = _o->sourceType;
   auto _tensorName = _o->tensorName.size() ? _fbb.CreateVectorOfStrings(_o->tensorName) : 0;
   auto _tensorNumber = _o->tensorNumber;
   auto _usage = _o->usage;
-  auto _subgraphs = _o->subgraphs.size() ? _fbb.CreateVector<flatbuffers::Offset<SubGraphProto>> (_o->subgraphs.size(), [](size_t i, _VectorArgs *__va) { return CreateSubGraphProto(*__va->__fbb, __va->__o->subgraphs[i].get(), __va->__rehasher); }, &_va ) : 0;
+  auto _subgraphs = _o->subgraphs.size() ? _fbb.CreateVector<flatbuffers::Offset<MNN::SubGraphProto>> (_o->subgraphs.size(), [](size_t i, _VectorArgs *__va) { return CreateSubGraphProto(*__va->__fbb, __va->__o->subgraphs[i].get(), __va->__rehasher); }, &_va ) : 0;
   return MNN::CreateNet(
       _fbb,
       _bizCode,
@@ -4775,358 +4768,358 @@ inline bool VerifyOpParameter(flatbuffers::Verifier &verifier, const void *obj,
       return true;
     }
     case OpParameter_QuantizedAdd: {
-      auto ptr = reinterpret_cast<const QuantizedAdd *>(obj);
+      auto ptr = reinterpret_cast<const MNN::QuantizedAdd *>(obj);
       return verifier.VerifyTable(ptr);
     }
     case OpParameter_ArgMax: {
-      auto ptr = reinterpret_cast<const ArgMax *>(obj);
+      auto ptr = reinterpret_cast<const MNN::ArgMax *>(obj);
       return verifier.VerifyTable(ptr);
     }
     case OpParameter_AsString: {
-      auto ptr = reinterpret_cast<const AsString *>(obj);
+      auto ptr = reinterpret_cast<const MNN::AsString *>(obj);
       return verifier.VerifyTable(ptr);
     }
     case OpParameter_Axis: {
-      auto ptr = reinterpret_cast<const Axis *>(obj);
+      auto ptr = reinterpret_cast<const MNN::Axis *>(obj);
       return verifier.VerifyTable(ptr);
     }
     case OpParameter_BatchNorm: {
-      auto ptr = reinterpret_cast<const BatchNorm *>(obj);
+      auto ptr = reinterpret_cast<const MNN::BatchNorm *>(obj);
       return verifier.VerifyTable(ptr);
     }
     case OpParameter_BinaryOp: {
-      auto ptr = reinterpret_cast<const BinaryOp *>(obj);
+      auto ptr = reinterpret_cast<const MNN::BinaryOp *>(obj);
       return verifier.VerifyTable(ptr);
     }
     case OpParameter_Blob: {
-      auto ptr = reinterpret_cast<const Blob *>(obj);
+      auto ptr = reinterpret_cast<const MNN::Blob *>(obj);
       return verifier.VerifyTable(ptr);
     }
     case OpParameter_CastParam: {
-      auto ptr = reinterpret_cast<const CastParam *>(obj);
+      auto ptr = reinterpret_cast<const MNN::CastParam *>(obj);
       return verifier.VerifyTable(ptr);
     }
     case OpParameter_Convolution2D: {
-      auto ptr = reinterpret_cast<const Convolution2D *>(obj);
+      auto ptr = reinterpret_cast<const MNN::Convolution2D *>(obj);
       return verifier.VerifyTable(ptr);
     }
     case OpParameter_Crop: {
-      auto ptr = reinterpret_cast<const Crop *>(obj);
+      auto ptr = reinterpret_cast<const MNN::Crop *>(obj);
       return verifier.VerifyTable(ptr);
     }
     case OpParameter_CropAndResize: {
-      auto ptr = reinterpret_cast<const CropAndResize *>(obj);
+      auto ptr = reinterpret_cast<const MNN::CropAndResize *>(obj);
       return verifier.VerifyTable(ptr);
     }
     case OpParameter_Dequantize: {
-      auto ptr = reinterpret_cast<const Dequantize *>(obj);
+      auto ptr = reinterpret_cast<const MNN::Dequantize *>(obj);
       return verifier.VerifyTable(ptr);
     }
     case OpParameter_DetectionOutput: {
-      auto ptr = reinterpret_cast<const DetectionOutput *>(obj);
+      auto ptr = reinterpret_cast<const MNN::DetectionOutput *>(obj);
       return verifier.VerifyTable(ptr);
     }
     case OpParameter_Eltwise: {
-      auto ptr = reinterpret_cast<const Eltwise *>(obj);
+      auto ptr = reinterpret_cast<const MNN::Eltwise *>(obj);
       return verifier.VerifyTable(ptr);
     }
     case OpParameter_ExpandDims: {
-      auto ptr = reinterpret_cast<const ExpandDims *>(obj);
+      auto ptr = reinterpret_cast<const MNN::ExpandDims *>(obj);
       return verifier.VerifyTable(ptr);
     }
     case OpParameter_Fill: {
-      auto ptr = reinterpret_cast<const Fill *>(obj);
+      auto ptr = reinterpret_cast<const MNN::Fill *>(obj);
       return verifier.VerifyTable(ptr);
     }
     case OpParameter_Flatten: {
-      auto ptr = reinterpret_cast<const Flatten *>(obj);
+      auto ptr = reinterpret_cast<const MNN::Flatten *>(obj);
       return verifier.VerifyTable(ptr);
     }
     case OpParameter_Gather: {
-      auto ptr = reinterpret_cast<const Gather *>(obj);
+      auto ptr = reinterpret_cast<const MNN::Gather *>(obj);
       return verifier.VerifyTable(ptr);
     }
     case OpParameter_GatherV2: {
-      auto ptr = reinterpret_cast<const GatherV2 *>(obj);
+      auto ptr = reinterpret_cast<const MNN::GatherV2 *>(obj);
       return verifier.VerifyTable(ptr);
     }
     case OpParameter_InnerProduct: {
-      auto ptr = reinterpret_cast<const InnerProduct *>(obj);
+      auto ptr = reinterpret_cast<const MNN::InnerProduct *>(obj);
       return verifier.VerifyTable(ptr);
     }
     case OpParameter_Input: {
-      auto ptr = reinterpret_cast<const Input *>(obj);
+      auto ptr = reinterpret_cast<const MNN::Input *>(obj);
       return verifier.VerifyTable(ptr);
     }
     case OpParameter_Interp: {
-      auto ptr = reinterpret_cast<const Interp *>(obj);
+      auto ptr = reinterpret_cast<const MNN::Interp *>(obj);
       return verifier.VerifyTable(ptr);
     }
     case OpParameter_LRN: {
-      auto ptr = reinterpret_cast<const LRN *>(obj);
+      auto ptr = reinterpret_cast<const MNN::LRN *>(obj);
       return verifier.VerifyTable(ptr);
     }
     case OpParameter_LSTM: {
-      auto ptr = reinterpret_cast<const LSTM *>(obj);
+      auto ptr = reinterpret_cast<const MNN::LSTM *>(obj);
       return verifier.VerifyTable(ptr);
     }
     case OpParameter_MatMul: {
-      auto ptr = reinterpret_cast<const MatMul *>(obj);
+      auto ptr = reinterpret_cast<const MNN::MatMul *>(obj);
       return verifier.VerifyTable(ptr);
     }
     case OpParameter_NonMaxSuppressionV2: {
-      auto ptr = reinterpret_cast<const NonMaxSuppressionV2 *>(obj);
+      auto ptr = reinterpret_cast<const MNN::NonMaxSuppressionV2 *>(obj);
       return verifier.VerifyTable(ptr);
     }
     case OpParameter_Normalize: {
-      auto ptr = reinterpret_cast<const Normalize *>(obj);
+      auto ptr = reinterpret_cast<const MNN::Normalize *>(obj);
       return verifier.VerifyTable(ptr);
     }
     case OpParameter_PackParam: {
-      auto ptr = reinterpret_cast<const PackParam *>(obj);
+      auto ptr = reinterpret_cast<const MNN::PackParam *>(obj);
       return verifier.VerifyTable(ptr);
     }
     case OpParameter_Permute: {
-      auto ptr = reinterpret_cast<const Permute *>(obj);
+      auto ptr = reinterpret_cast<const MNN::Permute *>(obj);
       return verifier.VerifyTable(ptr);
     }
     case OpParameter_Plugin: {
-      auto ptr = reinterpret_cast<const Plugin *>(obj);
+      auto ptr = reinterpret_cast<const MNN::Plugin *>(obj);
       return verifier.VerifyTable(ptr);
     }
     case OpParameter_Pool: {
-      auto ptr = reinterpret_cast<const Pool *>(obj);
+      auto ptr = reinterpret_cast<const MNN::Pool *>(obj);
       return verifier.VerifyTable(ptr);
     }
     case OpParameter_PRelu: {
-      auto ptr = reinterpret_cast<const PRelu *>(obj);
+      auto ptr = reinterpret_cast<const MNN::PRelu *>(obj);
       return verifier.VerifyTable(ptr);
     }
     case OpParameter_PriorBox: {
-      auto ptr = reinterpret_cast<const PriorBox *>(obj);
+      auto ptr = reinterpret_cast<const MNN::PriorBox *>(obj);
       return verifier.VerifyTable(ptr);
     }
     case OpParameter_Proposal: {
-      auto ptr = reinterpret_cast<const Proposal *>(obj);
+      auto ptr = reinterpret_cast<const MNN::Proposal *>(obj);
       return verifier.VerifyTable(ptr);
     }
     case OpParameter_QuantizedAvgPool: {
-      auto ptr = reinterpret_cast<const QuantizedAvgPool *>(obj);
+      auto ptr = reinterpret_cast<const MNN::QuantizedAvgPool *>(obj);
       return verifier.VerifyTable(ptr);
     }
     case OpParameter_QuantizedBiasAdd: {
-      auto ptr = reinterpret_cast<const QuantizedBiasAdd *>(obj);
+      auto ptr = reinterpret_cast<const MNN::QuantizedBiasAdd *>(obj);
       return verifier.VerifyTable(ptr);
     }
     case OpParameter_QuantizedConcat: {
-      auto ptr = reinterpret_cast<const QuantizedConcat *>(obj);
+      auto ptr = reinterpret_cast<const MNN::QuantizedConcat *>(obj);
       return verifier.VerifyTable(ptr);
     }
     case OpParameter_QuantizedLogistic: {
-      auto ptr = reinterpret_cast<const QuantizedLogistic *>(obj);
+      auto ptr = reinterpret_cast<const MNN::QuantizedLogistic *>(obj);
       return verifier.VerifyTable(ptr);
     }
     case OpParameter_QuantizedMatMul: {
-      auto ptr = reinterpret_cast<const QuantizedMatMul *>(obj);
+      auto ptr = reinterpret_cast<const MNN::QuantizedMatMul *>(obj);
       return verifier.VerifyTable(ptr);
     }
     case OpParameter_QuantizedMaxPool: {
-      auto ptr = reinterpret_cast<const QuantizedMaxPool *>(obj);
+      auto ptr = reinterpret_cast<const MNN::QuantizedMaxPool *>(obj);
       return verifier.VerifyTable(ptr);
     }
     case OpParameter_QuantizedRelu: {
-      auto ptr = reinterpret_cast<const QuantizedRelu *>(obj);
+      auto ptr = reinterpret_cast<const MNN::QuantizedRelu *>(obj);
       return verifier.VerifyTable(ptr);
     }
     case OpParameter_QuantizedRelu6: {
-      auto ptr = reinterpret_cast<const QuantizedRelu6 *>(obj);
+      auto ptr = reinterpret_cast<const MNN::QuantizedRelu6 *>(obj);
       return verifier.VerifyTable(ptr);
     }
     case OpParameter_QuantizedReshape: {
-      auto ptr = reinterpret_cast<const QuantizedReshape *>(obj);
+      auto ptr = reinterpret_cast<const MNN::QuantizedReshape *>(obj);
       return verifier.VerifyTable(ptr);
     }
     case OpParameter_QuantizedSoftmax: {
-      auto ptr = reinterpret_cast<const QuantizedSoftmax *>(obj);
+      auto ptr = reinterpret_cast<const MNN::QuantizedSoftmax *>(obj);
       return verifier.VerifyTable(ptr);
     }
     case OpParameter_QuantizeMaxMin: {
-      auto ptr = reinterpret_cast<const QuantizeMaxMin *>(obj);
+      auto ptr = reinterpret_cast<const MNN::QuantizeMaxMin *>(obj);
       return verifier.VerifyTable(ptr);
     }
     case OpParameter_QuantizeV2: {
-      auto ptr = reinterpret_cast<const QuantizeV2 *>(obj);
+      auto ptr = reinterpret_cast<const MNN::QuantizeV2 *>(obj);
       return verifier.VerifyTable(ptr);
     }
     case OpParameter_Range: {
-      auto ptr = reinterpret_cast<const Range *>(obj);
+      auto ptr = reinterpret_cast<const MNN::Range *>(obj);
       return verifier.VerifyTable(ptr);
     }
     case OpParameter_Rank: {
-      auto ptr = reinterpret_cast<const Rank *>(obj);
+      auto ptr = reinterpret_cast<const MNN::Rank *>(obj);
       return verifier.VerifyTable(ptr);
     }
     case OpParameter_ReduceJoin: {
-      auto ptr = reinterpret_cast<const ReduceJoin *>(obj);
+      auto ptr = reinterpret_cast<const MNN::ReduceJoin *>(obj);
       return verifier.VerifyTable(ptr);
     }
     case OpParameter_ReductionParam: {
-      auto ptr = reinterpret_cast<const ReductionParam *>(obj);
+      auto ptr = reinterpret_cast<const MNN::ReductionParam *>(obj);
       return verifier.VerifyTable(ptr);
     }
     case OpParameter_Relu: {
-      auto ptr = reinterpret_cast<const Relu *>(obj);
+      auto ptr = reinterpret_cast<const MNN::Relu *>(obj);
       return verifier.VerifyTable(ptr);
     }
     case OpParameter_Relu6: {
-      auto ptr = reinterpret_cast<const Relu6 *>(obj);
+      auto ptr = reinterpret_cast<const MNN::Relu6 *>(obj);
       return verifier.VerifyTable(ptr);
     }
     case OpParameter_RequantizationRange: {
-      auto ptr = reinterpret_cast<const RequantizationRange *>(obj);
+      auto ptr = reinterpret_cast<const MNN::RequantizationRange *>(obj);
       return verifier.VerifyTable(ptr);
     }
     case OpParameter_Requantize: {
-      auto ptr = reinterpret_cast<const Requantize *>(obj);
+      auto ptr = reinterpret_cast<const MNN::Requantize *>(obj);
       return verifier.VerifyTable(ptr);
     }
     case OpParameter_Reshape: {
-      auto ptr = reinterpret_cast<const Reshape *>(obj);
+      auto ptr = reinterpret_cast<const MNN::Reshape *>(obj);
       return verifier.VerifyTable(ptr);
     }
     case OpParameter_Resize: {
-      auto ptr = reinterpret_cast<const Resize *>(obj);
+      auto ptr = reinterpret_cast<const MNN::Resize *>(obj);
       return verifier.VerifyTable(ptr);
     }
     case OpParameter_RoiPooling: {
-      auto ptr = reinterpret_cast<const RoiPooling *>(obj);
+      auto ptr = reinterpret_cast<const MNN::RoiPooling *>(obj);
       return verifier.VerifyTable(ptr);
     }
     case OpParameter_Scale: {
-      auto ptr = reinterpret_cast<const Scale *>(obj);
+      auto ptr = reinterpret_cast<const MNN::Scale *>(obj);
       return verifier.VerifyTable(ptr);
     }
     case OpParameter_Selu: {
-      auto ptr = reinterpret_cast<const Selu *>(obj);
+      auto ptr = reinterpret_cast<const MNN::Selu *>(obj);
       return verifier.VerifyTable(ptr);
     }
     case OpParameter_Size: {
-      auto ptr = reinterpret_cast<const Size *>(obj);
+      auto ptr = reinterpret_cast<const MNN::Size *>(obj);
       return verifier.VerifyTable(ptr);
     }
     case OpParameter_Slice: {
-      auto ptr = reinterpret_cast<const Slice *>(obj);
+      auto ptr = reinterpret_cast<const MNN::Slice *>(obj);
       return verifier.VerifyTable(ptr);
     }
     case OpParameter_SliceTf: {
-      auto ptr = reinterpret_cast<const SliceTf *>(obj);
+      auto ptr = reinterpret_cast<const MNN::SliceTf *>(obj);
       return verifier.VerifyTable(ptr);
     }
     case OpParameter_SpaceBatch: {
-      auto ptr = reinterpret_cast<const SpaceBatch *>(obj);
+      auto ptr = reinterpret_cast<const MNN::SpaceBatch *>(obj);
       return verifier.VerifyTable(ptr);
     }
     case OpParameter_SqueezeParam: {
-      auto ptr = reinterpret_cast<const SqueezeParam *>(obj);
+      auto ptr = reinterpret_cast<const MNN::SqueezeParam *>(obj);
       return verifier.VerifyTable(ptr);
     }
     case OpParameter_StridedSliceParam: {
-      auto ptr = reinterpret_cast<const StridedSliceParam *>(obj);
+      auto ptr = reinterpret_cast<const MNN::StridedSliceParam *>(obj);
       return verifier.VerifyTable(ptr);
     }
     case OpParameter_TensorConvertInfo: {
-      auto ptr = reinterpret_cast<const TensorConvertInfo *>(obj);
+      auto ptr = reinterpret_cast<const MNN::TensorConvertInfo *>(obj);
       return verifier.VerifyTable(ptr);
     }
     case OpParameter_TfQuantizedConv2D: {
-      auto ptr = reinterpret_cast<const TfQuantizedConv2D *>(obj);
+      auto ptr = reinterpret_cast<const MNN::TfQuantizedConv2D *>(obj);
       return verifier.VerifyTable(ptr);
     }
     case OpParameter_TopKV2: {
-      auto ptr = reinterpret_cast<const TopKV2 *>(obj);
+      auto ptr = reinterpret_cast<const MNN::TopKV2 *>(obj);
       return verifier.VerifyTable(ptr);
     }
     case OpParameter_Transpose: {
-      auto ptr = reinterpret_cast<const Transpose *>(obj);
+      auto ptr = reinterpret_cast<const MNN::Transpose *>(obj);
       return verifier.VerifyTable(ptr);
     }
     case OpParameter_UnaryOp: {
-      auto ptr = reinterpret_cast<const UnaryOp *>(obj);
+      auto ptr = reinterpret_cast<const MNN::UnaryOp *>(obj);
       return verifier.VerifyTable(ptr);
     }
     case OpParameter_MomentsParam: {
-      auto ptr = reinterpret_cast<const MomentsParam *>(obj);
+      auto ptr = reinterpret_cast<const MNN::MomentsParam *>(obj);
       return verifier.VerifyTable(ptr);
     }
     case OpParameter_RNNParam: {
-      auto ptr = reinterpret_cast<const RNNParam *>(obj);
+      auto ptr = reinterpret_cast<const MNN::RNNParam *>(obj);
       return verifier.VerifyTable(ptr);
     }
     case OpParameter_BatchMatMulParam: {
-      auto ptr = reinterpret_cast<const BatchMatMulParam *>(obj);
+      auto ptr = reinterpret_cast<const MNN::BatchMatMulParam *>(obj);
       return verifier.VerifyTable(ptr);
     }
     case OpParameter_QuantizedFloatParam: {
-      auto ptr = reinterpret_cast<const QuantizedFloatParam *>(obj);
+      auto ptr = reinterpret_cast<const MNN::QuantizedFloatParam *>(obj);
       return verifier.VerifyTable(ptr);
     }
     case OpParameter_DepthSpaceParam: {
-      auto ptr = reinterpret_cast<const DepthSpaceParam *>(obj);
+      auto ptr = reinterpret_cast<const MNN::DepthSpaceParam *>(obj);
       return verifier.VerifyTable(ptr);
     }
     case OpParameter_EltwiseInt8: {
-      auto ptr = reinterpret_cast<const EltwiseInt8 *>(obj);
+      auto ptr = reinterpret_cast<const MNN::EltwiseInt8 *>(obj);
       return verifier.VerifyTable(ptr);
     }
     case OpParameter_ReverseSequenceParam: {
-      auto ptr = reinterpret_cast<const ReverseSequenceParam *>(obj);
+      auto ptr = reinterpret_cast<const MNN::ReverseSequenceParam *>(obj);
       return verifier.VerifyTable(ptr);
     }
     case OpParameter_Extra: {
-      auto ptr = reinterpret_cast<const Extra *>(obj);
+      auto ptr = reinterpret_cast<const MNN::Extra *>(obj);
       return verifier.VerifyTable(ptr);
     }
     case OpParameter_Pool3D: {
-      auto ptr = reinterpret_cast<const Pool3D *>(obj);
+      auto ptr = reinterpret_cast<const MNN::Pool3D *>(obj);
       return verifier.VerifyTable(ptr);
     }
     case OpParameter_Convolution3D: {
-      auto ptr = reinterpret_cast<const Convolution3D *>(obj);
+      auto ptr = reinterpret_cast<const MNN::Convolution3D *>(obj);
       return verifier.VerifyTable(ptr);
     }
     case OpParameter_ELU: {
-      auto ptr = reinterpret_cast<const ELU *>(obj);
+      auto ptr = reinterpret_cast<const MNN::ELU *>(obj);
       return verifier.VerifyTable(ptr);
     }
     case OpParameter_DetectionPostProcessParam: {
-      auto ptr = reinterpret_cast<const DetectionPostProcessParam *>(obj);
+      auto ptr = reinterpret_cast<const MNN::DetectionPostProcessParam *>(obj);
       return verifier.VerifyTable(ptr);
     }
     case OpParameter_OneHotParam: {
-      auto ptr = reinterpret_cast<const OneHotParam *>(obj);
+      auto ptr = reinterpret_cast<const MNN::OneHotParam *>(obj);
       return verifier.VerifyTable(ptr);
     }
     case OpParameter_PadParam: {
-      auto ptr = reinterpret_cast<const PadParam *>(obj);
+      auto ptr = reinterpret_cast<const MNN::PadParam *>(obj);
       return verifier.VerifyTable(ptr);
     }
     case OpParameter_WhileParam: {
-      auto ptr = reinterpret_cast<const WhileParam *>(obj);
+      auto ptr = reinterpret_cast<const MNN::WhileParam *>(obj);
       return verifier.VerifyTable(ptr);
     }
     case OpParameter_IfParam: {
-      auto ptr = reinterpret_cast<const IfParam *>(obj);
+      auto ptr = reinterpret_cast<const MNN::IfParam *>(obj);
       return verifier.VerifyTable(ptr);
     }
     case OpParameter_RandomUniform: {
-      auto ptr = reinterpret_cast<const RandomUniform *>(obj);
+      auto ptr = reinterpret_cast<const MNN::RandomUniform *>(obj);
       return verifier.VerifyTable(ptr);
     }
     case OpParameter_LayerNorm: {
-      auto ptr = reinterpret_cast<const LayerNorm *>(obj);
+      auto ptr = reinterpret_cast<const MNN::LayerNorm *>(obj);
       return verifier.VerifyTable(ptr);
     }
-    default: return false;
+    default: return true;
   }
 }
 
@@ -5145,355 +5138,355 @@ inline bool VerifyOpParameterVector(flatbuffers::Verifier &verifier, const flatb
 inline void *OpParameterUnion::UnPack(const void *obj, OpParameter type, const flatbuffers::resolver_function_t *resolver) {
   switch (type) {
     case OpParameter_QuantizedAdd: {
-      auto ptr = reinterpret_cast<const QuantizedAdd *>(obj);
+      auto ptr = reinterpret_cast<const MNN::QuantizedAdd *>(obj);
       return ptr->UnPack(resolver);
     }
     case OpParameter_ArgMax: {
-      auto ptr = reinterpret_cast<const ArgMax *>(obj);
+      auto ptr = reinterpret_cast<const MNN::ArgMax *>(obj);
       return ptr->UnPack(resolver);
     }
     case OpParameter_AsString: {
-      auto ptr = reinterpret_cast<const AsString *>(obj);
+      auto ptr = reinterpret_cast<const MNN::AsString *>(obj);
       return ptr->UnPack(resolver);
     }
     case OpParameter_Axis: {
-      auto ptr = reinterpret_cast<const Axis *>(obj);
+      auto ptr = reinterpret_cast<const MNN::Axis *>(obj);
       return ptr->UnPack(resolver);
     }
     case OpParameter_BatchNorm: {
-      auto ptr = reinterpret_cast<const BatchNorm *>(obj);
+      auto ptr = reinterpret_cast<const MNN::BatchNorm *>(obj);
       return ptr->UnPack(resolver);
     }
     case OpParameter_BinaryOp: {
-      auto ptr = reinterpret_cast<const BinaryOp *>(obj);
+      auto ptr = reinterpret_cast<const MNN::BinaryOp *>(obj);
       return ptr->UnPack(resolver);
     }
     case OpParameter_Blob: {
-      auto ptr = reinterpret_cast<const Blob *>(obj);
+      auto ptr = reinterpret_cast<const MNN::Blob *>(obj);
       return ptr->UnPack(resolver);
     }
     case OpParameter_CastParam: {
-      auto ptr = reinterpret_cast<const CastParam *>(obj);
+      auto ptr = reinterpret_cast<const MNN::CastParam *>(obj);
       return ptr->UnPack(resolver);
     }
     case OpParameter_Convolution2D: {
-      auto ptr = reinterpret_cast<const Convolution2D *>(obj);
+      auto ptr = reinterpret_cast<const MNN::Convolution2D *>(obj);
       return ptr->UnPack(resolver);
     }
     case OpParameter_Crop: {
-      auto ptr = reinterpret_cast<const Crop *>(obj);
+      auto ptr = reinterpret_cast<const MNN::Crop *>(obj);
       return ptr->UnPack(resolver);
     }
     case OpParameter_CropAndResize: {
-      auto ptr = reinterpret_cast<const CropAndResize *>(obj);
+      auto ptr = reinterpret_cast<const MNN::CropAndResize *>(obj);
       return ptr->UnPack(resolver);
     }
     case OpParameter_Dequantize: {
-      auto ptr = reinterpret_cast<const Dequantize *>(obj);
+      auto ptr = reinterpret_cast<const MNN::Dequantize *>(obj);
       return ptr->UnPack(resolver);
     }
     case OpParameter_DetectionOutput: {
-      auto ptr = reinterpret_cast<const DetectionOutput *>(obj);
+      auto ptr = reinterpret_cast<const MNN::DetectionOutput *>(obj);
       return ptr->UnPack(resolver);
     }
     case OpParameter_Eltwise: {
-      auto ptr = reinterpret_cast<const Eltwise *>(obj);
+      auto ptr = reinterpret_cast<const MNN::Eltwise *>(obj);
       return ptr->UnPack(resolver);
     }
     case OpParameter_ExpandDims: {
-      auto ptr = reinterpret_cast<const ExpandDims *>(obj);
+      auto ptr = reinterpret_cast<const MNN::ExpandDims *>(obj);
       return ptr->UnPack(resolver);
     }
     case OpParameter_Fill: {
-      auto ptr = reinterpret_cast<const Fill *>(obj);
+      auto ptr = reinterpret_cast<const MNN::Fill *>(obj);
       return ptr->UnPack(resolver);
     }
     case OpParameter_Flatten: {
-      auto ptr = reinterpret_cast<const Flatten *>(obj);
+      auto ptr = reinterpret_cast<const MNN::Flatten *>(obj);
       return ptr->UnPack(resolver);
     }
     case OpParameter_Gather: {
-      auto ptr = reinterpret_cast<const Gather *>(obj);
+      auto ptr = reinterpret_cast<const MNN::Gather *>(obj);
       return ptr->UnPack(resolver);
     }
     case OpParameter_GatherV2: {
-      auto ptr = reinterpret_cast<const GatherV2 *>(obj);
+      auto ptr = reinterpret_cast<const MNN::GatherV2 *>(obj);
       return ptr->UnPack(resolver);
     }
     case OpParameter_InnerProduct: {
-      auto ptr = reinterpret_cast<const InnerProduct *>(obj);
+      auto ptr = reinterpret_cast<const MNN::InnerProduct *>(obj);
       return ptr->UnPack(resolver);
     }
     case OpParameter_Input: {
-      auto ptr = reinterpret_cast<const Input *>(obj);
+      auto ptr = reinterpret_cast<const MNN::Input *>(obj);
       return ptr->UnPack(resolver);
     }
     case OpParameter_Interp: {
-      auto ptr = reinterpret_cast<const Interp *>(obj);
+      auto ptr = reinterpret_cast<const MNN::Interp *>(obj);
       return ptr->UnPack(resolver);
     }
     case OpParameter_LRN: {
-      auto ptr = reinterpret_cast<const LRN *>(obj);
+      auto ptr = reinterpret_cast<const MNN::LRN *>(obj);
       return ptr->UnPack(resolver);
     }
     case OpParameter_LSTM: {
-      auto ptr = reinterpret_cast<const LSTM *>(obj);
+      auto ptr = reinterpret_cast<const MNN::LSTM *>(obj);
       return ptr->UnPack(resolver);
     }
     case OpParameter_MatMul: {
-      auto ptr = reinterpret_cast<const MatMul *>(obj);
+      auto ptr = reinterpret_cast<const MNN::MatMul *>(obj);
       return ptr->UnPack(resolver);
     }
     case OpParameter_NonMaxSuppressionV2: {
-      auto ptr = reinterpret_cast<const NonMaxSuppressionV2 *>(obj);
+      auto ptr = reinterpret_cast<const MNN::NonMaxSuppressionV2 *>(obj);
       return ptr->UnPack(resolver);
     }
     case OpParameter_Normalize: {
-      auto ptr = reinterpret_cast<const Normalize *>(obj);
+      auto ptr = reinterpret_cast<const MNN::Normalize *>(obj);
       return ptr->UnPack(resolver);
     }
     case OpParameter_PackParam: {
-      auto ptr = reinterpret_cast<const PackParam *>(obj);
+      auto ptr = reinterpret_cast<const MNN::PackParam *>(obj);
       return ptr->UnPack(resolver);
     }
     case OpParameter_Permute: {
-      auto ptr = reinterpret_cast<const Permute *>(obj);
+      auto ptr = reinterpret_cast<const MNN::Permute *>(obj);
       return ptr->UnPack(resolver);
     }
     case OpParameter_Plugin: {
-      auto ptr = reinterpret_cast<const Plugin *>(obj);
+      auto ptr = reinterpret_cast<const MNN::Plugin *>(obj);
       return ptr->UnPack(resolver);
     }
     case OpParameter_Pool: {
-      auto ptr = reinterpret_cast<const Pool *>(obj);
+      auto ptr = reinterpret_cast<const MNN::Pool *>(obj);
       return ptr->UnPack(resolver);
     }
     case OpParameter_PRelu: {
-      auto ptr = reinterpret_cast<const PRelu *>(obj);
+      auto ptr = reinterpret_cast<const MNN::PRelu *>(obj);
       return ptr->UnPack(resolver);
     }
     case OpParameter_PriorBox: {
-      auto ptr = reinterpret_cast<const PriorBox *>(obj);
+      auto ptr = reinterpret_cast<const MNN::PriorBox *>(obj);
       return ptr->UnPack(resolver);
     }
     case OpParameter_Proposal: {
-      auto ptr = reinterpret_cast<const Proposal *>(obj);
+      auto ptr = reinterpret_cast<const MNN::Proposal *>(obj);
       return ptr->UnPack(resolver);
     }
     case OpParameter_QuantizedAvgPool: {
-      auto ptr = reinterpret_cast<const QuantizedAvgPool *>(obj);
+      auto ptr = reinterpret_cast<const MNN::QuantizedAvgPool *>(obj);
       return ptr->UnPack(resolver);
     }
     case OpParameter_QuantizedBiasAdd: {
-      auto ptr = reinterpret_cast<const QuantizedBiasAdd *>(obj);
+      auto ptr = reinterpret_cast<const MNN::QuantizedBiasAdd *>(obj);
       return ptr->UnPack(resolver);
     }
     case OpParameter_QuantizedConcat: {
-      auto ptr = reinterpret_cast<const QuantizedConcat *>(obj);
+      auto ptr = reinterpret_cast<const MNN::QuantizedConcat *>(obj);
       return ptr->UnPack(resolver);
     }
     case OpParameter_QuantizedLogistic: {
-      auto ptr = reinterpret_cast<const QuantizedLogistic *>(obj);
+      auto ptr = reinterpret_cast<const MNN::QuantizedLogistic *>(obj);
       return ptr->UnPack(resolver);
     }
     case OpParameter_QuantizedMatMul: {
-      auto ptr = reinterpret_cast<const QuantizedMatMul *>(obj);
+      auto ptr = reinterpret_cast<const MNN::QuantizedMatMul *>(obj);
       return ptr->UnPack(resolver);
     }
     case OpParameter_QuantizedMaxPool: {
-      auto ptr = reinterpret_cast<const QuantizedMaxPool *>(obj);
+      auto ptr = reinterpret_cast<const MNN::QuantizedMaxPool *>(obj);
       return ptr->UnPack(resolver);
     }
     case OpParameter_QuantizedRelu: {
-      auto ptr = reinterpret_cast<const QuantizedRelu *>(obj);
+      auto ptr = reinterpret_cast<const MNN::QuantizedRelu *>(obj);
       return ptr->UnPack(resolver);
     }
     case OpParameter_QuantizedRelu6: {
-      auto ptr = reinterpret_cast<const QuantizedRelu6 *>(obj);
+      auto ptr = reinterpret_cast<const MNN::QuantizedRelu6 *>(obj);
       return ptr->UnPack(resolver);
     }
     case OpParameter_QuantizedReshape: {
-      auto ptr = reinterpret_cast<const QuantizedReshape *>(obj);
+      auto ptr = reinterpret_cast<const MNN::QuantizedReshape *>(obj);
       return ptr->UnPack(resolver);
     }
     case OpParameter_QuantizedSoftmax: {
-      auto ptr = reinterpret_cast<const QuantizedSoftmax *>(obj);
+      auto ptr = reinterpret_cast<const MNN::QuantizedSoftmax *>(obj);
       return ptr->UnPack(resolver);
     }
     case OpParameter_QuantizeMaxMin: {
-      auto ptr = reinterpret_cast<const QuantizeMaxMin *>(obj);
+      auto ptr = reinterpret_cast<const MNN::QuantizeMaxMin *>(obj);
       return ptr->UnPack(resolver);
     }
     case OpParameter_QuantizeV2: {
-      auto ptr = reinterpret_cast<const QuantizeV2 *>(obj);
+      auto ptr = reinterpret_cast<const MNN::QuantizeV2 *>(obj);
       return ptr->UnPack(resolver);
     }
     case OpParameter_Range: {
-      auto ptr = reinterpret_cast<const Range *>(obj);
+      auto ptr = reinterpret_cast<const MNN::Range *>(obj);
       return ptr->UnPack(resolver);
     }
     case OpParameter_Rank: {
-      auto ptr = reinterpret_cast<const Rank *>(obj);
+      auto ptr = reinterpret_cast<const MNN::Rank *>(obj);
       return ptr->UnPack(resolver);
     }
     case OpParameter_ReduceJoin: {
-      auto ptr = reinterpret_cast<const ReduceJoin *>(obj);
+      auto ptr = reinterpret_cast<const MNN::ReduceJoin *>(obj);
       return ptr->UnPack(resolver);
     }
     case OpParameter_ReductionParam: {
-      auto ptr = reinterpret_cast<const ReductionParam *>(obj);
+      auto ptr = reinterpret_cast<const MNN::ReductionParam *>(obj);
       return ptr->UnPack(resolver);
     }
     case OpParameter_Relu: {
-      auto ptr = reinterpret_cast<const Relu *>(obj);
+      auto ptr = reinterpret_cast<const MNN::Relu *>(obj);
       return ptr->UnPack(resolver);
     }
     case OpParameter_Relu6: {
-      auto ptr = reinterpret_cast<const Relu6 *>(obj);
+      auto ptr = reinterpret_cast<const MNN::Relu6 *>(obj);
       return ptr->UnPack(resolver);
     }
     case OpParameter_RequantizationRange: {
-      auto ptr = reinterpret_cast<const RequantizationRange *>(obj);
+      auto ptr = reinterpret_cast<const MNN::RequantizationRange *>(obj);
       return ptr->UnPack(resolver);
     }
     case OpParameter_Requantize: {
-      auto ptr = reinterpret_cast<const Requantize *>(obj);
+      auto ptr = reinterpret_cast<const MNN::Requantize *>(obj);
       return ptr->UnPack(resolver);
     }
     case OpParameter_Reshape: {
-      auto ptr = reinterpret_cast<const Reshape *>(obj);
+      auto ptr = reinterpret_cast<const MNN::Reshape *>(obj);
       return ptr->UnPack(resolver);
     }
     case OpParameter_Resize: {
-      auto ptr = reinterpret_cast<const Resize *>(obj);
+      auto ptr = reinterpret_cast<const MNN::Resize *>(obj);
       return ptr->UnPack(resolver);
     }
     case OpParameter_RoiPooling: {
-      auto ptr = reinterpret_cast<const RoiPooling *>(obj);
+      auto ptr = reinterpret_cast<const MNN::RoiPooling *>(obj);
       return ptr->UnPack(resolver);
     }
     case OpParameter_Scale: {
-      auto ptr = reinterpret_cast<const Scale *>(obj);
+      auto ptr = reinterpret_cast<const MNN::Scale *>(obj);
       return ptr->UnPack(resolver);
     }
     case OpParameter_Selu: {
-      auto ptr = reinterpret_cast<const Selu *>(obj);
+      auto ptr = reinterpret_cast<const MNN::Selu *>(obj);
       return ptr->UnPack(resolver);
     }
     case OpParameter_Size: {
-      auto ptr = reinterpret_cast<const Size *>(obj);
+      auto ptr = reinterpret_cast<const MNN::Size *>(obj);
       return ptr->UnPack(resolver);
     }
     case OpParameter_Slice: {
-      auto ptr = reinterpret_cast<const Slice *>(obj);
+      auto ptr = reinterpret_cast<const MNN::Slice *>(obj);
       return ptr->UnPack(resolver);
     }
     case OpParameter_SliceTf: {
-      auto ptr = reinterpret_cast<const SliceTf *>(obj);
+      auto ptr = reinterpret_cast<const MNN::SliceTf *>(obj);
       return ptr->UnPack(resolver);
     }
     case OpParameter_SpaceBatch: {
-      auto ptr = reinterpret_cast<const SpaceBatch *>(obj);
+      auto ptr = reinterpret_cast<const MNN::SpaceBatch *>(obj);
       return ptr->UnPack(resolver);
     }
     case OpParameter_SqueezeParam: {
-      auto ptr = reinterpret_cast<const SqueezeParam *>(obj);
+      auto ptr = reinterpret_cast<const MNN::SqueezeParam *>(obj);
       return ptr->UnPack(resolver);
     }
     case OpParameter_StridedSliceParam: {
-      auto ptr = reinterpret_cast<const StridedSliceParam *>(obj);
+      auto ptr = reinterpret_cast<const MNN::StridedSliceParam *>(obj);
       return ptr->UnPack(resolver);
     }
     case OpParameter_TensorConvertInfo: {
-      auto ptr = reinterpret_cast<const TensorConvertInfo *>(obj);
+      auto ptr = reinterpret_cast<const MNN::TensorConvertInfo *>(obj);
       return ptr->UnPack(resolver);
     }
     case OpParameter_TfQuantizedConv2D: {
-      auto ptr = reinterpret_cast<const TfQuantizedConv2D *>(obj);
+      auto ptr = reinterpret_cast<const MNN::TfQuantizedConv2D *>(obj);
       return ptr->UnPack(resolver);
     }
     case OpParameter_TopKV2: {
-      auto ptr = reinterpret_cast<const TopKV2 *>(obj);
+      auto ptr = reinterpret_cast<const MNN::TopKV2 *>(obj);
       return ptr->UnPack(resolver);
     }
     case OpParameter_Transpose: {
-      auto ptr = reinterpret_cast<const Transpose *>(obj);
+      auto ptr = reinterpret_cast<const MNN::Transpose *>(obj);
       return ptr->UnPack(resolver);
     }
     case OpParameter_UnaryOp: {
-      auto ptr = reinterpret_cast<const UnaryOp *>(obj);
+      auto ptr = reinterpret_cast<const MNN::UnaryOp *>(obj);
       return ptr->UnPack(resolver);
     }
     case OpParameter_MomentsParam: {
-      auto ptr = reinterpret_cast<const MomentsParam *>(obj);
+      auto ptr = reinterpret_cast<const MNN::MomentsParam *>(obj);
       return ptr->UnPack(resolver);
     }
     case OpParameter_RNNParam: {
-      auto ptr = reinterpret_cast<const RNNParam *>(obj);
+      auto ptr = reinterpret_cast<const MNN::RNNParam *>(obj);
       return ptr->UnPack(resolver);
     }
     case OpParameter_BatchMatMulParam: {
-      auto ptr = reinterpret_cast<const BatchMatMulParam *>(obj);
+      auto ptr = reinterpret_cast<const MNN::BatchMatMulParam *>(obj);
       return ptr->UnPack(resolver);
     }
     case OpParameter_QuantizedFloatParam: {
-      auto ptr = reinterpret_cast<const QuantizedFloatParam *>(obj);
+      auto ptr = reinterpret_cast<const MNN::QuantizedFloatParam *>(obj);
       return ptr->UnPack(resolver);
     }
     case OpParameter_DepthSpaceParam: {
-      auto ptr = reinterpret_cast<const DepthSpaceParam *>(obj);
+      auto ptr = reinterpret_cast<const MNN::DepthSpaceParam *>(obj);
       return ptr->UnPack(resolver);
     }
     case OpParameter_EltwiseInt8: {
-      auto ptr = reinterpret_cast<const EltwiseInt8 *>(obj);
+      auto ptr = reinterpret_cast<const MNN::EltwiseInt8 *>(obj);
       return ptr->UnPack(resolver);
     }
     case OpParameter_ReverseSequenceParam: {
-      auto ptr = reinterpret_cast<const ReverseSequenceParam *>(obj);
+      auto ptr = reinterpret_cast<const MNN::ReverseSequenceParam *>(obj);
       return ptr->UnPack(resolver);
     }
     case OpParameter_Extra: {
-      auto ptr = reinterpret_cast<const Extra *>(obj);
+      auto ptr = reinterpret_cast<const MNN::Extra *>(obj);
       return ptr->UnPack(resolver);
     }
     case OpParameter_Pool3D: {
-      auto ptr = reinterpret_cast<const Pool3D *>(obj);
+      auto ptr = reinterpret_cast<const MNN::Pool3D *>(obj);
       return ptr->UnPack(resolver);
     }
     case OpParameter_Convolution3D: {
-      auto ptr = reinterpret_cast<const Convolution3D *>(obj);
+      auto ptr = reinterpret_cast<const MNN::Convolution3D *>(obj);
       return ptr->UnPack(resolver);
     }
     case OpParameter_ELU: {
-      auto ptr = reinterpret_cast<const ELU *>(obj);
+      auto ptr = reinterpret_cast<const MNN::ELU *>(obj);
       return ptr->UnPack(resolver);
     }
     case OpParameter_DetectionPostProcessParam: {
-      auto ptr = reinterpret_cast<const DetectionPostProcessParam *>(obj);
+      auto ptr = reinterpret_cast<const MNN::DetectionPostProcessParam *>(obj);
       return ptr->UnPack(resolver);
     }
     case OpParameter_OneHotParam: {
-      auto ptr = reinterpret_cast<const OneHotParam *>(obj);
+      auto ptr = reinterpret_cast<const MNN::OneHotParam *>(obj);
       return ptr->UnPack(resolver);
     }
     case OpParameter_PadParam: {
-      auto ptr = reinterpret_cast<const PadParam *>(obj);
+      auto ptr = reinterpret_cast<const MNN::PadParam *>(obj);
       return ptr->UnPack(resolver);
     }
     case OpParameter_WhileParam: {
-      auto ptr = reinterpret_cast<const WhileParam *>(obj);
+      auto ptr = reinterpret_cast<const MNN::WhileParam *>(obj);
       return ptr->UnPack(resolver);
     }
     case OpParameter_IfParam: {
-      auto ptr = reinterpret_cast<const IfParam *>(obj);
+      auto ptr = reinterpret_cast<const MNN::IfParam *>(obj);
       return ptr->UnPack(resolver);
     }
     case OpParameter_RandomUniform: {
-      auto ptr = reinterpret_cast<const RandomUniform *>(obj);
+      auto ptr = reinterpret_cast<const MNN::RandomUniform *>(obj);
       return ptr->UnPack(resolver);
     }
     case OpParameter_LayerNorm: {
-      auto ptr = reinterpret_cast<const LayerNorm *>(obj);
+      auto ptr = reinterpret_cast<const MNN::LayerNorm *>(obj);
       return ptr->UnPack(resolver);
     }
     default: return nullptr;
@@ -5503,713 +5496,713 @@ inline void *OpParameterUnion::UnPack(const void *obj, OpParameter type, const f
 inline flatbuffers::Offset<void> OpParameterUnion::Pack(flatbuffers::FlatBufferBuilder &_fbb, const flatbuffers::rehasher_function_t *_rehasher) const {
   switch (type) {
     case OpParameter_QuantizedAdd: {
-      auto ptr = reinterpret_cast<const QuantizedAddT *>(value);
+      auto ptr = reinterpret_cast<const MNN::QuantizedAddT *>(value);
       return CreateQuantizedAdd(_fbb, ptr, _rehasher).Union();
     }
     case OpParameter_ArgMax: {
-      auto ptr = reinterpret_cast<const ArgMaxT *>(value);
+      auto ptr = reinterpret_cast<const MNN::ArgMaxT *>(value);
       return CreateArgMax(_fbb, ptr, _rehasher).Union();
     }
     case OpParameter_AsString: {
-      auto ptr = reinterpret_cast<const AsStringT *>(value);
+      auto ptr = reinterpret_cast<const MNN::AsStringT *>(value);
       return CreateAsString(_fbb, ptr, _rehasher).Union();
     }
     case OpParameter_Axis: {
-      auto ptr = reinterpret_cast<const AxisT *>(value);
+      auto ptr = reinterpret_cast<const MNN::AxisT *>(value);
       return CreateAxis(_fbb, ptr, _rehasher).Union();
     }
     case OpParameter_BatchNorm: {
-      auto ptr = reinterpret_cast<const BatchNormT *>(value);
+      auto ptr = reinterpret_cast<const MNN::BatchNormT *>(value);
       return CreateBatchNorm(_fbb, ptr, _rehasher).Union();
     }
     case OpParameter_BinaryOp: {
-      auto ptr = reinterpret_cast<const BinaryOpT *>(value);
+      auto ptr = reinterpret_cast<const MNN::BinaryOpT *>(value);
       return CreateBinaryOp(_fbb, ptr, _rehasher).Union();
     }
     case OpParameter_Blob: {
-      auto ptr = reinterpret_cast<const BlobT *>(value);
+      auto ptr = reinterpret_cast<const MNN::BlobT *>(value);
       return CreateBlob(_fbb, ptr, _rehasher).Union();
     }
     case OpParameter_CastParam: {
-      auto ptr = reinterpret_cast<const CastParamT *>(value);
+      auto ptr = reinterpret_cast<const MNN::CastParamT *>(value);
       return CreateCastParam(_fbb, ptr, _rehasher).Union();
     }
     case OpParameter_Convolution2D: {
-      auto ptr = reinterpret_cast<const Convolution2DT *>(value);
+      auto ptr = reinterpret_cast<const MNN::Convolution2DT *>(value);
       return CreateConvolution2D(_fbb, ptr, _rehasher).Union();
     }
     case OpParameter_Crop: {
-      auto ptr = reinterpret_cast<const CropT *>(value);
+      auto ptr = reinterpret_cast<const MNN::CropT *>(value);
       return CreateCrop(_fbb, ptr, _rehasher).Union();
     }
     case OpParameter_CropAndResize: {
-      auto ptr = reinterpret_cast<const CropAndResizeT *>(value);
+      auto ptr = reinterpret_cast<const MNN::CropAndResizeT *>(value);
       return CreateCropAndResize(_fbb, ptr, _rehasher).Union();
     }
     case OpParameter_Dequantize: {
-      auto ptr = reinterpret_cast<const DequantizeT *>(value);
+      auto ptr = reinterpret_cast<const MNN::DequantizeT *>(value);
       return CreateDequantize(_fbb, ptr, _rehasher).Union();
     }
     case OpParameter_DetectionOutput: {
-      auto ptr = reinterpret_cast<const DetectionOutputT *>(value);
+      auto ptr = reinterpret_cast<const MNN::DetectionOutputT *>(value);
       return CreateDetectionOutput(_fbb, ptr, _rehasher).Union();
     }
     case OpParameter_Eltwise: {
-      auto ptr = reinterpret_cast<const EltwiseT *>(value);
+      auto ptr = reinterpret_cast<const MNN::EltwiseT *>(value);
       return CreateEltwise(_fbb, ptr, _rehasher).Union();
     }
     case OpParameter_ExpandDims: {
-      auto ptr = reinterpret_cast<const ExpandDimsT *>(value);
+      auto ptr = reinterpret_cast<const MNN::ExpandDimsT *>(value);
       return CreateExpandDims(_fbb, ptr, _rehasher).Union();
     }
     case OpParameter_Fill: {
-      auto ptr = reinterpret_cast<const FillT *>(value);
+      auto ptr = reinterpret_cast<const MNN::FillT *>(value);
       return CreateFill(_fbb, ptr, _rehasher).Union();
     }
     case OpParameter_Flatten: {
-      auto ptr = reinterpret_cast<const FlattenT *>(value);
+      auto ptr = reinterpret_cast<const MNN::FlattenT *>(value);
       return CreateFlatten(_fbb, ptr, _rehasher).Union();
     }
     case OpParameter_Gather: {
-      auto ptr = reinterpret_cast<const GatherT *>(value);
+      auto ptr = reinterpret_cast<const MNN::GatherT *>(value);
       return CreateGather(_fbb, ptr, _rehasher).Union();
     }
     case OpParameter_GatherV2: {
-      auto ptr = reinterpret_cast<const GatherV2T *>(value);
+      auto ptr = reinterpret_cast<const MNN::GatherV2T *>(value);
       return CreateGatherV2(_fbb, ptr, _rehasher).Union();
     }
     case OpParameter_InnerProduct: {
-      auto ptr = reinterpret_cast<const InnerProductT *>(value);
+      auto ptr = reinterpret_cast<const MNN::InnerProductT *>(value);
       return CreateInnerProduct(_fbb, ptr, _rehasher).Union();
     }
     case OpParameter_Input: {
-      auto ptr = reinterpret_cast<const InputT *>(value);
+      auto ptr = reinterpret_cast<const MNN::InputT *>(value);
       return CreateInput(_fbb, ptr, _rehasher).Union();
     }
     case OpParameter_Interp: {
-      auto ptr = reinterpret_cast<const InterpT *>(value);
+      auto ptr = reinterpret_cast<const MNN::InterpT *>(value);
       return CreateInterp(_fbb, ptr, _rehasher).Union();
     }
     case OpParameter_LRN: {
-      auto ptr = reinterpret_cast<const LRNT *>(value);
+      auto ptr = reinterpret_cast<const MNN::LRNT *>(value);
       return CreateLRN(_fbb, ptr, _rehasher).Union();
     }
     case OpParameter_LSTM: {
-      auto ptr = reinterpret_cast<const LSTMT *>(value);
+      auto ptr = reinterpret_cast<const MNN::LSTMT *>(value);
       return CreateLSTM(_fbb, ptr, _rehasher).Union();
     }
     case OpParameter_MatMul: {
-      auto ptr = reinterpret_cast<const MatMulT *>(value);
+      auto ptr = reinterpret_cast<const MNN::MatMulT *>(value);
       return CreateMatMul(_fbb, ptr, _rehasher).Union();
     }
     case OpParameter_NonMaxSuppressionV2: {
-      auto ptr = reinterpret_cast<const NonMaxSuppressionV2T *>(value);
+      auto ptr = reinterpret_cast<const MNN::NonMaxSuppressionV2T *>(value);
       return CreateNonMaxSuppressionV2(_fbb, ptr, _rehasher).Union();
     }
     case OpParameter_Normalize: {
-      auto ptr = reinterpret_cast<const NormalizeT *>(value);
+      auto ptr = reinterpret_cast<const MNN::NormalizeT *>(value);
       return CreateNormalize(_fbb, ptr, _rehasher).Union();
     }
     case OpParameter_PackParam: {
-      auto ptr = reinterpret_cast<const PackParamT *>(value);
+      auto ptr = reinterpret_cast<const MNN::PackParamT *>(value);
       return CreatePackParam(_fbb, ptr, _rehasher).Union();
     }
     case OpParameter_Permute: {
-      auto ptr = reinterpret_cast<const PermuteT *>(value);
+      auto ptr = reinterpret_cast<const MNN::PermuteT *>(value);
       return CreatePermute(_fbb, ptr, _rehasher).Union();
     }
     case OpParameter_Plugin: {
-      auto ptr = reinterpret_cast<const PluginT *>(value);
+      auto ptr = reinterpret_cast<const MNN::PluginT *>(value);
       return CreatePlugin(_fbb, ptr, _rehasher).Union();
     }
     case OpParameter_Pool: {
-      auto ptr = reinterpret_cast<const PoolT *>(value);
+      auto ptr = reinterpret_cast<const MNN::PoolT *>(value);
       return CreatePool(_fbb, ptr, _rehasher).Union();
     }
     case OpParameter_PRelu: {
-      auto ptr = reinterpret_cast<const PReluT *>(value);
+      auto ptr = reinterpret_cast<const MNN::PReluT *>(value);
       return CreatePRelu(_fbb, ptr, _rehasher).Union();
     }
     case OpParameter_PriorBox: {
-      auto ptr = reinterpret_cast<const PriorBoxT *>(value);
+      auto ptr = reinterpret_cast<const MNN::PriorBoxT *>(value);
       return CreatePriorBox(_fbb, ptr, _rehasher).Union();
     }
     case OpParameter_Proposal: {
-      auto ptr = reinterpret_cast<const ProposalT *>(value);
+      auto ptr = reinterpret_cast<const MNN::ProposalT *>(value);
       return CreateProposal(_fbb, ptr, _rehasher).Union();
     }
     case OpParameter_QuantizedAvgPool: {
-      auto ptr = reinterpret_cast<const QuantizedAvgPoolT *>(value);
+      auto ptr = reinterpret_cast<const MNN::QuantizedAvgPoolT *>(value);
       return CreateQuantizedAvgPool(_fbb, ptr, _rehasher).Union();
     }
     case OpParameter_QuantizedBiasAdd: {
-      auto ptr = reinterpret_cast<const QuantizedBiasAddT *>(value);
+      auto ptr = reinterpret_cast<const MNN::QuantizedBiasAddT *>(value);
       return CreateQuantizedBiasAdd(_fbb, ptr, _rehasher).Union();
     }
     case OpParameter_QuantizedConcat: {
-      auto ptr = reinterpret_cast<const QuantizedConcatT *>(value);
+      auto ptr = reinterpret_cast<const MNN::QuantizedConcatT *>(value);
       return CreateQuantizedConcat(_fbb, ptr, _rehasher).Union();
     }
     case OpParameter_QuantizedLogistic: {
-      auto ptr = reinterpret_cast<const QuantizedLogisticT *>(value);
+      auto ptr = reinterpret_cast<const MNN::QuantizedLogisticT *>(value);
       return CreateQuantizedLogistic(_fbb, ptr, _rehasher).Union();
     }
     case OpParameter_QuantizedMatMul: {
-      auto ptr = reinterpret_cast<const QuantizedMatMulT *>(value);
+      auto ptr = reinterpret_cast<const MNN::QuantizedMatMulT *>(value);
       return CreateQuantizedMatMul(_fbb, ptr, _rehasher).Union();
     }
     case OpParameter_QuantizedMaxPool: {
-      auto ptr = reinterpret_cast<const QuantizedMaxPoolT *>(value);
+      auto ptr = reinterpret_cast<const MNN::QuantizedMaxPoolT *>(value);
       return CreateQuantizedMaxPool(_fbb, ptr, _rehasher).Union();
     }
     case OpParameter_QuantizedRelu: {
-      auto ptr = reinterpret_cast<const QuantizedReluT *>(value);
+      auto ptr = reinterpret_cast<const MNN::QuantizedReluT *>(value);
       return CreateQuantizedRelu(_fbb, ptr, _rehasher).Union();
     }
     case OpParameter_QuantizedRelu6: {
-      auto ptr = reinterpret_cast<const QuantizedRelu6T *>(value);
+      auto ptr = reinterpret_cast<const MNN::QuantizedRelu6T *>(value);
       return CreateQuantizedRelu6(_fbb, ptr, _rehasher).Union();
     }
     case OpParameter_QuantizedReshape: {
-      auto ptr = reinterpret_cast<const QuantizedReshapeT *>(value);
+      auto ptr = reinterpret_cast<const MNN::QuantizedReshapeT *>(value);
       return CreateQuantizedReshape(_fbb, ptr, _rehasher).Union();
     }
     case OpParameter_QuantizedSoftmax: {
-      auto ptr = reinterpret_cast<const QuantizedSoftmaxT *>(value);
+      auto ptr = reinterpret_cast<const MNN::QuantizedSoftmaxT *>(value);
       return CreateQuantizedSoftmax(_fbb, ptr, _rehasher).Union();
     }
     case OpParameter_QuantizeMaxMin: {
-      auto ptr = reinterpret_cast<const QuantizeMaxMinT *>(value);
+      auto ptr = reinterpret_cast<const MNN::QuantizeMaxMinT *>(value);
       return CreateQuantizeMaxMin(_fbb, ptr, _rehasher).Union();
     }
     case OpParameter_QuantizeV2: {
-      auto ptr = reinterpret_cast<const QuantizeV2T *>(value);
+      auto ptr = reinterpret_cast<const MNN::QuantizeV2T *>(value);
       return CreateQuantizeV2(_fbb, ptr, _rehasher).Union();
     }
     case OpParameter_Range: {
-      auto ptr = reinterpret_cast<const RangeT *>(value);
+      auto ptr = reinterpret_cast<const MNN::RangeT *>(value);
       return CreateRange(_fbb, ptr, _rehasher).Union();
     }
     case OpParameter_Rank: {
-      auto ptr = reinterpret_cast<const RankT *>(value);
+      auto ptr = reinterpret_cast<const MNN::RankT *>(value);
       return CreateRank(_fbb, ptr, _rehasher).Union();
     }
     case OpParameter_ReduceJoin: {
-      auto ptr = reinterpret_cast<const ReduceJoinT *>(value);
+      auto ptr = reinterpret_cast<const MNN::ReduceJoinT *>(value);
       return CreateReduceJoin(_fbb, ptr, _rehasher).Union();
     }
     case OpParameter_ReductionParam: {
-      auto ptr = reinterpret_cast<const ReductionParamT *>(value);
+      auto ptr = reinterpret_cast<const MNN::ReductionParamT *>(value);
       return CreateReductionParam(_fbb, ptr, _rehasher).Union();
     }
     case OpParameter_Relu: {
-      auto ptr = reinterpret_cast<const ReluT *>(value);
+      auto ptr = reinterpret_cast<const MNN::ReluT *>(value);
       return CreateRelu(_fbb, ptr, _rehasher).Union();
     }
     case OpParameter_Relu6: {
-      auto ptr = reinterpret_cast<const Relu6T *>(value);
+      auto ptr = reinterpret_cast<const MNN::Relu6T *>(value);
       return CreateRelu6(_fbb, ptr, _rehasher).Union();
     }
     case OpParameter_RequantizationRange: {
-      auto ptr = reinterpret_cast<const RequantizationRangeT *>(value);
+      auto ptr = reinterpret_cast<const MNN::RequantizationRangeT *>(value);
       return CreateRequantizationRange(_fbb, ptr, _rehasher).Union();
     }
     case OpParameter_Requantize: {
-      auto ptr = reinterpret_cast<const RequantizeT *>(value);
+      auto ptr = reinterpret_cast<const MNN::RequantizeT *>(value);
       return CreateRequantize(_fbb, ptr, _rehasher).Union();
     }
     case OpParameter_Reshape: {
-      auto ptr = reinterpret_cast<const ReshapeT *>(value);
+      auto ptr = reinterpret_cast<const MNN::ReshapeT *>(value);
       return CreateReshape(_fbb, ptr, _rehasher).Union();
     }
     case OpParameter_Resize: {
-      auto ptr = reinterpret_cast<const ResizeT *>(value);
+      auto ptr = reinterpret_cast<const MNN::ResizeT *>(value);
       return CreateResize(_fbb, ptr, _rehasher).Union();
     }
     case OpParameter_RoiPooling: {
-      auto ptr = reinterpret_cast<const RoiPoolingT *>(value);
+      auto ptr = reinterpret_cast<const MNN::RoiPoolingT *>(value);
       return CreateRoiPooling(_fbb, ptr, _rehasher).Union();
     }
     case OpParameter_Scale: {
-      auto ptr = reinterpret_cast<const ScaleT *>(value);
+      auto ptr = reinterpret_cast<const MNN::ScaleT *>(value);
       return CreateScale(_fbb, ptr, _rehasher).Union();
     }
     case OpParameter_Selu: {
-      auto ptr = reinterpret_cast<const SeluT *>(value);
+      auto ptr = reinterpret_cast<const MNN::SeluT *>(value);
       return CreateSelu(_fbb, ptr, _rehasher).Union();
     }
     case OpParameter_Size: {
-      auto ptr = reinterpret_cast<const SizeT *>(value);
+      auto ptr = reinterpret_cast<const MNN::SizeT *>(value);
       return CreateSize(_fbb, ptr, _rehasher).Union();
     }
     case OpParameter_Slice: {
-      auto ptr = reinterpret_cast<const SliceT *>(value);
+      auto ptr = reinterpret_cast<const MNN::SliceT *>(value);
       return CreateSlice(_fbb, ptr, _rehasher).Union();
     }
     case OpParameter_SliceTf: {
-      auto ptr = reinterpret_cast<const SliceTfT *>(value);
+      auto ptr = reinterpret_cast<const MNN::SliceTfT *>(value);
       return CreateSliceTf(_fbb, ptr, _rehasher).Union();
     }
     case OpParameter_SpaceBatch: {
-      auto ptr = reinterpret_cast<const SpaceBatchT *>(value);
+      auto ptr = reinterpret_cast<const MNN::SpaceBatchT *>(value);
       return CreateSpaceBatch(_fbb, ptr, _rehasher).Union();
     }
     case OpParameter_SqueezeParam: {
-      auto ptr = reinterpret_cast<const SqueezeParamT *>(value);
+      auto ptr = reinterpret_cast<const MNN::SqueezeParamT *>(value);
       return CreateSqueezeParam(_fbb, ptr, _rehasher).Union();
     }
     case OpParameter_StridedSliceParam: {
-      auto ptr = reinterpret_cast<const StridedSliceParamT *>(value);
+      auto ptr = reinterpret_cast<const MNN::StridedSliceParamT *>(value);
       return CreateStridedSliceParam(_fbb, ptr, _rehasher).Union();
     }
     case OpParameter_TensorConvertInfo: {
-      auto ptr = reinterpret_cast<const TensorConvertInfoT *>(value);
+      auto ptr = reinterpret_cast<const MNN::TensorConvertInfoT *>(value);
       return CreateTensorConvertInfo(_fbb, ptr, _rehasher).Union();
     }
     case OpParameter_TfQuantizedConv2D: {
-      auto ptr = reinterpret_cast<const TfQuantizedConv2DT *>(value);
+      auto ptr = reinterpret_cast<const MNN::TfQuantizedConv2DT *>(value);
       return CreateTfQuantizedConv2D(_fbb, ptr, _rehasher).Union();
     }
     case OpParameter_TopKV2: {
-      auto ptr = reinterpret_cast<const TopKV2T *>(value);
+      auto ptr = reinterpret_cast<const MNN::TopKV2T *>(value);
       return CreateTopKV2(_fbb, ptr, _rehasher).Union();
     }
     case OpParameter_Transpose: {
-      auto ptr = reinterpret_cast<const TransposeT *>(value);
+      auto ptr = reinterpret_cast<const MNN::TransposeT *>(value);
       return CreateTranspose(_fbb, ptr, _rehasher).Union();
     }
     case OpParameter_UnaryOp: {
-      auto ptr = reinterpret_cast<const UnaryOpT *>(value);
+      auto ptr = reinterpret_cast<const MNN::UnaryOpT *>(value);
       return CreateUnaryOp(_fbb, ptr, _rehasher).Union();
     }
     case OpParameter_MomentsParam: {
-      auto ptr = reinterpret_cast<const MomentsParamT *>(value);
+      auto ptr = reinterpret_cast<const MNN::MomentsParamT *>(value);
       return CreateMomentsParam(_fbb, ptr, _rehasher).Union();
     }
     case OpParameter_RNNParam: {
-      auto ptr = reinterpret_cast<const RNNParamT *>(value);
+      auto ptr = reinterpret_cast<const MNN::RNNParamT *>(value);
       return CreateRNNParam(_fbb, ptr, _rehasher).Union();
     }
     case OpParameter_BatchMatMulParam: {
-      auto ptr = reinterpret_cast<const BatchMatMulParamT *>(value);
+      auto ptr = reinterpret_cast<const MNN::BatchMatMulParamT *>(value);
       return CreateBatchMatMulParam(_fbb, ptr, _rehasher).Union();
     }
     case OpParameter_QuantizedFloatParam: {
-      auto ptr = reinterpret_cast<const QuantizedFloatParamT *>(value);
+      auto ptr = reinterpret_cast<const MNN::QuantizedFloatParamT *>(value);
       return CreateQuantizedFloatParam(_fbb, ptr, _rehasher).Union();
     }
     case OpParameter_DepthSpaceParam: {
-      auto ptr = reinterpret_cast<const DepthSpaceParamT *>(value);
+      auto ptr = reinterpret_cast<const MNN::DepthSpaceParamT *>(value);
       return CreateDepthSpaceParam(_fbb, ptr, _rehasher).Union();
     }
     case OpParameter_EltwiseInt8: {
-      auto ptr = reinterpret_cast<const EltwiseInt8T *>(value);
+      auto ptr = reinterpret_cast<const MNN::EltwiseInt8T *>(value);
       return CreateEltwiseInt8(_fbb, ptr, _rehasher).Union();
     }
     case OpParameter_ReverseSequenceParam: {
-      auto ptr = reinterpret_cast<const ReverseSequenceParamT *>(value);
+      auto ptr = reinterpret_cast<const MNN::ReverseSequenceParamT *>(value);
       return CreateReverseSequenceParam(_fbb, ptr, _rehasher).Union();
     }
     case OpParameter_Extra: {
-      auto ptr = reinterpret_cast<const ExtraT *>(value);
+      auto ptr = reinterpret_cast<const MNN::ExtraT *>(value);
       return CreateExtra(_fbb, ptr, _rehasher).Union();
     }
     case OpParameter_Pool3D: {
-      auto ptr = reinterpret_cast<const Pool3DT *>(value);
+      auto ptr = reinterpret_cast<const MNN::Pool3DT *>(value);
       return CreatePool3D(_fbb, ptr, _rehasher).Union();
     }
     case OpParameter_Convolution3D: {
-      auto ptr = reinterpret_cast<const Convolution3DT *>(value);
+      auto ptr = reinterpret_cast<const MNN::Convolution3DT *>(value);
       return CreateConvolution3D(_fbb, ptr, _rehasher).Union();
     }
     case OpParameter_ELU: {
-      auto ptr = reinterpret_cast<const ELUT *>(value);
+      auto ptr = reinterpret_cast<const MNN::ELUT *>(value);
       return CreateELU(_fbb, ptr, _rehasher).Union();
     }
     case OpParameter_DetectionPostProcessParam: {
-      auto ptr = reinterpret_cast<const DetectionPostProcessParamT *>(value);
+      auto ptr = reinterpret_cast<const MNN::DetectionPostProcessParamT *>(value);
       return CreateDetectionPostProcessParam(_fbb, ptr, _rehasher).Union();
     }
     case OpParameter_OneHotParam: {
-      auto ptr = reinterpret_cast<const OneHotParamT *>(value);
+      auto ptr = reinterpret_cast<const MNN::OneHotParamT *>(value);
       return CreateOneHotParam(_fbb, ptr, _rehasher).Union();
     }
     case OpParameter_PadParam: {
-      auto ptr = reinterpret_cast<const PadParamT *>(value);
+      auto ptr = reinterpret_cast<const MNN::PadParamT *>(value);
       return CreatePadParam(_fbb, ptr, _rehasher).Union();
     }
     case OpParameter_WhileParam: {
-      auto ptr = reinterpret_cast<const WhileParamT *>(value);
+      auto ptr = reinterpret_cast<const MNN::WhileParamT *>(value);
       return CreateWhileParam(_fbb, ptr, _rehasher).Union();
     }
     case OpParameter_IfParam: {
-      auto ptr = reinterpret_cast<const IfParamT *>(value);
+      auto ptr = reinterpret_cast<const MNN::IfParamT *>(value);
       return CreateIfParam(_fbb, ptr, _rehasher).Union();
     }
     case OpParameter_RandomUniform: {
-      auto ptr = reinterpret_cast<const RandomUniformT *>(value);
+      auto ptr = reinterpret_cast<const MNN::RandomUniformT *>(value);
       return CreateRandomUniform(_fbb, ptr, _rehasher).Union();
     }
     case OpParameter_LayerNorm: {
-      auto ptr = reinterpret_cast<const LayerNormT *>(value);
+      auto ptr = reinterpret_cast<const MNN::LayerNormT *>(value);
       return CreateLayerNorm(_fbb, ptr, _rehasher).Union();
     }
     default: return 0;
   }
 }
 
-inline OpParameterUnion::OpParameterUnion(const OpParameterUnion &u) FLATBUFFERS_NOEXCEPT : type(u.type), value(nullptr) {
+inline OpParameterUnion::OpParameterUnion(const OpParameterUnion &u) : type(u.type), value(nullptr) {
   switch (type) {
     case OpParameter_QuantizedAdd: {
-      FLATBUFFERS_ASSERT(false);  // QuantizedAddT not copyable.
+      FLATBUFFERS_ASSERT(false);  // MNN::QuantizedAddT not copyable.
       break;
     }
     case OpParameter_ArgMax: {
-      value = new ArgMaxT(*reinterpret_cast<ArgMaxT *>(u.value));
+      value = new MNN::ArgMaxT(*reinterpret_cast<MNN::ArgMaxT *>(u.value));
       break;
     }
     case OpParameter_AsString: {
-      value = new AsStringT(*reinterpret_cast<AsStringT *>(u.value));
+      value = new MNN::AsStringT(*reinterpret_cast<MNN::AsStringT *>(u.value));
       break;
     }
     case OpParameter_Axis: {
-      value = new AxisT(*reinterpret_cast<AxisT *>(u.value));
+      value = new MNN::AxisT(*reinterpret_cast<MNN::AxisT *>(u.value));
       break;
     }
     case OpParameter_BatchNorm: {
-      value = new BatchNormT(*reinterpret_cast<BatchNormT *>(u.value));
+      value = new MNN::BatchNormT(*reinterpret_cast<MNN::BatchNormT *>(u.value));
       break;
     }
     case OpParameter_BinaryOp: {
-      value = new BinaryOpT(*reinterpret_cast<BinaryOpT *>(u.value));
+      value = new MNN::BinaryOpT(*reinterpret_cast<MNN::BinaryOpT *>(u.value));
       break;
     }
     case OpParameter_Blob: {
-      value = new BlobT(*reinterpret_cast<BlobT *>(u.value));
+      value = new MNN::BlobT(*reinterpret_cast<MNN::BlobT *>(u.value));
       break;
     }
     case OpParameter_CastParam: {
-      value = new CastParamT(*reinterpret_cast<CastParamT *>(u.value));
+      value = new MNN::CastParamT(*reinterpret_cast<MNN::CastParamT *>(u.value));
       break;
     }
     case OpParameter_Convolution2D: {
-      FLATBUFFERS_ASSERT(false);  // Convolution2DT not copyable.
+      FLATBUFFERS_ASSERT(false);  // MNN::Convolution2DT not copyable.
       break;
     }
     case OpParameter_Crop: {
-      value = new CropT(*reinterpret_cast<CropT *>(u.value));
+      value = new MNN::CropT(*reinterpret_cast<MNN::CropT *>(u.value));
       break;
     }
     case OpParameter_CropAndResize: {
-      value = new CropAndResizeT(*reinterpret_cast<CropAndResizeT *>(u.value));
+      value = new MNN::CropAndResizeT(*reinterpret_cast<MNN::CropAndResizeT *>(u.value));
       break;
     }
     case OpParameter_Dequantize: {
-      FLATBUFFERS_ASSERT(false);  // DequantizeT not copyable.
+      FLATBUFFERS_ASSERT(false);  // MNN::DequantizeT not copyable.
       break;
     }
     case OpParameter_DetectionOutput: {
-      value = new DetectionOutputT(*reinterpret_cast<DetectionOutputT *>(u.value));
+      value = new MNN::DetectionOutputT(*reinterpret_cast<MNN::DetectionOutputT *>(u.value));
       break;
     }
     case OpParameter_Eltwise: {
-      value = new EltwiseT(*reinterpret_cast<EltwiseT *>(u.value));
+      value = new MNN::EltwiseT(*reinterpret_cast<MNN::EltwiseT *>(u.value));
       break;
     }
     case OpParameter_ExpandDims: {
-      value = new ExpandDimsT(*reinterpret_cast<ExpandDimsT *>(u.value));
+      value = new MNN::ExpandDimsT(*reinterpret_cast<MNN::ExpandDimsT *>(u.value));
       break;
     }
     case OpParameter_Fill: {
-      value = new FillT(*reinterpret_cast<FillT *>(u.value));
+      value = new MNN::FillT(*reinterpret_cast<MNN::FillT *>(u.value));
       break;
     }
     case OpParameter_Flatten: {
-      value = new FlattenT(*reinterpret_cast<FlattenT *>(u.value));
+      value = new MNN::FlattenT(*reinterpret_cast<MNN::FlattenT *>(u.value));
       break;
     }
     case OpParameter_Gather: {
-      value = new GatherT(*reinterpret_cast<GatherT *>(u.value));
+      value = new MNN::GatherT(*reinterpret_cast<MNN::GatherT *>(u.value));
       break;
     }
     case OpParameter_GatherV2: {
-      value = new GatherV2T(*reinterpret_cast<GatherV2T *>(u.value));
+      value = new MNN::GatherV2T(*reinterpret_cast<MNN::GatherV2T *>(u.value));
       break;
     }
     case OpParameter_InnerProduct: {
-      FLATBUFFERS_ASSERT(false);  // InnerProductT not copyable.
+      FLATBUFFERS_ASSERT(false);  // MNN::InnerProductT not copyable.
       break;
     }
     case OpParameter_Input: {
-      value = new InputT(*reinterpret_cast<InputT *>(u.value));
+      value = new MNN::InputT(*reinterpret_cast<MNN::InputT *>(u.value));
       break;
     }
     case OpParameter_Interp: {
-      value = new InterpT(*reinterpret_cast<InterpT *>(u.value));
+      value = new MNN::InterpT(*reinterpret_cast<MNN::InterpT *>(u.value));
       break;
     }
     case OpParameter_LRN: {
-      value = new LRNT(*reinterpret_cast<LRNT *>(u.value));
+      value = new MNN::LRNT(*reinterpret_cast<MNN::LRNT *>(u.value));
       break;
     }
     case OpParameter_LSTM: {
-      FLATBUFFERS_ASSERT(false);  // LSTMT not copyable.
+      FLATBUFFERS_ASSERT(false);  // MNN::LSTMT not copyable.
       break;
     }
     case OpParameter_MatMul: {
-      value = new MatMulT(*reinterpret_cast<MatMulT *>(u.value));
+      value = new MNN::MatMulT(*reinterpret_cast<MNN::MatMulT *>(u.value));
       break;
     }
     case OpParameter_NonMaxSuppressionV2: {
-      value = new NonMaxSuppressionV2T(*reinterpret_cast<NonMaxSuppressionV2T *>(u.value));
+      value = new MNN::NonMaxSuppressionV2T(*reinterpret_cast<MNN::NonMaxSuppressionV2T *>(u.value));
       break;
     }
     case OpParameter_Normalize: {
-      value = new NormalizeT(*reinterpret_cast<NormalizeT *>(u.value));
+      value = new MNN::NormalizeT(*reinterpret_cast<MNN::NormalizeT *>(u.value));
       break;
     }
     case OpParameter_PackParam: {
-      value = new PackParamT(*reinterpret_cast<PackParamT *>(u.value));
+      value = new MNN::PackParamT(*reinterpret_cast<MNN::PackParamT *>(u.value));
       break;
     }
     case OpParameter_Permute: {
-      value = new PermuteT(*reinterpret_cast<PermuteT *>(u.value));
+      value = new MNN::PermuteT(*reinterpret_cast<MNN::PermuteT *>(u.value));
       break;
     }
     case OpParameter_Plugin: {
-      FLATBUFFERS_ASSERT(false);  // PluginT not copyable.
+      FLATBUFFERS_ASSERT(false);  // MNN::PluginT not copyable.
       break;
     }
     case OpParameter_Pool: {
-      value = new PoolT(*reinterpret_cast<PoolT *>(u.value));
+      value = new MNN::PoolT(*reinterpret_cast<MNN::PoolT *>(u.value));
       break;
     }
     case OpParameter_PRelu: {
-      value = new PReluT(*reinterpret_cast<PReluT *>(u.value));
+      value = new MNN::PReluT(*reinterpret_cast<MNN::PReluT *>(u.value));
       break;
     }
     case OpParameter_PriorBox: {
-      value = new PriorBoxT(*reinterpret_cast<PriorBoxT *>(u.value));
+      value = new MNN::PriorBoxT(*reinterpret_cast<MNN::PriorBoxT *>(u.value));
       break;
     }
     case OpParameter_Proposal: {
-      FLATBUFFERS_ASSERT(false);  // ProposalT not copyable.
+      FLATBUFFERS_ASSERT(false);  // MNN::ProposalT not copyable.
       break;
     }
     case OpParameter_QuantizedAvgPool: {
-      value = new QuantizedAvgPoolT(*reinterpret_cast<QuantizedAvgPoolT *>(u.value));
+      value = new MNN::QuantizedAvgPoolT(*reinterpret_cast<MNN::QuantizedAvgPoolT *>(u.value));
       break;
     }
     case OpParameter_QuantizedBiasAdd: {
-      value = new QuantizedBiasAddT(*reinterpret_cast<QuantizedBiasAddT *>(u.value));
+      value = new MNN::QuantizedBiasAddT(*reinterpret_cast<MNN::QuantizedBiasAddT *>(u.value));
       break;
     }
     case OpParameter_QuantizedConcat: {
-      FLATBUFFERS_ASSERT(false);  // QuantizedConcatT not copyable.
+      FLATBUFFERS_ASSERT(false);  // MNN::QuantizedConcatT not copyable.
       break;
     }
     case OpParameter_QuantizedLogistic: {
-      FLATBUFFERS_ASSERT(false);  // QuantizedLogisticT not copyable.
+      FLATBUFFERS_ASSERT(false);  // MNN::QuantizedLogisticT not copyable.
       break;
     }
     case OpParameter_QuantizedMatMul: {
-      value = new QuantizedMatMulT(*reinterpret_cast<QuantizedMatMulT *>(u.value));
+      value = new MNN::QuantizedMatMulT(*reinterpret_cast<MNN::QuantizedMatMulT *>(u.value));
       break;
     }
     case OpParameter_QuantizedMaxPool: {
-      value = new QuantizedMaxPoolT(*reinterpret_cast<QuantizedMaxPoolT *>(u.value));
+      value = new MNN::QuantizedMaxPoolT(*reinterpret_cast<MNN::QuantizedMaxPoolT *>(u.value));
       break;
     }
     case OpParameter_QuantizedRelu: {
-      value = new QuantizedReluT(*reinterpret_cast<QuantizedReluT *>(u.value));
+      value = new MNN::QuantizedReluT(*reinterpret_cast<MNN::QuantizedReluT *>(u.value));
       break;
     }
     case OpParameter_QuantizedRelu6: {
-      value = new QuantizedRelu6T(*reinterpret_cast<QuantizedRelu6T *>(u.value));
+      value = new MNN::QuantizedRelu6T(*reinterpret_cast<MNN::QuantizedRelu6T *>(u.value));
       break;
     }
     case OpParameter_QuantizedReshape: {
-      value = new QuantizedReshapeT(*reinterpret_cast<QuantizedReshapeT *>(u.value));
+      value = new MNN::QuantizedReshapeT(*reinterpret_cast<MNN::QuantizedReshapeT *>(u.value));
       break;
     }
     case OpParameter_QuantizedSoftmax: {
-      value = new QuantizedSoftmaxT(*reinterpret_cast<QuantizedSoftmaxT *>(u.value));
+      value = new MNN::QuantizedSoftmaxT(*reinterpret_cast<MNN::QuantizedSoftmaxT *>(u.value));
       break;
     }
     case OpParameter_QuantizeMaxMin: {
-      value = new QuantizeMaxMinT(*reinterpret_cast<QuantizeMaxMinT *>(u.value));
+      value = new MNN::QuantizeMaxMinT(*reinterpret_cast<MNN::QuantizeMaxMinT *>(u.value));
       break;
     }
     case OpParameter_QuantizeV2: {
-      value = new QuantizeV2T(*reinterpret_cast<QuantizeV2T *>(u.value));
+      value = new MNN::QuantizeV2T(*reinterpret_cast<MNN::QuantizeV2T *>(u.value));
       break;
     }
     case OpParameter_Range: {
-      value = new RangeT(*reinterpret_cast<RangeT *>(u.value));
+      value = new MNN::RangeT(*reinterpret_cast<MNN::RangeT *>(u.value));
       break;
     }
     case OpParameter_Rank: {
-      value = new RankT(*reinterpret_cast<RankT *>(u.value));
+      value = new MNN::RankT(*reinterpret_cast<MNN::RankT *>(u.value));
       break;
     }
     case OpParameter_ReduceJoin: {
-      value = new ReduceJoinT(*reinterpret_cast<ReduceJoinT *>(u.value));
+      value = new MNN::ReduceJoinT(*reinterpret_cast<MNN::ReduceJoinT *>(u.value));
       break;
     }
     case OpParameter_ReductionParam: {
-      value = new ReductionParamT(*reinterpret_cast<ReductionParamT *>(u.value));
+      value = new MNN::ReductionParamT(*reinterpret_cast<MNN::ReductionParamT *>(u.value));
       break;
     }
     case OpParameter_Relu: {
-      value = new ReluT(*reinterpret_cast<ReluT *>(u.value));
+      value = new MNN::ReluT(*reinterpret_cast<MNN::ReluT *>(u.value));
       break;
     }
     case OpParameter_Relu6: {
-      value = new Relu6T(*reinterpret_cast<Relu6T *>(u.value));
+      value = new MNN::Relu6T(*reinterpret_cast<MNN::Relu6T *>(u.value));
       break;
     }
     case OpParameter_RequantizationRange: {
-      value = new RequantizationRangeT(*reinterpret_cast<RequantizationRangeT *>(u.value));
+      value = new MNN::RequantizationRangeT(*reinterpret_cast<MNN::RequantizationRangeT *>(u.value));
       break;
     }
     case OpParameter_Requantize: {
-      value = new RequantizeT(*reinterpret_cast<RequantizeT *>(u.value));
+      value = new MNN::RequantizeT(*reinterpret_cast<MNN::RequantizeT *>(u.value));
       break;
     }
     case OpParameter_Reshape: {
-      value = new ReshapeT(*reinterpret_cast<ReshapeT *>(u.value));
+      value = new MNN::ReshapeT(*reinterpret_cast<MNN::ReshapeT *>(u.value));
       break;
     }
     case OpParameter_Resize: {
-      value = new ResizeT(*reinterpret_cast<ResizeT *>(u.value));
+      value = new MNN::ResizeT(*reinterpret_cast<MNN::ResizeT *>(u.value));
       break;
     }
     case OpParameter_RoiPooling: {
-      value = new RoiPoolingT(*reinterpret_cast<RoiPoolingT *>(u.value));
+      value = new MNN::RoiPoolingT(*reinterpret_cast<MNN::RoiPoolingT *>(u.value));
       break;
     }
     case OpParameter_Scale: {
-      value = new ScaleT(*reinterpret_cast<ScaleT *>(u.value));
+      value = new MNN::ScaleT(*reinterpret_cast<MNN::ScaleT *>(u.value));
       break;
     }
     case OpParameter_Selu: {
-      value = new SeluT(*reinterpret_cast<SeluT *>(u.value));
+      value = new MNN::SeluT(*reinterpret_cast<MNN::SeluT *>(u.value));
       break;
     }
     case OpParameter_Size: {
-      value = new SizeT(*reinterpret_cast<SizeT *>(u.value));
+      value = new MNN::SizeT(*reinterpret_cast<MNN::SizeT *>(u.value));
       break;
     }
     case OpParameter_Slice: {
-      value = new SliceT(*reinterpret_cast<SliceT *>(u.value));
+      value = new MNN::SliceT(*reinterpret_cast<MNN::SliceT *>(u.value));
       break;
     }
     case OpParameter_SliceTf: {
-      value = new SliceTfT(*reinterpret_cast<SliceTfT *>(u.value));
+      value = new MNN::SliceTfT(*reinterpret_cast<MNN::SliceTfT *>(u.value));
       break;
     }
     case OpParameter_SpaceBatch: {
-      FLATBUFFERS_ASSERT(false);  // SpaceBatchT not copyable.
+      FLATBUFFERS_ASSERT(false);  // MNN::SpaceBatchT not copyable.
       break;
     }
     case OpParameter_SqueezeParam: {
-      value = new SqueezeParamT(*reinterpret_cast<SqueezeParamT *>(u.value));
+      value = new MNN::SqueezeParamT(*reinterpret_cast<MNN::SqueezeParamT *>(u.value));
       break;
     }
     case OpParameter_StridedSliceParam: {
-      value = new StridedSliceParamT(*reinterpret_cast<StridedSliceParamT *>(u.value));
+      value = new MNN::StridedSliceParamT(*reinterpret_cast<MNN::StridedSliceParamT *>(u.value));
       break;
     }
     case OpParameter_TensorConvertInfo: {
-      value = new TensorConvertInfoT(*reinterpret_cast<TensorConvertInfoT *>(u.value));
+      value = new MNN::TensorConvertInfoT(*reinterpret_cast<MNN::TensorConvertInfoT *>(u.value));
       break;
     }
     case OpParameter_TfQuantizedConv2D: {
-      FLATBUFFERS_ASSERT(false);  // TfQuantizedConv2DT not copyable.
+      FLATBUFFERS_ASSERT(false);  // MNN::TfQuantizedConv2DT not copyable.
       break;
     }
     case OpParameter_TopKV2: {
-      value = new TopKV2T(*reinterpret_cast<TopKV2T *>(u.value));
+      value = new MNN::TopKV2T(*reinterpret_cast<MNN::TopKV2T *>(u.value));
       break;
     }
     case OpParameter_Transpose: {
-      value = new TransposeT(*reinterpret_cast<TransposeT *>(u.value));
+      value = new MNN::TransposeT(*reinterpret_cast<MNN::TransposeT *>(u.value));
       break;
     }
     case OpParameter_UnaryOp: {
-      value = new UnaryOpT(*reinterpret_cast<UnaryOpT *>(u.value));
+      value = new MNN::UnaryOpT(*reinterpret_cast<MNN::UnaryOpT *>(u.value));
       break;
     }
     case OpParameter_MomentsParam: {
-      value = new MomentsParamT(*reinterpret_cast<MomentsParamT *>(u.value));
+      value = new MNN::MomentsParamT(*reinterpret_cast<MNN::MomentsParamT *>(u.value));
       break;
     }
     case OpParameter_RNNParam: {
-      FLATBUFFERS_ASSERT(false);  // RNNParamT not copyable.
+      FLATBUFFERS_ASSERT(false);  // MNN::RNNParamT not copyable.
       break;
     }
     case OpParameter_BatchMatMulParam: {
-      value = new BatchMatMulParamT(*reinterpret_cast<BatchMatMulParamT *>(u.value));
+      value = new MNN::BatchMatMulParamT(*reinterpret_cast<MNN::BatchMatMulParamT *>(u.value));
       break;
     }
     case OpParameter_QuantizedFloatParam: {
-      value = new QuantizedFloatParamT(*reinterpret_cast<QuantizedFloatParamT *>(u.value));
+      value = new MNN::QuantizedFloatParamT(*reinterpret_cast<MNN::QuantizedFloatParamT *>(u.value));
       break;
     }
     case OpParameter_DepthSpaceParam: {
-      value = new DepthSpaceParamT(*reinterpret_cast<DepthSpaceParamT *>(u.value));
+      value = new MNN::DepthSpaceParamT(*reinterpret_cast<MNN::DepthSpaceParamT *>(u.value));
       break;
     }
     case OpParameter_EltwiseInt8: {
-      FLATBUFFERS_ASSERT(false);  // EltwiseInt8T not copyable.
+      FLATBUFFERS_ASSERT(false);  // MNN::EltwiseInt8T not copyable.
       break;
     }
     case OpParameter_ReverseSequenceParam: {
-      value = new ReverseSequenceParamT(*reinterpret_cast<ReverseSequenceParamT *>(u.value));
+      value = new MNN::ReverseSequenceParamT(*reinterpret_cast<MNN::ReverseSequenceParamT *>(u.value));
       break;
     }
     case OpParameter_Extra: {
-      FLATBUFFERS_ASSERT(false);  // ExtraT not copyable.
+      FLATBUFFERS_ASSERT(false);  // MNN::ExtraT not copyable.
       break;
     }
     case OpParameter_Pool3D: {
-      value = new Pool3DT(*reinterpret_cast<Pool3DT *>(u.value));
+      value = new MNN::Pool3DT(*reinterpret_cast<MNN::Pool3DT *>(u.value));
       break;
     }
     case OpParameter_Convolution3D: {
-      FLATBUFFERS_ASSERT(false);  // Convolution3DT not copyable.
+      FLATBUFFERS_ASSERT(false);  // MNN::Convolution3DT not copyable.
       break;
     }
     case OpParameter_ELU: {
-      value = new ELUT(*reinterpret_cast<ELUT *>(u.value));
+      value = new MNN::ELUT(*reinterpret_cast<MNN::ELUT *>(u.value));
       break;
     }
     case OpParameter_DetectionPostProcessParam: {
-      value = new DetectionPostProcessParamT(*reinterpret_cast<DetectionPostProcessParamT *>(u.value));
+      value = new MNN::DetectionPostProcessParamT(*reinterpret_cast<MNN::DetectionPostProcessParamT *>(u.value));
       break;
     }
     case OpParameter_OneHotParam: {
-      value = new OneHotParamT(*reinterpret_cast<OneHotParamT *>(u.value));
+      value = new MNN::OneHotParamT(*reinterpret_cast<MNN::OneHotParamT *>(u.value));
       break;
     }
     case OpParameter_PadParam: {
-      value = new PadParamT(*reinterpret_cast<PadParamT *>(u.value));
+      value = new MNN::PadParamT(*reinterpret_cast<MNN::PadParamT *>(u.value));
       break;
     }
     case OpParameter_WhileParam: {
-      FLATBUFFERS_ASSERT(false);  // WhileParamT not copyable.
+      FLATBUFFERS_ASSERT(false);  // MNN::WhileParamT not copyable.
       break;
     }
     case OpParameter_IfParam: {
-      FLATBUFFERS_ASSERT(false);  // IfParamT not copyable.
+      FLATBUFFERS_ASSERT(false);  // MNN::IfParamT not copyable.
       break;
     }
     case OpParameter_RandomUniform: {
-      value = new RandomUniformT(*reinterpret_cast<RandomUniformT *>(u.value));
+      value = new MNN::RandomUniformT(*reinterpret_cast<MNN::RandomUniformT *>(u.value));
       break;
     }
     case OpParameter_LayerNorm: {
-      value = new LayerNormT(*reinterpret_cast<LayerNormT *>(u.value));
+      value = new MNN::LayerNormT(*reinterpret_cast<MNN::LayerNormT *>(u.value));
       break;
     }
     default:
@@ -6220,442 +6213,442 @@ inline OpParameterUnion::OpParameterUnion(const OpParameterUnion &u) FLATBUFFERS
 inline void OpParameterUnion::Reset() {
   switch (type) {
     case OpParameter_QuantizedAdd: {
-      auto ptr = reinterpret_cast<QuantizedAddT *>(value);
+      auto ptr = reinterpret_cast<MNN::QuantizedAddT *>(value);
       delete ptr;
       break;
     }
     case OpParameter_ArgMax: {
-      auto ptr = reinterpret_cast<ArgMaxT *>(value);
+      auto ptr = reinterpret_cast<MNN::ArgMaxT *>(value);
       delete ptr;
       break;
     }
     case OpParameter_AsString: {
-      auto ptr = reinterpret_cast<AsStringT *>(value);
+      auto ptr = reinterpret_cast<MNN::AsStringT *>(value);
       delete ptr;
       break;
     }
     case OpParameter_Axis: {
-      auto ptr = reinterpret_cast<AxisT *>(value);
+      auto ptr = reinterpret_cast<MNN::AxisT *>(value);
       delete ptr;
       break;
     }
     case OpParameter_BatchNorm: {
-      auto ptr = reinterpret_cast<BatchNormT *>(value);
+      auto ptr = reinterpret_cast<MNN::BatchNormT *>(value);
       delete ptr;
       break;
     }
     case OpParameter_BinaryOp: {
-      auto ptr = reinterpret_cast<BinaryOpT *>(value);
+      auto ptr = reinterpret_cast<MNN::BinaryOpT *>(value);
       delete ptr;
       break;
     }
     case OpParameter_Blob: {
-      auto ptr = reinterpret_cast<BlobT *>(value);
+      auto ptr = reinterpret_cast<MNN::BlobT *>(value);
       delete ptr;
       break;
     }
     case OpParameter_CastParam: {
-      auto ptr = reinterpret_cast<CastParamT *>(value);
+      auto ptr = reinterpret_cast<MNN::CastParamT *>(value);
       delete ptr;
       break;
     }
     case OpParameter_Convolution2D: {
-      auto ptr = reinterpret_cast<Convolution2DT *>(value);
+      auto ptr = reinterpret_cast<MNN::Convolution2DT *>(value);
       delete ptr;
       break;
     }
     case OpParameter_Crop: {
-      auto ptr = reinterpret_cast<CropT *>(value);
+      auto ptr = reinterpret_cast<MNN::CropT *>(value);
       delete ptr;
       break;
     }
     case OpParameter_CropAndResize: {
-      auto ptr = reinterpret_cast<CropAndResizeT *>(value);
+      auto ptr = reinterpret_cast<MNN::CropAndResizeT *>(value);
       delete ptr;
       break;
     }
     case OpParameter_Dequantize: {
-      auto ptr = reinterpret_cast<DequantizeT *>(value);
+      auto ptr = reinterpret_cast<MNN::DequantizeT *>(value);
       delete ptr;
       break;
     }
     case OpParameter_DetectionOutput: {
-      auto ptr = reinterpret_cast<DetectionOutputT *>(value);
+      auto ptr = reinterpret_cast<MNN::DetectionOutputT *>(value);
       delete ptr;
       break;
     }
     case OpParameter_Eltwise: {
-      auto ptr = reinterpret_cast<EltwiseT *>(value);
+      auto ptr = reinterpret_cast<MNN::EltwiseT *>(value);
       delete ptr;
       break;
     }
     case OpParameter_ExpandDims: {
-      auto ptr = reinterpret_cast<ExpandDimsT *>(value);
+      auto ptr = reinterpret_cast<MNN::ExpandDimsT *>(value);
       delete ptr;
       break;
     }
     case OpParameter_Fill: {
-      auto ptr = reinterpret_cast<FillT *>(value);
+      auto ptr = reinterpret_cast<MNN::FillT *>(value);
       delete ptr;
       break;
     }
     case OpParameter_Flatten: {
-      auto ptr = reinterpret_cast<FlattenT *>(value);
+      auto ptr = reinterpret_cast<MNN::FlattenT *>(value);
       delete ptr;
       break;
     }
     case OpParameter_Gather: {
-      auto ptr = reinterpret_cast<GatherT *>(value);
+      auto ptr = reinterpret_cast<MNN::GatherT *>(value);
       delete ptr;
       break;
     }
     case OpParameter_GatherV2: {
-      auto ptr = reinterpret_cast<GatherV2T *>(value);
+      auto ptr = reinterpret_cast<MNN::GatherV2T *>(value);
       delete ptr;
       break;
     }
     case OpParameter_InnerProduct: {
-      auto ptr = reinterpret_cast<InnerProductT *>(value);
+      auto ptr = reinterpret_cast<MNN::InnerProductT *>(value);
       delete ptr;
       break;
     }
     case OpParameter_Input: {
-      auto ptr = reinterpret_cast<InputT *>(value);
+      auto ptr = reinterpret_cast<MNN::InputT *>(value);
       delete ptr;
       break;
     }
     case OpParameter_Interp: {
-      auto ptr = reinterpret_cast<InterpT *>(value);
+      auto ptr = reinterpret_cast<MNN::InterpT *>(value);
       delete ptr;
       break;
     }
     case OpParameter_LRN: {
-      auto ptr = reinterpret_cast<LRNT *>(value);
+      auto ptr = reinterpret_cast<MNN::LRNT *>(value);
       delete ptr;
       break;
     }
     case OpParameter_LSTM: {
-      auto ptr = reinterpret_cast<LSTMT *>(value);
+      auto ptr = reinterpret_cast<MNN::LSTMT *>(value);
       delete ptr;
       break;
     }
     case OpParameter_MatMul: {
-      auto ptr = reinterpret_cast<MatMulT *>(value);
+      auto ptr = reinterpret_cast<MNN::MatMulT *>(value);
       delete ptr;
       break;
     }
     case OpParameter_NonMaxSuppressionV2: {
-      auto ptr = reinterpret_cast<NonMaxSuppressionV2T *>(value);
+      auto ptr = reinterpret_cast<MNN::NonMaxSuppressionV2T *>(value);
       delete ptr;
       break;
     }
     case OpParameter_Normalize: {
-      auto ptr = reinterpret_cast<NormalizeT *>(value);
+      auto ptr = reinterpret_cast<MNN::NormalizeT *>(value);
       delete ptr;
       break;
     }
     case OpParameter_PackParam: {
-      auto ptr = reinterpret_cast<PackParamT *>(value);
+      auto ptr = reinterpret_cast<MNN::PackParamT *>(value);
       delete ptr;
       break;
     }
     case OpParameter_Permute: {
-      auto ptr = reinterpret_cast<PermuteT *>(value);
+      auto ptr = reinterpret_cast<MNN::PermuteT *>(value);
       delete ptr;
       break;
     }
     case OpParameter_Plugin: {
-      auto ptr = reinterpret_cast<PluginT *>(value);
+      auto ptr = reinterpret_cast<MNN::PluginT *>(value);
       delete ptr;
       break;
     }
     case OpParameter_Pool: {
-      auto ptr = reinterpret_cast<PoolT *>(value);
+      auto ptr = reinterpret_cast<MNN::PoolT *>(value);
       delete ptr;
       break;
     }
     case OpParameter_PRelu: {
-      auto ptr = reinterpret_cast<PReluT *>(value);
+      auto ptr = reinterpret_cast<MNN::PReluT *>(value);
       delete ptr;
       break;
     }
     case OpParameter_PriorBox: {
-      auto ptr = reinterpret_cast<PriorBoxT *>(value);
+      auto ptr = reinterpret_cast<MNN::PriorBoxT *>(value);
       delete ptr;
       break;
     }
     case OpParameter_Proposal: {
-      auto ptr = reinterpret_cast<ProposalT *>(value);
+      auto ptr = reinterpret_cast<MNN::ProposalT *>(value);
       delete ptr;
       break;
     }
     case OpParameter_QuantizedAvgPool: {
-      auto ptr = reinterpret_cast<QuantizedAvgPoolT *>(value);
+      auto ptr = reinterpret_cast<MNN::QuantizedAvgPoolT *>(value);
       delete ptr;
       break;
     }
     case OpParameter_QuantizedBiasAdd: {
-      auto ptr = reinterpret_cast<QuantizedBiasAddT *>(value);
+      auto ptr = reinterpret_cast<MNN::QuantizedBiasAddT *>(value);
       delete ptr;
       break;
     }
     case OpParameter_QuantizedConcat: {
-      auto ptr = reinterpret_cast<QuantizedConcatT *>(value);
+      auto ptr = reinterpret_cast<MNN::QuantizedConcatT *>(value);
       delete ptr;
       break;
     }
     case OpParameter_QuantizedLogistic: {
-      auto ptr = reinterpret_cast<QuantizedLogisticT *>(value);
+      auto ptr = reinterpret_cast<MNN::QuantizedLogisticT *>(value);
       delete ptr;
       break;
     }
     case OpParameter_QuantizedMatMul: {
-      auto ptr = reinterpret_cast<QuantizedMatMulT *>(value);
+      auto ptr = reinterpret_cast<MNN::QuantizedMatMulT *>(value);
       delete ptr;
       break;
     }
     case OpParameter_QuantizedMaxPool: {
-      auto ptr = reinterpret_cast<QuantizedMaxPoolT *>(value);
+      auto ptr = reinterpret_cast<MNN::QuantizedMaxPoolT *>(value);
       delete ptr;
       break;
     }
     case OpParameter_QuantizedRelu: {
-      auto ptr = reinterpret_cast<QuantizedReluT *>(value);
+      auto ptr = reinterpret_cast<MNN::QuantizedReluT *>(value);
       delete ptr;
       break;
     }
     case OpParameter_QuantizedRelu6: {
-      auto ptr = reinterpret_cast<QuantizedRelu6T *>(value);
+      auto ptr = reinterpret_cast<MNN::QuantizedRelu6T *>(value);
       delete ptr;
       break;
     }
     case OpParameter_QuantizedReshape: {
-      auto ptr = reinterpret_cast<QuantizedReshapeT *>(value);
+      auto ptr = reinterpret_cast<MNN::QuantizedReshapeT *>(value);
       delete ptr;
       break;
     }
     case OpParameter_QuantizedSoftmax: {
-      auto ptr = reinterpret_cast<QuantizedSoftmaxT *>(value);
+      auto ptr = reinterpret_cast<MNN::QuantizedSoftmaxT *>(value);
       delete ptr;
       break;
     }
     case OpParameter_QuantizeMaxMin: {
-      auto ptr = reinterpret_cast<QuantizeMaxMinT *>(value);
+      auto ptr = reinterpret_cast<MNN::QuantizeMaxMinT *>(value);
       delete ptr;
       break;
     }
     case OpParameter_QuantizeV2: {
-      auto ptr = reinterpret_cast<QuantizeV2T *>(value);
+      auto ptr = reinterpret_cast<MNN::QuantizeV2T *>(value);
       delete ptr;
       break;
     }
     case OpParameter_Range: {
-      auto ptr = reinterpret_cast<RangeT *>(value);
+      auto ptr = reinterpret_cast<MNN::RangeT *>(value);
       delete ptr;
       break;
     }
     case OpParameter_Rank: {
-      auto ptr = reinterpret_cast<RankT *>(value);
+      auto ptr = reinterpret_cast<MNN::RankT *>(value);
       delete ptr;
       break;
     }
     case OpParameter_ReduceJoin: {
-      auto ptr = reinterpret_cast<ReduceJoinT *>(value);
+      auto ptr = reinterpret_cast<MNN::ReduceJoinT *>(value);
       delete ptr;
       break;
     }
     case OpParameter_ReductionParam: {
-      auto ptr = reinterpret_cast<ReductionParamT *>(value);
+      auto ptr = reinterpret_cast<MNN::ReductionParamT *>(value);
       delete ptr;
       break;
     }
     case OpParameter_Relu: {
-      auto ptr = reinterpret_cast<ReluT *>(value);
+      auto ptr = reinterpret_cast<MNN::ReluT *>(value);
       delete ptr;
       break;
     }
     case OpParameter_Relu6: {
-      auto ptr = reinterpret_cast<Relu6T *>(value);
+      auto ptr = reinterpret_cast<MNN::Relu6T *>(value);
       delete ptr;
       break;
     }
     case OpParameter_RequantizationRange: {
-      auto ptr = reinterpret_cast<RequantizationRangeT *>(value);
+      auto ptr = reinterpret_cast<MNN::RequantizationRangeT *>(value);
       delete ptr;
       break;
     }
     case OpParameter_Requantize: {
-      auto ptr = reinterpret_cast<RequantizeT *>(value);
+      auto ptr = reinterpret_cast<MNN::RequantizeT *>(value);
       delete ptr;
       break;
     }
     case OpParameter_Reshape: {
-      auto ptr = reinterpret_cast<ReshapeT *>(value);
+      auto ptr = reinterpret_cast<MNN::ReshapeT *>(value);
       delete ptr;
       break;
     }
     case OpParameter_Resize: {
-      auto ptr = reinterpret_cast<ResizeT *>(value);
+      auto ptr = reinterpret_cast<MNN::ResizeT *>(value);
       delete ptr;
       break;
     }
     case OpParameter_RoiPooling: {
-      auto ptr = reinterpret_cast<RoiPoolingT *>(value);
+      auto ptr = reinterpret_cast<MNN::RoiPoolingT *>(value);
       delete ptr;
       break;
     }
     case OpParameter_Scale: {
-      auto ptr = reinterpret_cast<ScaleT *>(value);
+      auto ptr = reinterpret_cast<MNN::ScaleT *>(value);
       delete ptr;
       break;
     }
     case OpParameter_Selu: {
-      auto ptr = reinterpret_cast<SeluT *>(value);
+      auto ptr = reinterpret_cast<MNN::SeluT *>(value);
       delete ptr;
       break;
     }
     case OpParameter_Size: {
-      auto ptr = reinterpret_cast<SizeT *>(value);
+      auto ptr = reinterpret_cast<MNN::SizeT *>(value);
       delete ptr;
       break;
     }
     case OpParameter_Slice: {
-      auto ptr = reinterpret_cast<SliceT *>(value);
+      auto ptr = reinterpret_cast<MNN::SliceT *>(value);
       delete ptr;
       break;
     }
     case OpParameter_SliceTf: {
-      auto ptr = reinterpret_cast<SliceTfT *>(value);
+      auto ptr = reinterpret_cast<MNN::SliceTfT *>(value);
       delete ptr;
       break;
     }
     case OpParameter_SpaceBatch: {
-      auto ptr = reinterpret_cast<SpaceBatchT *>(value);
+      auto ptr = reinterpret_cast<MNN::SpaceBatchT *>(value);
       delete ptr;
       break;
     }
     case OpParameter_SqueezeParam: {
-      auto ptr = reinterpret_cast<SqueezeParamT *>(value);
+      auto ptr = reinterpret_cast<MNN::SqueezeParamT *>(value);
       delete ptr;
       break;
     }
     case OpParameter_StridedSliceParam: {
-      auto ptr = reinterpret_cast<StridedSliceParamT *>(value);
+      auto ptr = reinterpret_cast<MNN::StridedSliceParamT *>(value);
       delete ptr;
       break;
     }
     case OpParameter_TensorConvertInfo: {
-      auto ptr = reinterpret_cast<TensorConvertInfoT *>(value);
+      auto ptr = reinterpret_cast<MNN::TensorConvertInfoT *>(value);
       delete ptr;
       break;
     }
     case OpParameter_TfQuantizedConv2D: {
-      auto ptr = reinterpret_cast<TfQuantizedConv2DT *>(value);
+      auto ptr = reinterpret_cast<MNN::TfQuantizedConv2DT *>(value);
       delete ptr;
       break;
     }
     case OpParameter_TopKV2: {
-      auto ptr = reinterpret_cast<TopKV2T *>(value);
+      auto ptr = reinterpret_cast<MNN::TopKV2T *>(value);
       delete ptr;
       break;
     }
     case OpParameter_Transpose: {
-      auto ptr = reinterpret_cast<TransposeT *>(value);
+      auto ptr = reinterpret_cast<MNN::TransposeT *>(value);
       delete ptr;
       break;
     }
     case OpParameter_UnaryOp: {
-      auto ptr = reinterpret_cast<UnaryOpT *>(value);
+      auto ptr = reinterpret_cast<MNN::UnaryOpT *>(value);
       delete ptr;
       break;
     }
     case OpParameter_MomentsParam: {
-      auto ptr = reinterpret_cast<MomentsParamT *>(value);
+      auto ptr = reinterpret_cast<MNN::MomentsParamT *>(value);
       delete ptr;
       break;
     }
     case OpParameter_RNNParam: {
-      auto ptr = reinterpret_cast<RNNParamT *>(value);
+      auto ptr = reinterpret_cast<MNN::RNNParamT *>(value);
       delete ptr;
       break;
     }
     case OpParameter_BatchMatMulParam: {
-      auto ptr = reinterpret_cast<BatchMatMulParamT *>(value);
+      auto ptr = reinterpret_cast<MNN::BatchMatMulParamT *>(value);
       delete ptr;
       break;
     }
     case OpParameter_QuantizedFloatParam: {
-      auto ptr = reinterpret_cast<QuantizedFloatParamT *>(value);
+      auto ptr = reinterpret_cast<MNN::QuantizedFloatParamT *>(value);
       delete ptr;
       break;
     }
     case OpParameter_DepthSpaceParam: {
-      auto ptr = reinterpret_cast<DepthSpaceParamT *>(value);
+      auto ptr = reinterpret_cast<MNN::DepthSpaceParamT *>(value);
       delete ptr;
       break;
     }
     case OpParameter_EltwiseInt8: {
-      auto ptr = reinterpret_cast<EltwiseInt8T *>(value);
+      auto ptr = reinterpret_cast<MNN::EltwiseInt8T *>(value);
       delete ptr;
       break;
     }
     case OpParameter_ReverseSequenceParam: {
-      auto ptr = reinterpret_cast<ReverseSequenceParamT *>(value);
+      auto ptr = reinterpret_cast<MNN::ReverseSequenceParamT *>(value);
       delete ptr;
       break;
     }
     case OpParameter_Extra: {
-      auto ptr = reinterpret_cast<ExtraT *>(value);
+      auto ptr = reinterpret_cast<MNN::ExtraT *>(value);
       delete ptr;
       break;
     }
     case OpParameter_Pool3D: {
-      auto ptr = reinterpret_cast<Pool3DT *>(value);
+      auto ptr = reinterpret_cast<MNN::Pool3DT *>(value);
       delete ptr;
       break;
     }
     case OpParameter_Convolution3D: {
-      auto ptr = reinterpret_cast<Convolution3DT *>(value);
+      auto ptr = reinterpret_cast<MNN::Convolution3DT *>(value);
       delete ptr;
       break;
     }
     case OpParameter_ELU: {
-      auto ptr = reinterpret_cast<ELUT *>(value);
+      auto ptr = reinterpret_cast<MNN::ELUT *>(value);
       delete ptr;
       break;
     }
     case OpParameter_DetectionPostProcessParam: {
-      auto ptr = reinterpret_cast<DetectionPostProcessParamT *>(value);
+      auto ptr = reinterpret_cast<MNN::DetectionPostProcessParamT *>(value);
       delete ptr;
       break;
     }
     case OpParameter_OneHotParam: {
-      auto ptr = reinterpret_cast<OneHotParamT *>(value);
+      auto ptr = reinterpret_cast<MNN::OneHotParamT *>(value);
       delete ptr;
       break;
     }
     case OpParameter_PadParam: {
-      auto ptr = reinterpret_cast<PadParamT *>(value);
+      auto ptr = reinterpret_cast<MNN::PadParamT *>(value);
       delete ptr;
       break;
     }
     case OpParameter_WhileParam: {
-      auto ptr = reinterpret_cast<WhileParamT *>(value);
+      auto ptr = reinterpret_cast<MNN::WhileParamT *>(value);
       delete ptr;
       break;
     }
     case OpParameter_IfParam: {
-      auto ptr = reinterpret_cast<IfParamT *>(value);
+      auto ptr = reinterpret_cast<MNN::IfParamT *>(value);
       delete ptr;
       break;
     }
     case OpParameter_RandomUniform: {
-      auto ptr = reinterpret_cast<RandomUniformT *>(value);
+      auto ptr = reinterpret_cast<MNN::RandomUniformT *>(value);
       delete ptr;
       break;
     }
     case OpParameter_LayerNorm: {
-      auto ptr = reinterpret_cast<LayerNormT *>(value);
+      auto ptr = reinterpret_cast<MNN::LayerNormT *>(value);
       delete ptr;
       break;
     }
@@ -6819,7 +6812,7 @@ inline const flatbuffers::TypeTable *OpTypeTypeTable() {
     { flatbuffers::ET_INT, 0, 0 }
   };
   static const flatbuffers::TypeFunction type_refs[] = {
-    OpTypeTypeTable
+    MNN::OpTypeTypeTable
   };
   static const int64_t values[] = { 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 128, 129, 130, 131, 132, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 512, 513, 514, 515, 516, 517, 518, 600, 601, 603 };
   static const char * const names[] = {
@@ -6975,7 +6968,7 @@ inline const flatbuffers::TypeTable *OpTypeTypeTable() {
     "LayerNorm"
   };
   static const flatbuffers::TypeTable tt = {
-    flatbuffers::ST_ENUM, 150, type_codes, type_refs, values, names
+    flatbuffers::ST_ENUM, 150, type_codes, type_refs, nullptr, values, names
   };
   return &tt;
 }
@@ -7073,94 +7066,94 @@ inline const flatbuffers::TypeTable *OpParameterTypeTable() {
     { flatbuffers::ET_SEQUENCE, 0, 87 }
   };
   static const flatbuffers::TypeFunction type_refs[] = {
-    QuantizedAddTypeTable,
-    ArgMaxTypeTable,
-    AsStringTypeTable,
-    AxisTypeTable,
-    BatchNormTypeTable,
-    BinaryOpTypeTable,
-    BlobTypeTable,
-    CastParamTypeTable,
-    Convolution2DTypeTable,
-    CropTypeTable,
-    CropAndResizeTypeTable,
-    DequantizeTypeTable,
-    DetectionOutputTypeTable,
-    EltwiseTypeTable,
-    ExpandDimsTypeTable,
-    FillTypeTable,
-    FlattenTypeTable,
-    GatherTypeTable,
-    GatherV2TypeTable,
-    InnerProductTypeTable,
-    InputTypeTable,
-    InterpTypeTable,
-    LRNTypeTable,
-    LSTMTypeTable,
-    MatMulTypeTable,
-    NonMaxSuppressionV2TypeTable,
-    NormalizeTypeTable,
-    PackParamTypeTable,
-    PermuteTypeTable,
-    PluginTypeTable,
-    PoolTypeTable,
-    PReluTypeTable,
-    PriorBoxTypeTable,
-    ProposalTypeTable,
-    QuantizedAvgPoolTypeTable,
-    QuantizedBiasAddTypeTable,
-    QuantizedConcatTypeTable,
-    QuantizedLogisticTypeTable,
-    QuantizedMatMulTypeTable,
-    QuantizedMaxPoolTypeTable,
-    QuantizedReluTypeTable,
-    QuantizedRelu6TypeTable,
-    QuantizedReshapeTypeTable,
-    QuantizedSoftmaxTypeTable,
-    QuantizeMaxMinTypeTable,
-    QuantizeV2TypeTable,
-    RangeTypeTable,
-    RankTypeTable,
-    ReduceJoinTypeTable,
-    ReductionParamTypeTable,
-    ReluTypeTable,
-    Relu6TypeTable,
-    RequantizationRangeTypeTable,
-    RequantizeTypeTable,
-    ReshapeTypeTable,
-    ResizeTypeTable,
-    RoiPoolingTypeTable,
-    ScaleTypeTable,
-    SeluTypeTable,
-    SizeTypeTable,
-    SliceTypeTable,
-    SliceTfTypeTable,
-    SpaceBatchTypeTable,
-    SqueezeParamTypeTable,
-    StridedSliceParamTypeTable,
-    TensorConvertInfoTypeTable,
-    TfQuantizedConv2DTypeTable,
-    TopKV2TypeTable,
-    TransposeTypeTable,
-    UnaryOpTypeTable,
-    MomentsParamTypeTable,
-    RNNParamTypeTable,
-    BatchMatMulParamTypeTable,
-    QuantizedFloatParamTypeTable,
-    DepthSpaceParamTypeTable,
-    EltwiseInt8TypeTable,
-    ReverseSequenceParamTypeTable,
-    ExtraTypeTable,
-    Pool3DTypeTable,
-    Convolution3DTypeTable,
-    ELUTypeTable,
-    DetectionPostProcessParamTypeTable,
-    OneHotParamTypeTable,
-    PadParamTypeTable,
-    WhileParamTypeTable,
-    IfParamTypeTable,
-    RandomUniformTypeTable,
-    LayerNormTypeTable
+    MNN::QuantizedAddTypeTable,
+    MNN::ArgMaxTypeTable,
+    MNN::AsStringTypeTable,
+    MNN::AxisTypeTable,
+    MNN::BatchNormTypeTable,
+    MNN::BinaryOpTypeTable,
+    MNN::BlobTypeTable,
+    MNN::CastParamTypeTable,
+    MNN::Convolution2DTypeTable,
+    MNN::CropTypeTable,
+    MNN::CropAndResizeTypeTable,
+    MNN::DequantizeTypeTable,
+    MNN::DetectionOutputTypeTable,
+    MNN::EltwiseTypeTable,
+    MNN::ExpandDimsTypeTable,
+    MNN::FillTypeTable,
+    MNN::FlattenTypeTable,
+    MNN::GatherTypeTable,
+    MNN::GatherV2TypeTable,
+    MNN::InnerProductTypeTable,
+    MNN::InputTypeTable,
+    MNN::InterpTypeTable,
+    MNN::LRNTypeTable,
+    MNN::LSTMTypeTable,
+    MNN::MatMulTypeTable,
+    MNN::NonMaxSuppressionV2TypeTable,
+    MNN::NormalizeTypeTable,
+    MNN::PackParamTypeTable,
+    MNN::PermuteTypeTable,
+    MNN::PluginTypeTable,
+    MNN::PoolTypeTable,
+    MNN::PReluTypeTable,
+    MNN::PriorBoxTypeTable,
+    MNN::ProposalTypeTable,
+    MNN::QuantizedAvgPoolTypeTable,
+    MNN::QuantizedBiasAddTypeTable,
+    MNN::QuantizedConcatTypeTable,
+    MNN::QuantizedLogisticTypeTable,
+    MNN::QuantizedMatMulTypeTable,
+    MNN::QuantizedMaxPoolTypeTable,
+    MNN::QuantizedReluTypeTable,
+    MNN::QuantizedRelu6TypeTable,
+    MNN::QuantizedReshapeTypeTable,
+    MNN::QuantizedSoftmaxTypeTable,
+    MNN::QuantizeMaxMinTypeTable,
+    MNN::QuantizeV2TypeTable,
+    MNN::RangeTypeTable,
+    MNN::RankTypeTable,
+    MNN::ReduceJoinTypeTable,
+    MNN::ReductionParamTypeTable,
+    MNN::ReluTypeTable,
+    MNN::Relu6TypeTable,
+    MNN::RequantizationRangeTypeTable,
+    MNN::RequantizeTypeTable,
+    MNN::ReshapeTypeTable,
+    MNN::ResizeTypeTable,
+    MNN::RoiPoolingTypeTable,
+    MNN::ScaleTypeTable,
+    MNN::SeluTypeTable,
+    MNN::SizeTypeTable,
+    MNN::SliceTypeTable,
+    MNN::SliceTfTypeTable,
+    MNN::SpaceBatchTypeTable,
+    MNN::SqueezeParamTypeTable,
+    MNN::StridedSliceParamTypeTable,
+    MNN::TensorConvertInfoTypeTable,
+    MNN::TfQuantizedConv2DTypeTable,
+    MNN::TopKV2TypeTable,
+    MNN::TransposeTypeTable,
+    MNN::UnaryOpTypeTable,
+    MNN::MomentsParamTypeTable,
+    MNN::RNNParamTypeTable,
+    MNN::BatchMatMulParamTypeTable,
+    MNN::QuantizedFloatParamTypeTable,
+    MNN::DepthSpaceParamTypeTable,
+    MNN::EltwiseInt8TypeTable,
+    MNN::ReverseSequenceParamTypeTable,
+    MNN::ExtraTypeTable,
+    MNN::Pool3DTypeTable,
+    MNN::Convolution3DTypeTable,
+    MNN::ELUTypeTable,
+    MNN::DetectionPostProcessParamTypeTable,
+    MNN::OneHotParamTypeTable,
+    MNN::PadParamTypeTable,
+    MNN::WhileParamTypeTable,
+    MNN::IfParamTypeTable,
+    MNN::RandomUniformTypeTable,
+    MNN::LayerNormTypeTable
   };
   static const char * const names[] = {
     "NONE",
@@ -7254,7 +7247,7 @@ inline const flatbuffers::TypeTable *OpParameterTypeTable() {
     "LayerNorm"
   };
   static const flatbuffers::TypeTable tt = {
-    flatbuffers::ST_UNION, 89, type_codes, type_refs, nullptr, names
+    flatbuffers::ST_UNION, 89, type_codes, type_refs, nullptr, nullptr, names
   };
   return &tt;
 }
@@ -7268,7 +7261,7 @@ inline const flatbuffers::TypeTable *ForwardTypeTypeTable() {
     { flatbuffers::ET_CHAR, 0, 0 }
   };
   static const flatbuffers::TypeFunction type_refs[] = {
-    ForwardTypeTypeTable
+    MNN::ForwardTypeTypeTable
   };
   static const char * const names[] = {
     "CPU",
@@ -7278,7 +7271,7 @@ inline const flatbuffers::TypeTable *ForwardTypeTypeTable() {
     "VULKAN"
   };
   static const flatbuffers::TypeTable tt = {
-    flatbuffers::ST_ENUM, 5, type_codes, type_refs, nullptr, names
+    flatbuffers::ST_ENUM, 5, type_codes, type_refs, nullptr, nullptr, names
   };
   return &tt;
 }
@@ -7290,7 +7283,7 @@ inline const flatbuffers::TypeTable *UsageTypeTable() {
     { flatbuffers::ET_CHAR, 0, 0 }
   };
   static const flatbuffers::TypeFunction type_refs[] = {
-    UsageTypeTable
+    MNN::UsageTypeTable
   };
   static const char * const names[] = {
     "INFERENCE",
@@ -7298,7 +7291,7 @@ inline const flatbuffers::TypeTable *UsageTypeTable() {
     "INFERENCE_STATIC"
   };
   static const flatbuffers::TypeTable tt = {
-    flatbuffers::ST_ENUM, 3, type_codes, type_refs, nullptr, names
+    flatbuffers::ST_ENUM, 3, type_codes, type_refs, nullptr, nullptr, names
   };
   return &tt;
 }
@@ -7309,14 +7302,14 @@ inline const flatbuffers::TypeTable *PluginTypeTable() {
     { flatbuffers::ET_SEQUENCE, 1, 0 }
   };
   static const flatbuffers::TypeFunction type_refs[] = {
-    AttributeTypeTable
+    MNN::AttributeTypeTable
   };
   static const char * const names[] = {
     "type",
     "attr"
   };
   static const flatbuffers::TypeTable tt = {
-    flatbuffers::ST_TABLE, 2, type_codes, type_refs, nullptr, names
+    flatbuffers::ST_TABLE, 2, type_codes, type_refs, nullptr, nullptr, names
   };
   return &tt;
 }
@@ -7329,7 +7322,7 @@ inline const flatbuffers::TypeTable *ExtraTypeTable() {
     { flatbuffers::ET_SEQUENCE, 1, 0 }
   };
   static const flatbuffers::TypeFunction type_refs[] = {
-    AttributeTypeTable
+    MNN::AttributeTypeTable
   };
   static const char * const names[] = {
     "type",
@@ -7338,7 +7331,7 @@ inline const flatbuffers::TypeTable *ExtraTypeTable() {
     "attr"
   };
   static const flatbuffers::TypeTable tt = {
-    flatbuffers::ST_TABLE, 4, type_codes, type_refs, nullptr, names
+    flatbuffers::ST_TABLE, 4, type_codes, type_refs, nullptr, nullptr, names
   };
   return &tt;
 }
@@ -7351,7 +7344,7 @@ inline const flatbuffers::TypeTable *StringVecTypeTable() {
     "data"
   };
   static const flatbuffers::TypeTable tt = {
-    flatbuffers::ST_TABLE, 1, type_codes, nullptr, nullptr, names
+    flatbuffers::ST_TABLE, 1, type_codes, nullptr, nullptr, nullptr, names
   };
   return &tt;
 }
@@ -7365,7 +7358,7 @@ inline const flatbuffers::TypeTable *WhileParamTypeTable() {
     { flatbuffers::ET_SEQUENCE, 1, 0 }
   };
   static const flatbuffers::TypeFunction type_refs[] = {
-    StringVecTypeTable
+    MNN::StringVecTypeTable
   };
   static const char * const names[] = {
     "cond_graph",
@@ -7375,7 +7368,7 @@ inline const flatbuffers::TypeTable *WhileParamTypeTable() {
     "aliases_updates"
   };
   static const flatbuffers::TypeTable tt = {
-    flatbuffers::ST_TABLE, 5, type_codes, type_refs, nullptr, names
+    flatbuffers::ST_TABLE, 5, type_codes, type_refs, nullptr, nullptr, names
   };
   return &tt;
 }
@@ -7388,7 +7381,7 @@ inline const flatbuffers::TypeTable *IfParamTypeTable() {
     { flatbuffers::ET_SEQUENCE, 1, 0 }
   };
   static const flatbuffers::TypeFunction type_refs[] = {
-    StringVecTypeTable
+    MNN::StringVecTypeTable
   };
   static const char * const names[] = {
     "then_graph",
@@ -7397,7 +7390,7 @@ inline const flatbuffers::TypeTable *IfParamTypeTable() {
     "aliases_outputs"
   };
   static const flatbuffers::TypeTable tt = {
-    flatbuffers::ST_TABLE, 4, type_codes, type_refs, nullptr, names
+    flatbuffers::ST_TABLE, 4, type_codes, type_refs, nullptr, nullptr, names
   };
   return &tt;
 }
@@ -7413,9 +7406,9 @@ inline const flatbuffers::TypeTable *OpTypeTable() {
     { flatbuffers::ET_CHAR, 0, 2 }
   };
   static const flatbuffers::TypeFunction type_refs[] = {
-    OpParameterTypeTable,
-    OpTypeTypeTable,
-    MNN_DATA_FORMATTypeTable
+    MNN::OpParameterTypeTable,
+    MNN::OpTypeTypeTable,
+    MNN::MNN_DATA_FORMATTypeTable
   };
   static const char * const names[] = {
     "inputIndexes",
@@ -7427,7 +7420,7 @@ inline const flatbuffers::TypeTable *OpTypeTable() {
     "defaultDimentionFormat"
   };
   static const flatbuffers::TypeTable tt = {
-    flatbuffers::ST_TABLE, 7, type_codes, type_refs, nullptr, names
+    flatbuffers::ST_TABLE, 7, type_codes, type_refs, nullptr, nullptr, names
   };
   return &tt;
 }
@@ -7442,7 +7435,7 @@ inline const flatbuffers::TypeTable *ViewTypeTable() {
     "stride"
   };
   static const flatbuffers::TypeTable tt = {
-    flatbuffers::ST_TABLE, 2, type_codes, nullptr, nullptr, names
+    flatbuffers::ST_TABLE, 2, type_codes, nullptr, nullptr, nullptr, names
   };
   return &tt;
 }
@@ -7455,7 +7448,7 @@ inline const flatbuffers::TypeTable *RegionTypeTable() {
     { flatbuffers::ET_INT, 0, -1 }
   };
   static const flatbuffers::TypeFunction type_refs[] = {
-    ViewTypeTable
+    MNN::ViewTypeTable
   };
   static const char * const names[] = {
     "src",
@@ -7464,7 +7457,7 @@ inline const flatbuffers::TypeTable *RegionTypeTable() {
     "origin"
   };
   static const flatbuffers::TypeTable tt = {
-    flatbuffers::ST_TABLE, 4, type_codes, type_refs, nullptr, names
+    flatbuffers::ST_TABLE, 4, type_codes, type_refs, nullptr, nullptr, names
   };
   return &tt;
 }
@@ -7477,8 +7470,8 @@ inline const flatbuffers::TypeTable *TensorDescribeTypeTable() {
     { flatbuffers::ET_SEQUENCE, 1, 1 }
   };
   static const flatbuffers::TypeFunction type_refs[] = {
-    BlobTypeTable,
-    RegionTypeTable
+    MNN::BlobTypeTable,
+    MNN::RegionTypeTable
   };
   static const char * const names[] = {
     "blob",
@@ -7487,7 +7480,7 @@ inline const flatbuffers::TypeTable *TensorDescribeTypeTable() {
     "regions"
   };
   static const flatbuffers::TypeTable tt = {
-    flatbuffers::ST_TABLE, 4, type_codes, type_refs, nullptr, names
+    flatbuffers::ST_TABLE, 4, type_codes, type_refs, nullptr, nullptr, names
   };
   return &tt;
 }
@@ -7501,7 +7494,7 @@ inline const flatbuffers::TypeTable *SubGraphProtoTypeTable() {
     { flatbuffers::ET_SEQUENCE, 1, 0 }
   };
   static const flatbuffers::TypeFunction type_refs[] = {
-    OpTypeTable
+    MNN::OpTypeTable
   };
   static const char * const names[] = {
     "name",
@@ -7511,7 +7504,7 @@ inline const flatbuffers::TypeTable *SubGraphProtoTypeTable() {
     "nodes"
   };
   static const flatbuffers::TypeTable tt = {
-    flatbuffers::ST_TABLE, 5, type_codes, type_refs, nullptr, names
+    flatbuffers::ST_TABLE, 5, type_codes, type_refs, nullptr, nullptr, names
   };
   return &tt;
 }
@@ -7531,13 +7524,13 @@ inline const flatbuffers::TypeTable *NetTypeTable() {
     { flatbuffers::ET_SEQUENCE, 1, 6 }
   };
   static const flatbuffers::TypeFunction type_refs[] = {
-    TensorDescribeTypeTable,
-    GpuLibraryTypeTable,
-    OpTypeTable,
-    ForwardTypeTypeTable,
-    NetSourceTypeTable,
-    UsageTypeTable,
-    SubGraphProtoTypeTable
+    MNN::TensorDescribeTypeTable,
+    MNN::GpuLibraryTypeTable,
+    MNN::OpTypeTable,
+    MNN::ForwardTypeTypeTable,
+    MNN::NetSourceTypeTable,
+    MNN::UsageTypeTable,
+    MNN::SubGraphProtoTypeTable
   };
   static const char * const names[] = {
     "bizCode",
@@ -7553,7 +7546,7 @@ inline const flatbuffers::TypeTable *NetTypeTable() {
     "subgraphs"
   };
   static const flatbuffers::TypeTable tt = {
-    flatbuffers::ST_TABLE, 11, type_codes, type_refs, nullptr, names
+    flatbuffers::ST_TABLE, 11, type_codes, type_refs, nullptr, nullptr, names
   };
   return &tt;
 }
@@ -7588,10 +7581,16 @@ inline void FinishSizePrefixedNetBuffer(
   fbb.FinishSizePrefixed(root);
 }
 
-inline std::unique_ptr<NetT> UnPackNet(
+inline std::unique_ptr<MNN::NetT> UnPackNet(
+    const void *buf,
+    const flatbuffers::resolver_function_t *res = nullptr) {
+  return std::unique_ptr<MNN::NetT>(GetNet(buf)->UnPack(res));
+}
+
+inline std::unique_ptr<MNN::NetT> UnPackSizePrefixedNet(
     const void *buf,
     const flatbuffers::resolver_function_t *res = nullptr) {
-  return std::unique_ptr<NetT>(GetNet(buf)->UnPack(res));
+  return std::unique_ptr<MNN::NetT>(GetSizePrefixedNet(buf)->UnPack(res));
 }
 
 }  // namespace MNN
diff --git a/schema/current/TFQuantizeOp_generated.h b/schema/current/TFQuantizeOp_generated.h
index 18360b9c..34520b67 100644
--- a/schema/current/TFQuantizeOp_generated.h
+++ b/schema/current/TFQuantizeOp_generated.h
@@ -4,62 +4,80 @@
 #ifndef FLATBUFFERS_GENERATED_TFQUANTIZEOP_MNN_H_
 #define FLATBUFFERS_GENERATED_TFQUANTIZEOP_MNN_H_
 
+#include "flatbuffers/flatbuffers.h"
 
+#include "Type_generated.h"
 #include "CaffeOp_generated.h"
 #include "Tensor_generated.h"
-#include "Type_generated.h"
 
 namespace MNN {
 
 struct QuantizedParam;
+struct QuantizedParamBuilder;
 struct QuantizedParamT;
 
 struct QuantizedAdd;
+struct QuantizedAddBuilder;
 struct QuantizedAddT;
 
 struct Dequantize;
+struct DequantizeBuilder;
 struct DequantizeT;
 
 struct QuantizedAvgPool;
+struct QuantizedAvgPoolBuilder;
 struct QuantizedAvgPoolT;
 
 struct QuantizedBiasAdd;
+struct QuantizedBiasAddBuilder;
 struct QuantizedBiasAddT;
 
 struct QuantizedConcat;
+struct QuantizedConcatBuilder;
 struct QuantizedConcatT;
 
 struct QuantizedLogistic;
+struct QuantizedLogisticBuilder;
 struct QuantizedLogisticT;
 
 struct QuantizedMatMul;
+struct QuantizedMatMulBuilder;
 struct QuantizedMatMulT;
 
 struct QuantizedMaxPool;
+struct QuantizedMaxPoolBuilder;
 struct QuantizedMaxPoolT;
 
 struct QuantizedRelu;
+struct QuantizedReluBuilder;
 struct QuantizedReluT;
 
 struct QuantizedRelu6;
+struct QuantizedRelu6Builder;
 struct QuantizedRelu6T;
 
 struct QuantizedReshape;
+struct QuantizedReshapeBuilder;
 struct QuantizedReshapeT;
 
 struct QuantizedSoftmax;
+struct QuantizedSoftmaxBuilder;
 struct QuantizedSoftmaxT;
 
 struct QuantizeV2;
+struct QuantizeV2Builder;
 struct QuantizeV2T;
 
 struct RequantizationRange;
+struct RequantizationRangeBuilder;
 struct RequantizationRangeT;
 
 struct Requantize;
+struct RequantizeBuilder;
 struct RequantizeT;
 
 struct TfQuantizedConv2D;
+struct TfQuantizedConv2DBuilder;
 struct TfQuantizedConv2DT;
 
 inline const flatbuffers::TypeTable *QuantizedParamTypeTable();
@@ -96,7 +114,7 @@ inline const flatbuffers::TypeTable *RequantizeTypeTable();
 
 inline const flatbuffers::TypeTable *TfQuantizedConv2DTypeTable();
 
-enum FusedActivation {
+enum FusedActivation : int8_t {
   FusedActivation_kTfLiteActNone = 0,
   FusedActivation_kTfLiteActRelu = 1,
   FusedActivation_kTfLiteActRelu1 = 2,
@@ -122,7 +140,7 @@ inline const FusedActivation (&EnumValuesFusedActivation())[7] {
 }
 
 inline const char * const *EnumNamesFusedActivation() {
-  static const char * const names[] = {
+  static const char * const names[8] = {
     "kTfLiteActNone",
     "kTfLiteActRelu",
     "kTfLiteActRelu1",
@@ -136,12 +154,12 @@ inline const char * const *EnumNamesFusedActivation() {
 }
 
 inline const char *EnumNameFusedActivation(FusedActivation e) {
-  if (e < FusedActivation_kTfLiteActNone || e > FusedActivation_kTfLiteActSigmoid) return "";
-  const size_t index = static_cast<int>(e);
+  if (flatbuffers::IsOutRange(e, FusedActivation_kTfLiteActNone, FusedActivation_kTfLiteActSigmoid)) return "";
+  const size_t index = static_cast<size_t>(e);
   return EnumNamesFusedActivation()[index];
 }
 
-enum ModeFormat {
+enum ModeFormat : int8_t {
   ModeFormat_TENSORFLOW = 0,
   ModeFormat_TFLITE = 1,
   ModeFormat_MIN = ModeFormat_TENSORFLOW,
@@ -157,7 +175,7 @@ inline const ModeFormat (&EnumValuesModeFormat())[2] {
 }
 
 inline const char * const *EnumNamesModeFormat() {
-  static const char * const names[] = {
+  static const char * const names[3] = {
     "TENSORFLOW",
     "TFLITE",
     nullptr
@@ -166,12 +184,12 @@ inline const char * const *EnumNamesModeFormat() {
 }
 
 inline const char *EnumNameModeFormat(ModeFormat e) {
-  if (e < ModeFormat_TENSORFLOW || e > ModeFormat_TFLITE) return "";
-  const size_t index = static_cast<int>(e);
+  if (flatbuffers::IsOutRange(e, ModeFormat_TENSORFLOW, ModeFormat_TFLITE)) return "";
+  const size_t index = static_cast<size_t>(e);
   return EnumNamesModeFormat()[index];
 }
 
-enum QuantizeMode {
+enum QuantizeMode : int8_t {
   QuantizeMode_MIN_COMBINED = 0,
   QuantizeMode_MIN_FIRST = 1,
   QuantizeMode_SCALED = 2,
@@ -189,7 +207,7 @@ inline const QuantizeMode (&EnumValuesQuantizeMode())[3] {
 }
 
 inline const char * const *EnumNamesQuantizeMode() {
-  static const char * const names[] = {
+  static const char * const names[4] = {
     "MIN_COMBINED",
     "MIN_FIRST",
     "SCALED",
@@ -199,12 +217,12 @@ inline const char * const *EnumNamesQuantizeMode() {
 }
 
 inline const char *EnumNameQuantizeMode(QuantizeMode e) {
-  if (e < QuantizeMode_MIN_COMBINED || e > QuantizeMode_SCALED) return "";
-  const size_t index = static_cast<int>(e);
+  if (flatbuffers::IsOutRange(e, QuantizeMode_MIN_COMBINED, QuantizeMode_SCALED)) return "";
+  const size_t index = static_cast<size_t>(e);
   return EnumNamesQuantizeMode()[index];
 }
 
-enum QuantizeRoundMode {
+enum QuantizeRoundMode : int8_t {
   QuantizeRoundMode_HALF_AWAY_FROM_ZERO = 0,
   QuantizeRoundMode_HALF_TO_EVEN = 1,
   QuantizeRoundMode_MIN = QuantizeRoundMode_HALF_AWAY_FROM_ZERO,
@@ -220,7 +238,7 @@ inline const QuantizeRoundMode (&EnumValuesQuantizeRoundMode())[2] {
 }
 
 inline const char * const *EnumNamesQuantizeRoundMode() {
-  static const char * const names[] = {
+  static const char * const names[3] = {
     "HALF_AWAY_FROM_ZERO",
     "HALF_TO_EVEN",
     nullptr
@@ -229,23 +247,20 @@ inline const char * const *EnumNamesQuantizeRoundMode() {
 }
 
 inline const char *EnumNameQuantizeRoundMode(QuantizeRoundMode e) {
-  if (e < QuantizeRoundMode_HALF_AWAY_FROM_ZERO || e > QuantizeRoundMode_HALF_TO_EVEN) return "";
-  const size_t index = static_cast<int>(e);
+  if (flatbuffers::IsOutRange(e, QuantizeRoundMode_HALF_AWAY_FROM_ZERO, QuantizeRoundMode_HALF_TO_EVEN)) return "";
+  const size_t index = static_cast<size_t>(e);
   return EnumNamesQuantizeRoundMode()[index];
 }
 
 struct QuantizedParamT : public flatbuffers::NativeTable {
   typedef QuantizedParam TableType;
-  int32_t zeroPoint;
-  float scale;
-  QuantizedParamT()
-      : zeroPoint(0),
-        scale(0.0f) {
-  }
+  int32_t zeroPoint = 0;
+  float scale = 0.0f;
 };
 
 struct QuantizedParam FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
   typedef QuantizedParamT NativeTableType;
+  typedef QuantizedParamBuilder Builder;
   static const flatbuffers::TypeTable *MiniReflectTypeTable() {
     return QuantizedParamTypeTable();
   }
@@ -271,6 +286,7 @@ struct QuantizedParam FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
 };
 
 struct QuantizedParamBuilder {
+  typedef QuantizedParam Table;
   flatbuffers::FlatBufferBuilder &fbb_;
   flatbuffers::uoffset_t start_;
   void add_zeroPoint(int32_t zeroPoint) {
@@ -283,7 +299,6 @@ struct QuantizedParamBuilder {
         : fbb_(_fbb) {
     start_ = fbb_.StartTable();
   }
-  QuantizedParamBuilder &operator=(const QuantizedParamBuilder &);
   flatbuffers::Offset<QuantizedParam> Finish() {
     const auto end = fbb_.EndTable(start_);
     auto o = flatbuffers::Offset<QuantizedParam>(end);
@@ -305,17 +320,15 @@ flatbuffers::Offset<QuantizedParam> CreateQuantizedParam(flatbuffers::FlatBuffer
 
 struct QuantizedAddT : public flatbuffers::NativeTable {
   typedef QuantizedAdd TableType;
-  FusedActivation activationType;
-  std::unique_ptr<QuantizedParamT> input1QuantizedParam;
-  std::unique_ptr<QuantizedParamT> input2QuantizedParam;
-  std::unique_ptr<QuantizedParamT> outputQuantizedParam;
-  QuantizedAddT()
-      : activationType(FusedActivation_kTfLiteActNone) {
-  }
+  MNN::FusedActivation activationType = MNN::FusedActivation_kTfLiteActNone;
+  std::unique_ptr<MNN::QuantizedParamT> input1QuantizedParam{};
+  std::unique_ptr<MNN::QuantizedParamT> input2QuantizedParam{};
+  std::unique_ptr<MNN::QuantizedParamT> outputQuantizedParam{};
 };
 
 struct QuantizedAdd FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
   typedef QuantizedAddT NativeTableType;
+  typedef QuantizedAddBuilder Builder;
   static const flatbuffers::TypeTable *MiniReflectTypeTable() {
     return QuantizedAddTypeTable();
   }
@@ -325,17 +338,17 @@ struct QuantizedAdd FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
     VT_INPUT2QUANTIZEDPARAM = 8,
     VT_OUTPUTQUANTIZEDPARAM = 10
   };
-  FusedActivation activationType() const {
-    return static_cast<FusedActivation>(GetField<int8_t>(VT_ACTIVATIONTYPE, 0));
+  MNN::FusedActivation activationType() const {
+    return static_cast<MNN::FusedActivation>(GetField<int8_t>(VT_ACTIVATIONTYPE, 0));
   }
-  const QuantizedParam *input1QuantizedParam() const {
-    return GetPointer<const QuantizedParam *>(VT_INPUT1QUANTIZEDPARAM);
+  const MNN::QuantizedParam *input1QuantizedParam() const {
+    return GetPointer<const MNN::QuantizedParam *>(VT_INPUT1QUANTIZEDPARAM);
   }
-  const QuantizedParam *input2QuantizedParam() const {
-    return GetPointer<const QuantizedParam *>(VT_INPUT2QUANTIZEDPARAM);
+  const MNN::QuantizedParam *input2QuantizedParam() const {
+    return GetPointer<const MNN::QuantizedParam *>(VT_INPUT2QUANTIZEDPARAM);
   }
-  const QuantizedParam *outputQuantizedParam() const {
-    return GetPointer<const QuantizedParam *>(VT_OUTPUTQUANTIZEDPARAM);
+  const MNN::QuantizedParam *outputQuantizedParam() const {
+    return GetPointer<const MNN::QuantizedParam *>(VT_OUTPUTQUANTIZEDPARAM);
   }
   bool Verify(flatbuffers::Verifier &verifier) const {
     return VerifyTableStart(verifier) &&
@@ -354,25 +367,25 @@ struct QuantizedAdd FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
 };
 
 struct QuantizedAddBuilder {
+  typedef QuantizedAdd Table;
   flatbuffers::FlatBufferBuilder &fbb_;
   flatbuffers::uoffset_t start_;
-  void add_activationType(FusedActivation activationType) {
+  void add_activationType(MNN::FusedActivation activationType) {
     fbb_.AddElement<int8_t>(QuantizedAdd::VT_ACTIVATIONTYPE, static_cast<int8_t>(activationType), 0);
   }
-  void add_input1QuantizedParam(flatbuffers::Offset<QuantizedParam> input1QuantizedParam) {
+  void add_input1QuantizedParam(flatbuffers::Offset<MNN::QuantizedParam> input1QuantizedParam) {
     fbb_.AddOffset(QuantizedAdd::VT_INPUT1QUANTIZEDPARAM, input1QuantizedParam);
   }
-  void add_input2QuantizedParam(flatbuffers::Offset<QuantizedParam> input2QuantizedParam) {
+  void add_input2QuantizedParam(flatbuffers::Offset<MNN::QuantizedParam> input2QuantizedParam) {
     fbb_.AddOffset(QuantizedAdd::VT_INPUT2QUANTIZEDPARAM, input2QuantizedParam);
   }
-  void add_outputQuantizedParam(flatbuffers::Offset<QuantizedParam> outputQuantizedParam) {
+  void add_outputQuantizedParam(flatbuffers::Offset<MNN::QuantizedParam> outputQuantizedParam) {
     fbb_.AddOffset(QuantizedAdd::VT_OUTPUTQUANTIZEDPARAM, outputQuantizedParam);
   }
   explicit QuantizedAddBuilder(flatbuffers::FlatBufferBuilder &_fbb)
         : fbb_(_fbb) {
     start_ = fbb_.StartTable();
   }
-  QuantizedAddBuilder &operator=(const QuantizedAddBuilder &);
   flatbuffers::Offset<QuantizedAdd> Finish() {
     const auto end = fbb_.EndTable(start_);
     auto o = flatbuffers::Offset<QuantizedAdd>(end);
@@ -382,10 +395,10 @@ struct QuantizedAddBuilder {
 
 inline flatbuffers::Offset<QuantizedAdd> CreateQuantizedAdd(
     flatbuffers::FlatBufferBuilder &_fbb,
-    FusedActivation activationType = FusedActivation_kTfLiteActNone,
-    flatbuffers::Offset<QuantizedParam> input1QuantizedParam = 0,
-    flatbuffers::Offset<QuantizedParam> input2QuantizedParam = 0,
-    flatbuffers::Offset<QuantizedParam> outputQuantizedParam = 0) {
+    MNN::FusedActivation activationType = MNN::FusedActivation_kTfLiteActNone,
+    flatbuffers::Offset<MNN::QuantizedParam> input1QuantizedParam = 0,
+    flatbuffers::Offset<MNN::QuantizedParam> input2QuantizedParam = 0,
+    flatbuffers::Offset<MNN::QuantizedParam> outputQuantizedParam = 0) {
   QuantizedAddBuilder builder_(_fbb);
   builder_.add_outputQuantizedParam(outputQuantizedParam);
   builder_.add_input2QuantizedParam(input2QuantizedParam);
@@ -398,19 +411,15 @@ flatbuffers::Offset<QuantizedAdd> CreateQuantizedAdd(flatbuffers::FlatBufferBuil
 
 struct DequantizeT : public flatbuffers::NativeTable {
   typedef Dequantize TableType;
-  std::unique_ptr<QuantizedParamT> inputQuantizedParam;
-  QuantizeMode mode;
-  ModeFormat modelFormat;
-  DataType type;
-  DequantizeT()
-      : mode(QuantizeMode_MIN_COMBINED),
-        modelFormat(ModeFormat_TENSORFLOW),
-        type(DataType_DT_INVALID) {
-  }
+  std::unique_ptr<MNN::QuantizedParamT> inputQuantizedParam{};
+  MNN::QuantizeMode mode = MNN::QuantizeMode_MIN_COMBINED;
+  MNN::ModeFormat modelFormat = MNN::ModeFormat_TENSORFLOW;
+  MNN::DataType type = MNN::DataType_DT_INVALID;
 };
 
 struct Dequantize FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
   typedef DequantizeT NativeTableType;
+  typedef DequantizeBuilder Builder;
   static const flatbuffers::TypeTable *MiniReflectTypeTable() {
     return DequantizeTypeTable();
   }
@@ -420,17 +429,17 @@ struct Dequantize FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
     VT_MODELFORMAT = 8,
     VT_TYPE = 10
   };
-  const QuantizedParam *inputQuantizedParam() const {
-    return GetPointer<const QuantizedParam *>(VT_INPUTQUANTIZEDPARAM);
+  const MNN::QuantizedParam *inputQuantizedParam() const {
+    return GetPointer<const MNN::QuantizedParam *>(VT_INPUTQUANTIZEDPARAM);
   }
-  QuantizeMode mode() const {
-    return static_cast<QuantizeMode>(GetField<int8_t>(VT_MODE, 0));
+  MNN::QuantizeMode mode() const {
+    return static_cast<MNN::QuantizeMode>(GetField<int8_t>(VT_MODE, 0));
   }
-  ModeFormat modelFormat() const {
-    return static_cast<ModeFormat>(GetField<int8_t>(VT_MODELFORMAT, 0));
+  MNN::ModeFormat modelFormat() const {
+    return static_cast<MNN::ModeFormat>(GetField<int8_t>(VT_MODELFORMAT, 0));
   }
-  DataType type() const {
-    return static_cast<DataType>(GetField<int32_t>(VT_TYPE, 0));
+  MNN::DataType type() const {
+    return static_cast<MNN::DataType>(GetField<int32_t>(VT_TYPE, 0));
   }
   bool Verify(flatbuffers::Verifier &verifier) const {
     return VerifyTableStart(verifier) &&
@@ -447,25 +456,25 @@ struct Dequantize FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
 };
 
 struct DequantizeBuilder {
+  typedef Dequantize Table;
   flatbuffers::FlatBufferBuilder &fbb_;
   flatbuffers::uoffset_t start_;
-  void add_inputQuantizedParam(flatbuffers::Offset<QuantizedParam> inputQuantizedParam) {
+  void add_inputQuantizedParam(flatbuffers::Offset<MNN::QuantizedParam> inputQuantizedParam) {
     fbb_.AddOffset(Dequantize::VT_INPUTQUANTIZEDPARAM, inputQuantizedParam);
   }
-  void add_mode(QuantizeMode mode) {
+  void add_mode(MNN::QuantizeMode mode) {
     fbb_.AddElement<int8_t>(Dequantize::VT_MODE, static_cast<int8_t>(mode), 0);
   }
-  void add_modelFormat(ModeFormat modelFormat) {
+  void add_modelFormat(MNN::ModeFormat modelFormat) {
     fbb_.AddElement<int8_t>(Dequantize::VT_MODELFORMAT, static_cast<int8_t>(modelFormat), 0);
   }
-  void add_type(DataType type) {
+  void add_type(MNN::DataType type) {
     fbb_.AddElement<int32_t>(Dequantize::VT_TYPE, static_cast<int32_t>(type), 0);
   }
   explicit DequantizeBuilder(flatbuffers::FlatBufferBuilder &_fbb)
         : fbb_(_fbb) {
     start_ = fbb_.StartTable();
   }
-  DequantizeBuilder &operator=(const DequantizeBuilder &);
   flatbuffers::Offset<Dequantize> Finish() {
     const auto end = fbb_.EndTable(start_);
     auto o = flatbuffers::Offset<Dequantize>(end);
@@ -475,10 +484,10 @@ struct DequantizeBuilder {
 
 inline flatbuffers::Offset<Dequantize> CreateDequantize(
     flatbuffers::FlatBufferBuilder &_fbb,
-    flatbuffers::Offset<QuantizedParam> inputQuantizedParam = 0,
-    QuantizeMode mode = QuantizeMode_MIN_COMBINED,
-    ModeFormat modelFormat = ModeFormat_TENSORFLOW,
-    DataType type = DataType_DT_INVALID) {
+    flatbuffers::Offset<MNN::QuantizedParam> inputQuantizedParam = 0,
+    MNN::QuantizeMode mode = MNN::QuantizeMode_MIN_COMBINED,
+    MNN::ModeFormat modelFormat = MNN::ModeFormat_TENSORFLOW,
+    MNN::DataType type = MNN::DataType_DT_INVALID) {
   DequantizeBuilder builder_(_fbb);
   builder_.add_type(type);
   builder_.add_inputQuantizedParam(inputQuantizedParam);
@@ -491,34 +500,22 @@ flatbuffers::Offset<Dequantize> CreateDequantize(flatbuffers::FlatBufferBuilder
 
 struct QuantizedAvgPoolT : public flatbuffers::NativeTable {
   typedef QuantizedAvgPool TableType;
-  int32_t kernelX;
-  int32_t kernelY;
-  ModeFormat modelFormat;
-  int32_t outputActivationMax;
-  int32_t outputActivationMin;
-  PoolPadType padType;
-  int32_t padX;
-  int32_t padY;
-  int32_t strideX;
-  int32_t strideY;
-  DataType type;
-  QuantizedAvgPoolT()
-      : kernelX(0),
-        kernelY(0),
-        modelFormat(ModeFormat_TENSORFLOW),
-        outputActivationMax(0),
-        outputActivationMin(0),
-        padType(PoolPadType_CAFFE),
-        padX(0),
-        padY(0),
-        strideX(0),
-        strideY(0),
-        type(DataType_DT_INVALID) {
-  }
+  int32_t kernelX = 0;
+  int32_t kernelY = 0;
+  MNN::ModeFormat modelFormat = MNN::ModeFormat_TENSORFLOW;
+  int32_t outputActivationMax = 0;
+  int32_t outputActivationMin = 0;
+  MNN::PoolPadType padType = MNN::PoolPadType_CAFFE;
+  int32_t padX = 0;
+  int32_t padY = 0;
+  int32_t strideX = 0;
+  int32_t strideY = 0;
+  MNN::DataType type = MNN::DataType_DT_INVALID;
 };
 
 struct QuantizedAvgPool FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
   typedef QuantizedAvgPoolT NativeTableType;
+  typedef QuantizedAvgPoolBuilder Builder;
   static const flatbuffers::TypeTable *MiniReflectTypeTable() {
     return QuantizedAvgPoolTypeTable();
   }
@@ -541,8 +538,8 @@ struct QuantizedAvgPool FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
   int32_t kernelY() const {
     return GetField<int32_t>(VT_KERNELY, 0);
   }
-  ModeFormat modelFormat() const {
-    return static_cast<ModeFormat>(GetField<int8_t>(VT_MODELFORMAT, 0));
+  MNN::ModeFormat modelFormat() const {
+    return static_cast<MNN::ModeFormat>(GetField<int8_t>(VT_MODELFORMAT, 0));
   }
   int32_t outputActivationMax() const {
     return GetField<int32_t>(VT_OUTPUTACTIVATIONMAX, 0);
@@ -550,8 +547,8 @@ struct QuantizedAvgPool FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
   int32_t outputActivationMin() const {
     return GetField<int32_t>(VT_OUTPUTACTIVATIONMIN, 0);
   }
-  PoolPadType padType() const {
-    return static_cast<PoolPadType>(GetField<int8_t>(VT_PADTYPE, 0));
+  MNN::PoolPadType padType() const {
+    return static_cast<MNN::PoolPadType>(GetField<int8_t>(VT_PADTYPE, 0));
   }
   int32_t padX() const {
     return GetField<int32_t>(VT_PADX, 0);
@@ -565,8 +562,8 @@ struct QuantizedAvgPool FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
   int32_t strideY() const {
     return GetField<int32_t>(VT_STRIDEY, 0);
   }
-  DataType type() const {
-    return static_cast<DataType>(GetField<int32_t>(VT_TYPE, 0));
+  MNN::DataType type() const {
+    return static_cast<MNN::DataType>(GetField<int32_t>(VT_TYPE, 0));
   }
   bool Verify(flatbuffers::Verifier &verifier) const {
     return VerifyTableStart(verifier) &&
@@ -589,6 +586,7 @@ struct QuantizedAvgPool FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
 };
 
 struct QuantizedAvgPoolBuilder {
+  typedef QuantizedAvgPool Table;
   flatbuffers::FlatBufferBuilder &fbb_;
   flatbuffers::uoffset_t start_;
   void add_kernelX(int32_t kernelX) {
@@ -597,7 +595,7 @@ struct QuantizedAvgPoolBuilder {
   void add_kernelY(int32_t kernelY) {
     fbb_.AddElement<int32_t>(QuantizedAvgPool::VT_KERNELY, kernelY, 0);
   }
-  void add_modelFormat(ModeFormat modelFormat) {
+  void add_modelFormat(MNN::ModeFormat modelFormat) {
     fbb_.AddElement<int8_t>(QuantizedAvgPool::VT_MODELFORMAT, static_cast<int8_t>(modelFormat), 0);
   }
   void add_outputActivationMax(int32_t outputActivationMax) {
@@ -606,7 +604,7 @@ struct QuantizedAvgPoolBuilder {
   void add_outputActivationMin(int32_t outputActivationMin) {
     fbb_.AddElement<int32_t>(QuantizedAvgPool::VT_OUTPUTACTIVATIONMIN, outputActivationMin, 0);
   }
-  void add_padType(PoolPadType padType) {
+  void add_padType(MNN::PoolPadType padType) {
     fbb_.AddElement<int8_t>(QuantizedAvgPool::VT_PADTYPE, static_cast<int8_t>(padType), 0);
   }
   void add_padX(int32_t padX) {
@@ -621,14 +619,13 @@ struct QuantizedAvgPoolBuilder {
   void add_strideY(int32_t strideY) {
     fbb_.AddElement<int32_t>(QuantizedAvgPool::VT_STRIDEY, strideY, 0);
   }
-  void add_type(DataType type) {
+  void add_type(MNN::DataType type) {
     fbb_.AddElement<int32_t>(QuantizedAvgPool::VT_TYPE, static_cast<int32_t>(type), 0);
   }
   explicit QuantizedAvgPoolBuilder(flatbuffers::FlatBufferBuilder &_fbb)
         : fbb_(_fbb) {
     start_ = fbb_.StartTable();
   }
-  QuantizedAvgPoolBuilder &operator=(const QuantizedAvgPoolBuilder &);
   flatbuffers::Offset<QuantizedAvgPool> Finish() {
     const auto end = fbb_.EndTable(start_);
     auto o = flatbuffers::Offset<QuantizedAvgPool>(end);
@@ -640,15 +637,15 @@ inline flatbuffers::Offset<QuantizedAvgPool> CreateQuantizedAvgPool(
     flatbuffers::FlatBufferBuilder &_fbb,
     int32_t kernelX = 0,
     int32_t kernelY = 0,
-    ModeFormat modelFormat = ModeFormat_TENSORFLOW,
+    MNN::ModeFormat modelFormat = MNN::ModeFormat_TENSORFLOW,
     int32_t outputActivationMax = 0,
     int32_t outputActivationMin = 0,
-    PoolPadType padType = PoolPadType_CAFFE,
+    MNN::PoolPadType padType = MNN::PoolPadType_CAFFE,
     int32_t padX = 0,
     int32_t padY = 0,
     int32_t strideX = 0,
     int32_t strideY = 0,
-    DataType type = DataType_DT_INVALID) {
+    MNN::DataType type = MNN::DataType_DT_INVALID) {
   QuantizedAvgPoolBuilder builder_(_fbb);
   builder_.add_type(type);
   builder_.add_strideY(strideY);
@@ -668,21 +665,16 @@ flatbuffers::Offset<QuantizedAvgPool> CreateQuantizedAvgPool(flatbuffers::FlatBu
 
 struct QuantizedBiasAddT : public flatbuffers::NativeTable {
   typedef QuantizedBiasAdd TableType;
-  std::vector<int32_t> bias;
-  DataType inputType;
-  int32_t max;
-  int32_t min;
-  DataType outputType;
-  QuantizedBiasAddT()
-      : inputType(DataType_DT_INVALID),
-        max(0),
-        min(0),
-        outputType(DataType_DT_INVALID) {
-  }
+  std::vector<int32_t> bias{};
+  MNN::DataType inputType = MNN::DataType_DT_INVALID;
+  int32_t max = 0;
+  int32_t min = 0;
+  MNN::DataType outputType = MNN::DataType_DT_INVALID;
 };
 
 struct QuantizedBiasAdd FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
   typedef QuantizedBiasAddT NativeTableType;
+  typedef QuantizedBiasAddBuilder Builder;
   static const flatbuffers::TypeTable *MiniReflectTypeTable() {
     return QuantizedBiasAddTypeTable();
   }
@@ -696,8 +688,8 @@ struct QuantizedBiasAdd FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
   const flatbuffers::Vector<int32_t> *bias() const {
     return GetPointer<const flatbuffers::Vector<int32_t> *>(VT_BIAS);
   }
-  DataType inputType() const {
-    return static_cast<DataType>(GetField<int32_t>(VT_INPUTTYPE, 0));
+  MNN::DataType inputType() const {
+    return static_cast<MNN::DataType>(GetField<int32_t>(VT_INPUTTYPE, 0));
   }
   int32_t max() const {
     return GetField<int32_t>(VT_MAX, 0);
@@ -705,8 +697,8 @@ struct QuantizedBiasAdd FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
   int32_t min() const {
     return GetField<int32_t>(VT_MIN, 0);
   }
-  DataType outputType() const {
-    return static_cast<DataType>(GetField<int32_t>(VT_OUTPUTTYPE, 0));
+  MNN::DataType outputType() const {
+    return static_cast<MNN::DataType>(GetField<int32_t>(VT_OUTPUTTYPE, 0));
   }
   bool Verify(flatbuffers::Verifier &verifier) const {
     return VerifyTableStart(verifier) &&
@@ -724,12 +716,13 @@ struct QuantizedBiasAdd FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
 };
 
 struct QuantizedBiasAddBuilder {
+  typedef QuantizedBiasAdd Table;
   flatbuffers::FlatBufferBuilder &fbb_;
   flatbuffers::uoffset_t start_;
   void add_bias(flatbuffers::Offset<flatbuffers::Vector<int32_t>> bias) {
     fbb_.AddOffset(QuantizedBiasAdd::VT_BIAS, bias);
   }
-  void add_inputType(DataType inputType) {
+  void add_inputType(MNN::DataType inputType) {
     fbb_.AddElement<int32_t>(QuantizedBiasAdd::VT_INPUTTYPE, static_cast<int32_t>(inputType), 0);
   }
   void add_max(int32_t max) {
@@ -738,14 +731,13 @@ struct QuantizedBiasAddBuilder {
   void add_min(int32_t min) {
     fbb_.AddElement<int32_t>(QuantizedBiasAdd::VT_MIN, min, 0);
   }
-  void add_outputType(DataType outputType) {
+  void add_outputType(MNN::DataType outputType) {
     fbb_.AddElement<int32_t>(QuantizedBiasAdd::VT_OUTPUTTYPE, static_cast<int32_t>(outputType), 0);
   }
   explicit QuantizedBiasAddBuilder(flatbuffers::FlatBufferBuilder &_fbb)
         : fbb_(_fbb) {
     start_ = fbb_.StartTable();
   }
-  QuantizedBiasAddBuilder &operator=(const QuantizedBiasAddBuilder &);
   flatbuffers::Offset<QuantizedBiasAdd> Finish() {
     const auto end = fbb_.EndTable(start_);
     auto o = flatbuffers::Offset<QuantizedBiasAdd>(end);
@@ -756,10 +748,10 @@ struct QuantizedBiasAddBuilder {
 inline flatbuffers::Offset<QuantizedBiasAdd> CreateQuantizedBiasAdd(
     flatbuffers::FlatBufferBuilder &_fbb,
     flatbuffers::Offset<flatbuffers::Vector<int32_t>> bias = 0,
-    DataType inputType = DataType_DT_INVALID,
+    MNN::DataType inputType = MNN::DataType_DT_INVALID,
     int32_t max = 0,
     int32_t min = 0,
-    DataType outputType = DataType_DT_INVALID) {
+    MNN::DataType outputType = MNN::DataType_DT_INVALID) {
   QuantizedBiasAddBuilder builder_(_fbb);
   builder_.add_outputType(outputType);
   builder_.add_min(min);
@@ -772,10 +764,10 @@ inline flatbuffers::Offset<QuantizedBiasAdd> CreateQuantizedBiasAdd(
 inline flatbuffers::Offset<QuantizedBiasAdd> CreateQuantizedBiasAddDirect(
     flatbuffers::FlatBufferBuilder &_fbb,
     const std::vector<int32_t> *bias = nullptr,
-    DataType inputType = DataType_DT_INVALID,
+    MNN::DataType inputType = MNN::DataType_DT_INVALID,
     int32_t max = 0,
     int32_t min = 0,
-    DataType outputType = DataType_DT_INVALID) {
+    MNN::DataType outputType = MNN::DataType_DT_INVALID) {
   auto bias__ = bias ? _fbb.CreateVector<int32_t>(*bias) : 0;
   return MNN::CreateQuantizedBiasAdd(
       _fbb,
@@ -790,19 +782,16 @@ flatbuffers::Offset<QuantizedBiasAdd> CreateQuantizedBiasAdd(flatbuffers::FlatBu
 
 struct QuantizedConcatT : public flatbuffers::NativeTable {
   typedef QuantizedConcat TableType;
-  FusedActivation activationType;
-  int32_t axis;
-  std::vector<float> inputScale;
-  std::vector<int32_t> inputZeroPoint;
-  std::unique_ptr<QuantizedParamT> outputQuantizedParam;
-  QuantizedConcatT()
-      : activationType(FusedActivation_kTfLiteActNone),
-        axis(0) {
-  }
+  MNN::FusedActivation activationType = MNN::FusedActivation_kTfLiteActNone;
+  int32_t axis = 0;
+  std::vector<float> inputScale{};
+  std::vector<int32_t> inputZeroPoint{};
+  std::unique_ptr<MNN::QuantizedParamT> outputQuantizedParam{};
 };
 
 struct QuantizedConcat FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
   typedef QuantizedConcatT NativeTableType;
+  typedef QuantizedConcatBuilder Builder;
   static const flatbuffers::TypeTable *MiniReflectTypeTable() {
     return QuantizedConcatTypeTable();
   }
@@ -813,8 +802,8 @@ struct QuantizedConcat FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
     VT_INPUTZEROPOINT = 10,
     VT_OUTPUTQUANTIZEDPARAM = 12
   };
-  FusedActivation activationType() const {
-    return static_cast<FusedActivation>(GetField<int8_t>(VT_ACTIVATIONTYPE, 0));
+  MNN::FusedActivation activationType() const {
+    return static_cast<MNN::FusedActivation>(GetField<int8_t>(VT_ACTIVATIONTYPE, 0));
   }
   int32_t axis() const {
     return GetField<int32_t>(VT_AXIS, 0);
@@ -825,8 +814,8 @@ struct QuantizedConcat FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
   const flatbuffers::Vector<int32_t> *inputZeroPoint() const {
     return GetPointer<const flatbuffers::Vector<int32_t> *>(VT_INPUTZEROPOINT);
   }
-  const QuantizedParam *outputQuantizedParam() const {
-    return GetPointer<const QuantizedParam *>(VT_OUTPUTQUANTIZEDPARAM);
+  const MNN::QuantizedParam *outputQuantizedParam() const {
+    return GetPointer<const MNN::QuantizedParam *>(VT_OUTPUTQUANTIZEDPARAM);
   }
   bool Verify(flatbuffers::Verifier &verifier) const {
     return VerifyTableStart(verifier) &&
@@ -846,9 +835,10 @@ struct QuantizedConcat FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
 };
 
 struct QuantizedConcatBuilder {
+  typedef QuantizedConcat Table;
   flatbuffers::FlatBufferBuilder &fbb_;
   flatbuffers::uoffset_t start_;
-  void add_activationType(FusedActivation activationType) {
+  void add_activationType(MNN::FusedActivation activationType) {
     fbb_.AddElement<int8_t>(QuantizedConcat::VT_ACTIVATIONTYPE, static_cast<int8_t>(activationType), 0);
   }
   void add_axis(int32_t axis) {
@@ -860,14 +850,13 @@ struct QuantizedConcatBuilder {
   void add_inputZeroPoint(flatbuffers::Offset<flatbuffers::Vector<int32_t>> inputZeroPoint) {
     fbb_.AddOffset(QuantizedConcat::VT_INPUTZEROPOINT, inputZeroPoint);
   }
-  void add_outputQuantizedParam(flatbuffers::Offset<QuantizedParam> outputQuantizedParam) {
+  void add_outputQuantizedParam(flatbuffers::Offset<MNN::QuantizedParam> outputQuantizedParam) {
     fbb_.AddOffset(QuantizedConcat::VT_OUTPUTQUANTIZEDPARAM, outputQuantizedParam);
   }
   explicit QuantizedConcatBuilder(flatbuffers::FlatBufferBuilder &_fbb)
         : fbb_(_fbb) {
     start_ = fbb_.StartTable();
   }
-  QuantizedConcatBuilder &operator=(const QuantizedConcatBuilder &);
   flatbuffers::Offset<QuantizedConcat> Finish() {
     const auto end = fbb_.EndTable(start_);
     auto o = flatbuffers::Offset<QuantizedConcat>(end);
@@ -877,11 +866,11 @@ struct QuantizedConcatBuilder {
 
 inline flatbuffers::Offset<QuantizedConcat> CreateQuantizedConcat(
     flatbuffers::FlatBufferBuilder &_fbb,
-    FusedActivation activationType = FusedActivation_kTfLiteActNone,
+    MNN::FusedActivation activationType = MNN::FusedActivation_kTfLiteActNone,
     int32_t axis = 0,
     flatbuffers::Offset<flatbuffers::Vector<float>> inputScale = 0,
     flatbuffers::Offset<flatbuffers::Vector<int32_t>> inputZeroPoint = 0,
-    flatbuffers::Offset<QuantizedParam> outputQuantizedParam = 0) {
+    flatbuffers::Offset<MNN::QuantizedParam> outputQuantizedParam = 0) {
   QuantizedConcatBuilder builder_(_fbb);
   builder_.add_outputQuantizedParam(outputQuantizedParam);
   builder_.add_inputZeroPoint(inputZeroPoint);
@@ -893,11 +882,11 @@ inline flatbuffers::Offset<QuantizedConcat> CreateQuantizedConcat(
 
 inline flatbuffers::Offset<QuantizedConcat> CreateQuantizedConcatDirect(
     flatbuffers::FlatBufferBuilder &_fbb,
-    FusedActivation activationType = FusedActivation_kTfLiteActNone,
+    MNN::FusedActivation activationType = MNN::FusedActivation_kTfLiteActNone,
     int32_t axis = 0,
     const std::vector<float> *inputScale = nullptr,
     const std::vector<int32_t> *inputZeroPoint = nullptr,
-    flatbuffers::Offset<QuantizedParam> outputQuantizedParam = 0) {
+    flatbuffers::Offset<MNN::QuantizedParam> outputQuantizedParam = 0) {
   auto inputScale__ = inputScale ? _fbb.CreateVector<float>(*inputScale) : 0;
   auto inputZeroPoint__ = inputZeroPoint ? _fbb.CreateVector<int32_t>(*inputZeroPoint) : 0;
   return MNN::CreateQuantizedConcat(
@@ -913,14 +902,13 @@ flatbuffers::Offset<QuantizedConcat> CreateQuantizedConcat(flatbuffers::FlatBuff
 
 struct QuantizedLogisticT : public flatbuffers::NativeTable {
   typedef QuantizedLogistic TableType;
-  std::unique_ptr<QuantizedParamT> inputQuantizedParam;
-  std::unique_ptr<QuantizedParamT> outputQuantizedParam;
-  QuantizedLogisticT() {
-  }
+  std::unique_ptr<MNN::QuantizedParamT> inputQuantizedParam{};
+  std::unique_ptr<MNN::QuantizedParamT> outputQuantizedParam{};
 };
 
 struct QuantizedLogistic FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
   typedef QuantizedLogisticT NativeTableType;
+  typedef QuantizedLogisticBuilder Builder;
   static const flatbuffers::TypeTable *MiniReflectTypeTable() {
     return QuantizedLogisticTypeTable();
   }
@@ -928,11 +916,11 @@ struct QuantizedLogistic FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
     VT_INPUTQUANTIZEDPARAM = 4,
     VT_OUTPUTQUANTIZEDPARAM = 6
   };
-  const QuantizedParam *inputQuantizedParam() const {
-    return GetPointer<const QuantizedParam *>(VT_INPUTQUANTIZEDPARAM);
+  const MNN::QuantizedParam *inputQuantizedParam() const {
+    return GetPointer<const MNN::QuantizedParam *>(VT_INPUTQUANTIZEDPARAM);
   }
-  const QuantizedParam *outputQuantizedParam() const {
-    return GetPointer<const QuantizedParam *>(VT_OUTPUTQUANTIZEDPARAM);
+  const MNN::QuantizedParam *outputQuantizedParam() const {
+    return GetPointer<const MNN::QuantizedParam *>(VT_OUTPUTQUANTIZEDPARAM);
   }
   bool Verify(flatbuffers::Verifier &verifier) const {
     return VerifyTableStart(verifier) &&
@@ -948,19 +936,19 @@ struct QuantizedLogistic FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
 };
 
 struct QuantizedLogisticBuilder {
+  typedef QuantizedLogistic Table;
   flatbuffers::FlatBufferBuilder &fbb_;
   flatbuffers::uoffset_t start_;
-  void add_inputQuantizedParam(flatbuffers::Offset<QuantizedParam> inputQuantizedParam) {
+  void add_inputQuantizedParam(flatbuffers::Offset<MNN::QuantizedParam> inputQuantizedParam) {
     fbb_.AddOffset(QuantizedLogistic::VT_INPUTQUANTIZEDPARAM, inputQuantizedParam);
   }
-  void add_outputQuantizedParam(flatbuffers::Offset<QuantizedParam> outputQuantizedParam) {
+  void add_outputQuantizedParam(flatbuffers::Offset<MNN::QuantizedParam> outputQuantizedParam) {
     fbb_.AddOffset(QuantizedLogistic::VT_OUTPUTQUANTIZEDPARAM, outputQuantizedParam);
   }
   explicit QuantizedLogisticBuilder(flatbuffers::FlatBufferBuilder &_fbb)
         : fbb_(_fbb) {
     start_ = fbb_.StartTable();
   }
-  QuantizedLogisticBuilder &operator=(const QuantizedLogisticBuilder &);
   flatbuffers::Offset<QuantizedLogistic> Finish() {
     const auto end = fbb_.EndTable(start_);
     auto o = flatbuffers::Offset<QuantizedLogistic>(end);
@@ -970,8 +958,8 @@ struct QuantizedLogisticBuilder {
 
 inline flatbuffers::Offset<QuantizedLogistic> CreateQuantizedLogistic(
     flatbuffers::FlatBufferBuilder &_fbb,
-    flatbuffers::Offset<QuantizedParam> inputQuantizedParam = 0,
-    flatbuffers::Offset<QuantizedParam> outputQuantizedParam = 0) {
+    flatbuffers::Offset<MNN::QuantizedParam> inputQuantizedParam = 0,
+    flatbuffers::Offset<MNN::QuantizedParam> outputQuantizedParam = 0) {
   QuantizedLogisticBuilder builder_(_fbb);
   builder_.add_outputQuantizedParam(outputQuantizedParam);
   builder_.add_inputQuantizedParam(inputQuantizedParam);
@@ -982,16 +970,13 @@ flatbuffers::Offset<QuantizedLogistic> CreateQuantizedLogistic(flatbuffers::Flat
 
 struct QuantizedMatMulT : public flatbuffers::NativeTable {
   typedef QuantizedMatMul TableType;
-  bool transposeA;
-  bool transposeB;
-  QuantizedMatMulT()
-      : transposeA(false),
-        transposeB(false) {
-  }
+  bool transposeA = false;
+  bool transposeB = false;
 };
 
 struct QuantizedMatMul FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
   typedef QuantizedMatMulT NativeTableType;
+  typedef QuantizedMatMulBuilder Builder;
   static const flatbuffers::TypeTable *MiniReflectTypeTable() {
     return QuantizedMatMulTypeTable();
   }
@@ -1017,6 +1002,7 @@ struct QuantizedMatMul FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
 };
 
 struct QuantizedMatMulBuilder {
+  typedef QuantizedMatMul Table;
   flatbuffers::FlatBufferBuilder &fbb_;
   flatbuffers::uoffset_t start_;
   void add_transposeA(bool transposeA) {
@@ -1029,7 +1015,6 @@ struct QuantizedMatMulBuilder {
         : fbb_(_fbb) {
     start_ = fbb_.StartTable();
   }
-  QuantizedMatMulBuilder &operator=(const QuantizedMatMulBuilder &);
   flatbuffers::Offset<QuantizedMatMul> Finish() {
     const auto end = fbb_.EndTable(start_);
     auto o = flatbuffers::Offset<QuantizedMatMul>(end);
@@ -1051,34 +1036,22 @@ flatbuffers::Offset<QuantizedMatMul> CreateQuantizedMatMul(flatbuffers::FlatBuff
 
 struct QuantizedMaxPoolT : public flatbuffers::NativeTable {
   typedef QuantizedMaxPool TableType;
-  int32_t kernelX;
-  int32_t kernelY;
-  ModeFormat modelFormat;
-  int32_t outputActivationMax;
-  int32_t outputActivationMin;
-  PoolPadType padType;
-  int32_t padX;
-  int32_t padY;
-  int32_t strideX;
-  int32_t strideY;
-  DataType type;
-  QuantizedMaxPoolT()
-      : kernelX(0),
-        kernelY(0),
-        modelFormat(ModeFormat_TENSORFLOW),
-        outputActivationMax(0),
-        outputActivationMin(0),
-        padType(PoolPadType_CAFFE),
-        padX(0),
-        padY(0),
-        strideX(0),
-        strideY(0),
-        type(DataType_DT_INVALID) {
-  }
+  int32_t kernelX = 0;
+  int32_t kernelY = 0;
+  MNN::ModeFormat modelFormat = MNN::ModeFormat_TENSORFLOW;
+  int32_t outputActivationMax = 0;
+  int32_t outputActivationMin = 0;
+  MNN::PoolPadType padType = MNN::PoolPadType_CAFFE;
+  int32_t padX = 0;
+  int32_t padY = 0;
+  int32_t strideX = 0;
+  int32_t strideY = 0;
+  MNN::DataType type = MNN::DataType_DT_INVALID;
 };
 
 struct QuantizedMaxPool FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
   typedef QuantizedMaxPoolT NativeTableType;
+  typedef QuantizedMaxPoolBuilder Builder;
   static const flatbuffers::TypeTable *MiniReflectTypeTable() {
     return QuantizedMaxPoolTypeTable();
   }
@@ -1101,8 +1074,8 @@ struct QuantizedMaxPool FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
   int32_t kernelY() const {
     return GetField<int32_t>(VT_KERNELY, 0);
   }
-  ModeFormat modelFormat() const {
-    return static_cast<ModeFormat>(GetField<int8_t>(VT_MODELFORMAT, 0));
+  MNN::ModeFormat modelFormat() const {
+    return static_cast<MNN::ModeFormat>(GetField<int8_t>(VT_MODELFORMAT, 0));
   }
   int32_t outputActivationMax() const {
     return GetField<int32_t>(VT_OUTPUTACTIVATIONMAX, 0);
@@ -1110,8 +1083,8 @@ struct QuantizedMaxPool FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
   int32_t outputActivationMin() const {
     return GetField<int32_t>(VT_OUTPUTACTIVATIONMIN, 0);
   }
-  PoolPadType padType() const {
-    return static_cast<PoolPadType>(GetField<int8_t>(VT_PADTYPE, 0));
+  MNN::PoolPadType padType() const {
+    return static_cast<MNN::PoolPadType>(GetField<int8_t>(VT_PADTYPE, 0));
   }
   int32_t padX() const {
     return GetField<int32_t>(VT_PADX, 0);
@@ -1125,8 +1098,8 @@ struct QuantizedMaxPool FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
   int32_t strideY() const {
     return GetField<int32_t>(VT_STRIDEY, 0);
   }
-  DataType type() const {
-    return static_cast<DataType>(GetField<int32_t>(VT_TYPE, 0));
+  MNN::DataType type() const {
+    return static_cast<MNN::DataType>(GetField<int32_t>(VT_TYPE, 0));
   }
   bool Verify(flatbuffers::Verifier &verifier) const {
     return VerifyTableStart(verifier) &&
@@ -1149,6 +1122,7 @@ struct QuantizedMaxPool FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
 };
 
 struct QuantizedMaxPoolBuilder {
+  typedef QuantizedMaxPool Table;
   flatbuffers::FlatBufferBuilder &fbb_;
   flatbuffers::uoffset_t start_;
   void add_kernelX(int32_t kernelX) {
@@ -1157,7 +1131,7 @@ struct QuantizedMaxPoolBuilder {
   void add_kernelY(int32_t kernelY) {
     fbb_.AddElement<int32_t>(QuantizedMaxPool::VT_KERNELY, kernelY, 0);
   }
-  void add_modelFormat(ModeFormat modelFormat) {
+  void add_modelFormat(MNN::ModeFormat modelFormat) {
     fbb_.AddElement<int8_t>(QuantizedMaxPool::VT_MODELFORMAT, static_cast<int8_t>(modelFormat), 0);
   }
   void add_outputActivationMax(int32_t outputActivationMax) {
@@ -1166,7 +1140,7 @@ struct QuantizedMaxPoolBuilder {
   void add_outputActivationMin(int32_t outputActivationMin) {
     fbb_.AddElement<int32_t>(QuantizedMaxPool::VT_OUTPUTACTIVATIONMIN, outputActivationMin, 0);
   }
-  void add_padType(PoolPadType padType) {
+  void add_padType(MNN::PoolPadType padType) {
     fbb_.AddElement<int8_t>(QuantizedMaxPool::VT_PADTYPE, static_cast<int8_t>(padType), 0);
   }
   void add_padX(int32_t padX) {
@@ -1181,14 +1155,13 @@ struct QuantizedMaxPoolBuilder {
   void add_strideY(int32_t strideY) {
     fbb_.AddElement<int32_t>(QuantizedMaxPool::VT_STRIDEY, strideY, 0);
   }
-  void add_type(DataType type) {
+  void add_type(MNN::DataType type) {
     fbb_.AddElement<int32_t>(QuantizedMaxPool::VT_TYPE, static_cast<int32_t>(type), 0);
   }
   explicit QuantizedMaxPoolBuilder(flatbuffers::FlatBufferBuilder &_fbb)
         : fbb_(_fbb) {
     start_ = fbb_.StartTable();
   }
-  QuantizedMaxPoolBuilder &operator=(const QuantizedMaxPoolBuilder &);
   flatbuffers::Offset<QuantizedMaxPool> Finish() {
     const auto end = fbb_.EndTable(start_);
     auto o = flatbuffers::Offset<QuantizedMaxPool>(end);
@@ -1200,15 +1173,15 @@ inline flatbuffers::Offset<QuantizedMaxPool> CreateQuantizedMaxPool(
     flatbuffers::FlatBufferBuilder &_fbb,
     int32_t kernelX = 0,
     int32_t kernelY = 0,
-    ModeFormat modelFormat = ModeFormat_TENSORFLOW,
+    MNN::ModeFormat modelFormat = MNN::ModeFormat_TENSORFLOW,
     int32_t outputActivationMax = 0,
     int32_t outputActivationMin = 0,
-    PoolPadType padType = PoolPadType_CAFFE,
+    MNN::PoolPadType padType = MNN::PoolPadType_CAFFE,
     int32_t padX = 0,
     int32_t padY = 0,
     int32_t strideX = 0,
     int32_t strideY = 0,
-    DataType type = DataType_DT_INVALID) {
+    MNN::DataType type = MNN::DataType_DT_INVALID) {
   QuantizedMaxPoolBuilder builder_(_fbb);
   builder_.add_type(type);
   builder_.add_strideY(strideY);
@@ -1228,22 +1201,20 @@ flatbuffers::Offset<QuantizedMaxPool> CreateQuantizedMaxPool(flatbuffers::FlatBu
 
 struct QuantizedReluT : public flatbuffers::NativeTable {
   typedef QuantizedRelu TableType;
-  DataType type;
-  QuantizedReluT()
-      : type(DataType_DT_INVALID) {
-  }
+  MNN::DataType type = MNN::DataType_DT_INVALID;
 };
 
 struct QuantizedRelu FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
   typedef QuantizedReluT NativeTableType;
+  typedef QuantizedReluBuilder Builder;
   static const flatbuffers::TypeTable *MiniReflectTypeTable() {
     return QuantizedReluTypeTable();
   }
   enum FlatBuffersVTableOffset FLATBUFFERS_VTABLE_UNDERLYING_TYPE {
     VT_TYPE = 4
   };
-  DataType type() const {
-    return static_cast<DataType>(GetField<int32_t>(VT_TYPE, 0));
+  MNN::DataType type() const {
+    return static_cast<MNN::DataType>(GetField<int32_t>(VT_TYPE, 0));
   }
   bool Verify(flatbuffers::Verifier &verifier) const {
     return VerifyTableStart(verifier) &&
@@ -1256,16 +1227,16 @@ struct QuantizedRelu FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
 };
 
 struct QuantizedReluBuilder {
+  typedef QuantizedRelu Table;
   flatbuffers::FlatBufferBuilder &fbb_;
   flatbuffers::uoffset_t start_;
-  void add_type(DataType type) {
+  void add_type(MNN::DataType type) {
     fbb_.AddElement<int32_t>(QuantizedRelu::VT_TYPE, static_cast<int32_t>(type), 0);
   }
   explicit QuantizedReluBuilder(flatbuffers::FlatBufferBuilder &_fbb)
         : fbb_(_fbb) {
     start_ = fbb_.StartTable();
   }
-  QuantizedReluBuilder &operator=(const QuantizedReluBuilder &);
   flatbuffers::Offset<QuantizedRelu> Finish() {
     const auto end = fbb_.EndTable(start_);
     auto o = flatbuffers::Offset<QuantizedRelu>(end);
@@ -1275,7 +1246,7 @@ struct QuantizedReluBuilder {
 
 inline flatbuffers::Offset<QuantizedRelu> CreateQuantizedRelu(
     flatbuffers::FlatBufferBuilder &_fbb,
-    DataType type = DataType_DT_INVALID) {
+    MNN::DataType type = MNN::DataType_DT_INVALID) {
   QuantizedReluBuilder builder_(_fbb);
   builder_.add_type(type);
   return builder_.Finish();
@@ -1285,22 +1256,20 @@ flatbuffers::Offset<QuantizedRelu> CreateQuantizedRelu(flatbuffers::FlatBufferBu
 
 struct QuantizedRelu6T : public flatbuffers::NativeTable {
   typedef QuantizedRelu6 TableType;
-  DataType type;
-  QuantizedRelu6T()
-      : type(DataType_DT_INVALID) {
-  }
+  MNN::DataType type = MNN::DataType_DT_INVALID;
 };
 
 struct QuantizedRelu6 FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
   typedef QuantizedRelu6T NativeTableType;
+  typedef QuantizedRelu6Builder Builder;
   static const flatbuffers::TypeTable *MiniReflectTypeTable() {
     return QuantizedRelu6TypeTable();
   }
   enum FlatBuffersVTableOffset FLATBUFFERS_VTABLE_UNDERLYING_TYPE {
     VT_TYPE = 4
   };
-  DataType type() const {
-    return static_cast<DataType>(GetField<int32_t>(VT_TYPE, 0));
+  MNN::DataType type() const {
+    return static_cast<MNN::DataType>(GetField<int32_t>(VT_TYPE, 0));
   }
   bool Verify(flatbuffers::Verifier &verifier) const {
     return VerifyTableStart(verifier) &&
@@ -1313,16 +1282,16 @@ struct QuantizedRelu6 FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
 };
 
 struct QuantizedRelu6Builder {
+  typedef QuantizedRelu6 Table;
   flatbuffers::FlatBufferBuilder &fbb_;
   flatbuffers::uoffset_t start_;
-  void add_type(DataType type) {
+  void add_type(MNN::DataType type) {
     fbb_.AddElement<int32_t>(QuantizedRelu6::VT_TYPE, static_cast<int32_t>(type), 0);
   }
   explicit QuantizedRelu6Builder(flatbuffers::FlatBufferBuilder &_fbb)
         : fbb_(_fbb) {
     start_ = fbb_.StartTable();
   }
-  QuantizedRelu6Builder &operator=(const QuantizedRelu6Builder &);
   flatbuffers::Offset<QuantizedRelu6> Finish() {
     const auto end = fbb_.EndTable(start_);
     auto o = flatbuffers::Offset<QuantizedRelu6>(end);
@@ -1332,7 +1301,7 @@ struct QuantizedRelu6Builder {
 
 inline flatbuffers::Offset<QuantizedRelu6> CreateQuantizedRelu6(
     flatbuffers::FlatBufferBuilder &_fbb,
-    DataType type = DataType_DT_INVALID) {
+    MNN::DataType type = MNN::DataType_DT_INVALID) {
   QuantizedRelu6Builder builder_(_fbb);
   builder_.add_type(type);
   return builder_.Finish();
@@ -1342,15 +1311,13 @@ flatbuffers::Offset<QuantizedRelu6> CreateQuantizedRelu6(flatbuffers::FlatBuffer
 
 struct QuantizedReshapeT : public flatbuffers::NativeTable {
   typedef QuantizedReshape TableType;
-  std::vector<int32_t> dims;
-  ModeFormat modelFormat;
-  QuantizedReshapeT()
-      : modelFormat(ModeFormat_TENSORFLOW) {
-  }
+  std::vector<int32_t> dims{};
+  MNN::ModeFormat modelFormat = MNN::ModeFormat_TENSORFLOW;
 };
 
 struct QuantizedReshape FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
   typedef QuantizedReshapeT NativeTableType;
+  typedef QuantizedReshapeBuilder Builder;
   static const flatbuffers::TypeTable *MiniReflectTypeTable() {
     return QuantizedReshapeTypeTable();
   }
@@ -1361,8 +1328,8 @@ struct QuantizedReshape FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
   const flatbuffers::Vector<int32_t> *dims() const {
     return GetPointer<const flatbuffers::Vector<int32_t> *>(VT_DIMS);
   }
-  ModeFormat modelFormat() const {
-    return static_cast<ModeFormat>(GetField<int8_t>(VT_MODELFORMAT, 0));
+  MNN::ModeFormat modelFormat() const {
+    return static_cast<MNN::ModeFormat>(GetField<int8_t>(VT_MODELFORMAT, 0));
   }
   bool Verify(flatbuffers::Verifier &verifier) const {
     return VerifyTableStart(verifier) &&
@@ -1377,19 +1344,19 @@ struct QuantizedReshape FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
 };
 
 struct QuantizedReshapeBuilder {
+  typedef QuantizedReshape Table;
   flatbuffers::FlatBufferBuilder &fbb_;
   flatbuffers::uoffset_t start_;
   void add_dims(flatbuffers::Offset<flatbuffers::Vector<int32_t>> dims) {
     fbb_.AddOffset(QuantizedReshape::VT_DIMS, dims);
   }
-  void add_modelFormat(ModeFormat modelFormat) {
+  void add_modelFormat(MNN::ModeFormat modelFormat) {
     fbb_.AddElement<int8_t>(QuantizedReshape::VT_MODELFORMAT, static_cast<int8_t>(modelFormat), 0);
   }
   explicit QuantizedReshapeBuilder(flatbuffers::FlatBufferBuilder &_fbb)
         : fbb_(_fbb) {
     start_ = fbb_.StartTable();
   }
-  QuantizedReshapeBuilder &operator=(const QuantizedReshapeBuilder &);
   flatbuffers::Offset<QuantizedReshape> Finish() {
     const auto end = fbb_.EndTable(start_);
     auto o = flatbuffers::Offset<QuantizedReshape>(end);
@@ -1400,7 +1367,7 @@ struct QuantizedReshapeBuilder {
 inline flatbuffers::Offset<QuantizedReshape> CreateQuantizedReshape(
     flatbuffers::FlatBufferBuilder &_fbb,
     flatbuffers::Offset<flatbuffers::Vector<int32_t>> dims = 0,
-    ModeFormat modelFormat = ModeFormat_TENSORFLOW) {
+    MNN::ModeFormat modelFormat = MNN::ModeFormat_TENSORFLOW) {
   QuantizedReshapeBuilder builder_(_fbb);
   builder_.add_dims(dims);
   builder_.add_modelFormat(modelFormat);
@@ -1410,7 +1377,7 @@ inline flatbuffers::Offset<QuantizedReshape> CreateQuantizedReshape(
 inline flatbuffers::Offset<QuantizedReshape> CreateQuantizedReshapeDirect(
     flatbuffers::FlatBufferBuilder &_fbb,
     const std::vector<int32_t> *dims = nullptr,
-    ModeFormat modelFormat = ModeFormat_TENSORFLOW) {
+    MNN::ModeFormat modelFormat = MNN::ModeFormat_TENSORFLOW) {
   auto dims__ = dims ? _fbb.CreateVector<int32_t>(*dims) : 0;
   return MNN::CreateQuantizedReshape(
       _fbb,
@@ -1422,16 +1389,13 @@ flatbuffers::Offset<QuantizedReshape> CreateQuantizedReshape(flatbuffers::FlatBu
 
 struct QuantizedSoftmaxT : public flatbuffers::NativeTable {
   typedef QuantizedSoftmax TableType;
-  float beta;
-  float inputScale;
-  QuantizedSoftmaxT()
-      : beta(0.0f),
-        inputScale(0.0f) {
-  }
+  float beta = 0.0f;
+  float inputScale = 0.0f;
 };
 
 struct QuantizedSoftmax FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
   typedef QuantizedSoftmaxT NativeTableType;
+  typedef QuantizedSoftmaxBuilder Builder;
   static const flatbuffers::TypeTable *MiniReflectTypeTable() {
     return QuantizedSoftmaxTypeTable();
   }
@@ -1457,6 +1421,7 @@ struct QuantizedSoftmax FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
 };
 
 struct QuantizedSoftmaxBuilder {
+  typedef QuantizedSoftmax Table;
   flatbuffers::FlatBufferBuilder &fbb_;
   flatbuffers::uoffset_t start_;
   void add_beta(float beta) {
@@ -1469,7 +1434,6 @@ struct QuantizedSoftmaxBuilder {
         : fbb_(_fbb) {
     start_ = fbb_.StartTable();
   }
-  QuantizedSoftmaxBuilder &operator=(const QuantizedSoftmaxBuilder &);
   flatbuffers::Offset<QuantizedSoftmax> Finish() {
     const auto end = fbb_.EndTable(start_);
     auto o = flatbuffers::Offset<QuantizedSoftmax>(end);
@@ -1491,18 +1455,14 @@ flatbuffers::Offset<QuantizedSoftmax> CreateQuantizedSoftmax(flatbuffers::FlatBu
 
 struct QuantizeV2T : public flatbuffers::NativeTable {
   typedef QuantizeV2 TableType;
-  DataType type;
-  QuantizeMode mode;
-  QuantizeRoundMode roundMode;
-  QuantizeV2T()
-      : type(DataType_DT_INVALID),
-        mode(QuantizeMode_MIN_COMBINED),
-        roundMode(QuantizeRoundMode_HALF_AWAY_FROM_ZERO) {
-  }
+  MNN::DataType type = MNN::DataType_DT_INVALID;
+  MNN::QuantizeMode mode = MNN::QuantizeMode_MIN_COMBINED;
+  MNN::QuantizeRoundMode roundMode = MNN::QuantizeRoundMode_HALF_AWAY_FROM_ZERO;
 };
 
 struct QuantizeV2 FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
   typedef QuantizeV2T NativeTableType;
+  typedef QuantizeV2Builder Builder;
   static const flatbuffers::TypeTable *MiniReflectTypeTable() {
     return QuantizeV2TypeTable();
   }
@@ -1511,14 +1471,14 @@ struct QuantizeV2 FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
     VT_MODE = 6,
     VT_ROUNDMODE = 8
   };
-  DataType type() const {
-    return static_cast<DataType>(GetField<int32_t>(VT_TYPE, 0));
+  MNN::DataType type() const {
+    return static_cast<MNN::DataType>(GetField<int32_t>(VT_TYPE, 0));
   }
-  QuantizeMode mode() const {
-    return static_cast<QuantizeMode>(GetField<int8_t>(VT_MODE, 0));
+  MNN::QuantizeMode mode() const {
+    return static_cast<MNN::QuantizeMode>(GetField<int8_t>(VT_MODE, 0));
   }
-  QuantizeRoundMode roundMode() const {
-    return static_cast<QuantizeRoundMode>(GetField<int8_t>(VT_ROUNDMODE, 0));
+  MNN::QuantizeRoundMode roundMode() const {
+    return static_cast<MNN::QuantizeRoundMode>(GetField<int8_t>(VT_ROUNDMODE, 0));
   }
   bool Verify(flatbuffers::Verifier &verifier) const {
     return VerifyTableStart(verifier) &&
@@ -1533,22 +1493,22 @@ struct QuantizeV2 FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
 };
 
 struct QuantizeV2Builder {
+  typedef QuantizeV2 Table;
   flatbuffers::FlatBufferBuilder &fbb_;
   flatbuffers::uoffset_t start_;
-  void add_type(DataType type) {
+  void add_type(MNN::DataType type) {
     fbb_.AddElement<int32_t>(QuantizeV2::VT_TYPE, static_cast<int32_t>(type), 0);
   }
-  void add_mode(QuantizeMode mode) {
+  void add_mode(MNN::QuantizeMode mode) {
     fbb_.AddElement<int8_t>(QuantizeV2::VT_MODE, static_cast<int8_t>(mode), 0);
   }
-  void add_roundMode(QuantizeRoundMode roundMode) {
+  void add_roundMode(MNN::QuantizeRoundMode roundMode) {
     fbb_.AddElement<int8_t>(QuantizeV2::VT_ROUNDMODE, static_cast<int8_t>(roundMode), 0);
   }
   explicit QuantizeV2Builder(flatbuffers::FlatBufferBuilder &_fbb)
         : fbb_(_fbb) {
     start_ = fbb_.StartTable();
   }
-  QuantizeV2Builder &operator=(const QuantizeV2Builder &);
   flatbuffers::Offset<QuantizeV2> Finish() {
     const auto end = fbb_.EndTable(start_);
     auto o = flatbuffers::Offset<QuantizeV2>(end);
@@ -1558,9 +1518,9 @@ struct QuantizeV2Builder {
 
 inline flatbuffers::Offset<QuantizeV2> CreateQuantizeV2(
     flatbuffers::FlatBufferBuilder &_fbb,
-    DataType type = DataType_DT_INVALID,
-    QuantizeMode mode = QuantizeMode_MIN_COMBINED,
-    QuantizeRoundMode roundMode = QuantizeRoundMode_HALF_AWAY_FROM_ZERO) {
+    MNN::DataType type = MNN::DataType_DT_INVALID,
+    MNN::QuantizeMode mode = MNN::QuantizeMode_MIN_COMBINED,
+    MNN::QuantizeRoundMode roundMode = MNN::QuantizeRoundMode_HALF_AWAY_FROM_ZERO) {
   QuantizeV2Builder builder_(_fbb);
   builder_.add_type(type);
   builder_.add_roundMode(roundMode);
@@ -1572,12 +1532,11 @@ flatbuffers::Offset<QuantizeV2> CreateQuantizeV2(flatbuffers::FlatBufferBuilder
 
 struct RequantizationRangeT : public flatbuffers::NativeTable {
   typedef RequantizationRange TableType;
-  RequantizationRangeT() {
-  }
 };
 
 struct RequantizationRange FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
   typedef RequantizationRangeT NativeTableType;
+  typedef RequantizationRangeBuilder Builder;
   static const flatbuffers::TypeTable *MiniReflectTypeTable() {
     return RequantizationRangeTypeTable();
   }
@@ -1591,13 +1550,13 @@ struct RequantizationRange FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table
 };
 
 struct RequantizationRangeBuilder {
+  typedef RequantizationRange Table;
   flatbuffers::FlatBufferBuilder &fbb_;
   flatbuffers::uoffset_t start_;
   explicit RequantizationRangeBuilder(flatbuffers::FlatBufferBuilder &_fbb)
         : fbb_(_fbb) {
     start_ = fbb_.StartTable();
   }
-  RequantizationRangeBuilder &operator=(const RequantizationRangeBuilder &);
   flatbuffers::Offset<RequantizationRange> Finish() {
     const auto end = fbb_.EndTable(start_);
     auto o = flatbuffers::Offset<RequantizationRange>(end);
@@ -1615,12 +1574,11 @@ flatbuffers::Offset<RequantizationRange> CreateRequantizationRange(flatbuffers::
 
 struct RequantizeT : public flatbuffers::NativeTable {
   typedef Requantize TableType;
-  RequantizeT() {
-  }
 };
 
 struct Requantize FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
   typedef RequantizeT NativeTableType;
+  typedef RequantizeBuilder Builder;
   static const flatbuffers::TypeTable *MiniReflectTypeTable() {
     return RequantizeTypeTable();
   }
@@ -1634,13 +1592,13 @@ struct Requantize FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
 };
 
 struct RequantizeBuilder {
+  typedef Requantize Table;
   flatbuffers::FlatBufferBuilder &fbb_;
   flatbuffers::uoffset_t start_;
   explicit RequantizeBuilder(flatbuffers::FlatBufferBuilder &_fbb)
         : fbb_(_fbb) {
     start_ = fbb_.StartTable();
   }
-  RequantizeBuilder &operator=(const RequantizeBuilder &);
   flatbuffers::Offset<Requantize> Finish() {
     const auto end = fbb_.EndTable(start_);
     auto o = flatbuffers::Offset<Requantize>(end);
@@ -1658,35 +1616,26 @@ flatbuffers::Offset<Requantize> CreateRequantize(flatbuffers::FlatBufferBuilder
 
 struct TfQuantizedConv2DT : public flatbuffers::NativeTable {
   typedef TfQuantizedConv2D TableType;
-  std::vector<int32_t> bias;
-  bool biasflag;
-  std::unique_ptr<Convolution2DCommonT> common;
-  std::vector<uint8_t> weight;
-  FusedActivation activationType;
-  int32_t multiplier;
-  int32_t outMax;
-  int32_t outMin;
-  int32_t shift;
-  std::unique_ptr<QuantizedParamT> biasQuantizedParam;
-  int32_t depthMultiplier;
-  std::unique_ptr<QuantizedParamT> filterQuantizedParam;
-  std::unique_ptr<QuantizedParamT> inputQuantizedParam;
-  ModeFormat modelFormat;
-  std::unique_ptr<QuantizedParamT> outputQuantizedParam;
-  TfQuantizedConv2DT()
-      : biasflag(false),
-        activationType(FusedActivation_kTfLiteActNone),
-        multiplier(0),
-        outMax(0),
-        outMin(0),
-        shift(0),
-        depthMultiplier(0),
-        modelFormat(ModeFormat_TENSORFLOW) {
-  }
+  std::vector<int32_t> bias{};
+  bool biasflag = false;
+  std::unique_ptr<MNN::Convolution2DCommonT> common{};
+  std::vector<uint8_t> weight{};
+  MNN::FusedActivation activationType = MNN::FusedActivation_kTfLiteActNone;
+  int32_t multiplier = 0;
+  int32_t outMax = 0;
+  int32_t outMin = 0;
+  int32_t shift = 0;
+  std::unique_ptr<MNN::QuantizedParamT> biasQuantizedParam{};
+  int32_t depthMultiplier = 0;
+  std::unique_ptr<MNN::QuantizedParamT> filterQuantizedParam{};
+  std::unique_ptr<MNN::QuantizedParamT> inputQuantizedParam{};
+  MNN::ModeFormat modelFormat = MNN::ModeFormat_TENSORFLOW;
+  std::unique_ptr<MNN::QuantizedParamT> outputQuantizedParam{};
 };
 
 struct TfQuantizedConv2D FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
   typedef TfQuantizedConv2DT NativeTableType;
+  typedef TfQuantizedConv2DBuilder Builder;
   static const flatbuffers::TypeTable *MiniReflectTypeTable() {
     return TfQuantizedConv2DTypeTable();
   }
@@ -1713,14 +1662,14 @@ struct TfQuantizedConv2D FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
   bool biasflag() const {
     return GetField<uint8_t>(VT_BIASFLAG, 0) != 0;
   }
-  const Convolution2DCommon *common() const {
-    return GetPointer<const Convolution2DCommon *>(VT_COMMON);
+  const MNN::Convolution2DCommon *common() const {
+    return GetPointer<const MNN::Convolution2DCommon *>(VT_COMMON);
   }
   const flatbuffers::Vector<uint8_t> *weight() const {
     return GetPointer<const flatbuffers::Vector<uint8_t> *>(VT_WEIGHT);
   }
-  FusedActivation activationType() const {
-    return static_cast<FusedActivation>(GetField<int8_t>(VT_ACTIVATIONTYPE, 0));
+  MNN::FusedActivation activationType() const {
+    return static_cast<MNN::FusedActivation>(GetField<int8_t>(VT_ACTIVATIONTYPE, 0));
   }
   int32_t multiplier() const {
     return GetField<int32_t>(VT_MULTIPLIER, 0);
@@ -1734,23 +1683,23 @@ struct TfQuantizedConv2D FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
   int32_t shift() const {
     return GetField<int32_t>(VT_SHIFT, 0);
   }
-  const QuantizedParam *biasQuantizedParam() const {
-    return GetPointer<const QuantizedParam *>(VT_BIASQUANTIZEDPARAM);
+  const MNN::QuantizedParam *biasQuantizedParam() const {
+    return GetPointer<const MNN::QuantizedParam *>(VT_BIASQUANTIZEDPARAM);
   }
   int32_t depthMultiplier() const {
     return GetField<int32_t>(VT_DEPTHMULTIPLIER, 0);
   }
-  const QuantizedParam *filterQuantizedParam() const {
-    return GetPointer<const QuantizedParam *>(VT_FILTERQUANTIZEDPARAM);
+  const MNN::QuantizedParam *filterQuantizedParam() const {
+    return GetPointer<const MNN::QuantizedParam *>(VT_FILTERQUANTIZEDPARAM);
   }
-  const QuantizedParam *inputQuantizedParam() const {
-    return GetPointer<const QuantizedParam *>(VT_INPUTQUANTIZEDPARAM);
+  const MNN::QuantizedParam *inputQuantizedParam() const {
+    return GetPointer<const MNN::QuantizedParam *>(VT_INPUTQUANTIZEDPARAM);
   }
-  ModeFormat modelFormat() const {
-    return static_cast<ModeFormat>(GetField<int8_t>(VT_MODELFORMAT, 0));
+  MNN::ModeFormat modelFormat() const {
+    return static_cast<MNN::ModeFormat>(GetField<int8_t>(VT_MODELFORMAT, 0));
   }
-  const QuantizedParam *outputQuantizedParam() const {
-    return GetPointer<const QuantizedParam *>(VT_OUTPUTQUANTIZEDPARAM);
+  const MNN::QuantizedParam *outputQuantizedParam() const {
+    return GetPointer<const MNN::QuantizedParam *>(VT_OUTPUTQUANTIZEDPARAM);
   }
   bool Verify(flatbuffers::Verifier &verifier) const {
     return VerifyTableStart(verifier) &&
@@ -1784,6 +1733,7 @@ struct TfQuantizedConv2D FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
 };
 
 struct TfQuantizedConv2DBuilder {
+  typedef TfQuantizedConv2D Table;
   flatbuffers::FlatBufferBuilder &fbb_;
   flatbuffers::uoffset_t start_;
   void add_bias(flatbuffers::Offset<flatbuffers::Vector<int32_t>> bias) {
@@ -1792,13 +1742,13 @@ struct TfQuantizedConv2DBuilder {
   void add_biasflag(bool biasflag) {
     fbb_.AddElement<uint8_t>(TfQuantizedConv2D::VT_BIASFLAG, static_cast<uint8_t>(biasflag), 0);
   }
-  void add_common(flatbuffers::Offset<Convolution2DCommon> common) {
+  void add_common(flatbuffers::Offset<MNN::Convolution2DCommon> common) {
     fbb_.AddOffset(TfQuantizedConv2D::VT_COMMON, common);
   }
   void add_weight(flatbuffers::Offset<flatbuffers::Vector<uint8_t>> weight) {
     fbb_.AddOffset(TfQuantizedConv2D::VT_WEIGHT, weight);
   }
-  void add_activationType(FusedActivation activationType) {
+  void add_activationType(MNN::FusedActivation activationType) {
     fbb_.AddElement<int8_t>(TfQuantizedConv2D::VT_ACTIVATIONTYPE, static_cast<int8_t>(activationType), 0);
   }
   void add_multiplier(int32_t multiplier) {
@@ -1813,29 +1763,28 @@ struct TfQuantizedConv2DBuilder {
   void add_shift(int32_t shift) {
     fbb_.AddElement<int32_t>(TfQuantizedConv2D::VT_SHIFT, shift, 0);
   }
-  void add_biasQuantizedParam(flatbuffers::Offset<QuantizedParam> biasQuantizedParam) {
+  void add_biasQuantizedParam(flatbuffers::Offset<MNN::QuantizedParam> biasQuantizedParam) {
     fbb_.AddOffset(TfQuantizedConv2D::VT_BIASQUANTIZEDPARAM, biasQuantizedParam);
   }
   void add_depthMultiplier(int32_t depthMultiplier) {
     fbb_.AddElement<int32_t>(TfQuantizedConv2D::VT_DEPTHMULTIPLIER, depthMultiplier, 0);
   }
-  void add_filterQuantizedParam(flatbuffers::Offset<QuantizedParam> filterQuantizedParam) {
+  void add_filterQuantizedParam(flatbuffers::Offset<MNN::QuantizedParam> filterQuantizedParam) {
     fbb_.AddOffset(TfQuantizedConv2D::VT_FILTERQUANTIZEDPARAM, filterQuantizedParam);
   }
-  void add_inputQuantizedParam(flatbuffers::Offset<QuantizedParam> inputQuantizedParam) {
+  void add_inputQuantizedParam(flatbuffers::Offset<MNN::QuantizedParam> inputQuantizedParam) {
     fbb_.AddOffset(TfQuantizedConv2D::VT_INPUTQUANTIZEDPARAM, inputQuantizedParam);
   }
-  void add_modelFormat(ModeFormat modelFormat) {
+  void add_modelFormat(MNN::ModeFormat modelFormat) {
     fbb_.AddElement<int8_t>(TfQuantizedConv2D::VT_MODELFORMAT, static_cast<int8_t>(modelFormat), 0);
   }
-  void add_outputQuantizedParam(flatbuffers::Offset<QuantizedParam> outputQuantizedParam) {
+  void add_outputQuantizedParam(flatbuffers::Offset<MNN::QuantizedParam> outputQuantizedParam) {
     fbb_.AddOffset(TfQuantizedConv2D::VT_OUTPUTQUANTIZEDPARAM, outputQuantizedParam);
   }
   explicit TfQuantizedConv2DBuilder(flatbuffers::FlatBufferBuilder &_fbb)
         : fbb_(_fbb) {
     start_ = fbb_.StartTable();
   }
-  TfQuantizedConv2DBuilder &operator=(const TfQuantizedConv2DBuilder &);
   flatbuffers::Offset<TfQuantizedConv2D> Finish() {
     const auto end = fbb_.EndTable(start_);
     auto o = flatbuffers::Offset<TfQuantizedConv2D>(end);
@@ -1847,19 +1796,19 @@ inline flatbuffers::Offset<TfQuantizedConv2D> CreateTfQuantizedConv2D(
     flatbuffers::FlatBufferBuilder &_fbb,
     flatbuffers::Offset<flatbuffers::Vector<int32_t>> bias = 0,
     bool biasflag = false,
-    flatbuffers::Offset<Convolution2DCommon> common = 0,
+    flatbuffers::Offset<MNN::Convolution2DCommon> common = 0,
     flatbuffers::Offset<flatbuffers::Vector<uint8_t>> weight = 0,
-    FusedActivation activationType = FusedActivation_kTfLiteActNone,
+    MNN::FusedActivation activationType = MNN::FusedActivation_kTfLiteActNone,
     int32_t multiplier = 0,
     int32_t outMax = 0,
     int32_t outMin = 0,
     int32_t shift = 0,
-    flatbuffers::Offset<QuantizedParam> biasQuantizedParam = 0,
+    flatbuffers::Offset<MNN::QuantizedParam> biasQuantizedParam = 0,
     int32_t depthMultiplier = 0,
-    flatbuffers::Offset<QuantizedParam> filterQuantizedParam = 0,
-    flatbuffers::Offset<QuantizedParam> inputQuantizedParam = 0,
-    ModeFormat modelFormat = ModeFormat_TENSORFLOW,
-    flatbuffers::Offset<QuantizedParam> outputQuantizedParam = 0) {
+    flatbuffers::Offset<MNN::QuantizedParam> filterQuantizedParam = 0,
+    flatbuffers::Offset<MNN::QuantizedParam> inputQuantizedParam = 0,
+    MNN::ModeFormat modelFormat = MNN::ModeFormat_TENSORFLOW,
+    flatbuffers::Offset<MNN::QuantizedParam> outputQuantizedParam = 0) {
   TfQuantizedConv2DBuilder builder_(_fbb);
   builder_.add_outputQuantizedParam(outputQuantizedParam);
   builder_.add_inputQuantizedParam(inputQuantizedParam);
@@ -1883,19 +1832,19 @@ inline flatbuffers::Offset<TfQuantizedConv2D> CreateTfQuantizedConv2DDirect(
     flatbuffers::FlatBufferBuilder &_fbb,
     const std::vector<int32_t> *bias = nullptr,
     bool biasflag = false,
-    flatbuffers::Offset<Convolution2DCommon> common = 0,
+    flatbuffers::Offset<MNN::Convolution2DCommon> common = 0,
     const std::vector<uint8_t> *weight = nullptr,
-    FusedActivation activationType = FusedActivation_kTfLiteActNone,
+    MNN::FusedActivation activationType = MNN::FusedActivation_kTfLiteActNone,
     int32_t multiplier = 0,
     int32_t outMax = 0,
     int32_t outMin = 0,
     int32_t shift = 0,
-    flatbuffers::Offset<QuantizedParam> biasQuantizedParam = 0,
+    flatbuffers::Offset<MNN::QuantizedParam> biasQuantizedParam = 0,
     int32_t depthMultiplier = 0,
-    flatbuffers::Offset<QuantizedParam> filterQuantizedParam = 0,
-    flatbuffers::Offset<QuantizedParam> inputQuantizedParam = 0,
-    ModeFormat modelFormat = ModeFormat_TENSORFLOW,
-    flatbuffers::Offset<QuantizedParam> outputQuantizedParam = 0) {
+    flatbuffers::Offset<MNN::QuantizedParam> filterQuantizedParam = 0,
+    flatbuffers::Offset<MNN::QuantizedParam> inputQuantizedParam = 0,
+    MNN::ModeFormat modelFormat = MNN::ModeFormat_TENSORFLOW,
+    flatbuffers::Offset<MNN::QuantizedParam> outputQuantizedParam = 0) {
   auto bias__ = bias ? _fbb.CreateVector<int32_t>(*bias) : 0;
   auto weight__ = weight ? _fbb.CreateVector<uint8_t>(*weight) : 0;
   return MNN::CreateTfQuantizedConv2D(
@@ -1920,16 +1869,16 @@ inline flatbuffers::Offset<TfQuantizedConv2D> CreateTfQuantizedConv2DDirect(
 flatbuffers::Offset<TfQuantizedConv2D> CreateTfQuantizedConv2D(flatbuffers::FlatBufferBuilder &_fbb, const TfQuantizedConv2DT *_o, const flatbuffers::rehasher_function_t *_rehasher = nullptr);
 
 inline QuantizedParamT *QuantizedParam::UnPack(const flatbuffers::resolver_function_t *_resolver) const {
-  auto _o = new QuantizedParamT();
-  UnPackTo(_o, _resolver);
-  return _o;
+  auto _o = std::unique_ptr<QuantizedParamT>(new QuantizedParamT());
+  UnPackTo(_o.get(), _resolver);
+  return _o.release();
 }
 
 inline void QuantizedParam::UnPackTo(QuantizedParamT *_o, const flatbuffers::resolver_function_t *_resolver) const {
   (void)_o;
   (void)_resolver;
-  { auto _e = zeroPoint(); _o->zeroPoint = _e; };
-  { auto _e = scale(); _o->scale = _e; };
+  { auto _e = zeroPoint(); _o->zeroPoint = _e; }
+  { auto _e = scale(); _o->scale = _e; }
 }
 
 inline flatbuffers::Offset<QuantizedParam> QuantizedParam::Pack(flatbuffers::FlatBufferBuilder &_fbb, const QuantizedParamT* _o, const flatbuffers::rehasher_function_t *_rehasher) {
@@ -1949,18 +1898,18 @@ inline flatbuffers::Offset<QuantizedParam> CreateQuantizedParam(flatbuffers::Fla
 }
 
 inline QuantizedAddT *QuantizedAdd::UnPack(const flatbuffers::resolver_function_t *_resolver) const {
-  auto _o = new QuantizedAddT();
-  UnPackTo(_o, _resolver);
-  return _o;
+  auto _o = std::unique_ptr<QuantizedAddT>(new QuantizedAddT());
+  UnPackTo(_o.get(), _resolver);
+  return _o.release();
 }
 
 inline void QuantizedAdd::UnPackTo(QuantizedAddT *_o, const flatbuffers::resolver_function_t *_resolver) const {
   (void)_o;
   (void)_resolver;
-  { auto _e = activationType(); _o->activationType = _e; };
-  { auto _e = input1QuantizedParam(); if (_e) _o->input1QuantizedParam = std::unique_ptr<QuantizedParamT>(_e->UnPack(_resolver)); };
-  { auto _e = input2QuantizedParam(); if (_e) _o->input2QuantizedParam = std::unique_ptr<QuantizedParamT>(_e->UnPack(_resolver)); };
-  { auto _e = outputQuantizedParam(); if (_e) _o->outputQuantizedParam = std::unique_ptr<QuantizedParamT>(_e->UnPack(_resolver)); };
+  { auto _e = activationType(); _o->activationType = _e; }
+  { auto _e = input1QuantizedParam(); if (_e) _o->input1QuantizedParam = std::unique_ptr<MNN::QuantizedParamT>(_e->UnPack(_resolver)); }
+  { auto _e = input2QuantizedParam(); if (_e) _o->input2QuantizedParam = std::unique_ptr<MNN::QuantizedParamT>(_e->UnPack(_resolver)); }
+  { auto _e = outputQuantizedParam(); if (_e) _o->outputQuantizedParam = std::unique_ptr<MNN::QuantizedParamT>(_e->UnPack(_resolver)); }
 }
 
 inline flatbuffers::Offset<QuantizedAdd> QuantizedAdd::Pack(flatbuffers::FlatBufferBuilder &_fbb, const QuantizedAddT* _o, const flatbuffers::rehasher_function_t *_rehasher) {
@@ -1984,18 +1933,18 @@ inline flatbuffers::Offset<QuantizedAdd> CreateQuantizedAdd(flatbuffers::FlatBuf
 }
 
 inline DequantizeT *Dequantize::UnPack(const flatbuffers::resolver_function_t *_resolver) const {
-  auto _o = new DequantizeT();
-  UnPackTo(_o, _resolver);
-  return _o;
+  auto _o = std::unique_ptr<DequantizeT>(new DequantizeT());
+  UnPackTo(_o.get(), _resolver);
+  return _o.release();
 }
 
 inline void Dequantize::UnPackTo(DequantizeT *_o, const flatbuffers::resolver_function_t *_resolver) const {
   (void)_o;
   (void)_resolver;
-  { auto _e = inputQuantizedParam(); if (_e) _o->inputQuantizedParam = std::unique_ptr<QuantizedParamT>(_e->UnPack(_resolver)); };
-  { auto _e = mode(); _o->mode = _e; };
-  { auto _e = modelFormat(); _o->modelFormat = _e; };
-  { auto _e = type(); _o->type = _e; };
+  { auto _e = inputQuantizedParam(); if (_e) _o->inputQuantizedParam = std::unique_ptr<MNN::QuantizedParamT>(_e->UnPack(_resolver)); }
+  { auto _e = mode(); _o->mode = _e; }
+  { auto _e = modelFormat(); _o->modelFormat = _e; }
+  { auto _e = type(); _o->type = _e; }
 }
 
 inline flatbuffers::Offset<Dequantize> Dequantize::Pack(flatbuffers::FlatBufferBuilder &_fbb, const DequantizeT* _o, const flatbuffers::rehasher_function_t *_rehasher) {
@@ -2019,25 +1968,25 @@ inline flatbuffers::Offset<Dequantize> CreateDequantize(flatbuffers::FlatBufferB
 }
 
 inline QuantizedAvgPoolT *QuantizedAvgPool::UnPack(const flatbuffers::resolver_function_t *_resolver) const {
-  auto _o = new QuantizedAvgPoolT();
-  UnPackTo(_o, _resolver);
-  return _o;
+  auto _o = std::unique_ptr<QuantizedAvgPoolT>(new QuantizedAvgPoolT());
+  UnPackTo(_o.get(), _resolver);
+  return _o.release();
 }
 
 inline void QuantizedAvgPool::UnPackTo(QuantizedAvgPoolT *_o, const flatbuffers::resolver_function_t *_resolver) const {
   (void)_o;
   (void)_resolver;
-  { auto _e = kernelX(); _o->kernelX = _e; };
-  { auto _e = kernelY(); _o->kernelY = _e; };
-  { auto _e = modelFormat(); _o->modelFormat = _e; };
-  { auto _e = outputActivationMax(); _o->outputActivationMax = _e; };
-  { auto _e = outputActivationMin(); _o->outputActivationMin = _e; };
-  { auto _e = padType(); _o->padType = _e; };
-  { auto _e = padX(); _o->padX = _e; };
-  { auto _e = padY(); _o->padY = _e; };
-  { auto _e = strideX(); _o->strideX = _e; };
-  { auto _e = strideY(); _o->strideY = _e; };
-  { auto _e = type(); _o->type = _e; };
+  { auto _e = kernelX(); _o->kernelX = _e; }
+  { auto _e = kernelY(); _o->kernelY = _e; }
+  { auto _e = modelFormat(); _o->modelFormat = _e; }
+  { auto _e = outputActivationMax(); _o->outputActivationMax = _e; }
+  { auto _e = outputActivationMin(); _o->outputActivationMin = _e; }
+  { auto _e = padType(); _o->padType = _e; }
+  { auto _e = padX(); _o->padX = _e; }
+  { auto _e = padY(); _o->padY = _e; }
+  { auto _e = strideX(); _o->strideX = _e; }
+  { auto _e = strideY(); _o->strideY = _e; }
+  { auto _e = type(); _o->type = _e; }
 }
 
 inline flatbuffers::Offset<QuantizedAvgPool> QuantizedAvgPool::Pack(flatbuffers::FlatBufferBuilder &_fbb, const QuantizedAvgPoolT* _o, const flatbuffers::rehasher_function_t *_rehasher) {
@@ -2075,19 +2024,19 @@ inline flatbuffers::Offset<QuantizedAvgPool> CreateQuantizedAvgPool(flatbuffers:
 }
 
 inline QuantizedBiasAddT *QuantizedBiasAdd::UnPack(const flatbuffers::resolver_function_t *_resolver) const {
-  auto _o = new QuantizedBiasAddT();
-  UnPackTo(_o, _resolver);
-  return _o;
+  auto _o = std::unique_ptr<QuantizedBiasAddT>(new QuantizedBiasAddT());
+  UnPackTo(_o.get(), _resolver);
+  return _o.release();
 }
 
 inline void QuantizedBiasAdd::UnPackTo(QuantizedBiasAddT *_o, const flatbuffers::resolver_function_t *_resolver) const {
   (void)_o;
   (void)_resolver;
-  { auto _e = bias(); if (_e) { _o->bias.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->bias[_i] = _e->Get(_i); } } };
-  { auto _e = inputType(); _o->inputType = _e; };
-  { auto _e = max(); _o->max = _e; };
-  { auto _e = min(); _o->min = _e; };
-  { auto _e = outputType(); _o->outputType = _e; };
+  { auto _e = bias(); if (_e) { _o->bias.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->bias[_i] = _e->Get(_i); } } }
+  { auto _e = inputType(); _o->inputType = _e; }
+  { auto _e = max(); _o->max = _e; }
+  { auto _e = min(); _o->min = _e; }
+  { auto _e = outputType(); _o->outputType = _e; }
 }
 
 inline flatbuffers::Offset<QuantizedBiasAdd> QuantizedBiasAdd::Pack(flatbuffers::FlatBufferBuilder &_fbb, const QuantizedBiasAddT* _o, const flatbuffers::rehasher_function_t *_rehasher) {
@@ -2113,19 +2062,19 @@ inline flatbuffers::Offset<QuantizedBiasAdd> CreateQuantizedBiasAdd(flatbuffers:
 }
 
 inline QuantizedConcatT *QuantizedConcat::UnPack(const flatbuffers::resolver_function_t *_resolver) const {
-  auto _o = new QuantizedConcatT();
-  UnPackTo(_o, _resolver);
-  return _o;
+  auto _o = std::unique_ptr<QuantizedConcatT>(new QuantizedConcatT());
+  UnPackTo(_o.get(), _resolver);
+  return _o.release();
 }
 
 inline void QuantizedConcat::UnPackTo(QuantizedConcatT *_o, const flatbuffers::resolver_function_t *_resolver) const {
   (void)_o;
   (void)_resolver;
-  { auto _e = activationType(); _o->activationType = _e; };
-  { auto _e = axis(); _o->axis = _e; };
-  { auto _e = inputScale(); if (_e) { _o->inputScale.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->inputScale[_i] = _e->Get(_i); } } };
-  { auto _e = inputZeroPoint(); if (_e) { _o->inputZeroPoint.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->inputZeroPoint[_i] = _e->Get(_i); } } };
-  { auto _e = outputQuantizedParam(); if (_e) _o->outputQuantizedParam = std::unique_ptr<QuantizedParamT>(_e->UnPack(_resolver)); };
+  { auto _e = activationType(); _o->activationType = _e; }
+  { auto _e = axis(); _o->axis = _e; }
+  { auto _e = inputScale(); if (_e) { _o->inputScale.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->inputScale[_i] = _e->Get(_i); } } }
+  { auto _e = inputZeroPoint(); if (_e) { _o->inputZeroPoint.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->inputZeroPoint[_i] = _e->Get(_i); } } }
+  { auto _e = outputQuantizedParam(); if (_e) _o->outputQuantizedParam = std::unique_ptr<MNN::QuantizedParamT>(_e->UnPack(_resolver)); }
 }
 
 inline flatbuffers::Offset<QuantizedConcat> QuantizedConcat::Pack(flatbuffers::FlatBufferBuilder &_fbb, const QuantizedConcatT* _o, const flatbuffers::rehasher_function_t *_rehasher) {
@@ -2151,16 +2100,16 @@ inline flatbuffers::Offset<QuantizedConcat> CreateQuantizedConcat(flatbuffers::F
 }
 
 inline QuantizedLogisticT *QuantizedLogistic::UnPack(const flatbuffers::resolver_function_t *_resolver) const {
-  auto _o = new QuantizedLogisticT();
-  UnPackTo(_o, _resolver);
-  return _o;
+  auto _o = std::unique_ptr<QuantizedLogisticT>(new QuantizedLogisticT());
+  UnPackTo(_o.get(), _resolver);
+  return _o.release();
 }
 
 inline void QuantizedLogistic::UnPackTo(QuantizedLogisticT *_o, const flatbuffers::resolver_function_t *_resolver) const {
   (void)_o;
   (void)_resolver;
-  { auto _e = inputQuantizedParam(); if (_e) _o->inputQuantizedParam = std::unique_ptr<QuantizedParamT>(_e->UnPack(_resolver)); };
-  { auto _e = outputQuantizedParam(); if (_e) _o->outputQuantizedParam = std::unique_ptr<QuantizedParamT>(_e->UnPack(_resolver)); };
+  { auto _e = inputQuantizedParam(); if (_e) _o->inputQuantizedParam = std::unique_ptr<MNN::QuantizedParamT>(_e->UnPack(_resolver)); }
+  { auto _e = outputQuantizedParam(); if (_e) _o->outputQuantizedParam = std::unique_ptr<MNN::QuantizedParamT>(_e->UnPack(_resolver)); }
 }
 
 inline flatbuffers::Offset<QuantizedLogistic> QuantizedLogistic::Pack(flatbuffers::FlatBufferBuilder &_fbb, const QuantizedLogisticT* _o, const flatbuffers::rehasher_function_t *_rehasher) {
@@ -2180,16 +2129,16 @@ inline flatbuffers::Offset<QuantizedLogistic> CreateQuantizedLogistic(flatbuffer
 }
 
 inline QuantizedMatMulT *QuantizedMatMul::UnPack(const flatbuffers::resolver_function_t *_resolver) const {
-  auto _o = new QuantizedMatMulT();
-  UnPackTo(_o, _resolver);
-  return _o;
+  auto _o = std::unique_ptr<QuantizedMatMulT>(new QuantizedMatMulT());
+  UnPackTo(_o.get(), _resolver);
+  return _o.release();
 }
 
 inline void QuantizedMatMul::UnPackTo(QuantizedMatMulT *_o, const flatbuffers::resolver_function_t *_resolver) const {
   (void)_o;
   (void)_resolver;
-  { auto _e = transposeA(); _o->transposeA = _e; };
-  { auto _e = transposeB(); _o->transposeB = _e; };
+  { auto _e = transposeA(); _o->transposeA = _e; }
+  { auto _e = transposeB(); _o->transposeB = _e; }
 }
 
 inline flatbuffers::Offset<QuantizedMatMul> QuantizedMatMul::Pack(flatbuffers::FlatBufferBuilder &_fbb, const QuantizedMatMulT* _o, const flatbuffers::rehasher_function_t *_rehasher) {
@@ -2209,25 +2158,25 @@ inline flatbuffers::Offset<QuantizedMatMul> CreateQuantizedMatMul(flatbuffers::F
 }
 
 inline QuantizedMaxPoolT *QuantizedMaxPool::UnPack(const flatbuffers::resolver_function_t *_resolver) const {
-  auto _o = new QuantizedMaxPoolT();
-  UnPackTo(_o, _resolver);
-  return _o;
+  auto _o = std::unique_ptr<QuantizedMaxPoolT>(new QuantizedMaxPoolT());
+  UnPackTo(_o.get(), _resolver);
+  return _o.release();
 }
 
 inline void QuantizedMaxPool::UnPackTo(QuantizedMaxPoolT *_o, const flatbuffers::resolver_function_t *_resolver) const {
   (void)_o;
   (void)_resolver;
-  { auto _e = kernelX(); _o->kernelX = _e; };
-  { auto _e = kernelY(); _o->kernelY = _e; };
-  { auto _e = modelFormat(); _o->modelFormat = _e; };
-  { auto _e = outputActivationMax(); _o->outputActivationMax = _e; };
-  { auto _e = outputActivationMin(); _o->outputActivationMin = _e; };
-  { auto _e = padType(); _o->padType = _e; };
-  { auto _e = padX(); _o->padX = _e; };
-  { auto _e = padY(); _o->padY = _e; };
-  { auto _e = strideX(); _o->strideX = _e; };
-  { auto _e = strideY(); _o->strideY = _e; };
-  { auto _e = type(); _o->type = _e; };
+  { auto _e = kernelX(); _o->kernelX = _e; }
+  { auto _e = kernelY(); _o->kernelY = _e; }
+  { auto _e = modelFormat(); _o->modelFormat = _e; }
+  { auto _e = outputActivationMax(); _o->outputActivationMax = _e; }
+  { auto _e = outputActivationMin(); _o->outputActivationMin = _e; }
+  { auto _e = padType(); _o->padType = _e; }
+  { auto _e = padX(); _o->padX = _e; }
+  { auto _e = padY(); _o->padY = _e; }
+  { auto _e = strideX(); _o->strideX = _e; }
+  { auto _e = strideY(); _o->strideY = _e; }
+  { auto _e = type(); _o->type = _e; }
 }
 
 inline flatbuffers::Offset<QuantizedMaxPool> QuantizedMaxPool::Pack(flatbuffers::FlatBufferBuilder &_fbb, const QuantizedMaxPoolT* _o, const flatbuffers::rehasher_function_t *_rehasher) {
@@ -2265,15 +2214,15 @@ inline flatbuffers::Offset<QuantizedMaxPool> CreateQuantizedMaxPool(flatbuffers:
 }
 
 inline QuantizedReluT *QuantizedRelu::UnPack(const flatbuffers::resolver_function_t *_resolver) const {
-  auto _o = new QuantizedReluT();
-  UnPackTo(_o, _resolver);
-  return _o;
+  auto _o = std::unique_ptr<QuantizedReluT>(new QuantizedReluT());
+  UnPackTo(_o.get(), _resolver);
+  return _o.release();
 }
 
 inline void QuantizedRelu::UnPackTo(QuantizedReluT *_o, const flatbuffers::resolver_function_t *_resolver) const {
   (void)_o;
   (void)_resolver;
-  { auto _e = type(); _o->type = _e; };
+  { auto _e = type(); _o->type = _e; }
 }
 
 inline flatbuffers::Offset<QuantizedRelu> QuantizedRelu::Pack(flatbuffers::FlatBufferBuilder &_fbb, const QuantizedReluT* _o, const flatbuffers::rehasher_function_t *_rehasher) {
@@ -2291,15 +2240,15 @@ inline flatbuffers::Offset<QuantizedRelu> CreateQuantizedRelu(flatbuffers::FlatB
 }
 
 inline QuantizedRelu6T *QuantizedRelu6::UnPack(const flatbuffers::resolver_function_t *_resolver) const {
-  auto _o = new QuantizedRelu6T();
-  UnPackTo(_o, _resolver);
-  return _o;
+  auto _o = std::unique_ptr<QuantizedRelu6T>(new QuantizedRelu6T());
+  UnPackTo(_o.get(), _resolver);
+  return _o.release();
 }
 
 inline void QuantizedRelu6::UnPackTo(QuantizedRelu6T *_o, const flatbuffers::resolver_function_t *_resolver) const {
   (void)_o;
   (void)_resolver;
-  { auto _e = type(); _o->type = _e; };
+  { auto _e = type(); _o->type = _e; }
 }
 
 inline flatbuffers::Offset<QuantizedRelu6> QuantizedRelu6::Pack(flatbuffers::FlatBufferBuilder &_fbb, const QuantizedRelu6T* _o, const flatbuffers::rehasher_function_t *_rehasher) {
@@ -2317,16 +2266,16 @@ inline flatbuffers::Offset<QuantizedRelu6> CreateQuantizedRelu6(flatbuffers::Fla
 }
 
 inline QuantizedReshapeT *QuantizedReshape::UnPack(const flatbuffers::resolver_function_t *_resolver) const {
-  auto _o = new QuantizedReshapeT();
-  UnPackTo(_o, _resolver);
-  return _o;
+  auto _o = std::unique_ptr<QuantizedReshapeT>(new QuantizedReshapeT());
+  UnPackTo(_o.get(), _resolver);
+  return _o.release();
 }
 
 inline void QuantizedReshape::UnPackTo(QuantizedReshapeT *_o, const flatbuffers::resolver_function_t *_resolver) const {
   (void)_o;
   (void)_resolver;
-  { auto _e = dims(); if (_e) { _o->dims.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->dims[_i] = _e->Get(_i); } } };
-  { auto _e = modelFormat(); _o->modelFormat = _e; };
+  { auto _e = dims(); if (_e) { _o->dims.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->dims[_i] = _e->Get(_i); } } }
+  { auto _e = modelFormat(); _o->modelFormat = _e; }
 }
 
 inline flatbuffers::Offset<QuantizedReshape> QuantizedReshape::Pack(flatbuffers::FlatBufferBuilder &_fbb, const QuantizedReshapeT* _o, const flatbuffers::rehasher_function_t *_rehasher) {
@@ -2346,16 +2295,16 @@ inline flatbuffers::Offset<QuantizedReshape> CreateQuantizedReshape(flatbuffers:
 }
 
 inline QuantizedSoftmaxT *QuantizedSoftmax::UnPack(const flatbuffers::resolver_function_t *_resolver) const {
-  auto _o = new QuantizedSoftmaxT();
-  UnPackTo(_o, _resolver);
-  return _o;
+  auto _o = std::unique_ptr<QuantizedSoftmaxT>(new QuantizedSoftmaxT());
+  UnPackTo(_o.get(), _resolver);
+  return _o.release();
 }
 
 inline void QuantizedSoftmax::UnPackTo(QuantizedSoftmaxT *_o, const flatbuffers::resolver_function_t *_resolver) const {
   (void)_o;
   (void)_resolver;
-  { auto _e = beta(); _o->beta = _e; };
-  { auto _e = inputScale(); _o->inputScale = _e; };
+  { auto _e = beta(); _o->beta = _e; }
+  { auto _e = inputScale(); _o->inputScale = _e; }
 }
 
 inline flatbuffers::Offset<QuantizedSoftmax> QuantizedSoftmax::Pack(flatbuffers::FlatBufferBuilder &_fbb, const QuantizedSoftmaxT* _o, const flatbuffers::rehasher_function_t *_rehasher) {
@@ -2375,17 +2324,17 @@ inline flatbuffers::Offset<QuantizedSoftmax> CreateQuantizedSoftmax(flatbuffers:
 }
 
 inline QuantizeV2T *QuantizeV2::UnPack(const flatbuffers::resolver_function_t *_resolver) const {
-  auto _o = new QuantizeV2T();
-  UnPackTo(_o, _resolver);
-  return _o;
+  auto _o = std::unique_ptr<QuantizeV2T>(new QuantizeV2T());
+  UnPackTo(_o.get(), _resolver);
+  return _o.release();
 }
 
 inline void QuantizeV2::UnPackTo(QuantizeV2T *_o, const flatbuffers::resolver_function_t *_resolver) const {
   (void)_o;
   (void)_resolver;
-  { auto _e = type(); _o->type = _e; };
-  { auto _e = mode(); _o->mode = _e; };
-  { auto _e = roundMode(); _o->roundMode = _e; };
+  { auto _e = type(); _o->type = _e; }
+  { auto _e = mode(); _o->mode = _e; }
+  { auto _e = roundMode(); _o->roundMode = _e; }
 }
 
 inline flatbuffers::Offset<QuantizeV2> QuantizeV2::Pack(flatbuffers::FlatBufferBuilder &_fbb, const QuantizeV2T* _o, const flatbuffers::rehasher_function_t *_rehasher) {
@@ -2407,9 +2356,9 @@ inline flatbuffers::Offset<QuantizeV2> CreateQuantizeV2(flatbuffers::FlatBufferB
 }
 
 inline RequantizationRangeT *RequantizationRange::UnPack(const flatbuffers::resolver_function_t *_resolver) const {
-  auto _o = new RequantizationRangeT();
-  UnPackTo(_o, _resolver);
-  return _o;
+  auto _o = std::unique_ptr<RequantizationRangeT>(new RequantizationRangeT());
+  UnPackTo(_o.get(), _resolver);
+  return _o.release();
 }
 
 inline void RequantizationRange::UnPackTo(RequantizationRangeT *_o, const flatbuffers::resolver_function_t *_resolver) const {
@@ -2430,9 +2379,9 @@ inline flatbuffers::Offset<RequantizationRange> CreateRequantizationRange(flatbu
 }
 
 inline RequantizeT *Requantize::UnPack(const flatbuffers::resolver_function_t *_resolver) const {
-  auto _o = new RequantizeT();
-  UnPackTo(_o, _resolver);
-  return _o;
+  auto _o = std::unique_ptr<RequantizeT>(new RequantizeT());
+  UnPackTo(_o.get(), _resolver);
+  return _o.release();
 }
 
 inline void Requantize::UnPackTo(RequantizeT *_o, const flatbuffers::resolver_function_t *_resolver) const {
@@ -2453,29 +2402,29 @@ inline flatbuffers::Offset<Requantize> CreateRequantize(flatbuffers::FlatBufferB
 }
 
 inline TfQuantizedConv2DT *TfQuantizedConv2D::UnPack(const flatbuffers::resolver_function_t *_resolver) const {
-  auto _o = new TfQuantizedConv2DT();
-  UnPackTo(_o, _resolver);
-  return _o;
+  auto _o = std::unique_ptr<TfQuantizedConv2DT>(new TfQuantizedConv2DT());
+  UnPackTo(_o.get(), _resolver);
+  return _o.release();
 }
 
 inline void TfQuantizedConv2D::UnPackTo(TfQuantizedConv2DT *_o, const flatbuffers::resolver_function_t *_resolver) const {
   (void)_o;
   (void)_resolver;
-  { auto _e = bias(); if (_e) { _o->bias.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->bias[_i] = _e->Get(_i); } } };
-  { auto _e = biasflag(); _o->biasflag = _e; };
-  { auto _e = common(); if (_e) _o->common = std::unique_ptr<Convolution2DCommonT>(_e->UnPack(_resolver)); };
-  { auto _e = weight(); if (_e) { _o->weight.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->weight[_i] = _e->Get(_i); } } };
-  { auto _e = activationType(); _o->activationType = _e; };
-  { auto _e = multiplier(); _o->multiplier = _e; };
-  { auto _e = outMax(); _o->outMax = _e; };
-  { auto _e = outMin(); _o->outMin = _e; };
-  { auto _e = shift(); _o->shift = _e; };
-  { auto _e = biasQuantizedParam(); if (_e) _o->biasQuantizedParam = std::unique_ptr<QuantizedParamT>(_e->UnPack(_resolver)); };
-  { auto _e = depthMultiplier(); _o->depthMultiplier = _e; };
-  { auto _e = filterQuantizedParam(); if (_e) _o->filterQuantizedParam = std::unique_ptr<QuantizedParamT>(_e->UnPack(_resolver)); };
-  { auto _e = inputQuantizedParam(); if (_e) _o->inputQuantizedParam = std::unique_ptr<QuantizedParamT>(_e->UnPack(_resolver)); };
-  { auto _e = modelFormat(); _o->modelFormat = _e; };
-  { auto _e = outputQuantizedParam(); if (_e) _o->outputQuantizedParam = std::unique_ptr<QuantizedParamT>(_e->UnPack(_resolver)); };
+  { auto _e = bias(); if (_e) { _o->bias.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->bias[_i] = _e->Get(_i); } } }
+  { auto _e = biasflag(); _o->biasflag = _e; }
+  { auto _e = common(); if (_e) _o->common = std::unique_ptr<MNN::Convolution2DCommonT>(_e->UnPack(_resolver)); }
+  { auto _e = weight(); if (_e) { _o->weight.resize(_e->size()); std::copy(_e->begin(), _e->end(), _o->weight.begin()); } }
+  { auto _e = activationType(); _o->activationType = _e; }
+  { auto _e = multiplier(); _o->multiplier = _e; }
+  { auto _e = outMax(); _o->outMax = _e; }
+  { auto _e = outMin(); _o->outMin = _e; }
+  { auto _e = shift(); _o->shift = _e; }
+  { auto _e = biasQuantizedParam(); if (_e) _o->biasQuantizedParam = std::unique_ptr<MNN::QuantizedParamT>(_e->UnPack(_resolver)); }
+  { auto _e = depthMultiplier(); _o->depthMultiplier = _e; }
+  { auto _e = filterQuantizedParam(); if (_e) _o->filterQuantizedParam = std::unique_ptr<MNN::QuantizedParamT>(_e->UnPack(_resolver)); }
+  { auto _e = inputQuantizedParam(); if (_e) _o->inputQuantizedParam = std::unique_ptr<MNN::QuantizedParamT>(_e->UnPack(_resolver)); }
+  { auto _e = modelFormat(); _o->modelFormat = _e; }
+  { auto _e = outputQuantizedParam(); if (_e) _o->outputQuantizedParam = std::unique_ptr<MNN::QuantizedParamT>(_e->UnPack(_resolver)); }
 }
 
 inline flatbuffers::Offset<TfQuantizedConv2D> TfQuantizedConv2D::Pack(flatbuffers::FlatBufferBuilder &_fbb, const TfQuantizedConv2DT* _o, const flatbuffers::rehasher_function_t *_rehasher) {
@@ -2531,7 +2480,7 @@ inline const flatbuffers::TypeTable *FusedActivationTypeTable() {
     { flatbuffers::ET_CHAR, 0, 0 }
   };
   static const flatbuffers::TypeFunction type_refs[] = {
-    FusedActivationTypeTable
+    MNN::FusedActivationTypeTable
   };
   static const char * const names[] = {
     "kTfLiteActNone",
@@ -2543,7 +2492,7 @@ inline const flatbuffers::TypeTable *FusedActivationTypeTable() {
     "kTfLiteActSigmoid"
   };
   static const flatbuffers::TypeTable tt = {
-    flatbuffers::ST_ENUM, 7, type_codes, type_refs, nullptr, names
+    flatbuffers::ST_ENUM, 7, type_codes, type_refs, nullptr, nullptr, names
   };
   return &tt;
 }
@@ -2554,14 +2503,14 @@ inline const flatbuffers::TypeTable *ModeFormatTypeTable() {
     { flatbuffers::ET_CHAR, 0, 0 }
   };
   static const flatbuffers::TypeFunction type_refs[] = {
-    ModeFormatTypeTable
+    MNN::ModeFormatTypeTable
   };
   static const char * const names[] = {
     "TENSORFLOW",
     "TFLITE"
   };
   static const flatbuffers::TypeTable tt = {
-    flatbuffers::ST_ENUM, 2, type_codes, type_refs, nullptr, names
+    flatbuffers::ST_ENUM, 2, type_codes, type_refs, nullptr, nullptr, names
   };
   return &tt;
 }
@@ -2573,7 +2522,7 @@ inline const flatbuffers::TypeTable *QuantizeModeTypeTable() {
     { flatbuffers::ET_CHAR, 0, 0 }
   };
   static const flatbuffers::TypeFunction type_refs[] = {
-    QuantizeModeTypeTable
+    MNN::QuantizeModeTypeTable
   };
   static const char * const names[] = {
     "MIN_COMBINED",
@@ -2581,7 +2530,7 @@ inline const flatbuffers::TypeTable *QuantizeModeTypeTable() {
     "SCALED"
   };
   static const flatbuffers::TypeTable tt = {
-    flatbuffers::ST_ENUM, 3, type_codes, type_refs, nullptr, names
+    flatbuffers::ST_ENUM, 3, type_codes, type_refs, nullptr, nullptr, names
   };
   return &tt;
 }
@@ -2592,14 +2541,14 @@ inline const flatbuffers::TypeTable *QuantizeRoundModeTypeTable() {
     { flatbuffers::ET_CHAR, 0, 0 }
   };
   static const flatbuffers::TypeFunction type_refs[] = {
-    QuantizeRoundModeTypeTable
+    MNN::QuantizeRoundModeTypeTable
   };
   static const char * const names[] = {
     "HALF_AWAY_FROM_ZERO",
     "HALF_TO_EVEN"
   };
   static const flatbuffers::TypeTable tt = {
-    flatbuffers::ST_ENUM, 2, type_codes, type_refs, nullptr, names
+    flatbuffers::ST_ENUM, 2, type_codes, type_refs, nullptr, nullptr, names
   };
   return &tt;
 }
@@ -2614,7 +2563,7 @@ inline const flatbuffers::TypeTable *QuantizedParamTypeTable() {
     "scale"
   };
   static const flatbuffers::TypeTable tt = {
-    flatbuffers::ST_TABLE, 2, type_codes, nullptr, nullptr, names
+    flatbuffers::ST_TABLE, 2, type_codes, nullptr, nullptr, nullptr, names
   };
   return &tt;
 }
@@ -2627,8 +2576,8 @@ inline const flatbuffers::TypeTable *QuantizedAddTypeTable() {
     { flatbuffers::ET_SEQUENCE, 0, 1 }
   };
   static const flatbuffers::TypeFunction type_refs[] = {
-    FusedActivationTypeTable,
-    QuantizedParamTypeTable
+    MNN::FusedActivationTypeTable,
+    MNN::QuantizedParamTypeTable
   };
   static const char * const names[] = {
     "activationType",
@@ -2637,7 +2586,7 @@ inline const flatbuffers::TypeTable *QuantizedAddTypeTable() {
     "outputQuantizedParam"
   };
   static const flatbuffers::TypeTable tt = {
-    flatbuffers::ST_TABLE, 4, type_codes, type_refs, nullptr, names
+    flatbuffers::ST_TABLE, 4, type_codes, type_refs, nullptr, nullptr, names
   };
   return &tt;
 }
@@ -2650,10 +2599,10 @@ inline const flatbuffers::TypeTable *DequantizeTypeTable() {
     { flatbuffers::ET_INT, 0, 3 }
   };
   static const flatbuffers::TypeFunction type_refs[] = {
-    QuantizedParamTypeTable,
-    QuantizeModeTypeTable,
-    ModeFormatTypeTable,
-    DataTypeTypeTable
+    MNN::QuantizedParamTypeTable,
+    MNN::QuantizeModeTypeTable,
+    MNN::ModeFormatTypeTable,
+    MNN::DataTypeTypeTable
   };
   static const char * const names[] = {
     "inputQuantizedParam",
@@ -2662,7 +2611,7 @@ inline const flatbuffers::TypeTable *DequantizeTypeTable() {
     "type"
   };
   static const flatbuffers::TypeTable tt = {
-    flatbuffers::ST_TABLE, 4, type_codes, type_refs, nullptr, names
+    flatbuffers::ST_TABLE, 4, type_codes, type_refs, nullptr, nullptr, names
   };
   return &tt;
 }
@@ -2682,9 +2631,9 @@ inline const flatbuffers::TypeTable *QuantizedAvgPoolTypeTable() {
     { flatbuffers::ET_INT, 0, 2 }
   };
   static const flatbuffers::TypeFunction type_refs[] = {
-    ModeFormatTypeTable,
-    PoolPadTypeTypeTable,
-    DataTypeTypeTable
+    MNN::ModeFormatTypeTable,
+    MNN::PoolPadTypeTypeTable,
+    MNN::DataTypeTypeTable
   };
   static const char * const names[] = {
     "kernelX",
@@ -2700,7 +2649,7 @@ inline const flatbuffers::TypeTable *QuantizedAvgPoolTypeTable() {
     "type"
   };
   static const flatbuffers::TypeTable tt = {
-    flatbuffers::ST_TABLE, 11, type_codes, type_refs, nullptr, names
+    flatbuffers::ST_TABLE, 11, type_codes, type_refs, nullptr, nullptr, names
   };
   return &tt;
 }
@@ -2714,7 +2663,7 @@ inline const flatbuffers::TypeTable *QuantizedBiasAddTypeTable() {
     { flatbuffers::ET_INT, 0, 0 }
   };
   static const flatbuffers::TypeFunction type_refs[] = {
-    DataTypeTypeTable
+    MNN::DataTypeTypeTable
   };
   static const char * const names[] = {
     "bias",
@@ -2724,7 +2673,7 @@ inline const flatbuffers::TypeTable *QuantizedBiasAddTypeTable() {
     "outputType"
   };
   static const flatbuffers::TypeTable tt = {
-    flatbuffers::ST_TABLE, 5, type_codes, type_refs, nullptr, names
+    flatbuffers::ST_TABLE, 5, type_codes, type_refs, nullptr, nullptr, names
   };
   return &tt;
 }
@@ -2738,8 +2687,8 @@ inline const flatbuffers::TypeTable *QuantizedConcatTypeTable() {
     { flatbuffers::ET_SEQUENCE, 0, 1 }
   };
   static const flatbuffers::TypeFunction type_refs[] = {
-    FusedActivationTypeTable,
-    QuantizedParamTypeTable
+    MNN::FusedActivationTypeTable,
+    MNN::QuantizedParamTypeTable
   };
   static const char * const names[] = {
     "activationType",
@@ -2749,7 +2698,7 @@ inline const flatbuffers::TypeTable *QuantizedConcatTypeTable() {
     "outputQuantizedParam"
   };
   static const flatbuffers::TypeTable tt = {
-    flatbuffers::ST_TABLE, 5, type_codes, type_refs, nullptr, names
+    flatbuffers::ST_TABLE, 5, type_codes, type_refs, nullptr, nullptr, names
   };
   return &tt;
 }
@@ -2760,14 +2709,14 @@ inline const flatbuffers::TypeTable *QuantizedLogisticTypeTable() {
     { flatbuffers::ET_SEQUENCE, 0, 0 }
   };
   static const flatbuffers::TypeFunction type_refs[] = {
-    QuantizedParamTypeTable
+    MNN::QuantizedParamTypeTable
   };
   static const char * const names[] = {
     "inputQuantizedParam",
     "outputQuantizedParam"
   };
   static const flatbuffers::TypeTable tt = {
-    flatbuffers::ST_TABLE, 2, type_codes, type_refs, nullptr, names
+    flatbuffers::ST_TABLE, 2, type_codes, type_refs, nullptr, nullptr, names
   };
   return &tt;
 }
@@ -2782,7 +2731,7 @@ inline const flatbuffers::TypeTable *QuantizedMatMulTypeTable() {
     "transposeB"
   };
   static const flatbuffers::TypeTable tt = {
-    flatbuffers::ST_TABLE, 2, type_codes, nullptr, nullptr, names
+    flatbuffers::ST_TABLE, 2, type_codes, nullptr, nullptr, nullptr, names
   };
   return &tt;
 }
@@ -2802,9 +2751,9 @@ inline const flatbuffers::TypeTable *QuantizedMaxPoolTypeTable() {
     { flatbuffers::ET_INT, 0, 2 }
   };
   static const flatbuffers::TypeFunction type_refs[] = {
-    ModeFormatTypeTable,
-    PoolPadTypeTypeTable,
-    DataTypeTypeTable
+    MNN::ModeFormatTypeTable,
+    MNN::PoolPadTypeTypeTable,
+    MNN::DataTypeTypeTable
   };
   static const char * const names[] = {
     "kernelX",
@@ -2820,7 +2769,7 @@ inline const flatbuffers::TypeTable *QuantizedMaxPoolTypeTable() {
     "type"
   };
   static const flatbuffers::TypeTable tt = {
-    flatbuffers::ST_TABLE, 11, type_codes, type_refs, nullptr, names
+    flatbuffers::ST_TABLE, 11, type_codes, type_refs, nullptr, nullptr, names
   };
   return &tt;
 }
@@ -2830,13 +2779,13 @@ inline const flatbuffers::TypeTable *QuantizedReluTypeTable() {
     { flatbuffers::ET_INT, 0, 0 }
   };
   static const flatbuffers::TypeFunction type_refs[] = {
-    DataTypeTypeTable
+    MNN::DataTypeTypeTable
   };
   static const char * const names[] = {
     "type"
   };
   static const flatbuffers::TypeTable tt = {
-    flatbuffers::ST_TABLE, 1, type_codes, type_refs, nullptr, names
+    flatbuffers::ST_TABLE, 1, type_codes, type_refs, nullptr, nullptr, names
   };
   return &tt;
 }
@@ -2846,13 +2795,13 @@ inline const flatbuffers::TypeTable *QuantizedRelu6TypeTable() {
     { flatbuffers::ET_INT, 0, 0 }
   };
   static const flatbuffers::TypeFunction type_refs[] = {
-    DataTypeTypeTable
+    MNN::DataTypeTypeTable
   };
   static const char * const names[] = {
     "type"
   };
   static const flatbuffers::TypeTable tt = {
-    flatbuffers::ST_TABLE, 1, type_codes, type_refs, nullptr, names
+    flatbuffers::ST_TABLE, 1, type_codes, type_refs, nullptr, nullptr, names
   };
   return &tt;
 }
@@ -2863,14 +2812,14 @@ inline const flatbuffers::TypeTable *QuantizedReshapeTypeTable() {
     { flatbuffers::ET_CHAR, 0, 0 }
   };
   static const flatbuffers::TypeFunction type_refs[] = {
-    ModeFormatTypeTable
+    MNN::ModeFormatTypeTable
   };
   static const char * const names[] = {
     "dims",
     "modelFormat"
   };
   static const flatbuffers::TypeTable tt = {
-    flatbuffers::ST_TABLE, 2, type_codes, type_refs, nullptr, names
+    flatbuffers::ST_TABLE, 2, type_codes, type_refs, nullptr, nullptr, names
   };
   return &tt;
 }
@@ -2885,7 +2834,7 @@ inline const flatbuffers::TypeTable *QuantizedSoftmaxTypeTable() {
     "inputScale"
   };
   static const flatbuffers::TypeTable tt = {
-    flatbuffers::ST_TABLE, 2, type_codes, nullptr, nullptr, names
+    flatbuffers::ST_TABLE, 2, type_codes, nullptr, nullptr, nullptr, names
   };
   return &tt;
 }
@@ -2897,9 +2846,9 @@ inline const flatbuffers::TypeTable *QuantizeV2TypeTable() {
     { flatbuffers::ET_CHAR, 0, 2 }
   };
   static const flatbuffers::TypeFunction type_refs[] = {
-    DataTypeTypeTable,
-    QuantizeModeTypeTable,
-    QuantizeRoundModeTypeTable
+    MNN::DataTypeTypeTable,
+    MNN::QuantizeModeTypeTable,
+    MNN::QuantizeRoundModeTypeTable
   };
   static const char * const names[] = {
     "type",
@@ -2907,21 +2856,21 @@ inline const flatbuffers::TypeTable *QuantizeV2TypeTable() {
     "roundMode"
   };
   static const flatbuffers::TypeTable tt = {
-    flatbuffers::ST_TABLE, 3, type_codes, type_refs, nullptr, names
+    flatbuffers::ST_TABLE, 3, type_codes, type_refs, nullptr, nullptr, names
   };
   return &tt;
 }
 
 inline const flatbuffers::TypeTable *RequantizationRangeTypeTable() {
   static const flatbuffers::TypeTable tt = {
-    flatbuffers::ST_TABLE, 0, nullptr, nullptr, nullptr, nullptr
+    flatbuffers::ST_TABLE, 0, nullptr, nullptr, nullptr, nullptr, nullptr
   };
   return &tt;
 }
 
 inline const flatbuffers::TypeTable *RequantizeTypeTable() {
   static const flatbuffers::TypeTable tt = {
-    flatbuffers::ST_TABLE, 0, nullptr, nullptr, nullptr, nullptr
+    flatbuffers::ST_TABLE, 0, nullptr, nullptr, nullptr, nullptr, nullptr
   };
   return &tt;
 }
@@ -2945,10 +2894,10 @@ inline const flatbuffers::TypeTable *TfQuantizedConv2DTypeTable() {
     { flatbuffers::ET_SEQUENCE, 0, 2 }
   };
   static const flatbuffers::TypeFunction type_refs[] = {
-    Convolution2DCommonTypeTable,
-    FusedActivationTypeTable,
-    QuantizedParamTypeTable,
-    ModeFormatTypeTable
+    MNN::Convolution2DCommonTypeTable,
+    MNN::FusedActivationTypeTable,
+    MNN::QuantizedParamTypeTable,
+    MNN::ModeFormatTypeTable
   };
   static const char * const names[] = {
     "bias",
@@ -2968,7 +2917,7 @@ inline const flatbuffers::TypeTable *TfQuantizedConv2DTypeTable() {
     "outputQuantizedParam"
   };
   static const flatbuffers::TypeTable tt = {
-    flatbuffers::ST_TABLE, 15, type_codes, type_refs, nullptr, names
+    flatbuffers::ST_TABLE, 15, type_codes, type_refs, nullptr, nullptr, names
   };
   return &tt;
 }
diff --git a/schema/current/Tensor_generated.h b/schema/current/Tensor_generated.h
index 6c7c0baa..455e66e9 100644
--- a/schema/current/Tensor_generated.h
+++ b/schema/current/Tensor_generated.h
@@ -4,21 +4,26 @@
 #ifndef FLATBUFFERS_GENERATED_TENSOR_MNN_H_
 #define FLATBUFFERS_GENERATED_TENSOR_MNN_H_
 
+#include "flatbuffers/flatbuffers.h"
 
 #include "Type_generated.h"
 
 namespace MNN {
 
 struct Blob;
+struct BlobBuilder;
 struct BlobT;
 
 struct ListValue;
+struct ListValueBuilder;
 struct ListValueT;
 
 struct Attribute;
+struct AttributeBuilder;
 struct AttributeT;
 
 struct NamedAttrList;
+struct NamedAttrListBuilder;
 struct NamedAttrListT;
 
 inline const flatbuffers::TypeTable *BlobTypeTable();
@@ -29,7 +34,7 @@ inline const flatbuffers::TypeTable *AttributeTypeTable();
 
 inline const flatbuffers::TypeTable *NamedAttrListTypeTable();
 
-enum MNN_DATA_FORMAT {
+enum MNN_DATA_FORMAT : int8_t {
   MNN_DATA_FORMAT_NCHW = 0,
   MNN_DATA_FORMAT_NHWC = 1,
   MNN_DATA_FORMAT_NC4HW4 = 2,
@@ -51,7 +56,7 @@ inline const MNN_DATA_FORMAT (&EnumValuesMNN_DATA_FORMAT())[5] {
 }
 
 inline const char * const *EnumNamesMNN_DATA_FORMAT() {
-  static const char * const names[] = {
+  static const char * const names[6] = {
     "NCHW",
     "NHWC",
     "NC4HW4",
@@ -63,30 +68,27 @@ inline const char * const *EnumNamesMNN_DATA_FORMAT() {
 }
 
 inline const char *EnumNameMNN_DATA_FORMAT(MNN_DATA_FORMAT e) {
-  if (e < MNN_DATA_FORMAT_NCHW || e > MNN_DATA_FORMAT_UNKNOWN) return "";
-  const size_t index = static_cast<int>(e);
+  if (flatbuffers::IsOutRange(e, MNN_DATA_FORMAT_NCHW, MNN_DATA_FORMAT_UNKNOWN)) return "";
+  const size_t index = static_cast<size_t>(e);
   return EnumNamesMNN_DATA_FORMAT()[index];
 }
 
 struct BlobT : public flatbuffers::NativeTable {
   typedef Blob TableType;
-  std::vector<int32_t> dims;
-  MNN_DATA_FORMAT dataFormat;
-  DataType dataType;
-  std::vector<uint8_t> uint8s;
-  std::vector<int8_t> int8s;
-  std::vector<int32_t> int32s;
-  std::vector<int64_t> int64s;
-  std::vector<float> float32s;
-  std::vector<std::string> strings;
-  BlobT()
-      : dataFormat(MNN_DATA_FORMAT_NCHW),
-        dataType(DataType_DT_FLOAT) {
-  }
+  std::vector<int32_t> dims{};
+  MNN::MNN_DATA_FORMAT dataFormat = MNN::MNN_DATA_FORMAT_NCHW;
+  MNN::DataType dataType = MNN::DataType_DT_FLOAT;
+  std::vector<uint8_t> uint8s{};
+  std::vector<int8_t> int8s{};
+  std::vector<int32_t> int32s{};
+  std::vector<int64_t> int64s{};
+  std::vector<float> float32s{};
+  std::vector<std::string> strings{};
 };
 
 struct Blob FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
   typedef BlobT NativeTableType;
+  typedef BlobBuilder Builder;
   static const flatbuffers::TypeTable *MiniReflectTypeTable() {
     return BlobTypeTable();
   }
@@ -104,11 +106,11 @@ struct Blob FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
   const flatbuffers::Vector<int32_t> *dims() const {
     return GetPointer<const flatbuffers::Vector<int32_t> *>(VT_DIMS);
   }
-  MNN_DATA_FORMAT dataFormat() const {
-    return static_cast<MNN_DATA_FORMAT>(GetField<int8_t>(VT_DATAFORMAT, 0));
+  MNN::MNN_DATA_FORMAT dataFormat() const {
+    return static_cast<MNN::MNN_DATA_FORMAT>(GetField<int8_t>(VT_DATAFORMAT, 0));
   }
-  DataType dataType() const {
-    return static_cast<DataType>(GetField<int32_t>(VT_DATATYPE, 1));
+  MNN::DataType dataType() const {
+    return static_cast<MNN::DataType>(GetField<int32_t>(VT_DATATYPE, 1));
   }
   const flatbuffers::Vector<uint8_t> *uint8s() const {
     return GetPointer<const flatbuffers::Vector<uint8_t> *>(VT_UINT8S);
@@ -155,15 +157,16 @@ struct Blob FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
 };
 
 struct BlobBuilder {
+  typedef Blob Table;
   flatbuffers::FlatBufferBuilder &fbb_;
   flatbuffers::uoffset_t start_;
   void add_dims(flatbuffers::Offset<flatbuffers::Vector<int32_t>> dims) {
     fbb_.AddOffset(Blob::VT_DIMS, dims);
   }
-  void add_dataFormat(MNN_DATA_FORMAT dataFormat) {
+  void add_dataFormat(MNN::MNN_DATA_FORMAT dataFormat) {
     fbb_.AddElement<int8_t>(Blob::VT_DATAFORMAT, static_cast<int8_t>(dataFormat), 0);
   }
-  void add_dataType(DataType dataType) {
+  void add_dataType(MNN::DataType dataType) {
     fbb_.AddElement<int32_t>(Blob::VT_DATATYPE, static_cast<int32_t>(dataType), 1);
   }
   void add_uint8s(flatbuffers::Offset<flatbuffers::Vector<uint8_t>> uint8s) {
@@ -188,7 +191,6 @@ struct BlobBuilder {
         : fbb_(_fbb) {
     start_ = fbb_.StartTable();
   }
-  BlobBuilder &operator=(const BlobBuilder &);
   flatbuffers::Offset<Blob> Finish() {
     const auto end = fbb_.EndTable(start_);
     auto o = flatbuffers::Offset<Blob>(end);
@@ -199,8 +201,8 @@ struct BlobBuilder {
 inline flatbuffers::Offset<Blob> CreateBlob(
     flatbuffers::FlatBufferBuilder &_fbb,
     flatbuffers::Offset<flatbuffers::Vector<int32_t>> dims = 0,
-    MNN_DATA_FORMAT dataFormat = MNN_DATA_FORMAT_NCHW,
-    DataType dataType = DataType_DT_FLOAT,
+    MNN::MNN_DATA_FORMAT dataFormat = MNN::MNN_DATA_FORMAT_NCHW,
+    MNN::DataType dataType = MNN::DataType_DT_FLOAT,
     flatbuffers::Offset<flatbuffers::Vector<uint8_t>> uint8s = 0,
     flatbuffers::Offset<flatbuffers::Vector<int8_t>> int8s = 0,
     flatbuffers::Offset<flatbuffers::Vector<int32_t>> int32s = 0,
@@ -223,8 +225,8 @@ inline flatbuffers::Offset<Blob> CreateBlob(
 inline flatbuffers::Offset<Blob> CreateBlobDirect(
     flatbuffers::FlatBufferBuilder &_fbb,
     const std::vector<int32_t> *dims = nullptr,
-    MNN_DATA_FORMAT dataFormat = MNN_DATA_FORMAT_NCHW,
-    DataType dataType = DataType_DT_FLOAT,
+    MNN::MNN_DATA_FORMAT dataFormat = MNN::MNN_DATA_FORMAT_NCHW,
+    MNN::DataType dataType = MNN::DataType_DT_FLOAT,
     const std::vector<uint8_t> *uint8s = nullptr,
     const std::vector<int8_t> *int8s = nullptr,
     const std::vector<int32_t> *int32s = nullptr,
@@ -255,17 +257,16 @@ flatbuffers::Offset<Blob> CreateBlob(flatbuffers::FlatBufferBuilder &_fbb, const
 
 struct ListValueT : public flatbuffers::NativeTable {
   typedef ListValue TableType;
-  std::vector<std::string> s;
-  std::vector<int32_t> i;
-  std::vector<float> f;
-  std::vector<bool> b;
-  std::vector<DataType> type;
-  ListValueT() {
-  }
+  std::vector<std::string> s{};
+  std::vector<int32_t> i{};
+  std::vector<float> f{};
+  std::vector<bool> b{};
+  std::vector<MNN::DataType> type{};
 };
 
 struct ListValue FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
   typedef ListValueT NativeTableType;
+  typedef ListValueBuilder Builder;
   static const flatbuffers::TypeTable *MiniReflectTypeTable() {
     return ListValueTypeTable();
   }
@@ -312,6 +313,7 @@ struct ListValue FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
 };
 
 struct ListValueBuilder {
+  typedef ListValue Table;
   flatbuffers::FlatBufferBuilder &fbb_;
   flatbuffers::uoffset_t start_;
   void add_s(flatbuffers::Offset<flatbuffers::Vector<flatbuffers::Offset<flatbuffers::String>>> s) {
@@ -333,7 +335,6 @@ struct ListValueBuilder {
         : fbb_(_fbb) {
     start_ = fbb_.StartTable();
   }
-  ListValueBuilder &operator=(const ListValueBuilder &);
   flatbuffers::Offset<ListValue> Finish() {
     const auto end = fbb_.EndTable(start_);
     auto o = flatbuffers::Offset<ListValue>(end);
@@ -382,25 +383,20 @@ flatbuffers::Offset<ListValue> CreateListValue(flatbuffers::FlatBufferBuilder &_
 
 struct AttributeT : public flatbuffers::NativeTable {
   typedef Attribute TableType;
-  std::string s;
-  int32_t i;
-  bool b;
-  std::string key;
-  DataType type;
-  float f;
-  std::unique_ptr<BlobT> tensor;
-  std::unique_ptr<ListValueT> list;
-  std::unique_ptr<NamedAttrListT> func;
-  AttributeT()
-      : i(0),
-        b(false),
-        type(DataType_DT_INVALID),
-        f(0.0f) {
-  }
+  std::string s{};
+  int32_t i = 0;
+  bool b = false;
+  std::string key{};
+  MNN::DataType type = MNN::DataType_DT_INVALID;
+  float f = 0.0f;
+  std::unique_ptr<MNN::BlobT> tensor{};
+  std::unique_ptr<MNN::ListValueT> list{};
+  std::unique_ptr<MNN::NamedAttrListT> func{};
 };
 
 struct Attribute FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
   typedef AttributeT NativeTableType;
+  typedef AttributeBuilder Builder;
   static const flatbuffers::TypeTable *MiniReflectTypeTable() {
     return AttributeTypeTable();
   }
@@ -427,20 +423,20 @@ struct Attribute FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
   const flatbuffers::String *key() const {
     return GetPointer<const flatbuffers::String *>(VT_KEY);
   }
-  DataType type() const {
-    return static_cast<DataType>(GetField<int32_t>(VT_TYPE, 0));
+  MNN::DataType type() const {
+    return static_cast<MNN::DataType>(GetField<int32_t>(VT_TYPE, 0));
   }
   float f() const {
     return GetField<float>(VT_F, 0.0f);
   }
-  const Blob *tensor() const {
-    return GetPointer<const Blob *>(VT_TENSOR);
+  const MNN::Blob *tensor() const {
+    return GetPointer<const MNN::Blob *>(VT_TENSOR);
   }
-  const ListValue *list() const {
-    return GetPointer<const ListValue *>(VT_LIST);
+  const MNN::ListValue *list() const {
+    return GetPointer<const MNN::ListValue *>(VT_LIST);
   }
-  const NamedAttrList *func() const {
-    return GetPointer<const NamedAttrList *>(VT_FUNC);
+  const MNN::NamedAttrList *func() const {
+    return GetPointer<const MNN::NamedAttrList *>(VT_FUNC);
   }
   bool Verify(flatbuffers::Verifier &verifier) const {
     return VerifyTableStart(verifier) &&
@@ -466,6 +462,7 @@ struct Attribute FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
 };
 
 struct AttributeBuilder {
+  typedef Attribute Table;
   flatbuffers::FlatBufferBuilder &fbb_;
   flatbuffers::uoffset_t start_;
   void add_s(flatbuffers::Offset<flatbuffers::String> s) {
@@ -480,26 +477,25 @@ struct AttributeBuilder {
   void add_key(flatbuffers::Offset<flatbuffers::String> key) {
     fbb_.AddOffset(Attribute::VT_KEY, key);
   }
-  void add_type(DataType type) {
+  void add_type(MNN::DataType type) {
     fbb_.AddElement<int32_t>(Attribute::VT_TYPE, static_cast<int32_t>(type), 0);
   }
   void add_f(float f) {
     fbb_.AddElement<float>(Attribute::VT_F, f, 0.0f);
   }
-  void add_tensor(flatbuffers::Offset<Blob> tensor) {
+  void add_tensor(flatbuffers::Offset<MNN::Blob> tensor) {
     fbb_.AddOffset(Attribute::VT_TENSOR, tensor);
   }
-  void add_list(flatbuffers::Offset<ListValue> list) {
+  void add_list(flatbuffers::Offset<MNN::ListValue> list) {
     fbb_.AddOffset(Attribute::VT_LIST, list);
   }
-  void add_func(flatbuffers::Offset<NamedAttrList> func) {
+  void add_func(flatbuffers::Offset<MNN::NamedAttrList> func) {
     fbb_.AddOffset(Attribute::VT_FUNC, func);
   }
   explicit AttributeBuilder(flatbuffers::FlatBufferBuilder &_fbb)
         : fbb_(_fbb) {
     start_ = fbb_.StartTable();
   }
-  AttributeBuilder &operator=(const AttributeBuilder &);
   flatbuffers::Offset<Attribute> Finish() {
     const auto end = fbb_.EndTable(start_);
     auto o = flatbuffers::Offset<Attribute>(end);
@@ -513,11 +509,11 @@ inline flatbuffers::Offset<Attribute> CreateAttribute(
     int32_t i = 0,
     bool b = false,
     flatbuffers::Offset<flatbuffers::String> key = 0,
-    DataType type = DataType_DT_INVALID,
+    MNN::DataType type = MNN::DataType_DT_INVALID,
     float f = 0.0f,
-    flatbuffers::Offset<Blob> tensor = 0,
-    flatbuffers::Offset<ListValue> list = 0,
-    flatbuffers::Offset<NamedAttrList> func = 0) {
+    flatbuffers::Offset<MNN::Blob> tensor = 0,
+    flatbuffers::Offset<MNN::ListValue> list = 0,
+    flatbuffers::Offset<MNN::NamedAttrList> func = 0) {
   AttributeBuilder builder_(_fbb);
   builder_.add_func(func);
   builder_.add_list(list);
@@ -537,11 +533,11 @@ inline flatbuffers::Offset<Attribute> CreateAttributeDirect(
     int32_t i = 0,
     bool b = false,
     const char *key = nullptr,
-    DataType type = DataType_DT_INVALID,
+    MNN::DataType type = MNN::DataType_DT_INVALID,
     float f = 0.0f,
-    flatbuffers::Offset<Blob> tensor = 0,
-    flatbuffers::Offset<ListValue> list = 0,
-    flatbuffers::Offset<NamedAttrList> func = 0) {
+    flatbuffers::Offset<MNN::Blob> tensor = 0,
+    flatbuffers::Offset<MNN::ListValue> list = 0,
+    flatbuffers::Offset<MNN::NamedAttrList> func = 0) {
   auto s__ = s ? _fbb.CreateString(s) : 0;
   auto key__ = key ? _fbb.CreateString(key) : 0;
   return MNN::CreateAttribute(
@@ -561,14 +557,13 @@ flatbuffers::Offset<Attribute> CreateAttribute(flatbuffers::FlatBufferBuilder &_
 
 struct NamedAttrListT : public flatbuffers::NativeTable {
   typedef NamedAttrList TableType;
-  std::string name;
-  std::vector<std::unique_ptr<AttributeT>> attr;
-  NamedAttrListT() {
-  }
+  std::string name{};
+  std::vector<std::unique_ptr<MNN::AttributeT>> attr{};
 };
 
 struct NamedAttrList FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
   typedef NamedAttrListT NativeTableType;
+  typedef NamedAttrListBuilder Builder;
   static const flatbuffers::TypeTable *MiniReflectTypeTable() {
     return NamedAttrListTypeTable();
   }
@@ -579,8 +574,8 @@ struct NamedAttrList FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
   const flatbuffers::String *name() const {
     return GetPointer<const flatbuffers::String *>(VT_NAME);
   }
-  const flatbuffers::Vector<flatbuffers::Offset<Attribute>> *attr() const {
-    return GetPointer<const flatbuffers::Vector<flatbuffers::Offset<Attribute>> *>(VT_ATTR);
+  const flatbuffers::Vector<flatbuffers::Offset<MNN::Attribute>> *attr() const {
+    return GetPointer<const flatbuffers::Vector<flatbuffers::Offset<MNN::Attribute>> *>(VT_ATTR);
   }
   bool Verify(flatbuffers::Verifier &verifier) const {
     return VerifyTableStart(verifier) &&
@@ -597,19 +592,19 @@ struct NamedAttrList FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
 };
 
 struct NamedAttrListBuilder {
+  typedef NamedAttrList Table;
   flatbuffers::FlatBufferBuilder &fbb_;
   flatbuffers::uoffset_t start_;
   void add_name(flatbuffers::Offset<flatbuffers::String> name) {
     fbb_.AddOffset(NamedAttrList::VT_NAME, name);
   }
-  void add_attr(flatbuffers::Offset<flatbuffers::Vector<flatbuffers::Offset<Attribute>>> attr) {
+  void add_attr(flatbuffers::Offset<flatbuffers::Vector<flatbuffers::Offset<MNN::Attribute>>> attr) {
     fbb_.AddOffset(NamedAttrList::VT_ATTR, attr);
   }
   explicit NamedAttrListBuilder(flatbuffers::FlatBufferBuilder &_fbb)
         : fbb_(_fbb) {
     start_ = fbb_.StartTable();
   }
-  NamedAttrListBuilder &operator=(const NamedAttrListBuilder &);
   flatbuffers::Offset<NamedAttrList> Finish() {
     const auto end = fbb_.EndTable(start_);
     auto o = flatbuffers::Offset<NamedAttrList>(end);
@@ -620,7 +615,7 @@ struct NamedAttrListBuilder {
 inline flatbuffers::Offset<NamedAttrList> CreateNamedAttrList(
     flatbuffers::FlatBufferBuilder &_fbb,
     flatbuffers::Offset<flatbuffers::String> name = 0,
-    flatbuffers::Offset<flatbuffers::Vector<flatbuffers::Offset<Attribute>>> attr = 0) {
+    flatbuffers::Offset<flatbuffers::Vector<flatbuffers::Offset<MNN::Attribute>>> attr = 0) {
   NamedAttrListBuilder builder_(_fbb);
   builder_.add_attr(attr);
   builder_.add_name(name);
@@ -630,9 +625,9 @@ inline flatbuffers::Offset<NamedAttrList> CreateNamedAttrList(
 inline flatbuffers::Offset<NamedAttrList> CreateNamedAttrListDirect(
     flatbuffers::FlatBufferBuilder &_fbb,
     const char *name = nullptr,
-    const std::vector<flatbuffers::Offset<Attribute>> *attr = nullptr) {
+    const std::vector<flatbuffers::Offset<MNN::Attribute>> *attr = nullptr) {
   auto name__ = name ? _fbb.CreateString(name) : 0;
-  auto attr__ = attr ? _fbb.CreateVector<flatbuffers::Offset<Attribute>>(*attr) : 0;
+  auto attr__ = attr ? _fbb.CreateVector<flatbuffers::Offset<MNN::Attribute>>(*attr) : 0;
   return MNN::CreateNamedAttrList(
       _fbb,
       name__,
@@ -642,23 +637,23 @@ inline flatbuffers::Offset<NamedAttrList> CreateNamedAttrListDirect(
 flatbuffers::Offset<NamedAttrList> CreateNamedAttrList(flatbuffers::FlatBufferBuilder &_fbb, const NamedAttrListT *_o, const flatbuffers::rehasher_function_t *_rehasher = nullptr);
 
 inline BlobT *Blob::UnPack(const flatbuffers::resolver_function_t *_resolver) const {
-  auto _o = new BlobT();
-  UnPackTo(_o, _resolver);
-  return _o;
+  auto _o = std::unique_ptr<BlobT>(new BlobT());
+  UnPackTo(_o.get(), _resolver);
+  return _o.release();
 }
 
 inline void Blob::UnPackTo(BlobT *_o, const flatbuffers::resolver_function_t *_resolver) const {
   (void)_o;
   (void)_resolver;
-  { auto _e = dims(); if (_e) { _o->dims.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->dims[_i] = _e->Get(_i); } } };
-  { auto _e = dataFormat(); _o->dataFormat = _e; };
-  { auto _e = dataType(); _o->dataType = _e; };
-  { auto _e = uint8s(); if (_e) { _o->uint8s.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->uint8s[_i] = _e->Get(_i); } } };
-  { auto _e = int8s(); if (_e) { _o->int8s.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->int8s[_i] = _e->Get(_i); } } };
-  { auto _e = int32s(); if (_e) { _o->int32s.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->int32s[_i] = _e->Get(_i); } } };
-  { auto _e = int64s(); if (_e) { _o->int64s.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->int64s[_i] = _e->Get(_i); } } };
-  { auto _e = float32s(); if (_e) { _o->float32s.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->float32s[_i] = _e->Get(_i); } } };
-  { auto _e = strings(); if (_e) { _o->strings.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->strings[_i] = _e->Get(_i)->str(); } } };
+  { auto _e = dims(); if (_e) { _o->dims.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->dims[_i] = _e->Get(_i); } } }
+  { auto _e = dataFormat(); _o->dataFormat = _e; }
+  { auto _e = dataType(); _o->dataType = _e; }
+  { auto _e = uint8s(); if (_e) { _o->uint8s.resize(_e->size()); std::copy(_e->begin(), _e->end(), _o->uint8s.begin()); } }
+  { auto _e = int8s(); if (_e) { _o->int8s.resize(_e->size()); std::copy(_e->begin(), _e->end(), _o->int8s.begin()); } }
+  { auto _e = int32s(); if (_e) { _o->int32s.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->int32s[_i] = _e->Get(_i); } } }
+  { auto _e = int64s(); if (_e) { _o->int64s.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->int64s[_i] = _e->Get(_i); } } }
+  { auto _e = float32s(); if (_e) { _o->float32s.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->float32s[_i] = _e->Get(_i); } } }
+  { auto _e = strings(); if (_e) { _o->strings.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->strings[_i] = _e->Get(_i)->str(); } } }
 }
 
 inline flatbuffers::Offset<Blob> Blob::Pack(flatbuffers::FlatBufferBuilder &_fbb, const BlobT* _o, const flatbuffers::rehasher_function_t *_rehasher) {
@@ -692,19 +687,19 @@ inline flatbuffers::Offset<Blob> CreateBlob(flatbuffers::FlatBufferBuilder &_fbb
 }
 
 inline ListValueT *ListValue::UnPack(const flatbuffers::resolver_function_t *_resolver) const {
-  auto _o = new ListValueT();
-  UnPackTo(_o, _resolver);
-  return _o;
+  auto _o = std::unique_ptr<ListValueT>(new ListValueT());
+  UnPackTo(_o.get(), _resolver);
+  return _o.release();
 }
 
 inline void ListValue::UnPackTo(ListValueT *_o, const flatbuffers::resolver_function_t *_resolver) const {
   (void)_o;
   (void)_resolver;
-  { auto _e = s(); if (_e) { _o->s.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->s[_i] = _e->Get(_i)->str(); } } };
-  { auto _e = i(); if (_e) { _o->i.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->i[_i] = _e->Get(_i); } } };
-  { auto _e = f(); if (_e) { _o->f.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->f[_i] = _e->Get(_i); } } };
-  { auto _e = b(); if (_e) { _o->b.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->b[_i] = _e->Get(_i) != 0; } } };
-  { auto _e = type(); if (_e) { _o->type.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->type[_i] = static_cast<DataType>(_e->Get(_i)); } } };
+  { auto _e = s(); if (_e) { _o->s.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->s[_i] = _e->Get(_i)->str(); } } }
+  { auto _e = i(); if (_e) { _o->i.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->i[_i] = _e->Get(_i); } } }
+  { auto _e = f(); if (_e) { _o->f.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->f[_i] = _e->Get(_i); } } }
+  { auto _e = b(); if (_e) { _o->b.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->b[_i] = _e->Get(_i) != 0; } } }
+  { auto _e = type(); if (_e) { _o->type.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->type[_i] = static_cast<MNN::DataType>(_e->Get(_i)); } } }
 }
 
 inline flatbuffers::Offset<ListValue> ListValue::Pack(flatbuffers::FlatBufferBuilder &_fbb, const ListValueT* _o, const flatbuffers::rehasher_function_t *_rehasher) {
@@ -730,23 +725,23 @@ inline flatbuffers::Offset<ListValue> CreateListValue(flatbuffers::FlatBufferBui
 }
 
 inline AttributeT *Attribute::UnPack(const flatbuffers::resolver_function_t *_resolver) const {
-  auto _o = new AttributeT();
-  UnPackTo(_o, _resolver);
-  return _o;
+  auto _o = std::unique_ptr<AttributeT>(new AttributeT());
+  UnPackTo(_o.get(), _resolver);
+  return _o.release();
 }
 
 inline void Attribute::UnPackTo(AttributeT *_o, const flatbuffers::resolver_function_t *_resolver) const {
   (void)_o;
   (void)_resolver;
-  { auto _e = s(); if (_e) _o->s = _e->str(); };
-  { auto _e = i(); _o->i = _e; };
-  { auto _e = b(); _o->b = _e; };
-  { auto _e = key(); if (_e) _o->key = _e->str(); };
-  { auto _e = type(); _o->type = _e; };
-  { auto _e = f(); _o->f = _e; };
-  { auto _e = tensor(); if (_e) _o->tensor = std::unique_ptr<BlobT>(_e->UnPack(_resolver)); };
-  { auto _e = list(); if (_e) _o->list = std::unique_ptr<ListValueT>(_e->UnPack(_resolver)); };
-  { auto _e = func(); if (_e) _o->func = std::unique_ptr<NamedAttrListT>(_e->UnPack(_resolver)); };
+  { auto _e = s(); if (_e) _o->s = _e->str(); }
+  { auto _e = i(); _o->i = _e; }
+  { auto _e = b(); _o->b = _e; }
+  { auto _e = key(); if (_e) _o->key = _e->str(); }
+  { auto _e = type(); _o->type = _e; }
+  { auto _e = f(); _o->f = _e; }
+  { auto _e = tensor(); if (_e) _o->tensor = std::unique_ptr<MNN::BlobT>(_e->UnPack(_resolver)); }
+  { auto _e = list(); if (_e) _o->list = std::unique_ptr<MNN::ListValueT>(_e->UnPack(_resolver)); }
+  { auto _e = func(); if (_e) _o->func = std::unique_ptr<MNN::NamedAttrListT>(_e->UnPack(_resolver)); }
 }
 
 inline flatbuffers::Offset<Attribute> Attribute::Pack(flatbuffers::FlatBufferBuilder &_fbb, const AttributeT* _o, const flatbuffers::rehasher_function_t *_rehasher) {
@@ -780,16 +775,16 @@ inline flatbuffers::Offset<Attribute> CreateAttribute(flatbuffers::FlatBufferBui
 }
 
 inline NamedAttrListT *NamedAttrList::UnPack(const flatbuffers::resolver_function_t *_resolver) const {
-  auto _o = new NamedAttrListT();
-  UnPackTo(_o, _resolver);
-  return _o;
+  auto _o = std::unique_ptr<NamedAttrListT>(new NamedAttrListT());
+  UnPackTo(_o.get(), _resolver);
+  return _o.release();
 }
 
 inline void NamedAttrList::UnPackTo(NamedAttrListT *_o, const flatbuffers::resolver_function_t *_resolver) const {
   (void)_o;
   (void)_resolver;
-  { auto _e = name(); if (_e) _o->name = _e->str(); };
-  { auto _e = attr(); if (_e) { _o->attr.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->attr[_i] = std::unique_ptr<AttributeT>(_e->Get(_i)->UnPack(_resolver)); } } };
+  { auto _e = name(); if (_e) _o->name = _e->str(); }
+  { auto _e = attr(); if (_e) { _o->attr.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->attr[_i] = std::unique_ptr<MNN::AttributeT>(_e->Get(_i)->UnPack(_resolver)); } } }
 }
 
 inline flatbuffers::Offset<NamedAttrList> NamedAttrList::Pack(flatbuffers::FlatBufferBuilder &_fbb, const NamedAttrListT* _o, const flatbuffers::rehasher_function_t *_rehasher) {
@@ -801,7 +796,7 @@ inline flatbuffers::Offset<NamedAttrList> CreateNamedAttrList(flatbuffers::FlatB
   (void)_o;
   struct _VectorArgs { flatbuffers::FlatBufferBuilder *__fbb; const NamedAttrListT* __o; const flatbuffers::rehasher_function_t *__rehasher; } _va = { &_fbb, _o, _rehasher}; (void)_va;
   auto _name = _o->name.empty() ? 0 : _fbb.CreateString(_o->name);
-  auto _attr = _o->attr.size() ? _fbb.CreateVector<flatbuffers::Offset<Attribute>> (_o->attr.size(), [](size_t i, _VectorArgs *__va) { return CreateAttribute(*__va->__fbb, __va->__o->attr[i].get(), __va->__rehasher); }, &_va ) : 0;
+  auto _attr = _o->attr.size() ? _fbb.CreateVector<flatbuffers::Offset<MNN::Attribute>> (_o->attr.size(), [](size_t i, _VectorArgs *__va) { return CreateAttribute(*__va->__fbb, __va->__o->attr[i].get(), __va->__rehasher); }, &_va ) : 0;
   return MNN::CreateNamedAttrList(
       _fbb,
       _name,
@@ -817,7 +812,7 @@ inline const flatbuffers::TypeTable *MNN_DATA_FORMATTypeTable() {
     { flatbuffers::ET_CHAR, 0, 0 }
   };
   static const flatbuffers::TypeFunction type_refs[] = {
-    MNN_DATA_FORMATTypeTable
+    MNN::MNN_DATA_FORMATTypeTable
   };
   static const char * const names[] = {
     "NCHW",
@@ -827,7 +822,7 @@ inline const flatbuffers::TypeTable *MNN_DATA_FORMATTypeTable() {
     "UNKNOWN"
   };
   static const flatbuffers::TypeTable tt = {
-    flatbuffers::ST_ENUM, 5, type_codes, type_refs, nullptr, names
+    flatbuffers::ST_ENUM, 5, type_codes, type_refs, nullptr, nullptr, names
   };
   return &tt;
 }
@@ -845,8 +840,8 @@ inline const flatbuffers::TypeTable *BlobTypeTable() {
     { flatbuffers::ET_STRING, 1, -1 }
   };
   static const flatbuffers::TypeFunction type_refs[] = {
-    MNN_DATA_FORMATTypeTable,
-    DataTypeTypeTable
+    MNN::MNN_DATA_FORMATTypeTable,
+    MNN::DataTypeTypeTable
   };
   static const char * const names[] = {
     "dims",
@@ -860,7 +855,7 @@ inline const flatbuffers::TypeTable *BlobTypeTable() {
     "strings"
   };
   static const flatbuffers::TypeTable tt = {
-    flatbuffers::ST_TABLE, 9, type_codes, type_refs, nullptr, names
+    flatbuffers::ST_TABLE, 9, type_codes, type_refs, nullptr, nullptr, names
   };
   return &tt;
 }
@@ -874,7 +869,7 @@ inline const flatbuffers::TypeTable *ListValueTypeTable() {
     { flatbuffers::ET_INT, 1, 0 }
   };
   static const flatbuffers::TypeFunction type_refs[] = {
-    DataTypeTypeTable
+    MNN::DataTypeTypeTable
   };
   static const char * const names[] = {
     "s",
@@ -884,7 +879,7 @@ inline const flatbuffers::TypeTable *ListValueTypeTable() {
     "type"
   };
   static const flatbuffers::TypeTable tt = {
-    flatbuffers::ST_TABLE, 5, type_codes, type_refs, nullptr, names
+    flatbuffers::ST_TABLE, 5, type_codes, type_refs, nullptr, nullptr, names
   };
   return &tt;
 }
@@ -902,10 +897,10 @@ inline const flatbuffers::TypeTable *AttributeTypeTable() {
     { flatbuffers::ET_SEQUENCE, 0, 3 }
   };
   static const flatbuffers::TypeFunction type_refs[] = {
-    DataTypeTypeTable,
-    BlobTypeTable,
-    ListValueTypeTable,
-    NamedAttrListTypeTable
+    MNN::DataTypeTypeTable,
+    MNN::BlobTypeTable,
+    MNN::ListValueTypeTable,
+    MNN::NamedAttrListTypeTable
   };
   static const char * const names[] = {
     "s",
@@ -919,7 +914,7 @@ inline const flatbuffers::TypeTable *AttributeTypeTable() {
     "func"
   };
   static const flatbuffers::TypeTable tt = {
-    flatbuffers::ST_TABLE, 9, type_codes, type_refs, nullptr, names
+    flatbuffers::ST_TABLE, 9, type_codes, type_refs, nullptr, nullptr, names
   };
   return &tt;
 }
@@ -930,14 +925,14 @@ inline const flatbuffers::TypeTable *NamedAttrListTypeTable() {
     { flatbuffers::ET_SEQUENCE, 1, 0 }
   };
   static const flatbuffers::TypeFunction type_refs[] = {
-    AttributeTypeTable
+    MNN::AttributeTypeTable
   };
   static const char * const names[] = {
     "name",
     "attr"
   };
   static const flatbuffers::TypeTable tt = {
-    flatbuffers::ST_TABLE, 2, type_codes, type_refs, nullptr, names
+    flatbuffers::ST_TABLE, 2, type_codes, type_refs, nullptr, nullptr, names
   };
   return &tt;
 }
diff --git a/schema/current/TensorflowOp_generated.h b/schema/current/TensorflowOp_generated.h
index 3427a03a..b75296e2 100644
--- a/schema/current/TensorflowOp_generated.h
+++ b/schema/current/TensorflowOp_generated.h
@@ -4,118 +4,155 @@
 #ifndef FLATBUFFERS_GENERATED_TENSORFLOWOP_MNN_H_
 #define FLATBUFFERS_GENERATED_TENSORFLOWOP_MNN_H_
 
+#include "flatbuffers/flatbuffers.h"
 
-#include "Tensor_generated.h"
 #include "Type_generated.h"
+#include "Tensor_generated.h"
 
 namespace MNN {
 
 struct BinaryOp;
+struct BinaryOpBuilder;
 struct BinaryOpT;
 
 struct PackParam;
+struct PackParamBuilder;
 struct PackParamT;
 
 struct StridedSliceParam;
+struct StridedSliceParamBuilder;
 struct StridedSliceParamT;
 
 struct SqueezeParam;
+struct SqueezeParamBuilder;
 struct SqueezeParamT;
 
 struct CastParam;
+struct CastParamBuilder;
 struct CastParamT;
 
 struct ReductionParam;
+struct ReductionParamBuilder;
 struct ReductionParamT;
 
 struct Gather;
+struct GatherBuilder;
 struct GatherT;
 
 struct ExpandDims;
+struct ExpandDimsBuilder;
 struct ExpandDimsT;
 
 struct Selu;
+struct SeluBuilder;
 struct SeluT;
 
 struct AsString;
+struct AsStringBuilder;
 struct AsStringT;
 
 struct ReduceJoin;
+struct ReduceJoinBuilder;
 struct ReduceJoinT;
 
 struct UnaryOp;
+struct UnaryOpBuilder;
 struct UnaryOpT;
 
 struct TopKV2;
+struct TopKV2Builder;
 struct TopKV2T;
 
 struct CropAndResize;
+struct CropAndResizeBuilder;
 struct CropAndResizeT;
 
 struct Fill;
+struct FillBuilder;
 struct FillT;
 
 struct GatherV2;
+struct GatherV2Builder;
 struct GatherV2T;
 
 struct NonMaxSuppressionV2;
+struct NonMaxSuppressionV2Builder;
 struct NonMaxSuppressionV2T;
 
 struct Range;
+struct RangeBuilder;
 struct RangeT;
 
 struct Rank;
+struct RankBuilder;
 struct RankT;
 
 struct Size;
+struct SizeBuilder;
 struct SizeT;
 
 struct Transpose;
+struct TransposeBuilder;
 struct TransposeT;
 
 struct SliceTf;
+struct SliceTfBuilder;
 struct SliceTfT;
 
 struct QuantizeMaxMin;
+struct QuantizeMaxMinBuilder;
 struct QuantizeMaxMinT;
 
 struct Crop;
+struct CropBuilder;
 struct CropT;
 
 struct SpaceBatch;
+struct SpaceBatchBuilder;
 struct SpaceBatchT;
 
 struct MatMul;
+struct MatMulBuilder;
 struct MatMulT;
 
 struct MomentsParam;
+struct MomentsParamBuilder;
 struct MomentsParamT;
 
 struct RNNParam;
+struct RNNParamBuilder;
 struct RNNParamT;
 
 struct BatchMatMulParam;
+struct BatchMatMulParamBuilder;
 struct BatchMatMulParamT;
 
 struct DepthSpaceParam;
+struct DepthSpaceParamBuilder;
 struct DepthSpaceParamT;
 
 struct ReverseSequenceParam;
+struct ReverseSequenceParamBuilder;
 struct ReverseSequenceParamT;
 
 struct DetectionPostProcessParam;
+struct DetectionPostProcessParamBuilder;
 struct DetectionPostProcessParamT;
 
 struct OneHotParam;
+struct OneHotParamBuilder;
 struct OneHotParamT;
 
 struct PadParam;
+struct PadParamBuilder;
 struct PadParamT;
 
 struct LayerNorm;
+struct LayerNormBuilder;
 struct LayerNormT;
 
 struct RandomUniform;
+struct RandomUniformBuilder;
 struct RandomUniformT;
 
 inline const flatbuffers::TypeTable *BinaryOpTypeTable();
@@ -190,7 +227,7 @@ inline const flatbuffers::TypeTable *LayerNormTypeTable();
 
 inline const flatbuffers::TypeTable *RandomUniformTypeTable();
 
-enum BinaryOpOperation {
+enum BinaryOpOperation : int8_t {
   BinaryOpOperation_ADD = 0,
   BinaryOpOperation_SUB = 1,
   BinaryOpOperation_MUL = 2,
@@ -246,7 +283,7 @@ inline const BinaryOpOperation (&EnumValuesBinaryOpOperation())[22] {
 }
 
 inline const char * const *EnumNamesBinaryOpOperation() {
-  static const char * const names[] = {
+  static const char * const names[24] = {
     "ADD",
     "SUB",
     "MUL",
@@ -276,12 +313,12 @@ inline const char * const *EnumNamesBinaryOpOperation() {
 }
 
 inline const char *EnumNameBinaryOpOperation(BinaryOpOperation e) {
-  if (e < BinaryOpOperation_ADD || e > BinaryOpOperation_NOTEQUAL) return "";
-  const size_t index = static_cast<int>(e);
+  if (flatbuffers::IsOutRange(e, BinaryOpOperation_ADD, BinaryOpOperation_NOTEQUAL)) return "";
+  const size_t index = static_cast<size_t>(e);
   return EnumNamesBinaryOpOperation()[index];
 }
 
-enum ReductionType {
+enum ReductionType : int8_t {
   ReductionType_SUM = 0,
   ReductionType_ASUM = 1,
   ReductionType_SUMSQ = 2,
@@ -311,7 +348,7 @@ inline const ReductionType (&EnumValuesReductionType())[9] {
 }
 
 inline const char * const *EnumNamesReductionType() {
-  static const char * const names[] = {
+  static const char * const names[10] = {
     "SUM",
     "ASUM",
     "SUMSQ",
@@ -327,12 +364,12 @@ inline const char * const *EnumNamesReductionType() {
 }
 
 inline const char *EnumNameReductionType(ReductionType e) {
-  if (e < ReductionType_SUM || e > ReductionType_ALL) return "";
-  const size_t index = static_cast<int>(e);
+  if (flatbuffers::IsOutRange(e, ReductionType_SUM, ReductionType_ALL)) return "";
+  const size_t index = static_cast<size_t>(e);
   return EnumNamesReductionType()[index];
 }
 
-enum UnaryOpOperation {
+enum UnaryOpOperation : int32_t {
   UnaryOpOperation_ABS = 0,
   UnaryOpOperation_NEG = 1,
   UnaryOpOperation_FLOOR = 2,
@@ -406,7 +443,7 @@ inline const UnaryOpOperation (&EnumValuesUnaryOpOperation())[31] {
 }
 
 inline const char * const *EnumNamesUnaryOpOperation() {
-  static const char * const names[] = {
+  static const char * const names[32] = {
     "ABS",
     "NEG",
     "FLOOR",
@@ -444,12 +481,12 @@ inline const char * const *EnumNamesUnaryOpOperation() {
 }
 
 inline const char *EnumNameUnaryOpOperation(UnaryOpOperation e) {
-  if (e < UnaryOpOperation_ABS || e > UnaryOpOperation_TANH) return "";
-  const size_t index = static_cast<int>(e);
+  if (flatbuffers::IsOutRange(e, UnaryOpOperation_ABS, UnaryOpOperation_TANH)) return "";
+  const size_t index = static_cast<size_t>(e);
   return EnumNamesUnaryOpOperation()[index];
 }
 
-enum CropAndResizeMethod {
+enum CropAndResizeMethod : int8_t {
   CropAndResizeMethod_BILINEAR = 0,
   CropAndResizeMethod_NEAREST = 1,
   CropAndResizeMethod_MIN = CropAndResizeMethod_BILINEAR,
@@ -465,7 +502,7 @@ inline const CropAndResizeMethod (&EnumValuesCropAndResizeMethod())[2] {
 }
 
 inline const char * const *EnumNamesCropAndResizeMethod() {
-  static const char * const names[] = {
+  static const char * const names[3] = {
     "BILINEAR",
     "NEAREST",
     nullptr
@@ -474,12 +511,12 @@ inline const char * const *EnumNamesCropAndResizeMethod() {
 }
 
 inline const char *EnumNameCropAndResizeMethod(CropAndResizeMethod e) {
-  if (e < CropAndResizeMethod_BILINEAR || e > CropAndResizeMethod_NEAREST) return "";
-  const size_t index = static_cast<int>(e);
+  if (flatbuffers::IsOutRange(e, CropAndResizeMethod_BILINEAR, CropAndResizeMethod_NEAREST)) return "";
+  const size_t index = static_cast<size_t>(e);
   return EnumNamesCropAndResizeMethod()[index];
 }
 
-enum DepthToSpaceMode {
+enum DepthToSpaceMode : int8_t {
   DepthToSpaceMode_DCR = 0,
   DepthToSpaceMode_CRD = 1,
   DepthToSpaceMode_MIN = DepthToSpaceMode_DCR,
@@ -495,7 +532,7 @@ inline const DepthToSpaceMode (&EnumValuesDepthToSpaceMode())[2] {
 }
 
 inline const char * const *EnumNamesDepthToSpaceMode() {
-  static const char * const names[] = {
+  static const char * const names[3] = {
     "DCR",
     "CRD",
     nullptr
@@ -504,12 +541,12 @@ inline const char * const *EnumNamesDepthToSpaceMode() {
 }
 
 inline const char *EnumNameDepthToSpaceMode(DepthToSpaceMode e) {
-  if (e < DepthToSpaceMode_DCR || e > DepthToSpaceMode_CRD) return "";
-  const size_t index = static_cast<int>(e);
+  if (flatbuffers::IsOutRange(e, DepthToSpaceMode_DCR, DepthToSpaceMode_CRD)) return "";
+  const size_t index = static_cast<size_t>(e);
   return EnumNamesDepthToSpaceMode()[index];
 }
 
-enum PadValueMode {
+enum PadValueMode : int8_t {
   PadValueMode_CONSTANT = 0,
   PadValueMode_REFLECT = 1,
   PadValueMode_SYMMETRIC = 2,
@@ -527,7 +564,7 @@ inline const PadValueMode (&EnumValuesPadValueMode())[3] {
 }
 
 inline const char * const *EnumNamesPadValueMode() {
-  static const char * const names[] = {
+  static const char * const names[4] = {
     "CONSTANT",
     "REFLECT",
     "SYMMETRIC",
@@ -537,23 +574,20 @@ inline const char * const *EnumNamesPadValueMode() {
 }
 
 inline const char *EnumNamePadValueMode(PadValueMode e) {
-  if (e < PadValueMode_CONSTANT || e > PadValueMode_SYMMETRIC) return "";
-  const size_t index = static_cast<int>(e);
+  if (flatbuffers::IsOutRange(e, PadValueMode_CONSTANT, PadValueMode_SYMMETRIC)) return "";
+  const size_t index = static_cast<size_t>(e);
   return EnumNamesPadValueMode()[index];
 }
 
 struct BinaryOpT : public flatbuffers::NativeTable {
   typedef BinaryOp TableType;
-  int32_t opType;
-  DataType T;
-  BinaryOpT()
-      : opType(0),
-        T(DataType_DT_FLOAT) {
-  }
+  int32_t opType = 0;
+  MNN::DataType T = MNN::DataType_DT_FLOAT;
 };
 
 struct BinaryOp FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
   typedef BinaryOpT NativeTableType;
+  typedef BinaryOpBuilder Builder;
   static const flatbuffers::TypeTable *MiniReflectTypeTable() {
     return BinaryOpTypeTable();
   }
@@ -564,8 +598,8 @@ struct BinaryOp FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
   int32_t opType() const {
     return GetField<int32_t>(VT_OPTYPE, 0);
   }
-  DataType T() const {
-    return static_cast<DataType>(GetField<int32_t>(VT_T, 1));
+  MNN::DataType T() const {
+    return static_cast<MNN::DataType>(GetField<int32_t>(VT_T, 1));
   }
   bool Verify(flatbuffers::Verifier &verifier) const {
     return VerifyTableStart(verifier) &&
@@ -579,19 +613,19 @@ struct BinaryOp FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
 };
 
 struct BinaryOpBuilder {
+  typedef BinaryOp Table;
   flatbuffers::FlatBufferBuilder &fbb_;
   flatbuffers::uoffset_t start_;
   void add_opType(int32_t opType) {
     fbb_.AddElement<int32_t>(BinaryOp::VT_OPTYPE, opType, 0);
   }
-  void add_T(DataType T) {
+  void add_T(MNN::DataType T) {
     fbb_.AddElement<int32_t>(BinaryOp::VT_T, static_cast<int32_t>(T), 1);
   }
   explicit BinaryOpBuilder(flatbuffers::FlatBufferBuilder &_fbb)
         : fbb_(_fbb) {
     start_ = fbb_.StartTable();
   }
-  BinaryOpBuilder &operator=(const BinaryOpBuilder &);
   flatbuffers::Offset<BinaryOp> Finish() {
     const auto end = fbb_.EndTable(start_);
     auto o = flatbuffers::Offset<BinaryOp>(end);
@@ -602,7 +636,7 @@ struct BinaryOpBuilder {
 inline flatbuffers::Offset<BinaryOp> CreateBinaryOp(
     flatbuffers::FlatBufferBuilder &_fbb,
     int32_t opType = 0,
-    DataType T = DataType_DT_FLOAT) {
+    MNN::DataType T = MNN::DataType_DT_FLOAT) {
   BinaryOpBuilder builder_(_fbb);
   builder_.add_T(T);
   builder_.add_opType(opType);
@@ -613,16 +647,13 @@ flatbuffers::Offset<BinaryOp> CreateBinaryOp(flatbuffers::FlatBufferBuilder &_fb
 
 struct PackParamT : public flatbuffers::NativeTable {
   typedef PackParam TableType;
-  DataType dataType;
-  int32_t axis;
-  PackParamT()
-      : dataType(DataType_DT_INVALID),
-        axis(0) {
-  }
+  MNN::DataType dataType = MNN::DataType_DT_INVALID;
+  int32_t axis = 0;
 };
 
 struct PackParam FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
   typedef PackParamT NativeTableType;
+  typedef PackParamBuilder Builder;
   static const flatbuffers::TypeTable *MiniReflectTypeTable() {
     return PackParamTypeTable();
   }
@@ -630,8 +661,8 @@ struct PackParam FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
     VT_DATATYPE = 4,
     VT_AXIS = 6
   };
-  DataType dataType() const {
-    return static_cast<DataType>(GetField<int32_t>(VT_DATATYPE, 0));
+  MNN::DataType dataType() const {
+    return static_cast<MNN::DataType>(GetField<int32_t>(VT_DATATYPE, 0));
   }
   int32_t axis() const {
     return GetField<int32_t>(VT_AXIS, 0);
@@ -648,9 +679,10 @@ struct PackParam FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
 };
 
 struct PackParamBuilder {
+  typedef PackParam Table;
   flatbuffers::FlatBufferBuilder &fbb_;
   flatbuffers::uoffset_t start_;
-  void add_dataType(DataType dataType) {
+  void add_dataType(MNN::DataType dataType) {
     fbb_.AddElement<int32_t>(PackParam::VT_DATATYPE, static_cast<int32_t>(dataType), 0);
   }
   void add_axis(int32_t axis) {
@@ -660,7 +692,6 @@ struct PackParamBuilder {
         : fbb_(_fbb) {
     start_ = fbb_.StartTable();
   }
-  PackParamBuilder &operator=(const PackParamBuilder &);
   flatbuffers::Offset<PackParam> Finish() {
     const auto end = fbb_.EndTable(start_);
     auto o = flatbuffers::Offset<PackParam>(end);
@@ -670,7 +701,7 @@ struct PackParamBuilder {
 
 inline flatbuffers::Offset<PackParam> CreatePackParam(
     flatbuffers::FlatBufferBuilder &_fbb,
-    DataType dataType = DataType_DT_INVALID,
+    MNN::DataType dataType = MNN::DataType_DT_INVALID,
     int32_t axis = 0) {
   PackParamBuilder builder_(_fbb);
   builder_.add_axis(axis);
@@ -682,26 +713,18 @@ flatbuffers::Offset<PackParam> CreatePackParam(flatbuffers::FlatBufferBuilder &_
 
 struct StridedSliceParamT : public flatbuffers::NativeTable {
   typedef StridedSliceParam TableType;
-  DataType Index;
-  DataType T;
-  int32_t beginMask;
-  int32_t endMask;
-  int32_t ellipsisMask;
-  int32_t newAxisMask;
-  int32_t shrinkAxisMask;
-  StridedSliceParamT()
-      : Index(DataType_DT_INVALID),
-        T(DataType_DT_INVALID),
-        beginMask(0),
-        endMask(0),
-        ellipsisMask(0),
-        newAxisMask(0),
-        shrinkAxisMask(0) {
-  }
+  MNN::DataType Index = MNN::DataType_DT_INVALID;
+  MNN::DataType T = MNN::DataType_DT_INVALID;
+  int32_t beginMask = 0;
+  int32_t endMask = 0;
+  int32_t ellipsisMask = 0;
+  int32_t newAxisMask = 0;
+  int32_t shrinkAxisMask = 0;
 };
 
 struct StridedSliceParam FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
   typedef StridedSliceParamT NativeTableType;
+  typedef StridedSliceParamBuilder Builder;
   static const flatbuffers::TypeTable *MiniReflectTypeTable() {
     return StridedSliceParamTypeTable();
   }
@@ -714,11 +737,11 @@ struct StridedSliceParam FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
     VT_NEWAXISMASK = 14,
     VT_SHRINKAXISMASK = 16
   };
-  DataType Index() const {
-    return static_cast<DataType>(GetField<int32_t>(VT_INDEX, 0));
+  MNN::DataType Index() const {
+    return static_cast<MNN::DataType>(GetField<int32_t>(VT_INDEX, 0));
   }
-  DataType T() const {
-    return static_cast<DataType>(GetField<int32_t>(VT_T, 0));
+  MNN::DataType T() const {
+    return static_cast<MNN::DataType>(GetField<int32_t>(VT_T, 0));
   }
   int32_t beginMask() const {
     return GetField<int32_t>(VT_BEGINMASK, 0);
@@ -752,12 +775,13 @@ struct StridedSliceParam FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
 };
 
 struct StridedSliceParamBuilder {
+  typedef StridedSliceParam Table;
   flatbuffers::FlatBufferBuilder &fbb_;
   flatbuffers::uoffset_t start_;
-  void add_Index(DataType Index) {
+  void add_Index(MNN::DataType Index) {
     fbb_.AddElement<int32_t>(StridedSliceParam::VT_INDEX, static_cast<int32_t>(Index), 0);
   }
-  void add_T(DataType T) {
+  void add_T(MNN::DataType T) {
     fbb_.AddElement<int32_t>(StridedSliceParam::VT_T, static_cast<int32_t>(T), 0);
   }
   void add_beginMask(int32_t beginMask) {
@@ -779,7 +803,6 @@ struct StridedSliceParamBuilder {
         : fbb_(_fbb) {
     start_ = fbb_.StartTable();
   }
-  StridedSliceParamBuilder &operator=(const StridedSliceParamBuilder &);
   flatbuffers::Offset<StridedSliceParam> Finish() {
     const auto end = fbb_.EndTable(start_);
     auto o = flatbuffers::Offset<StridedSliceParam>(end);
@@ -789,8 +812,8 @@ struct StridedSliceParamBuilder {
 
 inline flatbuffers::Offset<StridedSliceParam> CreateStridedSliceParam(
     flatbuffers::FlatBufferBuilder &_fbb,
-    DataType Index = DataType_DT_INVALID,
-    DataType T = DataType_DT_INVALID,
+    MNN::DataType Index = MNN::DataType_DT_INVALID,
+    MNN::DataType T = MNN::DataType_DT_INVALID,
     int32_t beginMask = 0,
     int32_t endMask = 0,
     int32_t ellipsisMask = 0,
@@ -811,13 +834,12 @@ flatbuffers::Offset<StridedSliceParam> CreateStridedSliceParam(flatbuffers::Flat
 
 struct SqueezeParamT : public flatbuffers::NativeTable {
   typedef SqueezeParam TableType;
-  std::vector<int32_t> squeezeDims;
-  SqueezeParamT() {
-  }
+  std::vector<int32_t> squeezeDims{};
 };
 
 struct SqueezeParam FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
   typedef SqueezeParamT NativeTableType;
+  typedef SqueezeParamBuilder Builder;
   static const flatbuffers::TypeTable *MiniReflectTypeTable() {
     return SqueezeParamTypeTable();
   }
@@ -839,6 +861,7 @@ struct SqueezeParam FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
 };
 
 struct SqueezeParamBuilder {
+  typedef SqueezeParam Table;
   flatbuffers::FlatBufferBuilder &fbb_;
   flatbuffers::uoffset_t start_;
   void add_squeezeDims(flatbuffers::Offset<flatbuffers::Vector<int32_t>> squeezeDims) {
@@ -848,7 +871,6 @@ struct SqueezeParamBuilder {
         : fbb_(_fbb) {
     start_ = fbb_.StartTable();
   }
-  SqueezeParamBuilder &operator=(const SqueezeParamBuilder &);
   flatbuffers::Offset<SqueezeParam> Finish() {
     const auto end = fbb_.EndTable(start_);
     auto o = flatbuffers::Offset<SqueezeParam>(end);
@@ -877,16 +899,13 @@ flatbuffers::Offset<SqueezeParam> CreateSqueezeParam(flatbuffers::FlatBufferBuil
 
 struct CastParamT : public flatbuffers::NativeTable {
   typedef CastParam TableType;
-  DataType srcT;
-  DataType dstT;
-  CastParamT()
-      : srcT(DataType_DT_INVALID),
-        dstT(DataType_DT_INVALID) {
-  }
+  MNN::DataType srcT = MNN::DataType_DT_INVALID;
+  MNN::DataType dstT = MNN::DataType_DT_INVALID;
 };
 
 struct CastParam FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
   typedef CastParamT NativeTableType;
+  typedef CastParamBuilder Builder;
   static const flatbuffers::TypeTable *MiniReflectTypeTable() {
     return CastParamTypeTable();
   }
@@ -894,11 +913,11 @@ struct CastParam FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
     VT_SRCT = 4,
     VT_DSTT = 6
   };
-  DataType srcT() const {
-    return static_cast<DataType>(GetField<int32_t>(VT_SRCT, 0));
+  MNN::DataType srcT() const {
+    return static_cast<MNN::DataType>(GetField<int32_t>(VT_SRCT, 0));
   }
-  DataType dstT() const {
-    return static_cast<DataType>(GetField<int32_t>(VT_DSTT, 0));
+  MNN::DataType dstT() const {
+    return static_cast<MNN::DataType>(GetField<int32_t>(VT_DSTT, 0));
   }
   bool Verify(flatbuffers::Verifier &verifier) const {
     return VerifyTableStart(verifier) &&
@@ -912,19 +931,19 @@ struct CastParam FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
 };
 
 struct CastParamBuilder {
+  typedef CastParam Table;
   flatbuffers::FlatBufferBuilder &fbb_;
   flatbuffers::uoffset_t start_;
-  void add_srcT(DataType srcT) {
+  void add_srcT(MNN::DataType srcT) {
     fbb_.AddElement<int32_t>(CastParam::VT_SRCT, static_cast<int32_t>(srcT), 0);
   }
-  void add_dstT(DataType dstT) {
+  void add_dstT(MNN::DataType dstT) {
     fbb_.AddElement<int32_t>(CastParam::VT_DSTT, static_cast<int32_t>(dstT), 0);
   }
   explicit CastParamBuilder(flatbuffers::FlatBufferBuilder &_fbb)
         : fbb_(_fbb) {
     start_ = fbb_.StartTable();
   }
-  CastParamBuilder &operator=(const CastParamBuilder &);
   flatbuffers::Offset<CastParam> Finish() {
     const auto end = fbb_.EndTable(start_);
     auto o = flatbuffers::Offset<CastParam>(end);
@@ -934,8 +953,8 @@ struct CastParamBuilder {
 
 inline flatbuffers::Offset<CastParam> CreateCastParam(
     flatbuffers::FlatBufferBuilder &_fbb,
-    DataType srcT = DataType_DT_INVALID,
-    DataType dstT = DataType_DT_INVALID) {
+    MNN::DataType srcT = MNN::DataType_DT_INVALID,
+    MNN::DataType dstT = MNN::DataType_DT_INVALID) {
   CastParamBuilder builder_(_fbb);
   builder_.add_dstT(dstT);
   builder_.add_srcT(srcT);
@@ -946,21 +965,16 @@ flatbuffers::Offset<CastParam> CreateCastParam(flatbuffers::FlatBufferBuilder &_
 
 struct ReductionParamT : public flatbuffers::NativeTable {
   typedef ReductionParam TableType;
-  ReductionType operation;
-  std::vector<int32_t> dim;
-  float coeff;
-  bool keepDims;
-  DataType dType;
-  ReductionParamT()
-      : operation(ReductionType_SUM),
-        coeff(0.0f),
-        keepDims(false),
-        dType(DataType_DT_FLOAT) {
-  }
+  MNN::ReductionType operation = MNN::ReductionType_SUM;
+  std::vector<int32_t> dim{};
+  float coeff = 0.0f;
+  bool keepDims = false;
+  MNN::DataType dType = MNN::DataType_DT_FLOAT;
 };
 
 struct ReductionParam FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
   typedef ReductionParamT NativeTableType;
+  typedef ReductionParamBuilder Builder;
   static const flatbuffers::TypeTable *MiniReflectTypeTable() {
     return ReductionParamTypeTable();
   }
@@ -971,8 +985,8 @@ struct ReductionParam FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
     VT_KEEPDIMS = 10,
     VT_DTYPE = 12
   };
-  ReductionType operation() const {
-    return static_cast<ReductionType>(GetField<int8_t>(VT_OPERATION, 0));
+  MNN::ReductionType operation() const {
+    return static_cast<MNN::ReductionType>(GetField<int8_t>(VT_OPERATION, 0));
   }
   const flatbuffers::Vector<int32_t> *dim() const {
     return GetPointer<const flatbuffers::Vector<int32_t> *>(VT_DIM);
@@ -983,8 +997,8 @@ struct ReductionParam FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
   bool keepDims() const {
     return GetField<uint8_t>(VT_KEEPDIMS, 0) != 0;
   }
-  DataType dType() const {
-    return static_cast<DataType>(GetField<int32_t>(VT_DTYPE, 1));
+  MNN::DataType dType() const {
+    return static_cast<MNN::DataType>(GetField<int32_t>(VT_DTYPE, 1));
   }
   bool Verify(flatbuffers::Verifier &verifier) const {
     return VerifyTableStart(verifier) &&
@@ -1002,9 +1016,10 @@ struct ReductionParam FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
 };
 
 struct ReductionParamBuilder {
+  typedef ReductionParam Table;
   flatbuffers::FlatBufferBuilder &fbb_;
   flatbuffers::uoffset_t start_;
-  void add_operation(ReductionType operation) {
+  void add_operation(MNN::ReductionType operation) {
     fbb_.AddElement<int8_t>(ReductionParam::VT_OPERATION, static_cast<int8_t>(operation), 0);
   }
   void add_dim(flatbuffers::Offset<flatbuffers::Vector<int32_t>> dim) {
@@ -1016,14 +1031,13 @@ struct ReductionParamBuilder {
   void add_keepDims(bool keepDims) {
     fbb_.AddElement<uint8_t>(ReductionParam::VT_KEEPDIMS, static_cast<uint8_t>(keepDims), 0);
   }
-  void add_dType(DataType dType) {
+  void add_dType(MNN::DataType dType) {
     fbb_.AddElement<int32_t>(ReductionParam::VT_DTYPE, static_cast<int32_t>(dType), 1);
   }
   explicit ReductionParamBuilder(flatbuffers::FlatBufferBuilder &_fbb)
         : fbb_(_fbb) {
     start_ = fbb_.StartTable();
   }
-  ReductionParamBuilder &operator=(const ReductionParamBuilder &);
   flatbuffers::Offset<ReductionParam> Finish() {
     const auto end = fbb_.EndTable(start_);
     auto o = flatbuffers::Offset<ReductionParam>(end);
@@ -1033,11 +1047,11 @@ struct ReductionParamBuilder {
 
 inline flatbuffers::Offset<ReductionParam> CreateReductionParam(
     flatbuffers::FlatBufferBuilder &_fbb,
-    ReductionType operation = ReductionType_SUM,
+    MNN::ReductionType operation = MNN::ReductionType_SUM,
     flatbuffers::Offset<flatbuffers::Vector<int32_t>> dim = 0,
     float coeff = 0.0f,
     bool keepDims = false,
-    DataType dType = DataType_DT_FLOAT) {
+    MNN::DataType dType = MNN::DataType_DT_FLOAT) {
   ReductionParamBuilder builder_(_fbb);
   builder_.add_dType(dType);
   builder_.add_coeff(coeff);
@@ -1049,11 +1063,11 @@ inline flatbuffers::Offset<ReductionParam> CreateReductionParam(
 
 inline flatbuffers::Offset<ReductionParam> CreateReductionParamDirect(
     flatbuffers::FlatBufferBuilder &_fbb,
-    ReductionType operation = ReductionType_SUM,
+    MNN::ReductionType operation = MNN::ReductionType_SUM,
     const std::vector<int32_t> *dim = nullptr,
     float coeff = 0.0f,
     bool keepDims = false,
-    DataType dType = DataType_DT_FLOAT) {
+    MNN::DataType dType = MNN::DataType_DT_FLOAT) {
   auto dim__ = dim ? _fbb.CreateVector<int32_t>(*dim) : 0;
   return MNN::CreateReductionParam(
       _fbb,
@@ -1068,20 +1082,15 @@ flatbuffers::Offset<ReductionParam> CreateReductionParam(flatbuffers::FlatBuffer
 
 struct GatherT : public flatbuffers::NativeTable {
   typedef Gather TableType;
-  DataType Tindices;
-  DataType Tparams;
-  bool validateIndices;
-  int32_t axis;
-  GatherT()
-      : Tindices(DataType_DT_INVALID),
-        Tparams(DataType_DT_INVALID),
-        validateIndices(false),
-        axis(0) {
-  }
+  MNN::DataType Tindices = MNN::DataType_DT_INVALID;
+  MNN::DataType Tparams = MNN::DataType_DT_INVALID;
+  bool validateIndices = false;
+  int32_t axis = 0;
 };
 
 struct Gather FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
   typedef GatherT NativeTableType;
+  typedef GatherBuilder Builder;
   static const flatbuffers::TypeTable *MiniReflectTypeTable() {
     return GatherTypeTable();
   }
@@ -1091,11 +1100,11 @@ struct Gather FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
     VT_VALIDATEINDICES = 8,
     VT_AXIS = 10
   };
-  DataType Tindices() const {
-    return static_cast<DataType>(GetField<int32_t>(VT_TINDICES, 0));
+  MNN::DataType Tindices() const {
+    return static_cast<MNN::DataType>(GetField<int32_t>(VT_TINDICES, 0));
   }
-  DataType Tparams() const {
-    return static_cast<DataType>(GetField<int32_t>(VT_TPARAMS, 0));
+  MNN::DataType Tparams() const {
+    return static_cast<MNN::DataType>(GetField<int32_t>(VT_TPARAMS, 0));
   }
   bool validateIndices() const {
     return GetField<uint8_t>(VT_VALIDATEINDICES, 0) != 0;
@@ -1117,12 +1126,13 @@ struct Gather FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
 };
 
 struct GatherBuilder {
+  typedef Gather Table;
   flatbuffers::FlatBufferBuilder &fbb_;
   flatbuffers::uoffset_t start_;
-  void add_Tindices(DataType Tindices) {
+  void add_Tindices(MNN::DataType Tindices) {
     fbb_.AddElement<int32_t>(Gather::VT_TINDICES, static_cast<int32_t>(Tindices), 0);
   }
-  void add_Tparams(DataType Tparams) {
+  void add_Tparams(MNN::DataType Tparams) {
     fbb_.AddElement<int32_t>(Gather::VT_TPARAMS, static_cast<int32_t>(Tparams), 0);
   }
   void add_validateIndices(bool validateIndices) {
@@ -1135,7 +1145,6 @@ struct GatherBuilder {
         : fbb_(_fbb) {
     start_ = fbb_.StartTable();
   }
-  GatherBuilder &operator=(const GatherBuilder &);
   flatbuffers::Offset<Gather> Finish() {
     const auto end = fbb_.EndTable(start_);
     auto o = flatbuffers::Offset<Gather>(end);
@@ -1145,8 +1154,8 @@ struct GatherBuilder {
 
 inline flatbuffers::Offset<Gather> CreateGather(
     flatbuffers::FlatBufferBuilder &_fbb,
-    DataType Tindices = DataType_DT_INVALID,
-    DataType Tparams = DataType_DT_INVALID,
+    MNN::DataType Tindices = MNN::DataType_DT_INVALID,
+    MNN::DataType Tparams = MNN::DataType_DT_INVALID,
     bool validateIndices = false,
     int32_t axis = 0) {
   GatherBuilder builder_(_fbb);
@@ -1161,18 +1170,14 @@ flatbuffers::Offset<Gather> CreateGather(flatbuffers::FlatBufferBuilder &_fbb, c
 
 struct ExpandDimsT : public flatbuffers::NativeTable {
   typedef ExpandDims TableType;
-  DataType T;
-  DataType Tdim;
-  int32_t axis;
-  ExpandDimsT()
-      : T(DataType_DT_INVALID),
-        Tdim(DataType_DT_INVALID),
-        axis(0) {
-  }
+  MNN::DataType T = MNN::DataType_DT_INVALID;
+  MNN::DataType Tdim = MNN::DataType_DT_INVALID;
+  int32_t axis = 0;
 };
 
 struct ExpandDims FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
   typedef ExpandDimsT NativeTableType;
+  typedef ExpandDimsBuilder Builder;
   static const flatbuffers::TypeTable *MiniReflectTypeTable() {
     return ExpandDimsTypeTable();
   }
@@ -1181,11 +1186,11 @@ struct ExpandDims FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
     VT_TDIM = 6,
     VT_AXIS = 8
   };
-  DataType T() const {
-    return static_cast<DataType>(GetField<int32_t>(VT_T, 0));
+  MNN::DataType T() const {
+    return static_cast<MNN::DataType>(GetField<int32_t>(VT_T, 0));
   }
-  DataType Tdim() const {
-    return static_cast<DataType>(GetField<int32_t>(VT_TDIM, 0));
+  MNN::DataType Tdim() const {
+    return static_cast<MNN::DataType>(GetField<int32_t>(VT_TDIM, 0));
   }
   int32_t axis() const {
     return GetField<int32_t>(VT_AXIS, 0);
@@ -1203,12 +1208,13 @@ struct ExpandDims FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
 };
 
 struct ExpandDimsBuilder {
+  typedef ExpandDims Table;
   flatbuffers::FlatBufferBuilder &fbb_;
   flatbuffers::uoffset_t start_;
-  void add_T(DataType T) {
+  void add_T(MNN::DataType T) {
     fbb_.AddElement<int32_t>(ExpandDims::VT_T, static_cast<int32_t>(T), 0);
   }
-  void add_Tdim(DataType Tdim) {
+  void add_Tdim(MNN::DataType Tdim) {
     fbb_.AddElement<int32_t>(ExpandDims::VT_TDIM, static_cast<int32_t>(Tdim), 0);
   }
   void add_axis(int32_t axis) {
@@ -1218,7 +1224,6 @@ struct ExpandDimsBuilder {
         : fbb_(_fbb) {
     start_ = fbb_.StartTable();
   }
-  ExpandDimsBuilder &operator=(const ExpandDimsBuilder &);
   flatbuffers::Offset<ExpandDims> Finish() {
     const auto end = fbb_.EndTable(start_);
     auto o = flatbuffers::Offset<ExpandDims>(end);
@@ -1228,8 +1233,8 @@ struct ExpandDimsBuilder {
 
 inline flatbuffers::Offset<ExpandDims> CreateExpandDims(
     flatbuffers::FlatBufferBuilder &_fbb,
-    DataType T = DataType_DT_INVALID,
-    DataType Tdim = DataType_DT_INVALID,
+    MNN::DataType T = MNN::DataType_DT_INVALID,
+    MNN::DataType Tdim = MNN::DataType_DT_INVALID,
     int32_t axis = 0) {
   ExpandDimsBuilder builder_(_fbb);
   builder_.add_axis(axis);
@@ -1242,16 +1247,13 @@ flatbuffers::Offset<ExpandDims> CreateExpandDims(flatbuffers::FlatBufferBuilder
 
 struct SeluT : public flatbuffers::NativeTable {
   typedef Selu TableType;
-  float scale;
-  float alpha;
-  SeluT()
-      : scale(0.0f),
-        alpha(0.0f) {
-  }
+  float scale = 0.0f;
+  float alpha = 0.0f;
 };
 
 struct Selu FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
   typedef SeluT NativeTableType;
+  typedef SeluBuilder Builder;
   static const flatbuffers::TypeTable *MiniReflectTypeTable() {
     return SeluTypeTable();
   }
@@ -1277,6 +1279,7 @@ struct Selu FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
 };
 
 struct SeluBuilder {
+  typedef Selu Table;
   flatbuffers::FlatBufferBuilder &fbb_;
   flatbuffers::uoffset_t start_;
   void add_scale(float scale) {
@@ -1289,7 +1292,6 @@ struct SeluBuilder {
         : fbb_(_fbb) {
     start_ = fbb_.StartTable();
   }
-  SeluBuilder &operator=(const SeluBuilder &);
   flatbuffers::Offset<Selu> Finish() {
     const auto end = fbb_.EndTable(start_);
     auto o = flatbuffers::Offset<Selu>(end);
@@ -1311,23 +1313,17 @@ flatbuffers::Offset<Selu> CreateSelu(flatbuffers::FlatBufferBuilder &_fbb, const
 
 struct AsStringT : public flatbuffers::NativeTable {
   typedef AsString TableType;
-  DataType T;
-  int32_t precision;
-  bool scientific;
-  bool shortest;
-  int32_t width;
-  std::string fillString;
-  AsStringT()
-      : T(DataType_DT_INVALID),
-        precision(0),
-        scientific(false),
-        shortest(false),
-        width(0) {
-  }
+  MNN::DataType T = MNN::DataType_DT_INVALID;
+  int32_t precision = 0;
+  bool scientific = false;
+  bool shortest = false;
+  int32_t width = 0;
+  std::string fillString{};
 };
 
 struct AsString FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
   typedef AsStringT NativeTableType;
+  typedef AsStringBuilder Builder;
   static const flatbuffers::TypeTable *MiniReflectTypeTable() {
     return AsStringTypeTable();
   }
@@ -1339,8 +1335,8 @@ struct AsString FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
     VT_WIDTH = 12,
     VT_FILLSTRING = 14
   };
-  DataType T() const {
-    return static_cast<DataType>(GetField<int32_t>(VT_T, 0));
+  MNN::DataType T() const {
+    return static_cast<MNN::DataType>(GetField<int32_t>(VT_T, 0));
   }
   int32_t precision() const {
     return GetField<int32_t>(VT_PRECISION, 0);
@@ -1374,9 +1370,10 @@ struct AsString FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
 };
 
 struct AsStringBuilder {
+  typedef AsString Table;
   flatbuffers::FlatBufferBuilder &fbb_;
   flatbuffers::uoffset_t start_;
-  void add_T(DataType T) {
+  void add_T(MNN::DataType T) {
     fbb_.AddElement<int32_t>(AsString::VT_T, static_cast<int32_t>(T), 0);
   }
   void add_precision(int32_t precision) {
@@ -1398,7 +1395,6 @@ struct AsStringBuilder {
         : fbb_(_fbb) {
     start_ = fbb_.StartTable();
   }
-  AsStringBuilder &operator=(const AsStringBuilder &);
   flatbuffers::Offset<AsString> Finish() {
     const auto end = fbb_.EndTable(start_);
     auto o = flatbuffers::Offset<AsString>(end);
@@ -1408,7 +1404,7 @@ struct AsStringBuilder {
 
 inline flatbuffers::Offset<AsString> CreateAsString(
     flatbuffers::FlatBufferBuilder &_fbb,
-    DataType T = DataType_DT_INVALID,
+    MNN::DataType T = MNN::DataType_DT_INVALID,
     int32_t precision = 0,
     bool scientific = false,
     bool shortest = false,
@@ -1426,7 +1422,7 @@ inline flatbuffers::Offset<AsString> CreateAsString(
 
 inline flatbuffers::Offset<AsString> CreateAsStringDirect(
     flatbuffers::FlatBufferBuilder &_fbb,
-    DataType T = DataType_DT_INVALID,
+    MNN::DataType T = MNN::DataType_DT_INVALID,
     int32_t precision = 0,
     bool scientific = false,
     bool shortest = false,
@@ -1447,15 +1443,13 @@ flatbuffers::Offset<AsString> CreateAsString(flatbuffers::FlatBufferBuilder &_fb
 
 struct ReduceJoinT : public flatbuffers::NativeTable {
   typedef ReduceJoin TableType;
-  bool keepDims;
-  std::string separator;
-  ReduceJoinT()
-      : keepDims(false) {
-  }
+  bool keepDims = false;
+  std::string separator{};
 };
 
 struct ReduceJoin FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
   typedef ReduceJoinT NativeTableType;
+  typedef ReduceJoinBuilder Builder;
   static const flatbuffers::TypeTable *MiniReflectTypeTable() {
     return ReduceJoinTypeTable();
   }
@@ -1482,6 +1476,7 @@ struct ReduceJoin FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
 };
 
 struct ReduceJoinBuilder {
+  typedef ReduceJoin Table;
   flatbuffers::FlatBufferBuilder &fbb_;
   flatbuffers::uoffset_t start_;
   void add_keepDims(bool keepDims) {
@@ -1494,7 +1489,6 @@ struct ReduceJoinBuilder {
         : fbb_(_fbb) {
     start_ = fbb_.StartTable();
   }
-  ReduceJoinBuilder &operator=(const ReduceJoinBuilder &);
   flatbuffers::Offset<ReduceJoin> Finish() {
     const auto end = fbb_.EndTable(start_);
     auto o = flatbuffers::Offset<ReduceJoin>(end);
@@ -1527,16 +1521,13 @@ flatbuffers::Offset<ReduceJoin> CreateReduceJoin(flatbuffers::FlatBufferBuilder
 
 struct UnaryOpT : public flatbuffers::NativeTable {
   typedef UnaryOp TableType;
-  UnaryOpOperation opType;
-  DataType T;
-  UnaryOpT()
-      : opType(UnaryOpOperation_ABS),
-        T(DataType_DT_INVALID) {
-  }
+  MNN::UnaryOpOperation opType = MNN::UnaryOpOperation_ABS;
+  MNN::DataType T = MNN::DataType_DT_INVALID;
 };
 
 struct UnaryOp FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
   typedef UnaryOpT NativeTableType;
+  typedef UnaryOpBuilder Builder;
   static const flatbuffers::TypeTable *MiniReflectTypeTable() {
     return UnaryOpTypeTable();
   }
@@ -1544,11 +1535,11 @@ struct UnaryOp FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
     VT_OPTYPE = 4,
     VT_T = 6
   };
-  UnaryOpOperation opType() const {
-    return static_cast<UnaryOpOperation>(GetField<int32_t>(VT_OPTYPE, 0));
+  MNN::UnaryOpOperation opType() const {
+    return static_cast<MNN::UnaryOpOperation>(GetField<int32_t>(VT_OPTYPE, 0));
   }
-  DataType T() const {
-    return static_cast<DataType>(GetField<int32_t>(VT_T, 0));
+  MNN::DataType T() const {
+    return static_cast<MNN::DataType>(GetField<int32_t>(VT_T, 0));
   }
   bool Verify(flatbuffers::Verifier &verifier) const {
     return VerifyTableStart(verifier) &&
@@ -1562,19 +1553,19 @@ struct UnaryOp FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
 };
 
 struct UnaryOpBuilder {
+  typedef UnaryOp Table;
   flatbuffers::FlatBufferBuilder &fbb_;
   flatbuffers::uoffset_t start_;
-  void add_opType(UnaryOpOperation opType) {
+  void add_opType(MNN::UnaryOpOperation opType) {
     fbb_.AddElement<int32_t>(UnaryOp::VT_OPTYPE, static_cast<int32_t>(opType), 0);
   }
-  void add_T(DataType T) {
+  void add_T(MNN::DataType T) {
     fbb_.AddElement<int32_t>(UnaryOp::VT_T, static_cast<int32_t>(T), 0);
   }
   explicit UnaryOpBuilder(flatbuffers::FlatBufferBuilder &_fbb)
         : fbb_(_fbb) {
     start_ = fbb_.StartTable();
   }
-  UnaryOpBuilder &operator=(const UnaryOpBuilder &);
   flatbuffers::Offset<UnaryOp> Finish() {
     const auto end = fbb_.EndTable(start_);
     auto o = flatbuffers::Offset<UnaryOp>(end);
@@ -1584,8 +1575,8 @@ struct UnaryOpBuilder {
 
 inline flatbuffers::Offset<UnaryOp> CreateUnaryOp(
     flatbuffers::FlatBufferBuilder &_fbb,
-    UnaryOpOperation opType = UnaryOpOperation_ABS,
-    DataType T = DataType_DT_INVALID) {
+    MNN::UnaryOpOperation opType = MNN::UnaryOpOperation_ABS,
+    MNN::DataType T = MNN::DataType_DT_INVALID) {
   UnaryOpBuilder builder_(_fbb);
   builder_.add_T(T);
   builder_.add_opType(opType);
@@ -1596,16 +1587,13 @@ flatbuffers::Offset<UnaryOp> CreateUnaryOp(flatbuffers::FlatBufferBuilder &_fbb,
 
 struct TopKV2T : public flatbuffers::NativeTable {
   typedef TopKV2 TableType;
-  DataType T;
-  bool sorted;
-  TopKV2T()
-      : T(DataType_DT_FLOAT),
-        sorted(false) {
-  }
+  MNN::DataType T = MNN::DataType_DT_FLOAT;
+  bool sorted = false;
 };
 
 struct TopKV2 FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
   typedef TopKV2T NativeTableType;
+  typedef TopKV2Builder Builder;
   static const flatbuffers::TypeTable *MiniReflectTypeTable() {
     return TopKV2TypeTable();
   }
@@ -1613,8 +1601,8 @@ struct TopKV2 FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
     VT_T = 4,
     VT_SORTED = 6
   };
-  DataType T() const {
-    return static_cast<DataType>(GetField<int32_t>(VT_T, 1));
+  MNN::DataType T() const {
+    return static_cast<MNN::DataType>(GetField<int32_t>(VT_T, 1));
   }
   bool sorted() const {
     return GetField<uint8_t>(VT_SORTED, 0) != 0;
@@ -1631,9 +1619,10 @@ struct TopKV2 FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
 };
 
 struct TopKV2Builder {
+  typedef TopKV2 Table;
   flatbuffers::FlatBufferBuilder &fbb_;
   flatbuffers::uoffset_t start_;
-  void add_T(DataType T) {
+  void add_T(MNN::DataType T) {
     fbb_.AddElement<int32_t>(TopKV2::VT_T, static_cast<int32_t>(T), 1);
   }
   void add_sorted(bool sorted) {
@@ -1643,7 +1632,6 @@ struct TopKV2Builder {
         : fbb_(_fbb) {
     start_ = fbb_.StartTable();
   }
-  TopKV2Builder &operator=(const TopKV2Builder &);
   flatbuffers::Offset<TopKV2> Finish() {
     const auto end = fbb_.EndTable(start_);
     auto o = flatbuffers::Offset<TopKV2>(end);
@@ -1653,7 +1641,7 @@ struct TopKV2Builder {
 
 inline flatbuffers::Offset<TopKV2> CreateTopKV2(
     flatbuffers::FlatBufferBuilder &_fbb,
-    DataType T = DataType_DT_FLOAT,
+    MNN::DataType T = MNN::DataType_DT_FLOAT,
     bool sorted = false) {
   TopKV2Builder builder_(_fbb);
   builder_.add_T(T);
@@ -1665,16 +1653,13 @@ flatbuffers::Offset<TopKV2> CreateTopKV2(flatbuffers::FlatBufferBuilder &_fbb, c
 
 struct CropAndResizeT : public flatbuffers::NativeTable {
   typedef CropAndResize TableType;
-  float extrapolationValue;
-  CropAndResizeMethod method;
-  CropAndResizeT()
-      : extrapolationValue(0.0f),
-        method(CropAndResizeMethod_BILINEAR) {
-  }
+  float extrapolationValue = 0.0f;
+  MNN::CropAndResizeMethod method = MNN::CropAndResizeMethod_BILINEAR;
 };
 
 struct CropAndResize FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
   typedef CropAndResizeT NativeTableType;
+  typedef CropAndResizeBuilder Builder;
   static const flatbuffers::TypeTable *MiniReflectTypeTable() {
     return CropAndResizeTypeTable();
   }
@@ -1685,8 +1670,8 @@ struct CropAndResize FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
   float extrapolationValue() const {
     return GetField<float>(VT_EXTRAPOLATIONVALUE, 0.0f);
   }
-  CropAndResizeMethod method() const {
-    return static_cast<CropAndResizeMethod>(GetField<int8_t>(VT_METHOD, 0));
+  MNN::CropAndResizeMethod method() const {
+    return static_cast<MNN::CropAndResizeMethod>(GetField<int8_t>(VT_METHOD, 0));
   }
   bool Verify(flatbuffers::Verifier &verifier) const {
     return VerifyTableStart(verifier) &&
@@ -1700,19 +1685,19 @@ struct CropAndResize FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
 };
 
 struct CropAndResizeBuilder {
+  typedef CropAndResize Table;
   flatbuffers::FlatBufferBuilder &fbb_;
   flatbuffers::uoffset_t start_;
   void add_extrapolationValue(float extrapolationValue) {
     fbb_.AddElement<float>(CropAndResize::VT_EXTRAPOLATIONVALUE, extrapolationValue, 0.0f);
   }
-  void add_method(CropAndResizeMethod method) {
+  void add_method(MNN::CropAndResizeMethod method) {
     fbb_.AddElement<int8_t>(CropAndResize::VT_METHOD, static_cast<int8_t>(method), 0);
   }
   explicit CropAndResizeBuilder(flatbuffers::FlatBufferBuilder &_fbb)
         : fbb_(_fbb) {
     start_ = fbb_.StartTable();
   }
-  CropAndResizeBuilder &operator=(const CropAndResizeBuilder &);
   flatbuffers::Offset<CropAndResize> Finish() {
     const auto end = fbb_.EndTable(start_);
     auto o = flatbuffers::Offset<CropAndResize>(end);
@@ -1723,7 +1708,7 @@ struct CropAndResizeBuilder {
 inline flatbuffers::Offset<CropAndResize> CreateCropAndResize(
     flatbuffers::FlatBufferBuilder &_fbb,
     float extrapolationValue = 0.0f,
-    CropAndResizeMethod method = CropAndResizeMethod_BILINEAR) {
+    MNN::CropAndResizeMethod method = MNN::CropAndResizeMethod_BILINEAR) {
   CropAndResizeBuilder builder_(_fbb);
   builder_.add_extrapolationValue(extrapolationValue);
   builder_.add_method(method);
@@ -1734,12 +1719,11 @@ flatbuffers::Offset<CropAndResize> CreateCropAndResize(flatbuffers::FlatBufferBu
 
 struct FillT : public flatbuffers::NativeTable {
   typedef Fill TableType;
-  FillT() {
-  }
 };
 
 struct Fill FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
   typedef FillT NativeTableType;
+  typedef FillBuilder Builder;
   static const flatbuffers::TypeTable *MiniReflectTypeTable() {
     return FillTypeTable();
   }
@@ -1753,13 +1737,13 @@ struct Fill FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
 };
 
 struct FillBuilder {
+  typedef Fill Table;
   flatbuffers::FlatBufferBuilder &fbb_;
   flatbuffers::uoffset_t start_;
   explicit FillBuilder(flatbuffers::FlatBufferBuilder &_fbb)
         : fbb_(_fbb) {
     start_ = fbb_.StartTable();
   }
-  FillBuilder &operator=(const FillBuilder &);
   flatbuffers::Offset<Fill> Finish() {
     const auto end = fbb_.EndTable(start_);
     auto o = flatbuffers::Offset<Fill>(end);
@@ -1777,18 +1761,14 @@ flatbuffers::Offset<Fill> CreateFill(flatbuffers::FlatBufferBuilder &_fbb, const
 
 struct GatherV2T : public flatbuffers::NativeTable {
   typedef GatherV2 TableType;
-  DataType Taxis;
-  DataType Tindices;
-  DataType Tparams;
-  GatherV2T()
-      : Taxis(DataType_DT_INVALID),
-        Tindices(DataType_DT_INVALID),
-        Tparams(DataType_DT_INVALID) {
-  }
+  MNN::DataType Taxis = MNN::DataType_DT_INVALID;
+  MNN::DataType Tindices = MNN::DataType_DT_INVALID;
+  MNN::DataType Tparams = MNN::DataType_DT_INVALID;
 };
 
 struct GatherV2 FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
   typedef GatherV2T NativeTableType;
+  typedef GatherV2Builder Builder;
   static const flatbuffers::TypeTable *MiniReflectTypeTable() {
     return GatherV2TypeTable();
   }
@@ -1797,14 +1777,14 @@ struct GatherV2 FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
     VT_TINDICES = 6,
     VT_TPARAMS = 8
   };
-  DataType Taxis() const {
-    return static_cast<DataType>(GetField<int32_t>(VT_TAXIS, 0));
+  MNN::DataType Taxis() const {
+    return static_cast<MNN::DataType>(GetField<int32_t>(VT_TAXIS, 0));
   }
-  DataType Tindices() const {
-    return static_cast<DataType>(GetField<int32_t>(VT_TINDICES, 0));
+  MNN::DataType Tindices() const {
+    return static_cast<MNN::DataType>(GetField<int32_t>(VT_TINDICES, 0));
   }
-  DataType Tparams() const {
-    return static_cast<DataType>(GetField<int32_t>(VT_TPARAMS, 0));
+  MNN::DataType Tparams() const {
+    return static_cast<MNN::DataType>(GetField<int32_t>(VT_TPARAMS, 0));
   }
   bool Verify(flatbuffers::Verifier &verifier) const {
     return VerifyTableStart(verifier) &&
@@ -1819,22 +1799,22 @@ struct GatherV2 FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
 };
 
 struct GatherV2Builder {
+  typedef GatherV2 Table;
   flatbuffers::FlatBufferBuilder &fbb_;
   flatbuffers::uoffset_t start_;
-  void add_Taxis(DataType Taxis) {
+  void add_Taxis(MNN::DataType Taxis) {
     fbb_.AddElement<int32_t>(GatherV2::VT_TAXIS, static_cast<int32_t>(Taxis), 0);
   }
-  void add_Tindices(DataType Tindices) {
+  void add_Tindices(MNN::DataType Tindices) {
     fbb_.AddElement<int32_t>(GatherV2::VT_TINDICES, static_cast<int32_t>(Tindices), 0);
   }
-  void add_Tparams(DataType Tparams) {
+  void add_Tparams(MNN::DataType Tparams) {
     fbb_.AddElement<int32_t>(GatherV2::VT_TPARAMS, static_cast<int32_t>(Tparams), 0);
   }
   explicit GatherV2Builder(flatbuffers::FlatBufferBuilder &_fbb)
         : fbb_(_fbb) {
     start_ = fbb_.StartTable();
   }
-  GatherV2Builder &operator=(const GatherV2Builder &);
   flatbuffers::Offset<GatherV2> Finish() {
     const auto end = fbb_.EndTable(start_);
     auto o = flatbuffers::Offset<GatherV2>(end);
@@ -1844,9 +1824,9 @@ struct GatherV2Builder {
 
 inline flatbuffers::Offset<GatherV2> CreateGatherV2(
     flatbuffers::FlatBufferBuilder &_fbb,
-    DataType Taxis = DataType_DT_INVALID,
-    DataType Tindices = DataType_DT_INVALID,
-    DataType Tparams = DataType_DT_INVALID) {
+    MNN::DataType Taxis = MNN::DataType_DT_INVALID,
+    MNN::DataType Tindices = MNN::DataType_DT_INVALID,
+    MNN::DataType Tparams = MNN::DataType_DT_INVALID) {
   GatherV2Builder builder_(_fbb);
   builder_.add_Tparams(Tparams);
   builder_.add_Tindices(Tindices);
@@ -1858,12 +1838,11 @@ flatbuffers::Offset<GatherV2> CreateGatherV2(flatbuffers::FlatBufferBuilder &_fb
 
 struct NonMaxSuppressionV2T : public flatbuffers::NativeTable {
   typedef NonMaxSuppressionV2 TableType;
-  NonMaxSuppressionV2T() {
-  }
 };
 
 struct NonMaxSuppressionV2 FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
   typedef NonMaxSuppressionV2T NativeTableType;
+  typedef NonMaxSuppressionV2Builder Builder;
   static const flatbuffers::TypeTable *MiniReflectTypeTable() {
     return NonMaxSuppressionV2TypeTable();
   }
@@ -1877,13 +1856,13 @@ struct NonMaxSuppressionV2 FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table
 };
 
 struct NonMaxSuppressionV2Builder {
+  typedef NonMaxSuppressionV2 Table;
   flatbuffers::FlatBufferBuilder &fbb_;
   flatbuffers::uoffset_t start_;
   explicit NonMaxSuppressionV2Builder(flatbuffers::FlatBufferBuilder &_fbb)
         : fbb_(_fbb) {
     start_ = fbb_.StartTable();
   }
-  NonMaxSuppressionV2Builder &operator=(const NonMaxSuppressionV2Builder &);
   flatbuffers::Offset<NonMaxSuppressionV2> Finish() {
     const auto end = fbb_.EndTable(start_);
     auto o = flatbuffers::Offset<NonMaxSuppressionV2>(end);
@@ -1901,22 +1880,20 @@ flatbuffers::Offset<NonMaxSuppressionV2> CreateNonMaxSuppressionV2(flatbuffers::
 
 struct RangeT : public flatbuffers::NativeTable {
   typedef Range TableType;
-  DataType Tidx;
-  RangeT()
-      : Tidx(DataType_DT_INVALID) {
-  }
+  MNN::DataType Tidx = MNN::DataType_DT_INVALID;
 };
 
 struct Range FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
   typedef RangeT NativeTableType;
+  typedef RangeBuilder Builder;
   static const flatbuffers::TypeTable *MiniReflectTypeTable() {
     return RangeTypeTable();
   }
   enum FlatBuffersVTableOffset FLATBUFFERS_VTABLE_UNDERLYING_TYPE {
     VT_TIDX = 4
   };
-  DataType Tidx() const {
-    return static_cast<DataType>(GetField<int32_t>(VT_TIDX, 0));
+  MNN::DataType Tidx() const {
+    return static_cast<MNN::DataType>(GetField<int32_t>(VT_TIDX, 0));
   }
   bool Verify(flatbuffers::Verifier &verifier) const {
     return VerifyTableStart(verifier) &&
@@ -1929,16 +1906,16 @@ struct Range FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
 };
 
 struct RangeBuilder {
+  typedef Range Table;
   flatbuffers::FlatBufferBuilder &fbb_;
   flatbuffers::uoffset_t start_;
-  void add_Tidx(DataType Tidx) {
+  void add_Tidx(MNN::DataType Tidx) {
     fbb_.AddElement<int32_t>(Range::VT_TIDX, static_cast<int32_t>(Tidx), 0);
   }
   explicit RangeBuilder(flatbuffers::FlatBufferBuilder &_fbb)
         : fbb_(_fbb) {
     start_ = fbb_.StartTable();
   }
-  RangeBuilder &operator=(const RangeBuilder &);
   flatbuffers::Offset<Range> Finish() {
     const auto end = fbb_.EndTable(start_);
     auto o = flatbuffers::Offset<Range>(end);
@@ -1948,7 +1925,7 @@ struct RangeBuilder {
 
 inline flatbuffers::Offset<Range> CreateRange(
     flatbuffers::FlatBufferBuilder &_fbb,
-    DataType Tidx = DataType_DT_INVALID) {
+    MNN::DataType Tidx = MNN::DataType_DT_INVALID) {
   RangeBuilder builder_(_fbb);
   builder_.add_Tidx(Tidx);
   return builder_.Finish();
@@ -1958,12 +1935,11 @@ flatbuffers::Offset<Range> CreateRange(flatbuffers::FlatBufferBuilder &_fbb, con
 
 struct RankT : public flatbuffers::NativeTable {
   typedef Rank TableType;
-  RankT() {
-  }
 };
 
 struct Rank FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
   typedef RankT NativeTableType;
+  typedef RankBuilder Builder;
   static const flatbuffers::TypeTable *MiniReflectTypeTable() {
     return RankTypeTable();
   }
@@ -1977,13 +1953,13 @@ struct Rank FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
 };
 
 struct RankBuilder {
+  typedef Rank Table;
   flatbuffers::FlatBufferBuilder &fbb_;
   flatbuffers::uoffset_t start_;
   explicit RankBuilder(flatbuffers::FlatBufferBuilder &_fbb)
         : fbb_(_fbb) {
     start_ = fbb_.StartTable();
   }
-  RankBuilder &operator=(const RankBuilder &);
   flatbuffers::Offset<Rank> Finish() {
     const auto end = fbb_.EndTable(start_);
     auto o = flatbuffers::Offset<Rank>(end);
@@ -2001,22 +1977,20 @@ flatbuffers::Offset<Rank> CreateRank(flatbuffers::FlatBufferBuilder &_fbb, const
 
 struct SizeT : public flatbuffers::NativeTable {
   typedef Size TableType;
-  DataType outputDataType;
-  SizeT()
-      : outputDataType(DataType_DT_INVALID) {
-  }
+  MNN::DataType outputDataType = MNN::DataType_DT_INVALID;
 };
 
 struct Size FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
   typedef SizeT NativeTableType;
+  typedef SizeBuilder Builder;
   static const flatbuffers::TypeTable *MiniReflectTypeTable() {
     return SizeTypeTable();
   }
   enum FlatBuffersVTableOffset FLATBUFFERS_VTABLE_UNDERLYING_TYPE {
     VT_OUTPUTDATATYPE = 4
   };
-  DataType outputDataType() const {
-    return static_cast<DataType>(GetField<int32_t>(VT_OUTPUTDATATYPE, 0));
+  MNN::DataType outputDataType() const {
+    return static_cast<MNN::DataType>(GetField<int32_t>(VT_OUTPUTDATATYPE, 0));
   }
   bool Verify(flatbuffers::Verifier &verifier) const {
     return VerifyTableStart(verifier) &&
@@ -2029,16 +2003,16 @@ struct Size FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
 };
 
 struct SizeBuilder {
+  typedef Size Table;
   flatbuffers::FlatBufferBuilder &fbb_;
   flatbuffers::uoffset_t start_;
-  void add_outputDataType(DataType outputDataType) {
+  void add_outputDataType(MNN::DataType outputDataType) {
     fbb_.AddElement<int32_t>(Size::VT_OUTPUTDATATYPE, static_cast<int32_t>(outputDataType), 0);
   }
   explicit SizeBuilder(flatbuffers::FlatBufferBuilder &_fbb)
         : fbb_(_fbb) {
     start_ = fbb_.StartTable();
   }
-  SizeBuilder &operator=(const SizeBuilder &);
   flatbuffers::Offset<Size> Finish() {
     const auto end = fbb_.EndTable(start_);
     auto o = flatbuffers::Offset<Size>(end);
@@ -2048,7 +2022,7 @@ struct SizeBuilder {
 
 inline flatbuffers::Offset<Size> CreateSize(
     flatbuffers::FlatBufferBuilder &_fbb,
-    DataType outputDataType = DataType_DT_INVALID) {
+    MNN::DataType outputDataType = MNN::DataType_DT_INVALID) {
   SizeBuilder builder_(_fbb);
   builder_.add_outputDataType(outputDataType);
   return builder_.Finish();
@@ -2058,22 +2032,20 @@ flatbuffers::Offset<Size> CreateSize(flatbuffers::FlatBufferBuilder &_fbb, const
 
 struct TransposeT : public flatbuffers::NativeTable {
   typedef Transpose TableType;
-  DataType Tperm;
-  TransposeT()
-      : Tperm(DataType_DT_INVALID) {
-  }
+  MNN::DataType Tperm = MNN::DataType_DT_INVALID;
 };
 
 struct Transpose FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
   typedef TransposeT NativeTableType;
+  typedef TransposeBuilder Builder;
   static const flatbuffers::TypeTable *MiniReflectTypeTable() {
     return TransposeTypeTable();
   }
   enum FlatBuffersVTableOffset FLATBUFFERS_VTABLE_UNDERLYING_TYPE {
     VT_TPERM = 4
   };
-  DataType Tperm() const {
-    return static_cast<DataType>(GetField<int32_t>(VT_TPERM, 0));
+  MNN::DataType Tperm() const {
+    return static_cast<MNN::DataType>(GetField<int32_t>(VT_TPERM, 0));
   }
   bool Verify(flatbuffers::Verifier &verifier) const {
     return VerifyTableStart(verifier) &&
@@ -2086,16 +2058,16 @@ struct Transpose FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
 };
 
 struct TransposeBuilder {
+  typedef Transpose Table;
   flatbuffers::FlatBufferBuilder &fbb_;
   flatbuffers::uoffset_t start_;
-  void add_Tperm(DataType Tperm) {
+  void add_Tperm(MNN::DataType Tperm) {
     fbb_.AddElement<int32_t>(Transpose::VT_TPERM, static_cast<int32_t>(Tperm), 0);
   }
   explicit TransposeBuilder(flatbuffers::FlatBufferBuilder &_fbb)
         : fbb_(_fbb) {
     start_ = fbb_.StartTable();
   }
-  TransposeBuilder &operator=(const TransposeBuilder &);
   flatbuffers::Offset<Transpose> Finish() {
     const auto end = fbb_.EndTable(start_);
     auto o = flatbuffers::Offset<Transpose>(end);
@@ -2105,7 +2077,7 @@ struct TransposeBuilder {
 
 inline flatbuffers::Offset<Transpose> CreateTranspose(
     flatbuffers::FlatBufferBuilder &_fbb,
-    DataType Tperm = DataType_DT_INVALID) {
+    MNN::DataType Tperm = MNN::DataType_DT_INVALID) {
   TransposeBuilder builder_(_fbb);
   builder_.add_Tperm(Tperm);
   return builder_.Finish();
@@ -2115,22 +2087,20 @@ flatbuffers::Offset<Transpose> CreateTranspose(flatbuffers::FlatBufferBuilder &_
 
 struct SliceTfT : public flatbuffers::NativeTable {
   typedef SliceTf TableType;
-  DataType T;
-  SliceTfT()
-      : T(DataType_DT_INVALID) {
-  }
+  MNN::DataType T = MNN::DataType_DT_INVALID;
 };
 
 struct SliceTf FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
   typedef SliceTfT NativeTableType;
+  typedef SliceTfBuilder Builder;
   static const flatbuffers::TypeTable *MiniReflectTypeTable() {
     return SliceTfTypeTable();
   }
   enum FlatBuffersVTableOffset FLATBUFFERS_VTABLE_UNDERLYING_TYPE {
     VT_T = 4
   };
-  DataType T() const {
-    return static_cast<DataType>(GetField<int32_t>(VT_T, 0));
+  MNN::DataType T() const {
+    return static_cast<MNN::DataType>(GetField<int32_t>(VT_T, 0));
   }
   bool Verify(flatbuffers::Verifier &verifier) const {
     return VerifyTableStart(verifier) &&
@@ -2143,16 +2113,16 @@ struct SliceTf FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
 };
 
 struct SliceTfBuilder {
+  typedef SliceTf Table;
   flatbuffers::FlatBufferBuilder &fbb_;
   flatbuffers::uoffset_t start_;
-  void add_T(DataType T) {
+  void add_T(MNN::DataType T) {
     fbb_.AddElement<int32_t>(SliceTf::VT_T, static_cast<int32_t>(T), 0);
   }
   explicit SliceTfBuilder(flatbuffers::FlatBufferBuilder &_fbb)
         : fbb_(_fbb) {
     start_ = fbb_.StartTable();
   }
-  SliceTfBuilder &operator=(const SliceTfBuilder &);
   flatbuffers::Offset<SliceTf> Finish() {
     const auto end = fbb_.EndTable(start_);
     auto o = flatbuffers::Offset<SliceTf>(end);
@@ -2162,7 +2132,7 @@ struct SliceTfBuilder {
 
 inline flatbuffers::Offset<SliceTf> CreateSliceTf(
     flatbuffers::FlatBufferBuilder &_fbb,
-    DataType T = DataType_DT_INVALID) {
+    MNN::DataType T = MNN::DataType_DT_INVALID) {
   SliceTfBuilder builder_(_fbb);
   builder_.add_T(T);
   return builder_.Finish();
@@ -2172,22 +2142,20 @@ flatbuffers::Offset<SliceTf> CreateSliceTf(flatbuffers::FlatBufferBuilder &_fbb,
 
 struct QuantizeMaxMinT : public flatbuffers::NativeTable {
   typedef QuantizeMaxMin TableType;
-  DataType T;
-  QuantizeMaxMinT()
-      : T(DataType_DT_INVALID) {
-  }
+  MNN::DataType T = MNN::DataType_DT_INVALID;
 };
 
 struct QuantizeMaxMin FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
   typedef QuantizeMaxMinT NativeTableType;
+  typedef QuantizeMaxMinBuilder Builder;
   static const flatbuffers::TypeTable *MiniReflectTypeTable() {
     return QuantizeMaxMinTypeTable();
   }
   enum FlatBuffersVTableOffset FLATBUFFERS_VTABLE_UNDERLYING_TYPE {
     VT_T = 4
   };
-  DataType T() const {
-    return static_cast<DataType>(GetField<int32_t>(VT_T, 0));
+  MNN::DataType T() const {
+    return static_cast<MNN::DataType>(GetField<int32_t>(VT_T, 0));
   }
   bool Verify(flatbuffers::Verifier &verifier) const {
     return VerifyTableStart(verifier) &&
@@ -2200,16 +2168,16 @@ struct QuantizeMaxMin FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
 };
 
 struct QuantizeMaxMinBuilder {
+  typedef QuantizeMaxMin Table;
   flatbuffers::FlatBufferBuilder &fbb_;
   flatbuffers::uoffset_t start_;
-  void add_T(DataType T) {
+  void add_T(MNN::DataType T) {
     fbb_.AddElement<int32_t>(QuantizeMaxMin::VT_T, static_cast<int32_t>(T), 0);
   }
   explicit QuantizeMaxMinBuilder(flatbuffers::FlatBufferBuilder &_fbb)
         : fbb_(_fbb) {
     start_ = fbb_.StartTable();
   }
-  QuantizeMaxMinBuilder &operator=(const QuantizeMaxMinBuilder &);
   flatbuffers::Offset<QuantizeMaxMin> Finish() {
     const auto end = fbb_.EndTable(start_);
     auto o = flatbuffers::Offset<QuantizeMaxMin>(end);
@@ -2219,7 +2187,7 @@ struct QuantizeMaxMinBuilder {
 
 inline flatbuffers::Offset<QuantizeMaxMin> CreateQuantizeMaxMin(
     flatbuffers::FlatBufferBuilder &_fbb,
-    DataType T = DataType_DT_INVALID) {
+    MNN::DataType T = MNN::DataType_DT_INVALID) {
   QuantizeMaxMinBuilder builder_(_fbb);
   builder_.add_T(T);
   return builder_.Finish();
@@ -2229,15 +2197,13 @@ flatbuffers::Offset<QuantizeMaxMin> CreateQuantizeMaxMin(flatbuffers::FlatBuffer
 
 struct CropT : public flatbuffers::NativeTable {
   typedef Crop TableType;
-  int32_t axis;
-  std::vector<int32_t> offset;
-  CropT()
-      : axis(2) {
-  }
+  int32_t axis = 2;
+  std::vector<int32_t> offset{};
 };
 
 struct Crop FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
   typedef CropT NativeTableType;
+  typedef CropBuilder Builder;
   static const flatbuffers::TypeTable *MiniReflectTypeTable() {
     return CropTypeTable();
   }
@@ -2264,6 +2230,7 @@ struct Crop FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
 };
 
 struct CropBuilder {
+  typedef Crop Table;
   flatbuffers::FlatBufferBuilder &fbb_;
   flatbuffers::uoffset_t start_;
   void add_axis(int32_t axis) {
@@ -2276,7 +2243,6 @@ struct CropBuilder {
         : fbb_(_fbb) {
     start_ = fbb_.StartTable();
   }
-  CropBuilder &operator=(const CropBuilder &);
   flatbuffers::Offset<Crop> Finish() {
     const auto end = fbb_.EndTable(start_);
     auto o = flatbuffers::Offset<Crop>(end);
@@ -2309,14 +2275,13 @@ flatbuffers::Offset<Crop> CreateCrop(flatbuffers::FlatBufferBuilder &_fbb, const
 
 struct SpaceBatchT : public flatbuffers::NativeTable {
   typedef SpaceBatch TableType;
-  std::unique_ptr<BlobT> blockShape;
-  std::unique_ptr<BlobT> padding;
-  SpaceBatchT() {
-  }
+  std::unique_ptr<MNN::BlobT> blockShape{};
+  std::unique_ptr<MNN::BlobT> padding{};
 };
 
 struct SpaceBatch FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
   typedef SpaceBatchT NativeTableType;
+  typedef SpaceBatchBuilder Builder;
   static const flatbuffers::TypeTable *MiniReflectTypeTable() {
     return SpaceBatchTypeTable();
   }
@@ -2324,11 +2289,11 @@ struct SpaceBatch FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
     VT_BLOCKSHAPE = 4,
     VT_PADDING = 6
   };
-  const Blob *blockShape() const {
-    return GetPointer<const Blob *>(VT_BLOCKSHAPE);
+  const MNN::Blob *blockShape() const {
+    return GetPointer<const MNN::Blob *>(VT_BLOCKSHAPE);
   }
-  const Blob *padding() const {
-    return GetPointer<const Blob *>(VT_PADDING);
+  const MNN::Blob *padding() const {
+    return GetPointer<const MNN::Blob *>(VT_PADDING);
   }
   bool Verify(flatbuffers::Verifier &verifier) const {
     return VerifyTableStart(verifier) &&
@@ -2344,19 +2309,19 @@ struct SpaceBatch FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
 };
 
 struct SpaceBatchBuilder {
+  typedef SpaceBatch Table;
   flatbuffers::FlatBufferBuilder &fbb_;
   flatbuffers::uoffset_t start_;
-  void add_blockShape(flatbuffers::Offset<Blob> blockShape) {
+  void add_blockShape(flatbuffers::Offset<MNN::Blob> blockShape) {
     fbb_.AddOffset(SpaceBatch::VT_BLOCKSHAPE, blockShape);
   }
-  void add_padding(flatbuffers::Offset<Blob> padding) {
+  void add_padding(flatbuffers::Offset<MNN::Blob> padding) {
     fbb_.AddOffset(SpaceBatch::VT_PADDING, padding);
   }
   explicit SpaceBatchBuilder(flatbuffers::FlatBufferBuilder &_fbb)
         : fbb_(_fbb) {
     start_ = fbb_.StartTable();
   }
-  SpaceBatchBuilder &operator=(const SpaceBatchBuilder &);
   flatbuffers::Offset<SpaceBatch> Finish() {
     const auto end = fbb_.EndTable(start_);
     auto o = flatbuffers::Offset<SpaceBatch>(end);
@@ -2366,8 +2331,8 @@ struct SpaceBatchBuilder {
 
 inline flatbuffers::Offset<SpaceBatch> CreateSpaceBatch(
     flatbuffers::FlatBufferBuilder &_fbb,
-    flatbuffers::Offset<Blob> blockShape = 0,
-    flatbuffers::Offset<Blob> padding = 0) {
+    flatbuffers::Offset<MNN::Blob> blockShape = 0,
+    flatbuffers::Offset<MNN::Blob> padding = 0) {
   SpaceBatchBuilder builder_(_fbb);
   builder_.add_padding(padding);
   builder_.add_blockShape(blockShape);
@@ -2378,20 +2343,16 @@ flatbuffers::Offset<SpaceBatch> CreateSpaceBatch(flatbuffers::FlatBufferBuilder
 
 struct MatMulT : public flatbuffers::NativeTable {
   typedef MatMul TableType;
-  DataType T;
-  bool transposeA;
-  bool transposeB;
-  std::vector<float> weight;
-  std::vector<float> bias;
-  MatMulT()
-      : T(DataType_DT_INVALID),
-        transposeA(false),
-        transposeB(false) {
-  }
+  MNN::DataType T = MNN::DataType_DT_INVALID;
+  bool transposeA = false;
+  bool transposeB = false;
+  std::vector<float> weight{};
+  std::vector<float> bias{};
 };
 
 struct MatMul FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
   typedef MatMulT NativeTableType;
+  typedef MatMulBuilder Builder;
   static const flatbuffers::TypeTable *MiniReflectTypeTable() {
     return MatMulTypeTable();
   }
@@ -2402,8 +2363,8 @@ struct MatMul FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
     VT_WEIGHT = 10,
     VT_BIAS = 12
   };
-  DataType T() const {
-    return static_cast<DataType>(GetField<int32_t>(VT_T, 0));
+  MNN::DataType T() const {
+    return static_cast<MNN::DataType>(GetField<int32_t>(VT_T, 0));
   }
   bool transposeA() const {
     return GetField<uint8_t>(VT_TRANSPOSEA, 0) != 0;
@@ -2434,9 +2395,10 @@ struct MatMul FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
 };
 
 struct MatMulBuilder {
+  typedef MatMul Table;
   flatbuffers::FlatBufferBuilder &fbb_;
   flatbuffers::uoffset_t start_;
-  void add_T(DataType T) {
+  void add_T(MNN::DataType T) {
     fbb_.AddElement<int32_t>(MatMul::VT_T, static_cast<int32_t>(T), 0);
   }
   void add_transposeA(bool transposeA) {
@@ -2455,7 +2417,6 @@ struct MatMulBuilder {
         : fbb_(_fbb) {
     start_ = fbb_.StartTable();
   }
-  MatMulBuilder &operator=(const MatMulBuilder &);
   flatbuffers::Offset<MatMul> Finish() {
     const auto end = fbb_.EndTable(start_);
     auto o = flatbuffers::Offset<MatMul>(end);
@@ -2465,7 +2426,7 @@ struct MatMulBuilder {
 
 inline flatbuffers::Offset<MatMul> CreateMatMul(
     flatbuffers::FlatBufferBuilder &_fbb,
-    DataType T = DataType_DT_INVALID,
+    MNN::DataType T = MNN::DataType_DT_INVALID,
     bool transposeA = false,
     bool transposeB = false,
     flatbuffers::Offset<flatbuffers::Vector<float>> weight = 0,
@@ -2481,7 +2442,7 @@ inline flatbuffers::Offset<MatMul> CreateMatMul(
 
 inline flatbuffers::Offset<MatMul> CreateMatMulDirect(
     flatbuffers::FlatBufferBuilder &_fbb,
-    DataType T = DataType_DT_INVALID,
+    MNN::DataType T = MNN::DataType_DT_INVALID,
     bool transposeA = false,
     bool transposeB = false,
     const std::vector<float> *weight = nullptr,
@@ -2501,17 +2462,14 @@ flatbuffers::Offset<MatMul> CreateMatMul(flatbuffers::FlatBufferBuilder &_fbb, c
 
 struct MomentsParamT : public flatbuffers::NativeTable {
   typedef MomentsParam TableType;
-  std::vector<int32_t> dim;
-  bool keepDims;
-  DataType dType;
-  MomentsParamT()
-      : keepDims(true),
-        dType(DataType_DT_FLOAT) {
-  }
+  std::vector<int32_t> dim{};
+  bool keepDims = true;
+  MNN::DataType dType = MNN::DataType_DT_FLOAT;
 };
 
 struct MomentsParam FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
   typedef MomentsParamT NativeTableType;
+  typedef MomentsParamBuilder Builder;
   static const flatbuffers::TypeTable *MiniReflectTypeTable() {
     return MomentsParamTypeTable();
   }
@@ -2526,8 +2484,8 @@ struct MomentsParam FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
   bool keepDims() const {
     return GetField<uint8_t>(VT_KEEPDIMS, 1) != 0;
   }
-  DataType dType() const {
-    return static_cast<DataType>(GetField<int32_t>(VT_DTYPE, 1));
+  MNN::DataType dType() const {
+    return static_cast<MNN::DataType>(GetField<int32_t>(VT_DTYPE, 1));
   }
   bool Verify(flatbuffers::Verifier &verifier) const {
     return VerifyTableStart(verifier) &&
@@ -2543,6 +2501,7 @@ struct MomentsParam FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
 };
 
 struct MomentsParamBuilder {
+  typedef MomentsParam Table;
   flatbuffers::FlatBufferBuilder &fbb_;
   flatbuffers::uoffset_t start_;
   void add_dim(flatbuffers::Offset<flatbuffers::Vector<int32_t>> dim) {
@@ -2551,14 +2510,13 @@ struct MomentsParamBuilder {
   void add_keepDims(bool keepDims) {
     fbb_.AddElement<uint8_t>(MomentsParam::VT_KEEPDIMS, static_cast<uint8_t>(keepDims), 1);
   }
-  void add_dType(DataType dType) {
+  void add_dType(MNN::DataType dType) {
     fbb_.AddElement<int32_t>(MomentsParam::VT_DTYPE, static_cast<int32_t>(dType), 1);
   }
   explicit MomentsParamBuilder(flatbuffers::FlatBufferBuilder &_fbb)
         : fbb_(_fbb) {
     start_ = fbb_.StartTable();
   }
-  MomentsParamBuilder &operator=(const MomentsParamBuilder &);
   flatbuffers::Offset<MomentsParam> Finish() {
     const auto end = fbb_.EndTable(start_);
     auto o = flatbuffers::Offset<MomentsParam>(end);
@@ -2570,7 +2528,7 @@ inline flatbuffers::Offset<MomentsParam> CreateMomentsParam(
     flatbuffers::FlatBufferBuilder &_fbb,
     flatbuffers::Offset<flatbuffers::Vector<int32_t>> dim = 0,
     bool keepDims = true,
-    DataType dType = DataType_DT_FLOAT) {
+    MNN::DataType dType = MNN::DataType_DT_FLOAT) {
   MomentsParamBuilder builder_(_fbb);
   builder_.add_dType(dType);
   builder_.add_dim(dim);
@@ -2582,7 +2540,7 @@ inline flatbuffers::Offset<MomentsParam> CreateMomentsParamDirect(
     flatbuffers::FlatBufferBuilder &_fbb,
     const std::vector<int32_t> *dim = nullptr,
     bool keepDims = true,
-    DataType dType = DataType_DT_FLOAT) {
+    MNN::DataType dType = MNN::DataType_DT_FLOAT) {
   auto dim__ = dim ? _fbb.CreateVector<int32_t>(*dim) : 0;
   return MNN::CreateMomentsParam(
       _fbb,
@@ -2595,26 +2553,22 @@ flatbuffers::Offset<MomentsParam> CreateMomentsParam(flatbuffers::FlatBufferBuil
 
 struct RNNParamT : public flatbuffers::NativeTable {
   typedef RNNParam TableType;
-  int32_t numUnits;
-  bool isBidirectionalRNN;
-  bool keepAllOutputs;
-  std::unique_ptr<BlobT> fwGateWeight;
-  std::unique_ptr<BlobT> fwGateBias;
-  std::unique_ptr<BlobT> fwCandidateWeight;
-  std::unique_ptr<BlobT> fwCandidateBias;
-  std::unique_ptr<BlobT> bwGateWeight;
-  std::unique_ptr<BlobT> bwGateBias;
-  std::unique_ptr<BlobT> bwCandidateWeight;
-  std::unique_ptr<BlobT> bwCandidateBias;
-  RNNParamT()
-      : numUnits(0),
-        isBidirectionalRNN(false),
-        keepAllOutputs(false) {
-  }
+  int32_t numUnits = 0;
+  bool isBidirectionalRNN = false;
+  bool keepAllOutputs = false;
+  std::unique_ptr<MNN::BlobT> fwGateWeight{};
+  std::unique_ptr<MNN::BlobT> fwGateBias{};
+  std::unique_ptr<MNN::BlobT> fwCandidateWeight{};
+  std::unique_ptr<MNN::BlobT> fwCandidateBias{};
+  std::unique_ptr<MNN::BlobT> bwGateWeight{};
+  std::unique_ptr<MNN::BlobT> bwGateBias{};
+  std::unique_ptr<MNN::BlobT> bwCandidateWeight{};
+  std::unique_ptr<MNN::BlobT> bwCandidateBias{};
 };
 
 struct RNNParam FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
   typedef RNNParamT NativeTableType;
+  typedef RNNParamBuilder Builder;
   static const flatbuffers::TypeTable *MiniReflectTypeTable() {
     return RNNParamTypeTable();
   }
@@ -2640,29 +2594,29 @@ struct RNNParam FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
   bool keepAllOutputs() const {
     return GetField<uint8_t>(VT_KEEPALLOUTPUTS, 0) != 0;
   }
-  const Blob *fwGateWeight() const {
-    return GetPointer<const Blob *>(VT_FWGATEWEIGHT);
+  const MNN::Blob *fwGateWeight() const {
+    return GetPointer<const MNN::Blob *>(VT_FWGATEWEIGHT);
   }
-  const Blob *fwGateBias() const {
-    return GetPointer<const Blob *>(VT_FWGATEBIAS);
+  const MNN::Blob *fwGateBias() const {
+    return GetPointer<const MNN::Blob *>(VT_FWGATEBIAS);
   }
-  const Blob *fwCandidateWeight() const {
-    return GetPointer<const Blob *>(VT_FWCANDIDATEWEIGHT);
+  const MNN::Blob *fwCandidateWeight() const {
+    return GetPointer<const MNN::Blob *>(VT_FWCANDIDATEWEIGHT);
   }
-  const Blob *fwCandidateBias() const {
-    return GetPointer<const Blob *>(VT_FWCANDIDATEBIAS);
+  const MNN::Blob *fwCandidateBias() const {
+    return GetPointer<const MNN::Blob *>(VT_FWCANDIDATEBIAS);
   }
-  const Blob *bwGateWeight() const {
-    return GetPointer<const Blob *>(VT_BWGATEWEIGHT);
+  const MNN::Blob *bwGateWeight() const {
+    return GetPointer<const MNN::Blob *>(VT_BWGATEWEIGHT);
   }
-  const Blob *bwGateBias() const {
-    return GetPointer<const Blob *>(VT_BWGATEBIAS);
+  const MNN::Blob *bwGateBias() const {
+    return GetPointer<const MNN::Blob *>(VT_BWGATEBIAS);
   }
-  const Blob *bwCandidateWeight() const {
-    return GetPointer<const Blob *>(VT_BWCANDIDATEWEIGHT);
+  const MNN::Blob *bwCandidateWeight() const {
+    return GetPointer<const MNN::Blob *>(VT_BWCANDIDATEWEIGHT);
   }
-  const Blob *bwCandidateBias() const {
-    return GetPointer<const Blob *>(VT_BWCANDIDATEBIAS);
+  const MNN::Blob *bwCandidateBias() const {
+    return GetPointer<const MNN::Blob *>(VT_BWCANDIDATEBIAS);
   }
   bool Verify(flatbuffers::Verifier &verifier) const {
     return VerifyTableStart(verifier) &&
@@ -2693,6 +2647,7 @@ struct RNNParam FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
 };
 
 struct RNNParamBuilder {
+  typedef RNNParam Table;
   flatbuffers::FlatBufferBuilder &fbb_;
   flatbuffers::uoffset_t start_;
   void add_numUnits(int32_t numUnits) {
@@ -2704,35 +2659,34 @@ struct RNNParamBuilder {
   void add_keepAllOutputs(bool keepAllOutputs) {
     fbb_.AddElement<uint8_t>(RNNParam::VT_KEEPALLOUTPUTS, static_cast<uint8_t>(keepAllOutputs), 0);
   }
-  void add_fwGateWeight(flatbuffers::Offset<Blob> fwGateWeight) {
+  void add_fwGateWeight(flatbuffers::Offset<MNN::Blob> fwGateWeight) {
     fbb_.AddOffset(RNNParam::VT_FWGATEWEIGHT, fwGateWeight);
   }
-  void add_fwGateBias(flatbuffers::Offset<Blob> fwGateBias) {
+  void add_fwGateBias(flatbuffers::Offset<MNN::Blob> fwGateBias) {
     fbb_.AddOffset(RNNParam::VT_FWGATEBIAS, fwGateBias);
   }
-  void add_fwCandidateWeight(flatbuffers::Offset<Blob> fwCandidateWeight) {
+  void add_fwCandidateWeight(flatbuffers::Offset<MNN::Blob> fwCandidateWeight) {
     fbb_.AddOffset(RNNParam::VT_FWCANDIDATEWEIGHT, fwCandidateWeight);
   }
-  void add_fwCandidateBias(flatbuffers::Offset<Blob> fwCandidateBias) {
+  void add_fwCandidateBias(flatbuffers::Offset<MNN::Blob> fwCandidateBias) {
     fbb_.AddOffset(RNNParam::VT_FWCANDIDATEBIAS, fwCandidateBias);
   }
-  void add_bwGateWeight(flatbuffers::Offset<Blob> bwGateWeight) {
+  void add_bwGateWeight(flatbuffers::Offset<MNN::Blob> bwGateWeight) {
     fbb_.AddOffset(RNNParam::VT_BWGATEWEIGHT, bwGateWeight);
   }
-  void add_bwGateBias(flatbuffers::Offset<Blob> bwGateBias) {
+  void add_bwGateBias(flatbuffers::Offset<MNN::Blob> bwGateBias) {
     fbb_.AddOffset(RNNParam::VT_BWGATEBIAS, bwGateBias);
   }
-  void add_bwCandidateWeight(flatbuffers::Offset<Blob> bwCandidateWeight) {
+  void add_bwCandidateWeight(flatbuffers::Offset<MNN::Blob> bwCandidateWeight) {
     fbb_.AddOffset(RNNParam::VT_BWCANDIDATEWEIGHT, bwCandidateWeight);
   }
-  void add_bwCandidateBias(flatbuffers::Offset<Blob> bwCandidateBias) {
+  void add_bwCandidateBias(flatbuffers::Offset<MNN::Blob> bwCandidateBias) {
     fbb_.AddOffset(RNNParam::VT_BWCANDIDATEBIAS, bwCandidateBias);
   }
   explicit RNNParamBuilder(flatbuffers::FlatBufferBuilder &_fbb)
         : fbb_(_fbb) {
     start_ = fbb_.StartTable();
   }
-  RNNParamBuilder &operator=(const RNNParamBuilder &);
   flatbuffers::Offset<RNNParam> Finish() {
     const auto end = fbb_.EndTable(start_);
     auto o = flatbuffers::Offset<RNNParam>(end);
@@ -2745,14 +2699,14 @@ inline flatbuffers::Offset<RNNParam> CreateRNNParam(
     int32_t numUnits = 0,
     bool isBidirectionalRNN = false,
     bool keepAllOutputs = false,
-    flatbuffers::Offset<Blob> fwGateWeight = 0,
-    flatbuffers::Offset<Blob> fwGateBias = 0,
-    flatbuffers::Offset<Blob> fwCandidateWeight = 0,
-    flatbuffers::Offset<Blob> fwCandidateBias = 0,
-    flatbuffers::Offset<Blob> bwGateWeight = 0,
-    flatbuffers::Offset<Blob> bwGateBias = 0,
-    flatbuffers::Offset<Blob> bwCandidateWeight = 0,
-    flatbuffers::Offset<Blob> bwCandidateBias = 0) {
+    flatbuffers::Offset<MNN::Blob> fwGateWeight = 0,
+    flatbuffers::Offset<MNN::Blob> fwGateBias = 0,
+    flatbuffers::Offset<MNN::Blob> fwCandidateWeight = 0,
+    flatbuffers::Offset<MNN::Blob> fwCandidateBias = 0,
+    flatbuffers::Offset<MNN::Blob> bwGateWeight = 0,
+    flatbuffers::Offset<MNN::Blob> bwGateBias = 0,
+    flatbuffers::Offset<MNN::Blob> bwCandidateWeight = 0,
+    flatbuffers::Offset<MNN::Blob> bwCandidateBias = 0) {
   RNNParamBuilder builder_(_fbb);
   builder_.add_bwCandidateBias(bwCandidateBias);
   builder_.add_bwCandidateWeight(bwCandidateWeight);
@@ -2772,16 +2726,13 @@ flatbuffers::Offset<RNNParam> CreateRNNParam(flatbuffers::FlatBufferBuilder &_fb
 
 struct BatchMatMulParamT : public flatbuffers::NativeTable {
   typedef BatchMatMulParam TableType;
-  bool adjX;
-  bool adjY;
-  BatchMatMulParamT()
-      : adjX(false),
-        adjY(false) {
-  }
+  bool adjX = false;
+  bool adjY = false;
 };
 
 struct BatchMatMulParam FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
   typedef BatchMatMulParamT NativeTableType;
+  typedef BatchMatMulParamBuilder Builder;
   static const flatbuffers::TypeTable *MiniReflectTypeTable() {
     return BatchMatMulParamTypeTable();
   }
@@ -2807,6 +2758,7 @@ struct BatchMatMulParam FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
 };
 
 struct BatchMatMulParamBuilder {
+  typedef BatchMatMulParam Table;
   flatbuffers::FlatBufferBuilder &fbb_;
   flatbuffers::uoffset_t start_;
   void add_adjX(bool adjX) {
@@ -2819,7 +2771,6 @@ struct BatchMatMulParamBuilder {
         : fbb_(_fbb) {
     start_ = fbb_.StartTable();
   }
-  BatchMatMulParamBuilder &operator=(const BatchMatMulParamBuilder &);
   flatbuffers::Offset<BatchMatMulParam> Finish() {
     const auto end = fbb_.EndTable(start_);
     auto o = flatbuffers::Offset<BatchMatMulParam>(end);
@@ -2841,16 +2792,13 @@ flatbuffers::Offset<BatchMatMulParam> CreateBatchMatMulParam(flatbuffers::FlatBu
 
 struct DepthSpaceParamT : public flatbuffers::NativeTable {
   typedef DepthSpaceParam TableType;
-  int32_t blockSize;
-  DepthToSpaceMode mode;
-  DepthSpaceParamT()
-      : blockSize(0),
-        mode(DepthToSpaceMode_DCR) {
-  }
+  int32_t blockSize = 0;
+  MNN::DepthToSpaceMode mode = MNN::DepthToSpaceMode_DCR;
 };
 
 struct DepthSpaceParam FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
   typedef DepthSpaceParamT NativeTableType;
+  typedef DepthSpaceParamBuilder Builder;
   static const flatbuffers::TypeTable *MiniReflectTypeTable() {
     return DepthSpaceParamTypeTable();
   }
@@ -2861,8 +2809,8 @@ struct DepthSpaceParam FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
   int32_t blockSize() const {
     return GetField<int32_t>(VT_BLOCKSIZE, 0);
   }
-  DepthToSpaceMode mode() const {
-    return static_cast<DepthToSpaceMode>(GetField<int8_t>(VT_MODE, 0));
+  MNN::DepthToSpaceMode mode() const {
+    return static_cast<MNN::DepthToSpaceMode>(GetField<int8_t>(VT_MODE, 0));
   }
   bool Verify(flatbuffers::Verifier &verifier) const {
     return VerifyTableStart(verifier) &&
@@ -2876,19 +2824,19 @@ struct DepthSpaceParam FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
 };
 
 struct DepthSpaceParamBuilder {
+  typedef DepthSpaceParam Table;
   flatbuffers::FlatBufferBuilder &fbb_;
   flatbuffers::uoffset_t start_;
   void add_blockSize(int32_t blockSize) {
     fbb_.AddElement<int32_t>(DepthSpaceParam::VT_BLOCKSIZE, blockSize, 0);
   }
-  void add_mode(DepthToSpaceMode mode) {
+  void add_mode(MNN::DepthToSpaceMode mode) {
     fbb_.AddElement<int8_t>(DepthSpaceParam::VT_MODE, static_cast<int8_t>(mode), 0);
   }
   explicit DepthSpaceParamBuilder(flatbuffers::FlatBufferBuilder &_fbb)
         : fbb_(_fbb) {
     start_ = fbb_.StartTable();
   }
-  DepthSpaceParamBuilder &operator=(const DepthSpaceParamBuilder &);
   flatbuffers::Offset<DepthSpaceParam> Finish() {
     const auto end = fbb_.EndTable(start_);
     auto o = flatbuffers::Offset<DepthSpaceParam>(end);
@@ -2899,7 +2847,7 @@ struct DepthSpaceParamBuilder {
 inline flatbuffers::Offset<DepthSpaceParam> CreateDepthSpaceParam(
     flatbuffers::FlatBufferBuilder &_fbb,
     int32_t blockSize = 0,
-    DepthToSpaceMode mode = DepthToSpaceMode_DCR) {
+    MNN::DepthToSpaceMode mode = MNN::DepthToSpaceMode_DCR) {
   DepthSpaceParamBuilder builder_(_fbb);
   builder_.add_blockSize(blockSize);
   builder_.add_mode(mode);
@@ -2910,16 +2858,13 @@ flatbuffers::Offset<DepthSpaceParam> CreateDepthSpaceParam(flatbuffers::FlatBuff
 
 struct ReverseSequenceParamT : public flatbuffers::NativeTable {
   typedef ReverseSequenceParam TableType;
-  int32_t batchDim;
-  int32_t seqDim;
-  ReverseSequenceParamT()
-      : batchDim(0),
-        seqDim(0) {
-  }
+  int32_t batchDim = 0;
+  int32_t seqDim = 0;
 };
 
 struct ReverseSequenceParam FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
   typedef ReverseSequenceParamT NativeTableType;
+  typedef ReverseSequenceParamBuilder Builder;
   static const flatbuffers::TypeTable *MiniReflectTypeTable() {
     return ReverseSequenceParamTypeTable();
   }
@@ -2945,6 +2890,7 @@ struct ReverseSequenceParam FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table
 };
 
 struct ReverseSequenceParamBuilder {
+  typedef ReverseSequenceParam Table;
   flatbuffers::FlatBufferBuilder &fbb_;
   flatbuffers::uoffset_t start_;
   void add_batchDim(int32_t batchDim) {
@@ -2957,7 +2903,6 @@ struct ReverseSequenceParamBuilder {
         : fbb_(_fbb) {
     start_ = fbb_.StartTable();
   }
-  ReverseSequenceParamBuilder &operator=(const ReverseSequenceParamBuilder &);
   flatbuffers::Offset<ReverseSequenceParam> Finish() {
     const auto end = fbb_.EndTable(start_);
     auto o = flatbuffers::Offset<ReverseSequenceParam>(end);
@@ -2979,27 +2924,19 @@ flatbuffers::Offset<ReverseSequenceParam> CreateReverseSequenceParam(flatbuffers
 
 struct DetectionPostProcessParamT : public flatbuffers::NativeTable {
   typedef DetectionPostProcessParam TableType;
-  int32_t maxDetections;
-  int32_t maxClassesPerDetection;
-  int32_t detectionsPerClass;
-  float nmsScoreThreshold;
-  float iouThreshold;
-  int32_t numClasses;
-  bool useRegularNMS;
-  std::vector<float> centerSizeEncoding;
-  DetectionPostProcessParamT()
-      : maxDetections(0),
-        maxClassesPerDetection(0),
-        detectionsPerClass(0),
-        nmsScoreThreshold(0.0f),
-        iouThreshold(0.0f),
-        numClasses(0),
-        useRegularNMS(false) {
-  }
+  int32_t maxDetections = 0;
+  int32_t maxClassesPerDetection = 0;
+  int32_t detectionsPerClass = 0;
+  float nmsScoreThreshold = 0.0f;
+  float iouThreshold = 0.0f;
+  int32_t numClasses = 0;
+  bool useRegularNMS = false;
+  std::vector<float> centerSizeEncoding{};
 };
 
 struct DetectionPostProcessParam FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
   typedef DetectionPostProcessParamT NativeTableType;
+  typedef DetectionPostProcessParamBuilder Builder;
   static const flatbuffers::TypeTable *MiniReflectTypeTable() {
     return DetectionPostProcessParamTypeTable();
   }
@@ -3056,6 +2993,7 @@ struct DetectionPostProcessParam FLATBUFFERS_FINAL_CLASS : private flatbuffers::
 };
 
 struct DetectionPostProcessParamBuilder {
+  typedef DetectionPostProcessParam Table;
   flatbuffers::FlatBufferBuilder &fbb_;
   flatbuffers::uoffset_t start_;
   void add_maxDetections(int32_t maxDetections) {
@@ -3086,7 +3024,6 @@ struct DetectionPostProcessParamBuilder {
         : fbb_(_fbb) {
     start_ = fbb_.StartTable();
   }
-  DetectionPostProcessParamBuilder &operator=(const DetectionPostProcessParamBuilder &);
   flatbuffers::Offset<DetectionPostProcessParam> Finish() {
     const auto end = fbb_.EndTable(start_);
     auto o = flatbuffers::Offset<DetectionPostProcessParam>(end);
@@ -3143,16 +3080,13 @@ flatbuffers::Offset<DetectionPostProcessParam> CreateDetectionPostProcessParam(f
 
 struct OneHotParamT : public flatbuffers::NativeTable {
   typedef OneHotParam TableType;
-  DataType dType;
-  int32_t axis;
-  OneHotParamT()
-      : dType(DataType_DT_FLOAT),
-        axis(-1) {
-  }
+  MNN::DataType dType = MNN::DataType_DT_FLOAT;
+  int32_t axis = -1;
 };
 
 struct OneHotParam FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
   typedef OneHotParamT NativeTableType;
+  typedef OneHotParamBuilder Builder;
   static const flatbuffers::TypeTable *MiniReflectTypeTable() {
     return OneHotParamTypeTable();
   }
@@ -3160,8 +3094,8 @@ struct OneHotParam FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
     VT_DTYPE = 4,
     VT_AXIS = 6
   };
-  DataType dType() const {
-    return static_cast<DataType>(GetField<int32_t>(VT_DTYPE, 1));
+  MNN::DataType dType() const {
+    return static_cast<MNN::DataType>(GetField<int32_t>(VT_DTYPE, 1));
   }
   int32_t axis() const {
     return GetField<int32_t>(VT_AXIS, -1);
@@ -3178,9 +3112,10 @@ struct OneHotParam FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
 };
 
 struct OneHotParamBuilder {
+  typedef OneHotParam Table;
   flatbuffers::FlatBufferBuilder &fbb_;
   flatbuffers::uoffset_t start_;
-  void add_dType(DataType dType) {
+  void add_dType(MNN::DataType dType) {
     fbb_.AddElement<int32_t>(OneHotParam::VT_DTYPE, static_cast<int32_t>(dType), 1);
   }
   void add_axis(int32_t axis) {
@@ -3190,7 +3125,6 @@ struct OneHotParamBuilder {
         : fbb_(_fbb) {
     start_ = fbb_.StartTable();
   }
-  OneHotParamBuilder &operator=(const OneHotParamBuilder &);
   flatbuffers::Offset<OneHotParam> Finish() {
     const auto end = fbb_.EndTable(start_);
     auto o = flatbuffers::Offset<OneHotParam>(end);
@@ -3200,7 +3134,7 @@ struct OneHotParamBuilder {
 
 inline flatbuffers::Offset<OneHotParam> CreateOneHotParam(
     flatbuffers::FlatBufferBuilder &_fbb,
-    DataType dType = DataType_DT_FLOAT,
+    MNN::DataType dType = MNN::DataType_DT_FLOAT,
     int32_t axis = -1) {
   OneHotParamBuilder builder_(_fbb);
   builder_.add_axis(axis);
@@ -3212,22 +3146,20 @@ flatbuffers::Offset<OneHotParam> CreateOneHotParam(flatbuffers::FlatBufferBuilde
 
 struct PadParamT : public flatbuffers::NativeTable {
   typedef PadParam TableType;
-  PadValueMode mode;
-  PadParamT()
-      : mode(PadValueMode_CONSTANT) {
-  }
+  MNN::PadValueMode mode = MNN::PadValueMode_CONSTANT;
 };
 
 struct PadParam FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
   typedef PadParamT NativeTableType;
+  typedef PadParamBuilder Builder;
   static const flatbuffers::TypeTable *MiniReflectTypeTable() {
     return PadParamTypeTable();
   }
   enum FlatBuffersVTableOffset FLATBUFFERS_VTABLE_UNDERLYING_TYPE {
     VT_MODE = 4
   };
-  PadValueMode mode() const {
-    return static_cast<PadValueMode>(GetField<int8_t>(VT_MODE, 0));
+  MNN::PadValueMode mode() const {
+    return static_cast<MNN::PadValueMode>(GetField<int8_t>(VT_MODE, 0));
   }
   bool Verify(flatbuffers::Verifier &verifier) const {
     return VerifyTableStart(verifier) &&
@@ -3240,16 +3172,16 @@ struct PadParam FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
 };
 
 struct PadParamBuilder {
+  typedef PadParam Table;
   flatbuffers::FlatBufferBuilder &fbb_;
   flatbuffers::uoffset_t start_;
-  void add_mode(PadValueMode mode) {
+  void add_mode(MNN::PadValueMode mode) {
     fbb_.AddElement<int8_t>(PadParam::VT_MODE, static_cast<int8_t>(mode), 0);
   }
   explicit PadParamBuilder(flatbuffers::FlatBufferBuilder &_fbb)
         : fbb_(_fbb) {
     start_ = fbb_.StartTable();
   }
-  PadParamBuilder &operator=(const PadParamBuilder &);
   flatbuffers::Offset<PadParam> Finish() {
     const auto end = fbb_.EndTable(start_);
     auto o = flatbuffers::Offset<PadParam>(end);
@@ -3259,7 +3191,7 @@ struct PadParamBuilder {
 
 inline flatbuffers::Offset<PadParam> CreatePadParam(
     flatbuffers::FlatBufferBuilder &_fbb,
-    PadValueMode mode = PadValueMode_CONSTANT) {
+    MNN::PadValueMode mode = MNN::PadValueMode_CONSTANT) {
   PadParamBuilder builder_(_fbb);
   builder_.add_mode(mode);
   return builder_.Finish();
@@ -3269,17 +3201,15 @@ flatbuffers::Offset<PadParam> CreatePadParam(flatbuffers::FlatBufferBuilder &_fb
 
 struct LayerNormT : public flatbuffers::NativeTable {
   typedef LayerNorm TableType;
-  std::vector<int32_t> axis;
-  float epsilon;
-  std::vector<float> gamma;
-  std::vector<float> beta;
-  LayerNormT()
-      : epsilon(0.0f) {
-  }
+  std::vector<int32_t> axis{};
+  float epsilon = 0.0f;
+  std::vector<float> gamma{};
+  std::vector<float> beta{};
 };
 
 struct LayerNorm FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
   typedef LayerNormT NativeTableType;
+  typedef LayerNormBuilder Builder;
   static const flatbuffers::TypeTable *MiniReflectTypeTable() {
     return LayerNormTypeTable();
   }
@@ -3318,6 +3248,7 @@ struct LayerNorm FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
 };
 
 struct LayerNormBuilder {
+  typedef LayerNorm Table;
   flatbuffers::FlatBufferBuilder &fbb_;
   flatbuffers::uoffset_t start_;
   void add_axis(flatbuffers::Offset<flatbuffers::Vector<int32_t>> axis) {
@@ -3336,7 +3267,6 @@ struct LayerNormBuilder {
         : fbb_(_fbb) {
     start_ = fbb_.StartTable();
   }
-  LayerNormBuilder &operator=(const LayerNormBuilder &);
   flatbuffers::Offset<LayerNorm> Finish() {
     const auto end = fbb_.EndTable(start_);
     auto o = flatbuffers::Offset<LayerNorm>(end);
@@ -3379,20 +3309,15 @@ flatbuffers::Offset<LayerNorm> CreateLayerNorm(flatbuffers::FlatBufferBuilder &_
 
 struct RandomUniformT : public flatbuffers::NativeTable {
   typedef RandomUniform TableType;
-  int32_t seed;
-  int32_t seed2;
-  DataType type;
-  DataType T;
-  RandomUniformT()
-      : seed(0),
-        seed2(0),
-        type(DataType_DT_FLOAT),
-        T(DataType_DT_INT32) {
-  }
+  int32_t seed = 0;
+  int32_t seed2 = 0;
+  MNN::DataType type = MNN::DataType_DT_FLOAT;
+  MNN::DataType T = MNN::DataType_DT_INT32;
 };
 
 struct RandomUniform FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
   typedef RandomUniformT NativeTableType;
+  typedef RandomUniformBuilder Builder;
   static const flatbuffers::TypeTable *MiniReflectTypeTable() {
     return RandomUniformTypeTable();
   }
@@ -3408,11 +3333,11 @@ struct RandomUniform FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
   int32_t seed2() const {
     return GetField<int32_t>(VT_SEED2, 0);
   }
-  DataType type() const {
-    return static_cast<DataType>(GetField<int32_t>(VT_TYPE, 1));
+  MNN::DataType type() const {
+    return static_cast<MNN::DataType>(GetField<int32_t>(VT_TYPE, 1));
   }
-  DataType T() const {
-    return static_cast<DataType>(GetField<int32_t>(VT_T, 3));
+  MNN::DataType T() const {
+    return static_cast<MNN::DataType>(GetField<int32_t>(VT_T, 3));
   }
   bool Verify(flatbuffers::Verifier &verifier) const {
     return VerifyTableStart(verifier) &&
@@ -3428,6 +3353,7 @@ struct RandomUniform FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
 };
 
 struct RandomUniformBuilder {
+  typedef RandomUniform Table;
   flatbuffers::FlatBufferBuilder &fbb_;
   flatbuffers::uoffset_t start_;
   void add_seed(int32_t seed) {
@@ -3436,17 +3362,16 @@ struct RandomUniformBuilder {
   void add_seed2(int32_t seed2) {
     fbb_.AddElement<int32_t>(RandomUniform::VT_SEED2, seed2, 0);
   }
-  void add_type(DataType type) {
+  void add_type(MNN::DataType type) {
     fbb_.AddElement<int32_t>(RandomUniform::VT_TYPE, static_cast<int32_t>(type), 1);
   }
-  void add_T(DataType T) {
+  void add_T(MNN::DataType T) {
     fbb_.AddElement<int32_t>(RandomUniform::VT_T, static_cast<int32_t>(T), 3);
   }
   explicit RandomUniformBuilder(flatbuffers::FlatBufferBuilder &_fbb)
         : fbb_(_fbb) {
     start_ = fbb_.StartTable();
   }
-  RandomUniformBuilder &operator=(const RandomUniformBuilder &);
   flatbuffers::Offset<RandomUniform> Finish() {
     const auto end = fbb_.EndTable(start_);
     auto o = flatbuffers::Offset<RandomUniform>(end);
@@ -3458,8 +3383,8 @@ inline flatbuffers::Offset<RandomUniform> CreateRandomUniform(
     flatbuffers::FlatBufferBuilder &_fbb,
     int32_t seed = 0,
     int32_t seed2 = 0,
-    DataType type = DataType_DT_FLOAT,
-    DataType T = DataType_DT_INT32) {
+    MNN::DataType type = MNN::DataType_DT_FLOAT,
+    MNN::DataType T = MNN::DataType_DT_INT32) {
   RandomUniformBuilder builder_(_fbb);
   builder_.add_T(T);
   builder_.add_type(type);
@@ -3471,16 +3396,16 @@ inline flatbuffers::Offset<RandomUniform> CreateRandomUniform(
 flatbuffers::Offset<RandomUniform> CreateRandomUniform(flatbuffers::FlatBufferBuilder &_fbb, const RandomUniformT *_o, const flatbuffers::rehasher_function_t *_rehasher = nullptr);
 
 inline BinaryOpT *BinaryOp::UnPack(const flatbuffers::resolver_function_t *_resolver) const {
-  auto _o = new BinaryOpT();
-  UnPackTo(_o, _resolver);
-  return _o;
+  auto _o = std::unique_ptr<BinaryOpT>(new BinaryOpT());
+  UnPackTo(_o.get(), _resolver);
+  return _o.release();
 }
 
 inline void BinaryOp::UnPackTo(BinaryOpT *_o, const flatbuffers::resolver_function_t *_resolver) const {
   (void)_o;
   (void)_resolver;
-  { auto _e = opType(); _o->opType = _e; };
-  { auto _e = T(); _o->T = _e; };
+  { auto _e = opType(); _o->opType = _e; }
+  { auto _e = T(); _o->T = _e; }
 }
 
 inline flatbuffers::Offset<BinaryOp> BinaryOp::Pack(flatbuffers::FlatBufferBuilder &_fbb, const BinaryOpT* _o, const flatbuffers::rehasher_function_t *_rehasher) {
@@ -3500,16 +3425,16 @@ inline flatbuffers::Offset<BinaryOp> CreateBinaryOp(flatbuffers::FlatBufferBuild
 }
 
 inline PackParamT *PackParam::UnPack(const flatbuffers::resolver_function_t *_resolver) const {
-  auto _o = new PackParamT();
-  UnPackTo(_o, _resolver);
-  return _o;
+  auto _o = std::unique_ptr<PackParamT>(new PackParamT());
+  UnPackTo(_o.get(), _resolver);
+  return _o.release();
 }
 
 inline void PackParam::UnPackTo(PackParamT *_o, const flatbuffers::resolver_function_t *_resolver) const {
   (void)_o;
   (void)_resolver;
-  { auto _e = dataType(); _o->dataType = _e; };
-  { auto _e = axis(); _o->axis = _e; };
+  { auto _e = dataType(); _o->dataType = _e; }
+  { auto _e = axis(); _o->axis = _e; }
 }
 
 inline flatbuffers::Offset<PackParam> PackParam::Pack(flatbuffers::FlatBufferBuilder &_fbb, const PackParamT* _o, const flatbuffers::rehasher_function_t *_rehasher) {
@@ -3529,21 +3454,21 @@ inline flatbuffers::Offset<PackParam> CreatePackParam(flatbuffers::FlatBufferBui
 }
 
 inline StridedSliceParamT *StridedSliceParam::UnPack(const flatbuffers::resolver_function_t *_resolver) const {
-  auto _o = new StridedSliceParamT();
-  UnPackTo(_o, _resolver);
-  return _o;
+  auto _o = std::unique_ptr<StridedSliceParamT>(new StridedSliceParamT());
+  UnPackTo(_o.get(), _resolver);
+  return _o.release();
 }
 
 inline void StridedSliceParam::UnPackTo(StridedSliceParamT *_o, const flatbuffers::resolver_function_t *_resolver) const {
   (void)_o;
   (void)_resolver;
-  { auto _e = Index(); _o->Index = _e; };
-  { auto _e = T(); _o->T = _e; };
-  { auto _e = beginMask(); _o->beginMask = _e; };
-  { auto _e = endMask(); _o->endMask = _e; };
-  { auto _e = ellipsisMask(); _o->ellipsisMask = _e; };
-  { auto _e = newAxisMask(); _o->newAxisMask = _e; };
-  { auto _e = shrinkAxisMask(); _o->shrinkAxisMask = _e; };
+  { auto _e = Index(); _o->Index = _e; }
+  { auto _e = T(); _o->T = _e; }
+  { auto _e = beginMask(); _o->beginMask = _e; }
+  { auto _e = endMask(); _o->endMask = _e; }
+  { auto _e = ellipsisMask(); _o->ellipsisMask = _e; }
+  { auto _e = newAxisMask(); _o->newAxisMask = _e; }
+  { auto _e = shrinkAxisMask(); _o->shrinkAxisMask = _e; }
 }
 
 inline flatbuffers::Offset<StridedSliceParam> StridedSliceParam::Pack(flatbuffers::FlatBufferBuilder &_fbb, const StridedSliceParamT* _o, const flatbuffers::rehasher_function_t *_rehasher) {
@@ -3573,15 +3498,15 @@ inline flatbuffers::Offset<StridedSliceParam> CreateStridedSliceParam(flatbuffer
 }
 
 inline SqueezeParamT *SqueezeParam::UnPack(const flatbuffers::resolver_function_t *_resolver) const {
-  auto _o = new SqueezeParamT();
-  UnPackTo(_o, _resolver);
-  return _o;
+  auto _o = std::unique_ptr<SqueezeParamT>(new SqueezeParamT());
+  UnPackTo(_o.get(), _resolver);
+  return _o.release();
 }
 
 inline void SqueezeParam::UnPackTo(SqueezeParamT *_o, const flatbuffers::resolver_function_t *_resolver) const {
   (void)_o;
   (void)_resolver;
-  { auto _e = squeezeDims(); if (_e) { _o->squeezeDims.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->squeezeDims[_i] = _e->Get(_i); } } };
+  { auto _e = squeezeDims(); if (_e) { _o->squeezeDims.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->squeezeDims[_i] = _e->Get(_i); } } }
 }
 
 inline flatbuffers::Offset<SqueezeParam> SqueezeParam::Pack(flatbuffers::FlatBufferBuilder &_fbb, const SqueezeParamT* _o, const flatbuffers::rehasher_function_t *_rehasher) {
@@ -3599,16 +3524,16 @@ inline flatbuffers::Offset<SqueezeParam> CreateSqueezeParam(flatbuffers::FlatBuf
 }
 
 inline CastParamT *CastParam::UnPack(const flatbuffers::resolver_function_t *_resolver) const {
-  auto _o = new CastParamT();
-  UnPackTo(_o, _resolver);
-  return _o;
+  auto _o = std::unique_ptr<CastParamT>(new CastParamT());
+  UnPackTo(_o.get(), _resolver);
+  return _o.release();
 }
 
 inline void CastParam::UnPackTo(CastParamT *_o, const flatbuffers::resolver_function_t *_resolver) const {
   (void)_o;
   (void)_resolver;
-  { auto _e = srcT(); _o->srcT = _e; };
-  { auto _e = dstT(); _o->dstT = _e; };
+  { auto _e = srcT(); _o->srcT = _e; }
+  { auto _e = dstT(); _o->dstT = _e; }
 }
 
 inline flatbuffers::Offset<CastParam> CastParam::Pack(flatbuffers::FlatBufferBuilder &_fbb, const CastParamT* _o, const flatbuffers::rehasher_function_t *_rehasher) {
@@ -3628,19 +3553,19 @@ inline flatbuffers::Offset<CastParam> CreateCastParam(flatbuffers::FlatBufferBui
 }
 
 inline ReductionParamT *ReductionParam::UnPack(const flatbuffers::resolver_function_t *_resolver) const {
-  auto _o = new ReductionParamT();
-  UnPackTo(_o, _resolver);
-  return _o;
+  auto _o = std::unique_ptr<ReductionParamT>(new ReductionParamT());
+  UnPackTo(_o.get(), _resolver);
+  return _o.release();
 }
 
 inline void ReductionParam::UnPackTo(ReductionParamT *_o, const flatbuffers::resolver_function_t *_resolver) const {
   (void)_o;
   (void)_resolver;
-  { auto _e = operation(); _o->operation = _e; };
-  { auto _e = dim(); if (_e) { _o->dim.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->dim[_i] = _e->Get(_i); } } };
-  { auto _e = coeff(); _o->coeff = _e; };
-  { auto _e = keepDims(); _o->keepDims = _e; };
-  { auto _e = dType(); _o->dType = _e; };
+  { auto _e = operation(); _o->operation = _e; }
+  { auto _e = dim(); if (_e) { _o->dim.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->dim[_i] = _e->Get(_i); } } }
+  { auto _e = coeff(); _o->coeff = _e; }
+  { auto _e = keepDims(); _o->keepDims = _e; }
+  { auto _e = dType(); _o->dType = _e; }
 }
 
 inline flatbuffers::Offset<ReductionParam> ReductionParam::Pack(flatbuffers::FlatBufferBuilder &_fbb, const ReductionParamT* _o, const flatbuffers::rehasher_function_t *_rehasher) {
@@ -3666,18 +3591,18 @@ inline flatbuffers::Offset<ReductionParam> CreateReductionParam(flatbuffers::Fla
 }
 
 inline GatherT *Gather::UnPack(const flatbuffers::resolver_function_t *_resolver) const {
-  auto _o = new GatherT();
-  UnPackTo(_o, _resolver);
-  return _o;
+  auto _o = std::unique_ptr<GatherT>(new GatherT());
+  UnPackTo(_o.get(), _resolver);
+  return _o.release();
 }
 
 inline void Gather::UnPackTo(GatherT *_o, const flatbuffers::resolver_function_t *_resolver) const {
   (void)_o;
   (void)_resolver;
-  { auto _e = Tindices(); _o->Tindices = _e; };
-  { auto _e = Tparams(); _o->Tparams = _e; };
-  { auto _e = validateIndices(); _o->validateIndices = _e; };
-  { auto _e = axis(); _o->axis = _e; };
+  { auto _e = Tindices(); _o->Tindices = _e; }
+  { auto _e = Tparams(); _o->Tparams = _e; }
+  { auto _e = validateIndices(); _o->validateIndices = _e; }
+  { auto _e = axis(); _o->axis = _e; }
 }
 
 inline flatbuffers::Offset<Gather> Gather::Pack(flatbuffers::FlatBufferBuilder &_fbb, const GatherT* _o, const flatbuffers::rehasher_function_t *_rehasher) {
@@ -3701,17 +3626,17 @@ inline flatbuffers::Offset<Gather> CreateGather(flatbuffers::FlatBufferBuilder &
 }
 
 inline ExpandDimsT *ExpandDims::UnPack(const flatbuffers::resolver_function_t *_resolver) const {
-  auto _o = new ExpandDimsT();
-  UnPackTo(_o, _resolver);
-  return _o;
+  auto _o = std::unique_ptr<ExpandDimsT>(new ExpandDimsT());
+  UnPackTo(_o.get(), _resolver);
+  return _o.release();
 }
 
 inline void ExpandDims::UnPackTo(ExpandDimsT *_o, const flatbuffers::resolver_function_t *_resolver) const {
   (void)_o;
   (void)_resolver;
-  { auto _e = T(); _o->T = _e; };
-  { auto _e = Tdim(); _o->Tdim = _e; };
-  { auto _e = axis(); _o->axis = _e; };
+  { auto _e = T(); _o->T = _e; }
+  { auto _e = Tdim(); _o->Tdim = _e; }
+  { auto _e = axis(); _o->axis = _e; }
 }
 
 inline flatbuffers::Offset<ExpandDims> ExpandDims::Pack(flatbuffers::FlatBufferBuilder &_fbb, const ExpandDimsT* _o, const flatbuffers::rehasher_function_t *_rehasher) {
@@ -3733,16 +3658,16 @@ inline flatbuffers::Offset<ExpandDims> CreateExpandDims(flatbuffers::FlatBufferB
 }
 
 inline SeluT *Selu::UnPack(const flatbuffers::resolver_function_t *_resolver) const {
-  auto _o = new SeluT();
-  UnPackTo(_o, _resolver);
-  return _o;
+  auto _o = std::unique_ptr<SeluT>(new SeluT());
+  UnPackTo(_o.get(), _resolver);
+  return _o.release();
 }
 
 inline void Selu::UnPackTo(SeluT *_o, const flatbuffers::resolver_function_t *_resolver) const {
   (void)_o;
   (void)_resolver;
-  { auto _e = scale(); _o->scale = _e; };
-  { auto _e = alpha(); _o->alpha = _e; };
+  { auto _e = scale(); _o->scale = _e; }
+  { auto _e = alpha(); _o->alpha = _e; }
 }
 
 inline flatbuffers::Offset<Selu> Selu::Pack(flatbuffers::FlatBufferBuilder &_fbb, const SeluT* _o, const flatbuffers::rehasher_function_t *_rehasher) {
@@ -3762,20 +3687,20 @@ inline flatbuffers::Offset<Selu> CreateSelu(flatbuffers::FlatBufferBuilder &_fbb
 }
 
 inline AsStringT *AsString::UnPack(const flatbuffers::resolver_function_t *_resolver) const {
-  auto _o = new AsStringT();
-  UnPackTo(_o, _resolver);
-  return _o;
+  auto _o = std::unique_ptr<AsStringT>(new AsStringT());
+  UnPackTo(_o.get(), _resolver);
+  return _o.release();
 }
 
 inline void AsString::UnPackTo(AsStringT *_o, const flatbuffers::resolver_function_t *_resolver) const {
   (void)_o;
   (void)_resolver;
-  { auto _e = T(); _o->T = _e; };
-  { auto _e = precision(); _o->precision = _e; };
-  { auto _e = scientific(); _o->scientific = _e; };
-  { auto _e = shortest(); _o->shortest = _e; };
-  { auto _e = width(); _o->width = _e; };
-  { auto _e = fillString(); if (_e) _o->fillString = _e->str(); };
+  { auto _e = T(); _o->T = _e; }
+  { auto _e = precision(); _o->precision = _e; }
+  { auto _e = scientific(); _o->scientific = _e; }
+  { auto _e = shortest(); _o->shortest = _e; }
+  { auto _e = width(); _o->width = _e; }
+  { auto _e = fillString(); if (_e) _o->fillString = _e->str(); }
 }
 
 inline flatbuffers::Offset<AsString> AsString::Pack(flatbuffers::FlatBufferBuilder &_fbb, const AsStringT* _o, const flatbuffers::rehasher_function_t *_rehasher) {
@@ -3803,16 +3728,16 @@ inline flatbuffers::Offset<AsString> CreateAsString(flatbuffers::FlatBufferBuild
 }
 
 inline ReduceJoinT *ReduceJoin::UnPack(const flatbuffers::resolver_function_t *_resolver) const {
-  auto _o = new ReduceJoinT();
-  UnPackTo(_o, _resolver);
-  return _o;
+  auto _o = std::unique_ptr<ReduceJoinT>(new ReduceJoinT());
+  UnPackTo(_o.get(), _resolver);
+  return _o.release();
 }
 
 inline void ReduceJoin::UnPackTo(ReduceJoinT *_o, const flatbuffers::resolver_function_t *_resolver) const {
   (void)_o;
   (void)_resolver;
-  { auto _e = keepDims(); _o->keepDims = _e; };
-  { auto _e = separator(); if (_e) _o->separator = _e->str(); };
+  { auto _e = keepDims(); _o->keepDims = _e; }
+  { auto _e = separator(); if (_e) _o->separator = _e->str(); }
 }
 
 inline flatbuffers::Offset<ReduceJoin> ReduceJoin::Pack(flatbuffers::FlatBufferBuilder &_fbb, const ReduceJoinT* _o, const flatbuffers::rehasher_function_t *_rehasher) {
@@ -3832,16 +3757,16 @@ inline flatbuffers::Offset<ReduceJoin> CreateReduceJoin(flatbuffers::FlatBufferB
 }
 
 inline UnaryOpT *UnaryOp::UnPack(const flatbuffers::resolver_function_t *_resolver) const {
-  auto _o = new UnaryOpT();
-  UnPackTo(_o, _resolver);
-  return _o;
+  auto _o = std::unique_ptr<UnaryOpT>(new UnaryOpT());
+  UnPackTo(_o.get(), _resolver);
+  return _o.release();
 }
 
 inline void UnaryOp::UnPackTo(UnaryOpT *_o, const flatbuffers::resolver_function_t *_resolver) const {
   (void)_o;
   (void)_resolver;
-  { auto _e = opType(); _o->opType = _e; };
-  { auto _e = T(); _o->T = _e; };
+  { auto _e = opType(); _o->opType = _e; }
+  { auto _e = T(); _o->T = _e; }
 }
 
 inline flatbuffers::Offset<UnaryOp> UnaryOp::Pack(flatbuffers::FlatBufferBuilder &_fbb, const UnaryOpT* _o, const flatbuffers::rehasher_function_t *_rehasher) {
@@ -3861,16 +3786,16 @@ inline flatbuffers::Offset<UnaryOp> CreateUnaryOp(flatbuffers::FlatBufferBuilder
 }
 
 inline TopKV2T *TopKV2::UnPack(const flatbuffers::resolver_function_t *_resolver) const {
-  auto _o = new TopKV2T();
-  UnPackTo(_o, _resolver);
-  return _o;
+  auto _o = std::unique_ptr<TopKV2T>(new TopKV2T());
+  UnPackTo(_o.get(), _resolver);
+  return _o.release();
 }
 
 inline void TopKV2::UnPackTo(TopKV2T *_o, const flatbuffers::resolver_function_t *_resolver) const {
   (void)_o;
   (void)_resolver;
-  { auto _e = T(); _o->T = _e; };
-  { auto _e = sorted(); _o->sorted = _e; };
+  { auto _e = T(); _o->T = _e; }
+  { auto _e = sorted(); _o->sorted = _e; }
 }
 
 inline flatbuffers::Offset<TopKV2> TopKV2::Pack(flatbuffers::FlatBufferBuilder &_fbb, const TopKV2T* _o, const flatbuffers::rehasher_function_t *_rehasher) {
@@ -3890,16 +3815,16 @@ inline flatbuffers::Offset<TopKV2> CreateTopKV2(flatbuffers::FlatBufferBuilder &
 }
 
 inline CropAndResizeT *CropAndResize::UnPack(const flatbuffers::resolver_function_t *_resolver) const {
-  auto _o = new CropAndResizeT();
-  UnPackTo(_o, _resolver);
-  return _o;
+  auto _o = std::unique_ptr<CropAndResizeT>(new CropAndResizeT());
+  UnPackTo(_o.get(), _resolver);
+  return _o.release();
 }
 
 inline void CropAndResize::UnPackTo(CropAndResizeT *_o, const flatbuffers::resolver_function_t *_resolver) const {
   (void)_o;
   (void)_resolver;
-  { auto _e = extrapolationValue(); _o->extrapolationValue = _e; };
-  { auto _e = method(); _o->method = _e; };
+  { auto _e = extrapolationValue(); _o->extrapolationValue = _e; }
+  { auto _e = method(); _o->method = _e; }
 }
 
 inline flatbuffers::Offset<CropAndResize> CropAndResize::Pack(flatbuffers::FlatBufferBuilder &_fbb, const CropAndResizeT* _o, const flatbuffers::rehasher_function_t *_rehasher) {
@@ -3919,9 +3844,9 @@ inline flatbuffers::Offset<CropAndResize> CreateCropAndResize(flatbuffers::FlatB
 }
 
 inline FillT *Fill::UnPack(const flatbuffers::resolver_function_t *_resolver) const {
-  auto _o = new FillT();
-  UnPackTo(_o, _resolver);
-  return _o;
+  auto _o = std::unique_ptr<FillT>(new FillT());
+  UnPackTo(_o.get(), _resolver);
+  return _o.release();
 }
 
 inline void Fill::UnPackTo(FillT *_o, const flatbuffers::resolver_function_t *_resolver) const {
@@ -3942,17 +3867,17 @@ inline flatbuffers::Offset<Fill> CreateFill(flatbuffers::FlatBufferBuilder &_fbb
 }
 
 inline GatherV2T *GatherV2::UnPack(const flatbuffers::resolver_function_t *_resolver) const {
-  auto _o = new GatherV2T();
-  UnPackTo(_o, _resolver);
-  return _o;
+  auto _o = std::unique_ptr<GatherV2T>(new GatherV2T());
+  UnPackTo(_o.get(), _resolver);
+  return _o.release();
 }
 
 inline void GatherV2::UnPackTo(GatherV2T *_o, const flatbuffers::resolver_function_t *_resolver) const {
   (void)_o;
   (void)_resolver;
-  { auto _e = Taxis(); _o->Taxis = _e; };
-  { auto _e = Tindices(); _o->Tindices = _e; };
-  { auto _e = Tparams(); _o->Tparams = _e; };
+  { auto _e = Taxis(); _o->Taxis = _e; }
+  { auto _e = Tindices(); _o->Tindices = _e; }
+  { auto _e = Tparams(); _o->Tparams = _e; }
 }
 
 inline flatbuffers::Offset<GatherV2> GatherV2::Pack(flatbuffers::FlatBufferBuilder &_fbb, const GatherV2T* _o, const flatbuffers::rehasher_function_t *_rehasher) {
@@ -3974,9 +3899,9 @@ inline flatbuffers::Offset<GatherV2> CreateGatherV2(flatbuffers::FlatBufferBuild
 }
 
 inline NonMaxSuppressionV2T *NonMaxSuppressionV2::UnPack(const flatbuffers::resolver_function_t *_resolver) const {
-  auto _o = new NonMaxSuppressionV2T();
-  UnPackTo(_o, _resolver);
-  return _o;
+  auto _o = std::unique_ptr<NonMaxSuppressionV2T>(new NonMaxSuppressionV2T());
+  UnPackTo(_o.get(), _resolver);
+  return _o.release();
 }
 
 inline void NonMaxSuppressionV2::UnPackTo(NonMaxSuppressionV2T *_o, const flatbuffers::resolver_function_t *_resolver) const {
@@ -3997,15 +3922,15 @@ inline flatbuffers::Offset<NonMaxSuppressionV2> CreateNonMaxSuppressionV2(flatbu
 }
 
 inline RangeT *Range::UnPack(const flatbuffers::resolver_function_t *_resolver) const {
-  auto _o = new RangeT();
-  UnPackTo(_o, _resolver);
-  return _o;
+  auto _o = std::unique_ptr<RangeT>(new RangeT());
+  UnPackTo(_o.get(), _resolver);
+  return _o.release();
 }
 
 inline void Range::UnPackTo(RangeT *_o, const flatbuffers::resolver_function_t *_resolver) const {
   (void)_o;
   (void)_resolver;
-  { auto _e = Tidx(); _o->Tidx = _e; };
+  { auto _e = Tidx(); _o->Tidx = _e; }
 }
 
 inline flatbuffers::Offset<Range> Range::Pack(flatbuffers::FlatBufferBuilder &_fbb, const RangeT* _o, const flatbuffers::rehasher_function_t *_rehasher) {
@@ -4023,9 +3948,9 @@ inline flatbuffers::Offset<Range> CreateRange(flatbuffers::FlatBufferBuilder &_f
 }
 
 inline RankT *Rank::UnPack(const flatbuffers::resolver_function_t *_resolver) const {
-  auto _o = new RankT();
-  UnPackTo(_o, _resolver);
-  return _o;
+  auto _o = std::unique_ptr<RankT>(new RankT());
+  UnPackTo(_o.get(), _resolver);
+  return _o.release();
 }
 
 inline void Rank::UnPackTo(RankT *_o, const flatbuffers::resolver_function_t *_resolver) const {
@@ -4046,15 +3971,15 @@ inline flatbuffers::Offset<Rank> CreateRank(flatbuffers::FlatBufferBuilder &_fbb
 }
 
 inline SizeT *Size::UnPack(const flatbuffers::resolver_function_t *_resolver) const {
-  auto _o = new SizeT();
-  UnPackTo(_o, _resolver);
-  return _o;
+  auto _o = std::unique_ptr<SizeT>(new SizeT());
+  UnPackTo(_o.get(), _resolver);
+  return _o.release();
 }
 
 inline void Size::UnPackTo(SizeT *_o, const flatbuffers::resolver_function_t *_resolver) const {
   (void)_o;
   (void)_resolver;
-  { auto _e = outputDataType(); _o->outputDataType = _e; };
+  { auto _e = outputDataType(); _o->outputDataType = _e; }
 }
 
 inline flatbuffers::Offset<Size> Size::Pack(flatbuffers::FlatBufferBuilder &_fbb, const SizeT* _o, const flatbuffers::rehasher_function_t *_rehasher) {
@@ -4072,15 +3997,15 @@ inline flatbuffers::Offset<Size> CreateSize(flatbuffers::FlatBufferBuilder &_fbb
 }
 
 inline TransposeT *Transpose::UnPack(const flatbuffers::resolver_function_t *_resolver) const {
-  auto _o = new TransposeT();
-  UnPackTo(_o, _resolver);
-  return _o;
+  auto _o = std::unique_ptr<TransposeT>(new TransposeT());
+  UnPackTo(_o.get(), _resolver);
+  return _o.release();
 }
 
 inline void Transpose::UnPackTo(TransposeT *_o, const flatbuffers::resolver_function_t *_resolver) const {
   (void)_o;
   (void)_resolver;
-  { auto _e = Tperm(); _o->Tperm = _e; };
+  { auto _e = Tperm(); _o->Tperm = _e; }
 }
 
 inline flatbuffers::Offset<Transpose> Transpose::Pack(flatbuffers::FlatBufferBuilder &_fbb, const TransposeT* _o, const flatbuffers::rehasher_function_t *_rehasher) {
@@ -4098,15 +4023,15 @@ inline flatbuffers::Offset<Transpose> CreateTranspose(flatbuffers::FlatBufferBui
 }
 
 inline SliceTfT *SliceTf::UnPack(const flatbuffers::resolver_function_t *_resolver) const {
-  auto _o = new SliceTfT();
-  UnPackTo(_o, _resolver);
-  return _o;
+  auto _o = std::unique_ptr<SliceTfT>(new SliceTfT());
+  UnPackTo(_o.get(), _resolver);
+  return _o.release();
 }
 
 inline void SliceTf::UnPackTo(SliceTfT *_o, const flatbuffers::resolver_function_t *_resolver) const {
   (void)_o;
   (void)_resolver;
-  { auto _e = T(); _o->T = _e; };
+  { auto _e = T(); _o->T = _e; }
 }
 
 inline flatbuffers::Offset<SliceTf> SliceTf::Pack(flatbuffers::FlatBufferBuilder &_fbb, const SliceTfT* _o, const flatbuffers::rehasher_function_t *_rehasher) {
@@ -4124,15 +4049,15 @@ inline flatbuffers::Offset<SliceTf> CreateSliceTf(flatbuffers::FlatBufferBuilder
 }
 
 inline QuantizeMaxMinT *QuantizeMaxMin::UnPack(const flatbuffers::resolver_function_t *_resolver) const {
-  auto _o = new QuantizeMaxMinT();
-  UnPackTo(_o, _resolver);
-  return _o;
+  auto _o = std::unique_ptr<QuantizeMaxMinT>(new QuantizeMaxMinT());
+  UnPackTo(_o.get(), _resolver);
+  return _o.release();
 }
 
 inline void QuantizeMaxMin::UnPackTo(QuantizeMaxMinT *_o, const flatbuffers::resolver_function_t *_resolver) const {
   (void)_o;
   (void)_resolver;
-  { auto _e = T(); _o->T = _e; };
+  { auto _e = T(); _o->T = _e; }
 }
 
 inline flatbuffers::Offset<QuantizeMaxMin> QuantizeMaxMin::Pack(flatbuffers::FlatBufferBuilder &_fbb, const QuantizeMaxMinT* _o, const flatbuffers::rehasher_function_t *_rehasher) {
@@ -4150,16 +4075,16 @@ inline flatbuffers::Offset<QuantizeMaxMin> CreateQuantizeMaxMin(flatbuffers::Fla
 }
 
 inline CropT *Crop::UnPack(const flatbuffers::resolver_function_t *_resolver) const {
-  auto _o = new CropT();
-  UnPackTo(_o, _resolver);
-  return _o;
+  auto _o = std::unique_ptr<CropT>(new CropT());
+  UnPackTo(_o.get(), _resolver);
+  return _o.release();
 }
 
 inline void Crop::UnPackTo(CropT *_o, const flatbuffers::resolver_function_t *_resolver) const {
   (void)_o;
   (void)_resolver;
-  { auto _e = axis(); _o->axis = _e; };
-  { auto _e = offset(); if (_e) { _o->offset.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->offset[_i] = _e->Get(_i); } } };
+  { auto _e = axis(); _o->axis = _e; }
+  { auto _e = offset(); if (_e) { _o->offset.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->offset[_i] = _e->Get(_i); } } }
 }
 
 inline flatbuffers::Offset<Crop> Crop::Pack(flatbuffers::FlatBufferBuilder &_fbb, const CropT* _o, const flatbuffers::rehasher_function_t *_rehasher) {
@@ -4179,16 +4104,16 @@ inline flatbuffers::Offset<Crop> CreateCrop(flatbuffers::FlatBufferBuilder &_fbb
 }
 
 inline SpaceBatchT *SpaceBatch::UnPack(const flatbuffers::resolver_function_t *_resolver) const {
-  auto _o = new SpaceBatchT();
-  UnPackTo(_o, _resolver);
-  return _o;
+  auto _o = std::unique_ptr<SpaceBatchT>(new SpaceBatchT());
+  UnPackTo(_o.get(), _resolver);
+  return _o.release();
 }
 
 inline void SpaceBatch::UnPackTo(SpaceBatchT *_o, const flatbuffers::resolver_function_t *_resolver) const {
   (void)_o;
   (void)_resolver;
-  { auto _e = blockShape(); if (_e) _o->blockShape = std::unique_ptr<BlobT>(_e->UnPack(_resolver)); };
-  { auto _e = padding(); if (_e) _o->padding = std::unique_ptr<BlobT>(_e->UnPack(_resolver)); };
+  { auto _e = blockShape(); if (_e) _o->blockShape = std::unique_ptr<MNN::BlobT>(_e->UnPack(_resolver)); }
+  { auto _e = padding(); if (_e) _o->padding = std::unique_ptr<MNN::BlobT>(_e->UnPack(_resolver)); }
 }
 
 inline flatbuffers::Offset<SpaceBatch> SpaceBatch::Pack(flatbuffers::FlatBufferBuilder &_fbb, const SpaceBatchT* _o, const flatbuffers::rehasher_function_t *_rehasher) {
@@ -4208,19 +4133,19 @@ inline flatbuffers::Offset<SpaceBatch> CreateSpaceBatch(flatbuffers::FlatBufferB
 }
 
 inline MatMulT *MatMul::UnPack(const flatbuffers::resolver_function_t *_resolver) const {
-  auto _o = new MatMulT();
-  UnPackTo(_o, _resolver);
-  return _o;
+  auto _o = std::unique_ptr<MatMulT>(new MatMulT());
+  UnPackTo(_o.get(), _resolver);
+  return _o.release();
 }
 
 inline void MatMul::UnPackTo(MatMulT *_o, const flatbuffers::resolver_function_t *_resolver) const {
   (void)_o;
   (void)_resolver;
-  { auto _e = T(); _o->T = _e; };
-  { auto _e = transposeA(); _o->transposeA = _e; };
-  { auto _e = transposeB(); _o->transposeB = _e; };
-  { auto _e = weight(); if (_e) { _o->weight.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->weight[_i] = _e->Get(_i); } } };
-  { auto _e = bias(); if (_e) { _o->bias.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->bias[_i] = _e->Get(_i); } } };
+  { auto _e = T(); _o->T = _e; }
+  { auto _e = transposeA(); _o->transposeA = _e; }
+  { auto _e = transposeB(); _o->transposeB = _e; }
+  { auto _e = weight(); if (_e) { _o->weight.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->weight[_i] = _e->Get(_i); } } }
+  { auto _e = bias(); if (_e) { _o->bias.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->bias[_i] = _e->Get(_i); } } }
 }
 
 inline flatbuffers::Offset<MatMul> MatMul::Pack(flatbuffers::FlatBufferBuilder &_fbb, const MatMulT* _o, const flatbuffers::rehasher_function_t *_rehasher) {
@@ -4246,17 +4171,17 @@ inline flatbuffers::Offset<MatMul> CreateMatMul(flatbuffers::FlatBufferBuilder &
 }
 
 inline MomentsParamT *MomentsParam::UnPack(const flatbuffers::resolver_function_t *_resolver) const {
-  auto _o = new MomentsParamT();
-  UnPackTo(_o, _resolver);
-  return _o;
+  auto _o = std::unique_ptr<MomentsParamT>(new MomentsParamT());
+  UnPackTo(_o.get(), _resolver);
+  return _o.release();
 }
 
 inline void MomentsParam::UnPackTo(MomentsParamT *_o, const flatbuffers::resolver_function_t *_resolver) const {
   (void)_o;
   (void)_resolver;
-  { auto _e = dim(); if (_e) { _o->dim.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->dim[_i] = _e->Get(_i); } } };
-  { auto _e = keepDims(); _o->keepDims = _e; };
-  { auto _e = dType(); _o->dType = _e; };
+  { auto _e = dim(); if (_e) { _o->dim.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->dim[_i] = _e->Get(_i); } } }
+  { auto _e = keepDims(); _o->keepDims = _e; }
+  { auto _e = dType(); _o->dType = _e; }
 }
 
 inline flatbuffers::Offset<MomentsParam> MomentsParam::Pack(flatbuffers::FlatBufferBuilder &_fbb, const MomentsParamT* _o, const flatbuffers::rehasher_function_t *_rehasher) {
@@ -4278,25 +4203,25 @@ inline flatbuffers::Offset<MomentsParam> CreateMomentsParam(flatbuffers::FlatBuf
 }
 
 inline RNNParamT *RNNParam::UnPack(const flatbuffers::resolver_function_t *_resolver) const {
-  auto _o = new RNNParamT();
-  UnPackTo(_o, _resolver);
-  return _o;
+  auto _o = std::unique_ptr<RNNParamT>(new RNNParamT());
+  UnPackTo(_o.get(), _resolver);
+  return _o.release();
 }
 
 inline void RNNParam::UnPackTo(RNNParamT *_o, const flatbuffers::resolver_function_t *_resolver) const {
   (void)_o;
   (void)_resolver;
-  { auto _e = numUnits(); _o->numUnits = _e; };
-  { auto _e = isBidirectionalRNN(); _o->isBidirectionalRNN = _e; };
-  { auto _e = keepAllOutputs(); _o->keepAllOutputs = _e; };
-  { auto _e = fwGateWeight(); if (_e) _o->fwGateWeight = std::unique_ptr<BlobT>(_e->UnPack(_resolver)); };
-  { auto _e = fwGateBias(); if (_e) _o->fwGateBias = std::unique_ptr<BlobT>(_e->UnPack(_resolver)); };
-  { auto _e = fwCandidateWeight(); if (_e) _o->fwCandidateWeight = std::unique_ptr<BlobT>(_e->UnPack(_resolver)); };
-  { auto _e = fwCandidateBias(); if (_e) _o->fwCandidateBias = std::unique_ptr<BlobT>(_e->UnPack(_resolver)); };
-  { auto _e = bwGateWeight(); if (_e) _o->bwGateWeight = std::unique_ptr<BlobT>(_e->UnPack(_resolver)); };
-  { auto _e = bwGateBias(); if (_e) _o->bwGateBias = std::unique_ptr<BlobT>(_e->UnPack(_resolver)); };
-  { auto _e = bwCandidateWeight(); if (_e) _o->bwCandidateWeight = std::unique_ptr<BlobT>(_e->UnPack(_resolver)); };
-  { auto _e = bwCandidateBias(); if (_e) _o->bwCandidateBias = std::unique_ptr<BlobT>(_e->UnPack(_resolver)); };
+  { auto _e = numUnits(); _o->numUnits = _e; }
+  { auto _e = isBidirectionalRNN(); _o->isBidirectionalRNN = _e; }
+  { auto _e = keepAllOutputs(); _o->keepAllOutputs = _e; }
+  { auto _e = fwGateWeight(); if (_e) _o->fwGateWeight = std::unique_ptr<MNN::BlobT>(_e->UnPack(_resolver)); }
+  { auto _e = fwGateBias(); if (_e) _o->fwGateBias = std::unique_ptr<MNN::BlobT>(_e->UnPack(_resolver)); }
+  { auto _e = fwCandidateWeight(); if (_e) _o->fwCandidateWeight = std::unique_ptr<MNN::BlobT>(_e->UnPack(_resolver)); }
+  { auto _e = fwCandidateBias(); if (_e) _o->fwCandidateBias = std::unique_ptr<MNN::BlobT>(_e->UnPack(_resolver)); }
+  { auto _e = bwGateWeight(); if (_e) _o->bwGateWeight = std::unique_ptr<MNN::BlobT>(_e->UnPack(_resolver)); }
+  { auto _e = bwGateBias(); if (_e) _o->bwGateBias = std::unique_ptr<MNN::BlobT>(_e->UnPack(_resolver)); }
+  { auto _e = bwCandidateWeight(); if (_e) _o->bwCandidateWeight = std::unique_ptr<MNN::BlobT>(_e->UnPack(_resolver)); }
+  { auto _e = bwCandidateBias(); if (_e) _o->bwCandidateBias = std::unique_ptr<MNN::BlobT>(_e->UnPack(_resolver)); }
 }
 
 inline flatbuffers::Offset<RNNParam> RNNParam::Pack(flatbuffers::FlatBufferBuilder &_fbb, const RNNParamT* _o, const flatbuffers::rehasher_function_t *_rehasher) {
@@ -4334,16 +4259,16 @@ inline flatbuffers::Offset<RNNParam> CreateRNNParam(flatbuffers::FlatBufferBuild
 }
 
 inline BatchMatMulParamT *BatchMatMulParam::UnPack(const flatbuffers::resolver_function_t *_resolver) const {
-  auto _o = new BatchMatMulParamT();
-  UnPackTo(_o, _resolver);
-  return _o;
+  auto _o = std::unique_ptr<BatchMatMulParamT>(new BatchMatMulParamT());
+  UnPackTo(_o.get(), _resolver);
+  return _o.release();
 }
 
 inline void BatchMatMulParam::UnPackTo(BatchMatMulParamT *_o, const flatbuffers::resolver_function_t *_resolver) const {
   (void)_o;
   (void)_resolver;
-  { auto _e = adjX(); _o->adjX = _e; };
-  { auto _e = adjY(); _o->adjY = _e; };
+  { auto _e = adjX(); _o->adjX = _e; }
+  { auto _e = adjY(); _o->adjY = _e; }
 }
 
 inline flatbuffers::Offset<BatchMatMulParam> BatchMatMulParam::Pack(flatbuffers::FlatBufferBuilder &_fbb, const BatchMatMulParamT* _o, const flatbuffers::rehasher_function_t *_rehasher) {
@@ -4363,16 +4288,16 @@ inline flatbuffers::Offset<BatchMatMulParam> CreateBatchMatMulParam(flatbuffers:
 }
 
 inline DepthSpaceParamT *DepthSpaceParam::UnPack(const flatbuffers::resolver_function_t *_resolver) const {
-  auto _o = new DepthSpaceParamT();
-  UnPackTo(_o, _resolver);
-  return _o;
+  auto _o = std::unique_ptr<DepthSpaceParamT>(new DepthSpaceParamT());
+  UnPackTo(_o.get(), _resolver);
+  return _o.release();
 }
 
 inline void DepthSpaceParam::UnPackTo(DepthSpaceParamT *_o, const flatbuffers::resolver_function_t *_resolver) const {
   (void)_o;
   (void)_resolver;
-  { auto _e = blockSize(); _o->blockSize = _e; };
-  { auto _e = mode(); _o->mode = _e; };
+  { auto _e = blockSize(); _o->blockSize = _e; }
+  { auto _e = mode(); _o->mode = _e; }
 }
 
 inline flatbuffers::Offset<DepthSpaceParam> DepthSpaceParam::Pack(flatbuffers::FlatBufferBuilder &_fbb, const DepthSpaceParamT* _o, const flatbuffers::rehasher_function_t *_rehasher) {
@@ -4392,16 +4317,16 @@ inline flatbuffers::Offset<DepthSpaceParam> CreateDepthSpaceParam(flatbuffers::F
 }
 
 inline ReverseSequenceParamT *ReverseSequenceParam::UnPack(const flatbuffers::resolver_function_t *_resolver) const {
-  auto _o = new ReverseSequenceParamT();
-  UnPackTo(_o, _resolver);
-  return _o;
+  auto _o = std::unique_ptr<ReverseSequenceParamT>(new ReverseSequenceParamT());
+  UnPackTo(_o.get(), _resolver);
+  return _o.release();
 }
 
 inline void ReverseSequenceParam::UnPackTo(ReverseSequenceParamT *_o, const flatbuffers::resolver_function_t *_resolver) const {
   (void)_o;
   (void)_resolver;
-  { auto _e = batchDim(); _o->batchDim = _e; };
-  { auto _e = seqDim(); _o->seqDim = _e; };
+  { auto _e = batchDim(); _o->batchDim = _e; }
+  { auto _e = seqDim(); _o->seqDim = _e; }
 }
 
 inline flatbuffers::Offset<ReverseSequenceParam> ReverseSequenceParam::Pack(flatbuffers::FlatBufferBuilder &_fbb, const ReverseSequenceParamT* _o, const flatbuffers::rehasher_function_t *_rehasher) {
@@ -4421,22 +4346,22 @@ inline flatbuffers::Offset<ReverseSequenceParam> CreateReverseSequenceParam(flat
 }
 
 inline DetectionPostProcessParamT *DetectionPostProcessParam::UnPack(const flatbuffers::resolver_function_t *_resolver) const {
-  auto _o = new DetectionPostProcessParamT();
-  UnPackTo(_o, _resolver);
-  return _o;
+  auto _o = std::unique_ptr<DetectionPostProcessParamT>(new DetectionPostProcessParamT());
+  UnPackTo(_o.get(), _resolver);
+  return _o.release();
 }
 
 inline void DetectionPostProcessParam::UnPackTo(DetectionPostProcessParamT *_o, const flatbuffers::resolver_function_t *_resolver) const {
   (void)_o;
   (void)_resolver;
-  { auto _e = maxDetections(); _o->maxDetections = _e; };
-  { auto _e = maxClassesPerDetection(); _o->maxClassesPerDetection = _e; };
-  { auto _e = detectionsPerClass(); _o->detectionsPerClass = _e; };
-  { auto _e = nmsScoreThreshold(); _o->nmsScoreThreshold = _e; };
-  { auto _e = iouThreshold(); _o->iouThreshold = _e; };
-  { auto _e = numClasses(); _o->numClasses = _e; };
-  { auto _e = useRegularNMS(); _o->useRegularNMS = _e; };
-  { auto _e = centerSizeEncoding(); if (_e) { _o->centerSizeEncoding.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->centerSizeEncoding[_i] = _e->Get(_i); } } };
+  { auto _e = maxDetections(); _o->maxDetections = _e; }
+  { auto _e = maxClassesPerDetection(); _o->maxClassesPerDetection = _e; }
+  { auto _e = detectionsPerClass(); _o->detectionsPerClass = _e; }
+  { auto _e = nmsScoreThreshold(); _o->nmsScoreThreshold = _e; }
+  { auto _e = iouThreshold(); _o->iouThreshold = _e; }
+  { auto _e = numClasses(); _o->numClasses = _e; }
+  { auto _e = useRegularNMS(); _o->useRegularNMS = _e; }
+  { auto _e = centerSizeEncoding(); if (_e) { _o->centerSizeEncoding.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->centerSizeEncoding[_i] = _e->Get(_i); } } }
 }
 
 inline flatbuffers::Offset<DetectionPostProcessParam> DetectionPostProcessParam::Pack(flatbuffers::FlatBufferBuilder &_fbb, const DetectionPostProcessParamT* _o, const flatbuffers::rehasher_function_t *_rehasher) {
@@ -4468,16 +4393,16 @@ inline flatbuffers::Offset<DetectionPostProcessParam> CreateDetectionPostProcess
 }
 
 inline OneHotParamT *OneHotParam::UnPack(const flatbuffers::resolver_function_t *_resolver) const {
-  auto _o = new OneHotParamT();
-  UnPackTo(_o, _resolver);
-  return _o;
+  auto _o = std::unique_ptr<OneHotParamT>(new OneHotParamT());
+  UnPackTo(_o.get(), _resolver);
+  return _o.release();
 }
 
 inline void OneHotParam::UnPackTo(OneHotParamT *_o, const flatbuffers::resolver_function_t *_resolver) const {
   (void)_o;
   (void)_resolver;
-  { auto _e = dType(); _o->dType = _e; };
-  { auto _e = axis(); _o->axis = _e; };
+  { auto _e = dType(); _o->dType = _e; }
+  { auto _e = axis(); _o->axis = _e; }
 }
 
 inline flatbuffers::Offset<OneHotParam> OneHotParam::Pack(flatbuffers::FlatBufferBuilder &_fbb, const OneHotParamT* _o, const flatbuffers::rehasher_function_t *_rehasher) {
@@ -4497,15 +4422,15 @@ inline flatbuffers::Offset<OneHotParam> CreateOneHotParam(flatbuffers::FlatBuffe
 }
 
 inline PadParamT *PadParam::UnPack(const flatbuffers::resolver_function_t *_resolver) const {
-  auto _o = new PadParamT();
-  UnPackTo(_o, _resolver);
-  return _o;
+  auto _o = std::unique_ptr<PadParamT>(new PadParamT());
+  UnPackTo(_o.get(), _resolver);
+  return _o.release();
 }
 
 inline void PadParam::UnPackTo(PadParamT *_o, const flatbuffers::resolver_function_t *_resolver) const {
   (void)_o;
   (void)_resolver;
-  { auto _e = mode(); _o->mode = _e; };
+  { auto _e = mode(); _o->mode = _e; }
 }
 
 inline flatbuffers::Offset<PadParam> PadParam::Pack(flatbuffers::FlatBufferBuilder &_fbb, const PadParamT* _o, const flatbuffers::rehasher_function_t *_rehasher) {
@@ -4523,18 +4448,18 @@ inline flatbuffers::Offset<PadParam> CreatePadParam(flatbuffers::FlatBufferBuild
 }
 
 inline LayerNormT *LayerNorm::UnPack(const flatbuffers::resolver_function_t *_resolver) const {
-  auto _o = new LayerNormT();
-  UnPackTo(_o, _resolver);
-  return _o;
+  auto _o = std::unique_ptr<LayerNormT>(new LayerNormT());
+  UnPackTo(_o.get(), _resolver);
+  return _o.release();
 }
 
 inline void LayerNorm::UnPackTo(LayerNormT *_o, const flatbuffers::resolver_function_t *_resolver) const {
   (void)_o;
   (void)_resolver;
-  { auto _e = axis(); if (_e) { _o->axis.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->axis[_i] = _e->Get(_i); } } };
-  { auto _e = epsilon(); _o->epsilon = _e; };
-  { auto _e = gamma(); if (_e) { _o->gamma.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->gamma[_i] = _e->Get(_i); } } };
-  { auto _e = beta(); if (_e) { _o->beta.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->beta[_i] = _e->Get(_i); } } };
+  { auto _e = axis(); if (_e) { _o->axis.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->axis[_i] = _e->Get(_i); } } }
+  { auto _e = epsilon(); _o->epsilon = _e; }
+  { auto _e = gamma(); if (_e) { _o->gamma.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->gamma[_i] = _e->Get(_i); } } }
+  { auto _e = beta(); if (_e) { _o->beta.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->beta[_i] = _e->Get(_i); } } }
 }
 
 inline flatbuffers::Offset<LayerNorm> LayerNorm::Pack(flatbuffers::FlatBufferBuilder &_fbb, const LayerNormT* _o, const flatbuffers::rehasher_function_t *_rehasher) {
@@ -4558,18 +4483,18 @@ inline flatbuffers::Offset<LayerNorm> CreateLayerNorm(flatbuffers::FlatBufferBui
 }
 
 inline RandomUniformT *RandomUniform::UnPack(const flatbuffers::resolver_function_t *_resolver) const {
-  auto _o = new RandomUniformT();
-  UnPackTo(_o, _resolver);
-  return _o;
+  auto _o = std::unique_ptr<RandomUniformT>(new RandomUniformT());
+  UnPackTo(_o.get(), _resolver);
+  return _o.release();
 }
 
 inline void RandomUniform::UnPackTo(RandomUniformT *_o, const flatbuffers::resolver_function_t *_resolver) const {
   (void)_o;
   (void)_resolver;
-  { auto _e = seed(); _o->seed = _e; };
-  { auto _e = seed2(); _o->seed2 = _e; };
-  { auto _e = type(); _o->type = _e; };
-  { auto _e = T(); _o->T = _e; };
+  { auto _e = seed(); _o->seed = _e; }
+  { auto _e = seed2(); _o->seed2 = _e; }
+  { auto _e = type(); _o->type = _e; }
+  { auto _e = T(); _o->T = _e; }
 }
 
 inline flatbuffers::Offset<RandomUniform> RandomUniform::Pack(flatbuffers::FlatBufferBuilder &_fbb, const RandomUniformT* _o, const flatbuffers::rehasher_function_t *_rehasher) {
@@ -4618,7 +4543,7 @@ inline const flatbuffers::TypeTable *BinaryOpOperationTypeTable() {
     { flatbuffers::ET_CHAR, 0, 0 }
   };
   static const flatbuffers::TypeFunction type_refs[] = {
-    BinaryOpOperationTypeTable
+    MNN::BinaryOpOperationTypeTable
   };
   static const int64_t values[] = { 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 19, 20, 21, 22 };
   static const char * const names[] = {
@@ -4646,7 +4571,7 @@ inline const flatbuffers::TypeTable *BinaryOpOperationTypeTable() {
     "NOTEQUAL"
   };
   static const flatbuffers::TypeTable tt = {
-    flatbuffers::ST_ENUM, 22, type_codes, type_refs, values, names
+    flatbuffers::ST_ENUM, 22, type_codes, type_refs, nullptr, values, names
   };
   return &tt;
 }
@@ -4664,7 +4589,7 @@ inline const flatbuffers::TypeTable *ReductionTypeTypeTable() {
     { flatbuffers::ET_CHAR, 0, 0 }
   };
   static const flatbuffers::TypeFunction type_refs[] = {
-    ReductionTypeTypeTable
+    MNN::ReductionTypeTypeTable
   };
   static const char * const names[] = {
     "SUM",
@@ -4678,7 +4603,7 @@ inline const flatbuffers::TypeTable *ReductionTypeTypeTable() {
     "ALL"
   };
   static const flatbuffers::TypeTable tt = {
-    flatbuffers::ST_ENUM, 9, type_codes, type_refs, nullptr, names
+    flatbuffers::ST_ENUM, 9, type_codes, type_refs, nullptr, nullptr, names
   };
   return &tt;
 }
@@ -4718,7 +4643,7 @@ inline const flatbuffers::TypeTable *UnaryOpOperationTypeTable() {
     { flatbuffers::ET_INT, 0, 0 }
   };
   static const flatbuffers::TypeFunction type_refs[] = {
-    UnaryOpOperationTypeTable
+    MNN::UnaryOpOperationTypeTable
   };
   static const char * const names[] = {
     "ABS",
@@ -4754,7 +4679,7 @@ inline const flatbuffers::TypeTable *UnaryOpOperationTypeTable() {
     "TANH"
   };
   static const flatbuffers::TypeTable tt = {
-    flatbuffers::ST_ENUM, 31, type_codes, type_refs, nullptr, names
+    flatbuffers::ST_ENUM, 31, type_codes, type_refs, nullptr, nullptr, names
   };
   return &tt;
 }
@@ -4765,14 +4690,14 @@ inline const flatbuffers::TypeTable *CropAndResizeMethodTypeTable() {
     { flatbuffers::ET_CHAR, 0, 0 }
   };
   static const flatbuffers::TypeFunction type_refs[] = {
-    CropAndResizeMethodTypeTable
+    MNN::CropAndResizeMethodTypeTable
   };
   static const char * const names[] = {
     "BILINEAR",
     "NEAREST"
   };
   static const flatbuffers::TypeTable tt = {
-    flatbuffers::ST_ENUM, 2, type_codes, type_refs, nullptr, names
+    flatbuffers::ST_ENUM, 2, type_codes, type_refs, nullptr, nullptr, names
   };
   return &tt;
 }
@@ -4783,14 +4708,14 @@ inline const flatbuffers::TypeTable *DepthToSpaceModeTypeTable() {
     { flatbuffers::ET_CHAR, 0, 0 }
   };
   static const flatbuffers::TypeFunction type_refs[] = {
-    DepthToSpaceModeTypeTable
+    MNN::DepthToSpaceModeTypeTable
   };
   static const char * const names[] = {
     "DCR",
     "CRD"
   };
   static const flatbuffers::TypeTable tt = {
-    flatbuffers::ST_ENUM, 2, type_codes, type_refs, nullptr, names
+    flatbuffers::ST_ENUM, 2, type_codes, type_refs, nullptr, nullptr, names
   };
   return &tt;
 }
@@ -4802,7 +4727,7 @@ inline const flatbuffers::TypeTable *PadValueModeTypeTable() {
     { flatbuffers::ET_CHAR, 0, 0 }
   };
   static const flatbuffers::TypeFunction type_refs[] = {
-    PadValueModeTypeTable
+    MNN::PadValueModeTypeTable
   };
   static const char * const names[] = {
     "CONSTANT",
@@ -4810,7 +4735,7 @@ inline const flatbuffers::TypeTable *PadValueModeTypeTable() {
     "SYMMETRIC"
   };
   static const flatbuffers::TypeTable tt = {
-    flatbuffers::ST_ENUM, 3, type_codes, type_refs, nullptr, names
+    flatbuffers::ST_ENUM, 3, type_codes, type_refs, nullptr, nullptr, names
   };
   return &tt;
 }
@@ -4821,14 +4746,14 @@ inline const flatbuffers::TypeTable *BinaryOpTypeTable() {
     { flatbuffers::ET_INT, 0, 0 }
   };
   static const flatbuffers::TypeFunction type_refs[] = {
-    DataTypeTypeTable
+    MNN::DataTypeTypeTable
   };
   static const char * const names[] = {
     "opType",
     "T"
   };
   static const flatbuffers::TypeTable tt = {
-    flatbuffers::ST_TABLE, 2, type_codes, type_refs, nullptr, names
+    flatbuffers::ST_TABLE, 2, type_codes, type_refs, nullptr, nullptr, names
   };
   return &tt;
 }
@@ -4839,14 +4764,14 @@ inline const flatbuffers::TypeTable *PackParamTypeTable() {
     { flatbuffers::ET_INT, 0, -1 }
   };
   static const flatbuffers::TypeFunction type_refs[] = {
-    DataTypeTypeTable
+    MNN::DataTypeTypeTable
   };
   static const char * const names[] = {
     "dataType",
     "axis"
   };
   static const flatbuffers::TypeTable tt = {
-    flatbuffers::ST_TABLE, 2, type_codes, type_refs, nullptr, names
+    flatbuffers::ST_TABLE, 2, type_codes, type_refs, nullptr, nullptr, names
   };
   return &tt;
 }
@@ -4862,7 +4787,7 @@ inline const flatbuffers::TypeTable *StridedSliceParamTypeTable() {
     { flatbuffers::ET_INT, 0, -1 }
   };
   static const flatbuffers::TypeFunction type_refs[] = {
-    DataTypeTypeTable
+    MNN::DataTypeTypeTable
   };
   static const char * const names[] = {
     "Index",
@@ -4874,7 +4799,7 @@ inline const flatbuffers::TypeTable *StridedSliceParamTypeTable() {
     "shrinkAxisMask"
   };
   static const flatbuffers::TypeTable tt = {
-    flatbuffers::ST_TABLE, 7, type_codes, type_refs, nullptr, names
+    flatbuffers::ST_TABLE, 7, type_codes, type_refs, nullptr, nullptr, names
   };
   return &tt;
 }
@@ -4887,7 +4812,7 @@ inline const flatbuffers::TypeTable *SqueezeParamTypeTable() {
     "squeezeDims"
   };
   static const flatbuffers::TypeTable tt = {
-    flatbuffers::ST_TABLE, 1, type_codes, nullptr, nullptr, names
+    flatbuffers::ST_TABLE, 1, type_codes, nullptr, nullptr, nullptr, names
   };
   return &tt;
 }
@@ -4898,14 +4823,14 @@ inline const flatbuffers::TypeTable *CastParamTypeTable() {
     { flatbuffers::ET_INT, 0, 0 }
   };
   static const flatbuffers::TypeFunction type_refs[] = {
-    DataTypeTypeTable
+    MNN::DataTypeTypeTable
   };
   static const char * const names[] = {
     "srcT",
     "dstT"
   };
   static const flatbuffers::TypeTable tt = {
-    flatbuffers::ST_TABLE, 2, type_codes, type_refs, nullptr, names
+    flatbuffers::ST_TABLE, 2, type_codes, type_refs, nullptr, nullptr, names
   };
   return &tt;
 }
@@ -4919,8 +4844,8 @@ inline const flatbuffers::TypeTable *ReductionParamTypeTable() {
     { flatbuffers::ET_INT, 0, 1 }
   };
   static const flatbuffers::TypeFunction type_refs[] = {
-    ReductionTypeTypeTable,
-    DataTypeTypeTable
+    MNN::ReductionTypeTypeTable,
+    MNN::DataTypeTypeTable
   };
   static const char * const names[] = {
     "operation",
@@ -4930,7 +4855,7 @@ inline const flatbuffers::TypeTable *ReductionParamTypeTable() {
     "dType"
   };
   static const flatbuffers::TypeTable tt = {
-    flatbuffers::ST_TABLE, 5, type_codes, type_refs, nullptr, names
+    flatbuffers::ST_TABLE, 5, type_codes, type_refs, nullptr, nullptr, names
   };
   return &tt;
 }
@@ -4943,7 +4868,7 @@ inline const flatbuffers::TypeTable *GatherTypeTable() {
     { flatbuffers::ET_INT, 0, -1 }
   };
   static const flatbuffers::TypeFunction type_refs[] = {
-    DataTypeTypeTable
+    MNN::DataTypeTypeTable
   };
   static const char * const names[] = {
     "Tindices",
@@ -4952,7 +4877,7 @@ inline const flatbuffers::TypeTable *GatherTypeTable() {
     "axis"
   };
   static const flatbuffers::TypeTable tt = {
-    flatbuffers::ST_TABLE, 4, type_codes, type_refs, nullptr, names
+    flatbuffers::ST_TABLE, 4, type_codes, type_refs, nullptr, nullptr, names
   };
   return &tt;
 }
@@ -4964,7 +4889,7 @@ inline const flatbuffers::TypeTable *ExpandDimsTypeTable() {
     { flatbuffers::ET_INT, 0, -1 }
   };
   static const flatbuffers::TypeFunction type_refs[] = {
-    DataTypeTypeTable
+    MNN::DataTypeTypeTable
   };
   static const char * const names[] = {
     "T",
@@ -4972,7 +4897,7 @@ inline const flatbuffers::TypeTable *ExpandDimsTypeTable() {
     "axis"
   };
   static const flatbuffers::TypeTable tt = {
-    flatbuffers::ST_TABLE, 3, type_codes, type_refs, nullptr, names
+    flatbuffers::ST_TABLE, 3, type_codes, type_refs, nullptr, nullptr, names
   };
   return &tt;
 }
@@ -4987,7 +4912,7 @@ inline const flatbuffers::TypeTable *SeluTypeTable() {
     "alpha"
   };
   static const flatbuffers::TypeTable tt = {
-    flatbuffers::ST_TABLE, 2, type_codes, nullptr, nullptr, names
+    flatbuffers::ST_TABLE, 2, type_codes, nullptr, nullptr, nullptr, names
   };
   return &tt;
 }
@@ -5002,7 +4927,7 @@ inline const flatbuffers::TypeTable *AsStringTypeTable() {
     { flatbuffers::ET_STRING, 0, -1 }
   };
   static const flatbuffers::TypeFunction type_refs[] = {
-    DataTypeTypeTable
+    MNN::DataTypeTypeTable
   };
   static const char * const names[] = {
     "T",
@@ -5013,7 +4938,7 @@ inline const flatbuffers::TypeTable *AsStringTypeTable() {
     "fillString"
   };
   static const flatbuffers::TypeTable tt = {
-    flatbuffers::ST_TABLE, 6, type_codes, type_refs, nullptr, names
+    flatbuffers::ST_TABLE, 6, type_codes, type_refs, nullptr, nullptr, names
   };
   return &tt;
 }
@@ -5028,7 +4953,7 @@ inline const flatbuffers::TypeTable *ReduceJoinTypeTable() {
     "separator"
   };
   static const flatbuffers::TypeTable tt = {
-    flatbuffers::ST_TABLE, 2, type_codes, nullptr, nullptr, names
+    flatbuffers::ST_TABLE, 2, type_codes, nullptr, nullptr, nullptr, names
   };
   return &tt;
 }
@@ -5039,15 +4964,15 @@ inline const flatbuffers::TypeTable *UnaryOpTypeTable() {
     { flatbuffers::ET_INT, 0, 1 }
   };
   static const flatbuffers::TypeFunction type_refs[] = {
-    UnaryOpOperationTypeTable,
-    DataTypeTypeTable
+    MNN::UnaryOpOperationTypeTable,
+    MNN::DataTypeTypeTable
   };
   static const char * const names[] = {
     "opType",
     "T"
   };
   static const flatbuffers::TypeTable tt = {
-    flatbuffers::ST_TABLE, 2, type_codes, type_refs, nullptr, names
+    flatbuffers::ST_TABLE, 2, type_codes, type_refs, nullptr, nullptr, names
   };
   return &tt;
 }
@@ -5058,14 +4983,14 @@ inline const flatbuffers::TypeTable *TopKV2TypeTable() {
     { flatbuffers::ET_BOOL, 0, -1 }
   };
   static const flatbuffers::TypeFunction type_refs[] = {
-    DataTypeTypeTable
+    MNN::DataTypeTypeTable
   };
   static const char * const names[] = {
     "T",
     "sorted"
   };
   static const flatbuffers::TypeTable tt = {
-    flatbuffers::ST_TABLE, 2, type_codes, type_refs, nullptr, names
+    flatbuffers::ST_TABLE, 2, type_codes, type_refs, nullptr, nullptr, names
   };
   return &tt;
 }
@@ -5076,21 +5001,21 @@ inline const flatbuffers::TypeTable *CropAndResizeTypeTable() {
     { flatbuffers::ET_CHAR, 0, 0 }
   };
   static const flatbuffers::TypeFunction type_refs[] = {
-    CropAndResizeMethodTypeTable
+    MNN::CropAndResizeMethodTypeTable
   };
   static const char * const names[] = {
     "extrapolationValue",
     "method"
   };
   static const flatbuffers::TypeTable tt = {
-    flatbuffers::ST_TABLE, 2, type_codes, type_refs, nullptr, names
+    flatbuffers::ST_TABLE, 2, type_codes, type_refs, nullptr, nullptr, names
   };
   return &tt;
 }
 
 inline const flatbuffers::TypeTable *FillTypeTable() {
   static const flatbuffers::TypeTable tt = {
-    flatbuffers::ST_TABLE, 0, nullptr, nullptr, nullptr, nullptr
+    flatbuffers::ST_TABLE, 0, nullptr, nullptr, nullptr, nullptr, nullptr
   };
   return &tt;
 }
@@ -5102,7 +5027,7 @@ inline const flatbuffers::TypeTable *GatherV2TypeTable() {
     { flatbuffers::ET_INT, 0, 0 }
   };
   static const flatbuffers::TypeFunction type_refs[] = {
-    DataTypeTypeTable
+    MNN::DataTypeTypeTable
   };
   static const char * const names[] = {
     "Taxis",
@@ -5110,14 +5035,14 @@ inline const flatbuffers::TypeTable *GatherV2TypeTable() {
     "Tparams"
   };
   static const flatbuffers::TypeTable tt = {
-    flatbuffers::ST_TABLE, 3, type_codes, type_refs, nullptr, names
+    flatbuffers::ST_TABLE, 3, type_codes, type_refs, nullptr, nullptr, names
   };
   return &tt;
 }
 
 inline const flatbuffers::TypeTable *NonMaxSuppressionV2TypeTable() {
   static const flatbuffers::TypeTable tt = {
-    flatbuffers::ST_TABLE, 0, nullptr, nullptr, nullptr, nullptr
+    flatbuffers::ST_TABLE, 0, nullptr, nullptr, nullptr, nullptr, nullptr
   };
   return &tt;
 }
@@ -5127,20 +5052,20 @@ inline const flatbuffers::TypeTable *RangeTypeTable() {
     { flatbuffers::ET_INT, 0, 0 }
   };
   static const flatbuffers::TypeFunction type_refs[] = {
-    DataTypeTypeTable
+    MNN::DataTypeTypeTable
   };
   static const char * const names[] = {
     "Tidx"
   };
   static const flatbuffers::TypeTable tt = {
-    flatbuffers::ST_TABLE, 1, type_codes, type_refs, nullptr, names
+    flatbuffers::ST_TABLE, 1, type_codes, type_refs, nullptr, nullptr, names
   };
   return &tt;
 }
 
 inline const flatbuffers::TypeTable *RankTypeTable() {
   static const flatbuffers::TypeTable tt = {
-    flatbuffers::ST_TABLE, 0, nullptr, nullptr, nullptr, nullptr
+    flatbuffers::ST_TABLE, 0, nullptr, nullptr, nullptr, nullptr, nullptr
   };
   return &tt;
 }
@@ -5150,13 +5075,13 @@ inline const flatbuffers::TypeTable *SizeTypeTable() {
     { flatbuffers::ET_INT, 0, 0 }
   };
   static const flatbuffers::TypeFunction type_refs[] = {
-    DataTypeTypeTable
+    MNN::DataTypeTypeTable
   };
   static const char * const names[] = {
     "outputDataType"
   };
   static const flatbuffers::TypeTable tt = {
-    flatbuffers::ST_TABLE, 1, type_codes, type_refs, nullptr, names
+    flatbuffers::ST_TABLE, 1, type_codes, type_refs, nullptr, nullptr, names
   };
   return &tt;
 }
@@ -5166,13 +5091,13 @@ inline const flatbuffers::TypeTable *TransposeTypeTable() {
     { flatbuffers::ET_INT, 0, 0 }
   };
   static const flatbuffers::TypeFunction type_refs[] = {
-    DataTypeTypeTable
+    MNN::DataTypeTypeTable
   };
   static const char * const names[] = {
     "Tperm"
   };
   static const flatbuffers::TypeTable tt = {
-    flatbuffers::ST_TABLE, 1, type_codes, type_refs, nullptr, names
+    flatbuffers::ST_TABLE, 1, type_codes, type_refs, nullptr, nullptr, names
   };
   return &tt;
 }
@@ -5182,13 +5107,13 @@ inline const flatbuffers::TypeTable *SliceTfTypeTable() {
     { flatbuffers::ET_INT, 0, 0 }
   };
   static const flatbuffers::TypeFunction type_refs[] = {
-    DataTypeTypeTable
+    MNN::DataTypeTypeTable
   };
   static const char * const names[] = {
     "T"
   };
   static const flatbuffers::TypeTable tt = {
-    flatbuffers::ST_TABLE, 1, type_codes, type_refs, nullptr, names
+    flatbuffers::ST_TABLE, 1, type_codes, type_refs, nullptr, nullptr, names
   };
   return &tt;
 }
@@ -5198,13 +5123,13 @@ inline const flatbuffers::TypeTable *QuantizeMaxMinTypeTable() {
     { flatbuffers::ET_INT, 0, 0 }
   };
   static const flatbuffers::TypeFunction type_refs[] = {
-    DataTypeTypeTable
+    MNN::DataTypeTypeTable
   };
   static const char * const names[] = {
     "T"
   };
   static const flatbuffers::TypeTable tt = {
-    flatbuffers::ST_TABLE, 1, type_codes, type_refs, nullptr, names
+    flatbuffers::ST_TABLE, 1, type_codes, type_refs, nullptr, nullptr, names
   };
   return &tt;
 }
@@ -5219,7 +5144,7 @@ inline const flatbuffers::TypeTable *CropTypeTable() {
     "offset"
   };
   static const flatbuffers::TypeTable tt = {
-    flatbuffers::ST_TABLE, 2, type_codes, nullptr, nullptr, names
+    flatbuffers::ST_TABLE, 2, type_codes, nullptr, nullptr, nullptr, names
   };
   return &tt;
 }
@@ -5230,14 +5155,14 @@ inline const flatbuffers::TypeTable *SpaceBatchTypeTable() {
     { flatbuffers::ET_SEQUENCE, 0, 0 }
   };
   static const flatbuffers::TypeFunction type_refs[] = {
-    BlobTypeTable
+    MNN::BlobTypeTable
   };
   static const char * const names[] = {
     "blockShape",
     "padding"
   };
   static const flatbuffers::TypeTable tt = {
-    flatbuffers::ST_TABLE, 2, type_codes, type_refs, nullptr, names
+    flatbuffers::ST_TABLE, 2, type_codes, type_refs, nullptr, nullptr, names
   };
   return &tt;
 }
@@ -5251,7 +5176,7 @@ inline const flatbuffers::TypeTable *MatMulTypeTable() {
     { flatbuffers::ET_FLOAT, 1, -1 }
   };
   static const flatbuffers::TypeFunction type_refs[] = {
-    DataTypeTypeTable
+    MNN::DataTypeTypeTable
   };
   static const char * const names[] = {
     "T",
@@ -5261,7 +5186,7 @@ inline const flatbuffers::TypeTable *MatMulTypeTable() {
     "bias"
   };
   static const flatbuffers::TypeTable tt = {
-    flatbuffers::ST_TABLE, 5, type_codes, type_refs, nullptr, names
+    flatbuffers::ST_TABLE, 5, type_codes, type_refs, nullptr, nullptr, names
   };
   return &tt;
 }
@@ -5273,7 +5198,7 @@ inline const flatbuffers::TypeTable *MomentsParamTypeTable() {
     { flatbuffers::ET_INT, 0, 0 }
   };
   static const flatbuffers::TypeFunction type_refs[] = {
-    DataTypeTypeTable
+    MNN::DataTypeTypeTable
   };
   static const char * const names[] = {
     "dim",
@@ -5281,7 +5206,7 @@ inline const flatbuffers::TypeTable *MomentsParamTypeTable() {
     "dType"
   };
   static const flatbuffers::TypeTable tt = {
-    flatbuffers::ST_TABLE, 3, type_codes, type_refs, nullptr, names
+    flatbuffers::ST_TABLE, 3, type_codes, type_refs, nullptr, nullptr, names
   };
   return &tt;
 }
@@ -5301,7 +5226,7 @@ inline const flatbuffers::TypeTable *RNNParamTypeTable() {
     { flatbuffers::ET_SEQUENCE, 0, 0 }
   };
   static const flatbuffers::TypeFunction type_refs[] = {
-    BlobTypeTable
+    MNN::BlobTypeTable
   };
   static const char * const names[] = {
     "numUnits",
@@ -5317,7 +5242,7 @@ inline const flatbuffers::TypeTable *RNNParamTypeTable() {
     "bwCandidateBias"
   };
   static const flatbuffers::TypeTable tt = {
-    flatbuffers::ST_TABLE, 11, type_codes, type_refs, nullptr, names
+    flatbuffers::ST_TABLE, 11, type_codes, type_refs, nullptr, nullptr, names
   };
   return &tt;
 }
@@ -5332,7 +5257,7 @@ inline const flatbuffers::TypeTable *BatchMatMulParamTypeTable() {
     "adjY"
   };
   static const flatbuffers::TypeTable tt = {
-    flatbuffers::ST_TABLE, 2, type_codes, nullptr, nullptr, names
+    flatbuffers::ST_TABLE, 2, type_codes, nullptr, nullptr, nullptr, names
   };
   return &tt;
 }
@@ -5343,14 +5268,14 @@ inline const flatbuffers::TypeTable *DepthSpaceParamTypeTable() {
     { flatbuffers::ET_CHAR, 0, 0 }
   };
   static const flatbuffers::TypeFunction type_refs[] = {
-    DepthToSpaceModeTypeTable
+    MNN::DepthToSpaceModeTypeTable
   };
   static const char * const names[] = {
     "blockSize",
     "mode"
   };
   static const flatbuffers::TypeTable tt = {
-    flatbuffers::ST_TABLE, 2, type_codes, type_refs, nullptr, names
+    flatbuffers::ST_TABLE, 2, type_codes, type_refs, nullptr, nullptr, names
   };
   return &tt;
 }
@@ -5365,7 +5290,7 @@ inline const flatbuffers::TypeTable *ReverseSequenceParamTypeTable() {
     "seqDim"
   };
   static const flatbuffers::TypeTable tt = {
-    flatbuffers::ST_TABLE, 2, type_codes, nullptr, nullptr, names
+    flatbuffers::ST_TABLE, 2, type_codes, nullptr, nullptr, nullptr, names
   };
   return &tt;
 }
@@ -5392,7 +5317,7 @@ inline const flatbuffers::TypeTable *DetectionPostProcessParamTypeTable() {
     "centerSizeEncoding"
   };
   static const flatbuffers::TypeTable tt = {
-    flatbuffers::ST_TABLE, 8, type_codes, nullptr, nullptr, names
+    flatbuffers::ST_TABLE, 8, type_codes, nullptr, nullptr, nullptr, names
   };
   return &tt;
 }
@@ -5403,14 +5328,14 @@ inline const flatbuffers::TypeTable *OneHotParamTypeTable() {
     { flatbuffers::ET_INT, 0, -1 }
   };
   static const flatbuffers::TypeFunction type_refs[] = {
-    DataTypeTypeTable
+    MNN::DataTypeTypeTable
   };
   static const char * const names[] = {
     "dType",
     "axis"
   };
   static const flatbuffers::TypeTable tt = {
-    flatbuffers::ST_TABLE, 2, type_codes, type_refs, nullptr, names
+    flatbuffers::ST_TABLE, 2, type_codes, type_refs, nullptr, nullptr, names
   };
   return &tt;
 }
@@ -5420,13 +5345,13 @@ inline const flatbuffers::TypeTable *PadParamTypeTable() {
     { flatbuffers::ET_CHAR, 0, 0 }
   };
   static const flatbuffers::TypeFunction type_refs[] = {
-    PadValueModeTypeTable
+    MNN::PadValueModeTypeTable
   };
   static const char * const names[] = {
     "mode"
   };
   static const flatbuffers::TypeTable tt = {
-    flatbuffers::ST_TABLE, 1, type_codes, type_refs, nullptr, names
+    flatbuffers::ST_TABLE, 1, type_codes, type_refs, nullptr, nullptr, names
   };
   return &tt;
 }
@@ -5445,7 +5370,7 @@ inline const flatbuffers::TypeTable *LayerNormTypeTable() {
     "beta"
   };
   static const flatbuffers::TypeTable tt = {
-    flatbuffers::ST_TABLE, 4, type_codes, nullptr, nullptr, names
+    flatbuffers::ST_TABLE, 4, type_codes, nullptr, nullptr, nullptr, names
   };
   return &tt;
 }
@@ -5458,7 +5383,7 @@ inline const flatbuffers::TypeTable *RandomUniformTypeTable() {
     { flatbuffers::ET_INT, 0, 0 }
   };
   static const flatbuffers::TypeFunction type_refs[] = {
-    DataTypeTypeTable
+    MNN::DataTypeTypeTable
   };
   static const char * const names[] = {
     "seed",
@@ -5467,7 +5392,7 @@ inline const flatbuffers::TypeTable *RandomUniformTypeTable() {
     "T"
   };
   static const flatbuffers::TypeTable tt = {
-    flatbuffers::ST_TABLE, 4, type_codes, type_refs, nullptr, names
+    flatbuffers::ST_TABLE, 4, type_codes, type_refs, nullptr, nullptr, names
   };
   return &tt;
 }
diff --git a/schema/current/Type_generated.h b/schema/current/Type_generated.h
index f444072f..b7bfd4d9 100644
--- a/schema/current/Type_generated.h
+++ b/schema/current/Type_generated.h
@@ -8,7 +8,7 @@
 
 namespace MNN {
 
-enum NetSource {
+enum NetSource : int8_t {
   NetSource_CAFFE = 0,
   NetSource_TENSORFLOW = 1,
   NetSource_TFLITE = 2,
@@ -28,7 +28,7 @@ inline const NetSource (&EnumValuesNetSource())[4] {
 }
 
 inline const char * const *EnumNamesNetSource() {
-  static const char * const names[] = {
+  static const char * const names[5] = {
     "CAFFE",
     "TENSORFLOW",
     "TFLITE",
@@ -39,12 +39,12 @@ inline const char * const *EnumNamesNetSource() {
 }
 
 inline const char *EnumNameNetSource(NetSource e) {
-  if (e < NetSource_CAFFE || e > NetSource_ONNX) return "";
-  const size_t index = static_cast<int>(e);
+  if (flatbuffers::IsOutRange(e, NetSource_CAFFE, NetSource_ONNX)) return "";
+  const size_t index = static_cast<size_t>(e);
   return EnumNamesNetSource()[index];
 }
 
-enum DataType {
+enum DataType : int32_t {
   DataType_DT_INVALID = 0,
   DataType_DT_FLOAT = 1,
   DataType_DT_DOUBLE = 2,
@@ -100,7 +100,7 @@ inline const DataType (&EnumValuesDataType())[22] {
 }
 
 inline const char * const *EnumNamesDataType() {
-  static const char * const names[] = {
+  static const char * const names[23] = {
     "DT_INVALID",
     "DT_FLOAT",
     "DT_DOUBLE",
@@ -129,8 +129,8 @@ inline const char * const *EnumNamesDataType() {
 }
 
 inline const char *EnumNameDataType(DataType e) {
-  if (e < DataType_DT_INVALID || e > DataType_DT_VARIANT) return "";
-  const size_t index = static_cast<int>(e);
+  if (flatbuffers::IsOutRange(e, DataType_DT_INVALID, DataType_DT_VARIANT)) return "";
+  const size_t index = static_cast<size_t>(e);
   return EnumNamesDataType()[index];
 }
 
@@ -142,7 +142,7 @@ inline const flatbuffers::TypeTable *NetSourceTypeTable() {
     { flatbuffers::ET_CHAR, 0, 0 }
   };
   static const flatbuffers::TypeFunction type_refs[] = {
-    NetSourceTypeTable
+    MNN::NetSourceTypeTable
   };
   static const char * const names[] = {
     "CAFFE",
@@ -151,7 +151,7 @@ inline const flatbuffers::TypeTable *NetSourceTypeTable() {
     "ONNX"
   };
   static const flatbuffers::TypeTable tt = {
-    flatbuffers::ST_ENUM, 4, type_codes, type_refs, nullptr, names
+    flatbuffers::ST_ENUM, 4, type_codes, type_refs, nullptr, nullptr, names
   };
   return &tt;
 }
@@ -182,7 +182,7 @@ inline const flatbuffers::TypeTable *DataTypeTypeTable() {
     { flatbuffers::ET_INT, 0, 0 }
   };
   static const flatbuffers::TypeFunction type_refs[] = {
-    DataTypeTypeTable
+    MNN::DataTypeTypeTable
   };
   static const char * const names[] = {
     "DT_INVALID",
@@ -209,7 +209,7 @@ inline const flatbuffers::TypeTable *DataTypeTypeTable() {
     "DT_VARIANT"
   };
   static const flatbuffers::TypeTable tt = {
-    flatbuffers::ST_ENUM, 22, type_codes, type_refs, nullptr, names
+    flatbuffers::ST_ENUM, 22, type_codes, type_refs, nullptr, nullptr, names
   };
   return &tt;
 }
diff --git a/schema/current/UserDefine_generated.h b/schema/current/UserDefine_generated.h
index 7935cf21..f41a4771 100644
--- a/schema/current/UserDefine_generated.h
+++ b/schema/current/UserDefine_generated.h
@@ -4,29 +4,28 @@
 #ifndef FLATBUFFERS_GENERATED_USERDEFINE_MNN_H_
 #define FLATBUFFERS_GENERATED_USERDEFINE_MNN_H_
 
+#include "flatbuffers/flatbuffers.h"
 
-#include "Tensor_generated.h"
 #include "Type_generated.h"
+#include "Tensor_generated.h"
 
 namespace MNN {
 
 struct TensorConvertInfo;
+struct TensorConvertInfoBuilder;
 struct TensorConvertInfoT;
 
 inline const flatbuffers::TypeTable *TensorConvertInfoTypeTable();
 
 struct TensorConvertInfoT : public flatbuffers::NativeTable {
   typedef TensorConvertInfo TableType;
-  MNN_DATA_FORMAT source;
-  MNN_DATA_FORMAT dest;
-  TensorConvertInfoT()
-      : source(MNN_DATA_FORMAT_NCHW),
-        dest(MNN_DATA_FORMAT_NCHW) {
-  }
+  MNN::MNN_DATA_FORMAT source = MNN::MNN_DATA_FORMAT_NCHW;
+  MNN::MNN_DATA_FORMAT dest = MNN::MNN_DATA_FORMAT_NCHW;
 };
 
 struct TensorConvertInfo FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
   typedef TensorConvertInfoT NativeTableType;
+  typedef TensorConvertInfoBuilder Builder;
   static const flatbuffers::TypeTable *MiniReflectTypeTable() {
     return TensorConvertInfoTypeTable();
   }
@@ -34,11 +33,11 @@ struct TensorConvertInfo FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
     VT_SOURCE = 4,
     VT_DEST = 6
   };
-  MNN_DATA_FORMAT source() const {
-    return static_cast<MNN_DATA_FORMAT>(GetField<int8_t>(VT_SOURCE, 0));
+  MNN::MNN_DATA_FORMAT source() const {
+    return static_cast<MNN::MNN_DATA_FORMAT>(GetField<int8_t>(VT_SOURCE, 0));
   }
-  MNN_DATA_FORMAT dest() const {
-    return static_cast<MNN_DATA_FORMAT>(GetField<int8_t>(VT_DEST, 0));
+  MNN::MNN_DATA_FORMAT dest() const {
+    return static_cast<MNN::MNN_DATA_FORMAT>(GetField<int8_t>(VT_DEST, 0));
   }
   bool Verify(flatbuffers::Verifier &verifier) const {
     return VerifyTableStart(verifier) &&
@@ -52,19 +51,19 @@ struct TensorConvertInfo FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
 };
 
 struct TensorConvertInfoBuilder {
+  typedef TensorConvertInfo Table;
   flatbuffers::FlatBufferBuilder &fbb_;
   flatbuffers::uoffset_t start_;
-  void add_source(MNN_DATA_FORMAT source) {
+  void add_source(MNN::MNN_DATA_FORMAT source) {
     fbb_.AddElement<int8_t>(TensorConvertInfo::VT_SOURCE, static_cast<int8_t>(source), 0);
   }
-  void add_dest(MNN_DATA_FORMAT dest) {
+  void add_dest(MNN::MNN_DATA_FORMAT dest) {
     fbb_.AddElement<int8_t>(TensorConvertInfo::VT_DEST, static_cast<int8_t>(dest), 0);
   }
   explicit TensorConvertInfoBuilder(flatbuffers::FlatBufferBuilder &_fbb)
         : fbb_(_fbb) {
     start_ = fbb_.StartTable();
   }
-  TensorConvertInfoBuilder &operator=(const TensorConvertInfoBuilder &);
   flatbuffers::Offset<TensorConvertInfo> Finish() {
     const auto end = fbb_.EndTable(start_);
     auto o = flatbuffers::Offset<TensorConvertInfo>(end);
@@ -74,8 +73,8 @@ struct TensorConvertInfoBuilder {
 
 inline flatbuffers::Offset<TensorConvertInfo> CreateTensorConvertInfo(
     flatbuffers::FlatBufferBuilder &_fbb,
-    MNN_DATA_FORMAT source = MNN_DATA_FORMAT_NCHW,
-    MNN_DATA_FORMAT dest = MNN_DATA_FORMAT_NCHW) {
+    MNN::MNN_DATA_FORMAT source = MNN::MNN_DATA_FORMAT_NCHW,
+    MNN::MNN_DATA_FORMAT dest = MNN::MNN_DATA_FORMAT_NCHW) {
   TensorConvertInfoBuilder builder_(_fbb);
   builder_.add_dest(dest);
   builder_.add_source(source);
@@ -85,16 +84,16 @@ inline flatbuffers::Offset<TensorConvertInfo> CreateTensorConvertInfo(
 flatbuffers::Offset<TensorConvertInfo> CreateTensorConvertInfo(flatbuffers::FlatBufferBuilder &_fbb, const TensorConvertInfoT *_o, const flatbuffers::rehasher_function_t *_rehasher = nullptr);
 
 inline TensorConvertInfoT *TensorConvertInfo::UnPack(const flatbuffers::resolver_function_t *_resolver) const {
-  auto _o = new TensorConvertInfoT();
-  UnPackTo(_o, _resolver);
-  return _o;
+  auto _o = std::unique_ptr<TensorConvertInfoT>(new TensorConvertInfoT());
+  UnPackTo(_o.get(), _resolver);
+  return _o.release();
 }
 
 inline void TensorConvertInfo::UnPackTo(TensorConvertInfoT *_o, const flatbuffers::resolver_function_t *_resolver) const {
   (void)_o;
   (void)_resolver;
-  { auto _e = source(); _o->source = _e; };
-  { auto _e = dest(); _o->dest = _e; };
+  { auto _e = source(); _o->source = _e; }
+  { auto _e = dest(); _o->dest = _e; }
 }
 
 inline flatbuffers::Offset<TensorConvertInfo> TensorConvertInfo::Pack(flatbuffers::FlatBufferBuilder &_fbb, const TensorConvertInfoT* _o, const flatbuffers::rehasher_function_t *_rehasher) {
@@ -119,14 +118,14 @@ inline const flatbuffers::TypeTable *TensorConvertInfoTypeTable() {
     { flatbuffers::ET_CHAR, 0, 0 }
   };
   static const flatbuffers::TypeFunction type_refs[] = {
-    MNN_DATA_FORMATTypeTable
+    MNN::MNN_DATA_FORMATTypeTable
   };
   static const char * const names[] = {
     "source",
     "dest"
   };
   static const flatbuffers::TypeTable tt = {
-    flatbuffers::ST_TABLE, 2, type_codes, type_refs, nullptr, names
+    flatbuffers::ST_TABLE, 2, type_codes, type_refs, nullptr, nullptr, names
   };
   return &tt;
 }
